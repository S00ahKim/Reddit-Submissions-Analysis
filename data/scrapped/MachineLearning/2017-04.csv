,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,9,62pf9t,arxiv.org,Latent Sequence Decompositions -- can't this be applied for Machine Translation?,https://www.reddit.com/r/MachineLearning/comments/62pf9t/latent_sequence_decompositions_cant_this_be/,deepnewbie,1491006874,,0,1,False,default,,,,,
1,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,9,62pjjl,healthitanalytics.com,Top 4 Machine Learning Use Cases for Healthcare Providers,https://www.reddit.com/r/MachineLearning/comments/62pjjl/top_4_machine_learning_use_cases_for_healthcare/,Pabla_bla,1491008212,,0,1,False,default,,,,,
2,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,10,62ppou,udacity.com,Understanding Humans for ROBOTS (credit by Niko Cunningham at Udacity),https://www.reddit.com/r/MachineLearning/comments/62ppou/understanding_humans_for_robots_credit_by_niko/,gzupax,1491010188,,0,1,False,default,,,,,
3,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,11,62pwli,self.MachineLearning,[D] Have we mis-understood Res-Net?,https://www.reddit.com/r/MachineLearning/comments/62pwli/d_have_we_misunderstood_resnet/,Ayakalam,1491012300,"
So, I have read the Res-Net paper. I know and understand how this technology works, but I am a little underwhelmed by their claims. 

I know that the deeper we go, the more powerful we can make our representations, and certainly, their claim to be able to create much deeper nets that work and get better results are obvious. 

However, here is my nitpick: We are told that the deeper we go, the more powerful our representations can become, because of the abstractions taking place. Now while I can agree to this part, I do not see how we are doing this with ResNets, since the way I see it, we are effectively giving the network ""outs"" with all the various identity transformation paths. 

In other words, since the net is free to use the ""outs"" of the identity paths, this means that it is by definition not learning higher level abstractions, (or maybe, less so). And therefore if that is the case, then it does not seem to me that those networks are better because they are *deeper*. They are better for some other reason, but depth - ie - learning higher levels of abstractions - seems to be the least plausible reasons due to the outs provided by identity skip connections. 

Thoughts?",15,11,False,self,,,,,
4,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,11,62pxnv,youtu.be,How to Make a Chatbot - Intro to Deep Learning,https://www.reddit.com/r/MachineLearning/comments/62pxnv/how_to_make_a_chatbot_intro_to_deep_learning/,funtwo2,1491012627,,0,1,False,default,,,,,
5,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,11,62pyde,arxiv.org,A Neural Networks Approach to Predicting How Things Might Have Turned Out Had I Mustered the Nerve to Ask Barry Cottonfield to the Junior Prom Back in 1997,https://www.reddit.com/r/MachineLearning/comments/62pyde/a_neural_networks_approach_to_predicting_how/,Fa1l3r,1491012872,,0,1,False,default,,,,,
6,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,12,62qaqr,self.MachineLearning,Is there an implementation of the shattered gradients paper anywhere?,https://www.reddit.com/r/MachineLearning/comments/62qaqr/is_there_an_implementation_of_the_shattered/,darkconfidantislife,1491017154,[removed],0,1,False,default,,,,,
7,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,12,62qe0v,self.MachineLearning,[D] What to do is your computer is too slow to train on large sets of data?,https://www.reddit.com/r/MachineLearning/comments/62qe0v/d_what_to_do_is_your_computer_is_too_slow_to/,Batmantosh,1491018261,"I don't have the fastest computer and it's taking forever to train a particular network. 

Is there a solution to this type of issue? Perhaps an online server or something that can run the code?",14,0,False,self,,,,,
8,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,14,62qrmd,self.MachineLearning,[Q] is there an implementation of the shattered gradients paper?,https://www.reddit.com/r/MachineLearning/comments/62qrmd/q_is_there_an_implementation_of_the_shattered/,darkconfidantislife,1491023049,[removed],0,1,False,default,,,,,
9,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,15,62r0nj,self.MachineLearning,[D] Is there an implementation of the shattered gradients paper anywhere?,https://www.reddit.com/r/MachineLearning/comments/62r0nj/d_is_there_an_implementation_of_the_shattered/,darkconfidantislife,1491026569,I'm talking about this one: https://arxiv.org/abs/1702.08591 ,12,13,False,self,,,,,
10,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,16,62rd9a,openphilanthropy.org,[R] OpenAI awarded $30 million from the Open Philanthropy Project,https://www.reddit.com/r/MachineLearning/comments/62rd9a/r_openai_awarded_30_million_from_the_open/,downtownslim,1491032245,,51,114,False,default,,,,,
11,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,17,62rgig,nuit-blanche.blogspot.com,"[R] Saturday Morning Videos: Representation Learning Workshop at Simons Institute, Berkeley (March 27th-31st, 2017)",https://www.reddit.com/r/MachineLearning/comments/62rgig/r_saturday_morning_videos_representation_learning/,compsens,1491033808,,7,7,False,https://b.thumbs.redditmedia.com/Pc5_FuTgTqPtxl8kCKTUjzF5hXrcvQ5fS_SOZvdlZ2k.jpg,,,,,
12,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,17,62rjdf,self.MachineLearning,"Looking for deep learning PC parts advice (on a budget, &lt;$1200)?",https://www.reddit.com/r/MachineLearning/comments/62rjdf/looking_for_deep_learning_pc_parts_advice_on_a/,[deleted],1491035242,[removed],0,1,False,default,,,,,
13,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,18,62ro8x,eplex.cs.ucf.edu,"[R] ""Simple Evolutionary Optimization Can Rival Stochastic Gradient Descent in Neural Networks"" - GECCO 2016",https://www.reddit.com/r/MachineLearning/comments/62ro8x/r_simple_evolutionary_optimization_can_rival/,Delthc,1491037715,,18,18,False,default,,,,,
14,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,18,62rtoa,youtube.com,"I made some Tutorials for Deep Learning which includes CNN, Word2vec, LSTM and finally a Chatbot implementations in keras. It might be helpful.",https://www.reddit.com/r/MachineLearning/comments/62rtoa/i_made_some_tutorials_for_deep_learning_which/,[deleted],1491040460,[deleted],0,1,False,default,,,,,
15,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,18,62ru2h,self.MachineLearning,some problems while i was training mnist modoles,https://www.reddit.com/r/MachineLearning/comments/62ru2h/some_problems_while_i_was_training_mnist_modoles/,herhurl3200,1491040658,[removed],0,1,False,default,,,,,
16,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,19,62rvti,youtube.com,"I created some tutorials on CNN, LSTM, Word2vec and Chatbot Implementations. It might be useful.",https://www.reddit.com/r/MachineLearning/comments/62rvti/i_created_some_tutorials_on_cnn_lstm_word2vec_and/,[deleted],1491041466,[deleted],0,1,False,default,,,,,
17,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,19,62rxjl,self.MachineLearning,What are state of the art models and results for text modeling?,https://www.reddit.com/r/MachineLearning/comments/62rxjl/what_are_state_of_the_art_models_and_results_for/,shgidigo,1491042317,[removed],1,1,False,default,,,,,
18,MachineLearning,t5_2r3gv,2017-4-1,2017,4,1,21,62sbp2,youtube.com,[D] SIGBOVIK 2017 vid,https://www.reddit.com/r/MachineLearning/comments/62sbp2/d_sigbovik_2017_vid/,visarga,1491048384,,0,1,False,https://b.thumbs.redditmedia.com/cB9JR5ISXEykVRFl5IHB73wDHwuHkkwcT89mzoFk43c.jpg,,,,,
19,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,2,62u7an,nexus.leagueoflegends.com,"League of Legends implementing machine learning in new ""Advanced Bot""",https://www.reddit.com/r/MachineLearning/comments/62u7an/league_of_legends_implementing_machine_learning/,[deleted],1491068380,[deleted],0,1,False,default,,,,,
20,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,3,62ucf8,tech.grammarly.com,https://tech.grammarly.com/blog/paving-paving the way for human-level sentence corrections,https://www.reddit.com/r/MachineLearning/comments/62ucf8/httpstechgrammarlycomblogpavingpaving_the_way_for/,[deleted],1491069710,[deleted],0,1,False,default,,,,,
21,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,3,62uf6f,tech.grammarly.com,Paving the way for human-level sentence corrections,https://www.reddit.com/r/MachineLearning/comments/62uf6f/paving_the_way_for_humanlevel_sentence_corrections/,sunshinewyin,1491070421,,0,1,False,default,,,,,
22,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,3,62ufb0,self.MachineLearning,"DeepMind Solves AGI, Summons Demon",https://www.reddit.com/r/MachineLearning/comments/62ufb0/deepmind_solves_agi_summons_demon/,[deleted],1491070451,[removed],0,1,False,default,,,,,
23,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,3,62ufdx,junyanz.github.io,[R] Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/62ufdx/r_unpaired_imagetoimage_translation_using/,pmigdal,1491070470,,3,43,False,https://b.thumbs.redditmedia.com/BlCG0rlLoUy0kXX4kwmiLTxTaDBT_4mG_D1GIg4t77o.jpg,,,,,
24,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,3,62ujvn,approximatelycorrect.com,"[N] DeepMind Solves AGI, Summons Demon",https://www.reddit.com/r/MachineLearning/comments/62ujvn/n_deepmind_solves_agi_summons_demon/,clbam8,1491071680,,61,270,False,https://b.thumbs.redditmedia.com/Q-7IxhUnW-LYKHLFDHZJhNfgeXGRsLKiUTW_Almzk-U.jpg,,,,,
25,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,3,62uk80,blog.openai.com,[R] Spam detection in the physical world,https://www.reddit.com/r/MachineLearning/comments/62uk80/r_spam_detection_in_the_physical_world/,clbam8,1491071773,,2,23,False,https://b.thumbs.redditmedia.com/Ddb0D-_FVQFzrNOAGjWM_wGY2KuPZXOQ68b3yfqSlAg.jpg,,,,,
26,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,4,62upxn,youtube.com,I created some Machine Learning/ Deep Learning tutorials with some projects too. It might help.,https://www.reddit.com/r/MachineLearning/comments/62upxn/i_created_some_machine_learning_deep_learning/,[deleted],1491073296,[deleted],0,1,False,default,,,,,
27,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,7,62w0un,self.MachineLearning,"Recommended parameters for Random Forest classification - 3,000 features 135,000 samples (scikit-learn)",https://www.reddit.com/r/MachineLearning/comments/62w0un/recommended_parameters_for_random_forest/,lacroix_or_water,1491085805,[removed],0,1,False,default,,,,,
28,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,7,62w0yp,self.MachineLearning,My fully-connected layers are barely learning,https://www.reddit.com/r/MachineLearning/comments/62w0yp/my_fullyconnected_layers_are_barely_learning/,Juffin,1491085835,[removed],0,1,False,default,,,,,
29,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,8,62w90v,stat.cmu.edu,Convex Optimization Course,https://www.reddit.com/r/MachineLearning/comments/62w90v/convex_optimization_course/,[deleted],1491088269,[deleted],0,1,False,default,,,,,
30,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,9,62wosp,arxiv.org,[R] Improved Lossy Image Compression with Priming and Spatially Adaptive Bit Rates for Recurrent Networks,https://www.reddit.com/r/MachineLearning/comments/62wosp/r_improved_lossy_image_compression_with_priming/,downtownslim,1491093184,,2,5,False,default,,,,,
31,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,9,62wqgi,youtube.com,[P] Finally Got Around To Increasing Music-RNN's Dataset From 4 Mins To 21 Mins,https://www.reddit.com/r/MachineLearning/comments/62wqgi/p_finally_got_around_to_increasing_musicrnns/,JosephLChu,1491093690,,3,0,False,https://b.thumbs.redditmedia.com/mnG1RLF9-CUFvxLOlUfrQHaoA1xzc3nIZnYayor28qQ.jpg,,,,,
32,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,9,62wqqg,philpapers.org,[R] On the Impossibility of Supersized Machines,https://www.reddit.com/r/MachineLearning/comments/62wqqg/r_on_the_impossibility_of_supersized_machines/,crmflynn,1491093782,,2,8,False,https://b.thumbs.redditmedia.com/yccusLgSJJlBz0QVc2EVRYy9a1t3mg2wtOMZliKIbXQ.jpg,,,,,
33,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,11,62x9fc,nexus.leagueoflegends.com,[N] Riot Games Abuses Machine Learning Terminology In April Fool's Day Joke,https://www.reddit.com/r/MachineLearning/comments/62x9fc/n_riot_games_abuses_machine_learning_terminology/,JosephLChu,1491100049,,4,8,False,https://b.thumbs.redditmedia.com/doQbDT9w-F03VU7eMnOCUuNgCR37whvKDtLG1_gddYA.jpg,,,,,
34,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,11,62xe5l,self.MachineLearning,Text classification. TF.IDF with Naive Bayes?,https://www.reddit.com/r/MachineLearning/comments/62xe5l/text_classification_tfidf_with_naive_bayes/,deepdowninsideme,1491101767,[removed],0,1,False,default,,,,,
35,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,13,62xvep,youtu.be,AI is the new electricity,https://www.reddit.com/r/MachineLearning/comments/62xvep/ai_is_the_new_electricity/,mshrewd,1491108345,,0,1,False,default,,,,,
36,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,16,62yh8l,youtube.com,Google Cheese Master,https://www.reddit.com/r/MachineLearning/comments/62yh8l/google_cheese_master/,d3pd,1491118802,,0,1,False,default,,,,,
37,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,18,62yuer,self.MachineLearning,[D] Using neural art transfer to make video games look real,https://www.reddit.com/r/MachineLearning/comments/62yuer/d_using_neural_art_transfer_to_make_video_games/,Jean-Porte,1491126225,"Has there been any attempt to use neural art transfer using the style of real video footages and changing computer generated image to match them ?

I mean, instead of using the style of van gogh, just using the style of real images
I'd like to see the results or know why it doesn't work but it's not my reserach area and I don't have my own gpu ressources to try it

Thans",18,18,False,self,,,,,
38,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,21,62zfc5,github.com,[P] Playing Flappy Bird using Evolution Strategies,https://www.reddit.com/r/MachineLearning/comments/62zfc5/p_playing_flappy_bird_using_evolution_strategies/,mahdidibaiee,1491136810,,12,31,False,https://b.thumbs.redditmedia.com/VWJWSmxAwJDnvDcJE-Bj7TTmG-tqsiIs2Y1IB_l2JsE.jpg,,,,,
39,MachineLearning,t5_2r3gv,2017-4-2,2017,4,2,23,62zzox,medium.com,[P] My nephew vs ML,https://www.reddit.com/r/MachineLearning/comments/62zzox/p_my_nephew_vs_ml/,ericman93,1491144342,,27,198,False,https://b.thumbs.redditmedia.com/MPAnpLPN6ZtZEV2XGMgFp45tnjkoIuqsbFvgavUO2kA.jpg,,,,,
40,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,2,630sz3,self.MachineLearning,Help understanding the reparameterization trick of auto-encoding variational bayes,https://www.reddit.com/r/MachineLearning/comments/630sz3/help_understanding_the_reparameterization_trick/,yobichi,1491152869,[removed],0,1,False,default,,,,,
41,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,3,631a0s,self.MachineLearning,Math Courses to take?,https://www.reddit.com/r/MachineLearning/comments/631a0s/math_courses_to_take/,natedogdrake,1491157551,[removed],0,1,False,default,,,,,
42,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,3,631ckw,research.net,What are some of the scenarios for your application where you use machine learning?,https://www.reddit.com/r/MachineLearning/comments/631ckw/what_are_some_of_the_scenarios_for_your/,asthana86,1491158217,,0,1,False,default,,,,,
43,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,3,631epy,quora.com,What are the scenarios for you using machine learning?,https://www.reddit.com/r/MachineLearning/comments/631epy/what_are_the_scenarios_for_you_using_machine/,asthana86,1491158816,,0,1,False,default,,,,,
44,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,4,631pz6,self.MachineLearning,Question on algorithmic trading,https://www.reddit.com/r/MachineLearning/comments/631pz6/question_on_algorithmic_trading/,johnnyboyfart,1491161837,[removed],0,1,False,default,,,,,
45,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,4,631t2l,youtube.com,The deep count-ception network learning to count cells! [video] [OC],https://www.reddit.com/r/MachineLearning/comments/631t2l/the_deep_countception_network_learning_to_count/,ieee8023,1491162714,,0,2,False,default,,,,,
46,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,5,631xia,youtu.be,"Dispelling the hype. Let's listen to the experts, not self serving fear-mongers",https://www.reddit.com/r/MachineLearning/comments/631xia/dispelling_the_hype_lets_listen_to_the_experts/,mshrewd,1491163893,,0,1,False,default,,,,,
47,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,5,6323w5,self.MachineLearning,Experiences using Sentiment Analysis services,https://www.reddit.com/r/MachineLearning/comments/6323w5/experiences_using_sentiment_analysis_services/,alonsebastian,1491165692,[removed],0,1,False,default,,,,,
48,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,5,6325xp,self.MachineLearning,I am testing an OS X app to organize PDFs that I tend to download from arXiv into categories and rename the files into something that is easier when looking at a folder.,https://www.reddit.com/r/MachineLearning/comments/6325xp/i_am_testing_an_os_x_app_to_organize_pdfs_that_i/,[deleted],1491166306,[removed],0,1,False,default,,,,,
49,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,6,63286h,self.MachineLearning,[P] I am testing an OS X app to organize PDFs that I tend to download from arXiv into categories and rename the files into something that is easier when looking at a folder.,https://www.reddit.com/r/MachineLearning/comments/63286h/p_i_am_testing_an_os_x_app_to_organize_pdfs_that/,just_some_new_stuff,1491166936,"Does anyone want to help test this? (**Post here or PM me and I will provide the download code**). I think it should work fully since it works on my machine but I want to see how it works on other people's end.

It basically takes a directory of PDFs of your choice and assigns categories and renames it if you want (useful for arXiv PDFs) then outputs it. Also any useful features would be useful since this was mostly for my personal use case and I prefer folders to Mendeley?

I am still working on playing with the NLP and clustering to change the results. Not a serious project so I just named it GroupMeDF. If this isn't an appropriate place feel free to chuck the post

https://itunes.apple.com/us/app/groupmedf-intelligently-organize-pdfs/id1214161731?ls=1&amp;mt=12",2,3,False,self,,,,,
50,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,6,632g89,self.MachineLearning,Extending mapFeature from Andrew Ng's ML Class to N features in the dth degree,https://www.reddit.com/r/MachineLearning/comments/632g89/extending_mapfeature_from_andrew_ngs_ml_class_to/,distortion_25,1491169248,[removed],0,1,False,default,,,,,
51,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,6,632hvz,self.MachineLearning,How does regular backpropagation work on LSTM networks (as opposed to BTT)??,https://www.reddit.com/r/MachineLearning/comments/632hvz/how_does_regular_backpropagation_work_on_lstm/,butWhoWasBee,1491169697,[removed],0,1,False,default,,,,,
52,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,7,632wlc,self.MachineLearning,Optimizing a 9x9x9 neural network in Gridworld,https://www.reddit.com/r/MachineLearning/comments/632wlc/optimizing_a_9x9x9_neural_network_in_gridworld/,[deleted],1491173994,[removed],0,1,False,default,,,,,
53,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,8,632wty,self.MachineLearning,[P] How to choose a topic for a masters dissertation in ML?,https://www.reddit.com/r/MachineLearning/comments/632wty/p_how_to_choose_a_topic_for_a_masters/,roehst,1491174068,"Hi, I have a B.A. in economics and after 5 years working in consulting and finance I decided to pursue a graduate degree in CS, with focus on ML.

I am doing really well on the classes I take, but my knowledge on CS/ML is bits and pieces; deep in some places, but otherwise very unsystematic. I picked it up trying programming languages and reading Hacker News. So I am not familiar with doing ML research, or CS research for that matter.

I have many ideas on what to research; but I don't know how to judge if they are fit for a masters dissertation, because I don't know what is exactly expected of this research format and I don't know how to tell if a topic is important or even original.

How could I go about choosing a topic? I am not asking on what to research, but how to choose it.

Thanks!",21,1,False,self,,,,,
54,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,9,633jal,arxiv.org,[R][1703.10717] BEGAN: Boundary Equilibrium Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/633jal/r170310717_began_boundary_equilibrium_generative/,ajmooch,1491181023,,30,72,False,default,,,,,
55,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,11,6340ks,stats.stackexchange.com,How can data points be enough to learn a function?,https://www.reddit.com/r/MachineLearning/comments/6340ks/how_can_data_points_be_enough_to_learn_a_function/,FourthHead,1491186510,,0,1,False,default,,,,,
56,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,13,634q2c,youtu.be,Backpropagation in 5 Minutes,https://www.reddit.com/r/MachineLearning/comments/634q2c/backpropagation_in_5_minutes/,ackstazya,1491195570,,0,1,False,default,,,,,
57,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,14,634tjo,oreilly.com,"A better understanding of the reasons why neurons spike could lead to smart AI systems that can store more information more efficiently, according to Geoff Hinton, who is often referred to as the godfather of deep learning.",https://www.reddit.com/r/MachineLearning/comments/634tjo/a_better_understanding_of_the_reasons_why_neurons/,Jason_Fun,1491196923,,0,1,False,default,,,,,
58,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,16,635946,i.redd.it,"We need Some Deep Learning Memes, We need to have fun sometimes...",https://www.reddit.com/r/MachineLearning/comments/635946/we_need_some_deep_learning_memes_we_need_to_have/,TheNASAguy,1491203832,,0,1,False,default,,,,,
59,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,16,635bct,goo.gl,"Stand a chance to win a full pass to AI-ASIA 2017 worth SGD1,200 by completing the final survey (only 5 tickets).",https://www.reddit.com/r/MachineLearning/comments/635bct/stand_a_chance_to_win_a_full_pass_to_aiasia_2017/,corpasia,1491204897,,0,1,False,default,,,,,
60,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,16,635bp8,arxiv.org,[R] Multiagent Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat Games,https://www.reddit.com/r/MachineLearning/comments/635bp8/r_multiagent_bidirectionallycoordinated_nets_for/,whenmaster,1491205066,,4,17,False,default,,,,,
61,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,16,635cp2,self.MachineLearning,"If we primarily use LSTMs over RNNs to solve the vanishing gradient problem, why can't we just use ReLUs/leaky ReLUs with RNNs instead?",https://www.reddit.com/r/MachineLearning/comments/635cp2/if_we_primarily_use_lstms_over_rnns_to_solve_the/,[deleted],1491205578,[removed],1,1,False,default,,,,,
62,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,17,635el4,self.MachineLearning,Hierarchical Labels,https://www.reddit.com/r/MachineLearning/comments/635el4/hierarchical_labels/,spidey-fan,1491206537,[removed],0,1,False,default,,,,,
63,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,17,635ely,blog.paralleldots.com,List of Free Must-Read Books for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/635ely/list_of_free_mustread_books_for_machine_learning/,gargisharmapd,1491206547,,0,1,False,default,,,,,
64,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,18,635rmk,bitbucket.org,TensorFlow/Keras demo for group sparse regularization,https://www.reddit.com/r/MachineLearning/comments/635rmk/tensorflowkeras_demo_for_group_sparse/,[deleted],1491213075,[deleted],0,2,False,default,,,,,
65,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,20,63683w,self.MachineLearning,What are the SOTA ways to generate high resolution images?,https://www.reddit.com/r/MachineLearning/comments/63683w/what_are_the_sota_ways_to_generate_high/,[deleted],1491219837,[removed],0,1,False,default,,,,,
66,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,22,636pji,self.MachineLearning,[D] What are the SOTA ways to generate high resolution images?,https://www.reddit.com/r/MachineLearning/comments/636pji/d_what_are_the_sota_ways_to_generate_high/,perceptron01,1491225578,"I know there've been a number of advancements in the deep generative models literature recently, and I was wondering what are the current (preferably unsupervised) SOTA ways of generating high resolution images?

I know StackGAN generates 256x256, but I was wondering if there are other notable advancements on this front.
",3,3,False,self,,,,,
67,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,22,636sjj,codebuffet.co,Let AI come up with your next domain name! (x-post from /r/programming),https://www.reddit.com/r/MachineLearning/comments/636sjj/let_ai_come_up_with_your_next_domain_name_xpost/,peterwilli,1491226515,,0,1,False,default,,,,,
68,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,22,636uf8,blog.sourced.tech,[P] Using Docker &amp; CoreOS For GPU Based Deep Learning,https://www.reddit.com/r/MachineLearning/comments/636uf8/p_using_docker_coreos_for_gpu_based_deep_learning/,3150,1491227088,,7,75,False,https://a.thumbs.redditmedia.com/aq8JWqb7_Fu4rFAxkK5lx44Q2jE7qp-tyuc9XTZKfG8.jpg,,,,,
69,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,22,636vd6,youtube.com,C 86 BS,https://www.reddit.com/r/MachineLearning/comments/636vd6/c_86_bs/,allwinpackaging,1491227366,,0,1,False,default,,,,,
70,MachineLearning,t5_2r3gv,2017-4-3,2017,4,3,23,6378uz,github.com,[P] Datasets for start with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6378uz/p_datasets_for_start_with_machine_learning/,pplonski,1491231088,,0,1,False,default,,,,,
71,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,0,637fi8,people.idsia.ch,[D] Compressed Network Search Finds Complex Neural Controllers with a Million Weights,https://www.reddit.com/r/MachineLearning/comments/637fi8/d_compressed_network_search_finds_complex_neural/,flukeskywalker,1491232774,,0,5,False,https://b.thumbs.redditmedia.com/JKEgttdFS3QBc5Hk-jaHsNS1dZr_Ubx33beRVsi3O4k.jpg,,,,,
72,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,0,637ji7,datasets.maluuba.com,"[N] Maluuba, a Microsoft Company, releases the Frames dialogue dataset for language understanding research",https://www.reddit.com/r/MachineLearning/comments/637ji7/n_maluuba_a_microsoft_company_releases_the_frames/,juharris,1491233841,,0,19,False,https://a.thumbs.redditmedia.com/tDpk8EE0Pifs4HRM8lAXn2d7UNACi9mmCaV6eWwNLz0.jpg,,,,,
73,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,0,637noi,self.MachineLearning,Importance of image shape/resolution in object detection ?,https://www.reddit.com/r/MachineLearning/comments/637noi/importance_of_image_shaperesolution_in_object/,swentso,1491234954,[removed],0,1,False,default,,,,,
74,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,1,637u1l,arxiv.org,[R] Generalization and Equilibrium in Generative Adversarial Nets (GANs),https://www.reddit.com/r/MachineLearning/comments/637u1l/r_generalization_and_equilibrium_in_generative/,anonymousTestPoster,1491236649,,2,5,False,default,,,,,
75,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,1,6380ox,web.stanford.edu,CS224n: Natural Language Processing with Deep Learning Course Project Reports for 2017! ( Also some amazing works published on the fake news challenge ),https://www.reddit.com/r/MachineLearning/comments/6380ox/cs224n_natural_language_processing_with_deep/,[deleted],1491238325,[deleted],0,1,False,default,,,,,
76,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,2,638994,bitbucket.org,[R] Group sparse regularization for neural networks (TensorFlow/Keras demo),https://www.reddit.com/r/MachineLearning/comments/638994/r_group_sparse_regularization_for_neural_networks/,scardax88,1491240460,,0,9,False,default,,,,,
77,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,3,638j18,offconvex.org,Generalization and Equilibrium in Generative Adversarial Networks (GANs),https://www.reddit.com/r/MachineLearning/comments/638j18/generalization_and_equilibrium_in_generative/,[deleted],1491242834,[deleted],0,1,False,default,,,,,
78,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,3,638q7z,self.MachineLearning,What does connections mean in deep architectures?,https://www.reddit.com/r/MachineLearning/comments/638q7z/what_does_connections_mean_in_deep_architectures/,nivm321,1491244756,[removed],0,1,False,default,,,,,
79,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,3,638smn,github.com,[P] Turn Inception net into a multi-label classifier,https://www.reddit.com/r/MachineLearning/comments/638smn/p_turn_inception_net_into_a_multilabel_classifier/,rbartyzal,1491245391,,4,12,False,https://b.thumbs.redditmedia.com/CWqSEoptFx9ZhD76CDtCIrJZ20LyOd9hNV8r0nMmrfI.jpg,,,,,
80,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,3,638ues,self.MachineLearning,Call for Candidates to NASA FDL,https://www.reddit.com/r/MachineLearning/comments/638ues/call_for_candidates_to_nasa_fdl/,alisonblowndes,1491245838,[removed],0,1,False,default,,,,,
81,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,4,6396iw,self.MachineLearning,Subword tokenization of contractions in the English language,https://www.reddit.com/r/MachineLearning/comments/6396iw/subword_tokenization_of_contractions_in_the/,SuperCComplex,1491249339,[removed],0,1,False,default,,,,,
82,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,5,639fv2,self.MachineLearning,Will graduating early from college and missing courses relating to AI hurt my changes of getting into a PhD program?,https://www.reddit.com/r/MachineLearning/comments/639fv2/will_graduating_early_from_college_and_missing/,SpellCastrMemeMastr,1491252004,[removed],0,1,False,default,,,,,
83,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,5,639gje,self.MachineLearning,[D] Optimizing a 9x9x9 neural network in Gridworld,https://www.reddit.com/r/MachineLearning/comments/639gje/d_optimizing_a_9x9x9_neural_network_in_gridworld/,speakeasy518,1491252204,"Hello everyone, I have a question I'm hoping you guys might be able to help with.

So I've been experimenting with this artificial life simulator for a few weeks now called grid world. The goal of the simulation is to watch artificial selection develop agent based neural networks that compete for energy and reproductive dominance.

Initially, random neural networks are generated in a ""primordial soup"" from a list of around 50 different kinds of neurons, separated into 3 categories of input output and middle connections. Most die, in fact, in can take days for you to evolve a successful agent that can reproduce efficiently.

What follows from the genesis event is a boom and bust cycle that settles into equilibrium with the current environment and simulation parameters.

There's various hazards like lava, poison, and other agents that they slowly learn to avoid or co habituate with, and an astounding array of complex behaviors that can develop like multi cellular networks, communication via pheromone and pulses of light and viral injection of DNA. They can develop multiple ways to reproduce and evade danger. They have a variety of different ways to gather input from the environment in the form of eyes, light senors, movement sensors, antennae, DNA sensors, etc.

Middle inputs include threshold changers, regular neurons, randomizers, and neurons that allow signal transport to other neural networks around them.

Basically, its got a lot of cool stuff, and this is my first real dive into machine learning. I feel a little in the dark when I'm staring at the astounding amount of simulation parameters. I've watched a few intro videos on neural networks and read some different articles. I thoroughly overviews the manual. Yet still I have no idea how to even begin optimizing the networks.

Is their any steps I can take to increase the likely hood of developing a more complex network? Like for instances, someone in the forums talked about halving the maximum connection weight lead to his agents learning to evade lava(bright, painful, instant death) in a remarkably small time of 2 hours( could be hyperbole, but still the point remains)

Am I at the mercy of the simulation? Or can I take steps to create a more complex adaptive network?

Here's some screen shots

http://imgur.com/a/bnvND

http://imgur.com/a/E7t6T

http://imgur.com/a/3o5Uc

http://imgur.com/a/tceDt

http://imgur.com/a/oDpSu

http://imgur.com/a/v6Kgy

Thanks for your time in advance (:
",5,1,False,self,,,,,
84,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,5,639hyh,hackernoon.com,How to build a simple Spam-detecting machine learning classifier,https://www.reddit.com/r/MachineLearning/comments/639hyh/how_to_build_a_simple_spamdetecting_machine/,codedesi,1491252631,,0,1,False,default,,,,,
85,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,6,639l0k,self.MachineLearning,"what is ""embedding space"" in context of machine learning?",https://www.reddit.com/r/MachineLearning/comments/639l0k/what_is_embedding_space_in_context_of_machine/,John_Smith111,1491253484,[removed],0,1,False,default,,,,,
86,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,6,639ni3,self.MachineLearning,Best Linkedin group for AI and Machine-Learning?,https://www.reddit.com/r/MachineLearning/comments/639ni3/best_linkedin_group_for_ai_and_machinelearning/,Waso777,1491254210,[removed],0,1,False,default,,,,,
87,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,6,639v9d,self.MachineLearning,"Title: Deceiving Google's Cloud Video Intelligence API Built for Summarizing Videos Authors: Hossein Hosseini, Baicen Xiao, Radha Poovendran",https://www.reddit.com/r/MachineLearning/comments/639v9d/title_deceiving_googles_cloud_video_intelligence/,[deleted],1491255697,[removed],0,1,False,default,,,,,
88,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,6,639y1m,arxiv.org,Deceiving Google's Cloud Video Intelligence API Built for Summarizing,https://www.reddit.com/r/MachineLearning/comments/639y1m/deceiving_googles_cloud_video_intelligence_api/,[deleted],1491256339,[deleted],0,1,False,default,,,,,
89,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,6,639y2j,color.kvfrans.com,[P] Automatic colorization of anime/manga-style line art through tandem convnets,https://www.reddit.com/r/MachineLearning/comments/639y2j/p_automatic_colorization_of_animemangastyle_line/,kvfrans,1491256346,,20,172,False,https://b.thumbs.redditmedia.com/dQqbWkCpP7ZgVXlz7VgFMecRT-Tdgyc6jKUA4fXAgrQ.jpg,,,,,
90,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,7,63a0b5,arxiv.org,Deceiving Google's Cloud Video Intelligence API Built for Summarizing Videos,https://www.reddit.com/r/MachineLearning/comments/63a0b5/deceiving_googles_cloud_video_intelligence_api/,[deleted],1491256941,[deleted],0,1,False,default,,,,,
91,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,7,63a102,self.MachineLearning,Define Perceptron,https://www.reddit.com/r/MachineLearning/comments/63a102/define_perceptron/,unolk,1491257136,[removed],0,1,False,default,,,,,
92,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,8,63ak74,youtube.com,[P] Videos of Natural Language Processing with Deep Learning CS224N (Winter 2017) are now online,https://www.reddit.com/r/MachineLearning/comments/63ak74/p_videos_of_natural_language_processing_with_deep/,clbam8,1491262723,,12,172,False,https://a.thumbs.redditmedia.com/74vhhjbTt6FLi4YORZr4lt3_IBXuDS6WY_q1_HLPrQ4.jpg,,,,,
93,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,9,63ar1h,cioinsight.com,Can Characteristic-Based AI Fight Malware?,https://www.reddit.com/r/MachineLearning/comments/63ar1h/can_characteristicbased_ai_fight_malware/,Uaid_id,1491264831,,0,1,False,default,,,,,
94,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,9,63avhs,github.com,Video Activity Recognition with RNN and Temporal-ConvNet,https://www.reddit.com/r/MachineLearning/comments/63avhs/video_activity_recognition_with_rnn_and/,[deleted],1491266174,[deleted],0,1,False,default,,,,,
95,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,9,63axwc,github.com,[R] Video Activity Recognition with RNN and Temporal-ConvNet (starter code provided),https://www.reddit.com/r/MachineLearning/comments/63axwc/r_video_activity_recognition_with_rnn_and/,chihyaoma,1491266929,,0,0,False,https://b.thumbs.redditmedia.com/42kyaKt3e5ssdpJbhnplqKSXrbU_MR28aP7oT7X_tuI.jpg,,,,,
96,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,10,63b2pq,vigs.vn,sa iu ha ti H Ni,https://www.reddit.com/r/MachineLearning/comments/63b2pq/sa_iu_ha_ti_h_ni/,lynhan2911,1491268497,,0,1,False,default,,,,,
97,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,10,63b4uo,web.stanford.edu,[R] Beating Atari with Natural Language Guided Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/63b4uo/r_beating_atari_with_natural_language_guided/,evc123,1491269191,,10,39,False,default,,,,,
98,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,11,63bjp4,self.MachineLearning,[D] What tools for creating annotations?,https://www.reddit.com/r/MachineLearning/comments/63bjp4/d_what_tools_for_creating_annotations/,BrokenGumdrop,1491273985,"What tools do people currently use to annotate videos for ground truth?  I'd like to learn labels for a domain specific movements (dance) and I'll have to start with the labeling myself.  I've looked at ANVIL, but my host machine doesn't want to downgrade to Java 6 from 8, for obvious reasons.  I've looked at vatic, but it seems kinda clunking for this modern era and potentially painful for long videos.  Are people just using pre-labeled datasets these days?  ",2,8,False,self,,,,,
99,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,12,63bpwo,self.MachineLearning,Rating Memes from Neural Networks,https://www.reddit.com/r/MachineLearning/comments/63bpwo/rating_memes_from_neural_networks/,[deleted],1491276125,[removed],0,1,False,default,,,,,
100,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,13,63bz7w,arxiv.org,[1704.00028] Improved Training of Wasserstein GANs,https://www.reddit.com/r/MachineLearning/comments/63bz7w/170400028_improved_training_of_wasserstein_gans/,[deleted],1491279570,[deleted],0,1,False,default,,,,,
101,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,14,63cbl1,alchemy.cs.washington.edu,Sum Product Networks by Pedro Domingos and Hoifung Poon - does anyone else here find this interesting?,https://www.reddit.com/r/MachineLearning/comments/63cbl1/sum_product_networks_by_pedro_domingos_and/,adityakhanna,1491284561,,0,1,False,default,,,,,
102,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,16,63coga,self.MachineLearning,[D] Services to categories images?,https://www.reddit.com/r/MachineLearning/comments/63coga/d_services_to_categories_images/,CurryPuff99,1491290498,Let's say I have a really simple problem. Find out if a face has scar or tattoo. Assuming I have tons of faces with scars and faces with tattoos. Is there any platform that allow me to quickly pump these dataset in and then it has an api for me to submit a face picture and then tell me if it belongs to the scars or tattoo group? I dont mind paid services. Sorry newbie here. Appreciate any pointers to right direction.,7,1,False,self,,,,,
103,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,17,63cve8,arxiv.org,[1703.05051] Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG,https://www.reddit.com/r/MachineLearning/comments/63cve8/170305051_deep_learning_with_convolutional_neural/,[deleted],1491294179,[deleted],1,1,False,default,,,,,
104,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,19,63d8p2,self.MachineLearning,[D] Study Group on Piazza,https://www.reddit.com/r/MachineLearning/comments/63d8p2/d_study_group_on_piazza/,Kiuhnm,1491300863,"# What

I've finally decided to become more serious about Machine Learning and to be more systematic in my study.

For me, the best thing about University is that it gives you a broad overview of a discipline and forces you to study less exciting but extremely useful topics that you would disregard on your own.

For personal reasons, I can't go back to University and take a Phd in ML, but I don't want this to stop me from becoming an expert in Machine Learning.

This is a tentative list of what I'm about to study:

* Optimization [1](http://www.stat.cmu.edu/%7Eryantibs/convexopt/) [2](http://www.cs.cmu.edu/~suvrit/teach/index.html)
* Probabilistic Graphical Models [1](http://www.cs.cmu.edu/~epxing/Class/10708-17/lecture.html) [2](http://www.cs.columbia.edu/~blei/fogm/2016F/index.html) [3](http://www.cs.columbia.edu/~blei/seminar/2016_discrete_data/index.html)
* Deep Natural Language Processing [1](https://github.com/oxford-cs-deepnlp-2017/lectures)
* Deep Reinforcement Learning [1](http://rll.berkeley.edu/deeprlcourse/)
* Statistical Learning Theory [1](http://www.stat.cmu.edu/~ryantibs/statml/) [2](http://www.mit.edu/%7E9.520/fall15/index.html)

Note that most of these are Phd-level courses, so you'll need to have enough mathematical maturity to be able to understand and write simple proofs. I think that a good understanding of Linear Algebra, Multivariate Calculus and Probability should be enough.

I think I'll study 3 topics at a time. I've just started with Optimization (link [1](http://www.stat.cmu.edu/%7Eryantibs/convexopt/) + Boyd's [book](http://stanford.edu/~boyd/cvxbook/)) and maybe I'll also pick PGMs and Deep RL... I haven't decided yet.

# Where

I created a fake University in Piazza and an Optimization class (more classes will be added soon).

---

You can subscribe [here](http://piazza.com/kiuhnms_university/spring2017/ku701). **The code is the last part of the URL.**

---

I chose Piazza because it has direct support for LaTeX, but I'm completely new to this platform, so any suggestion is welcome!

While it's true that there are /r/MachineLearning/, /r/MLQuestions and /r/LearnMachineLearning, the first is more about news and the last two, let's admit it, are not very technical (in a mathematical sense). Also, it's easier to help each other when everyone is following the same course, doing the same exercises and reading the same books.

Please let me know what you think and feel free to give me suggestions.

# Important

You may join the classes (for now just Optimization) right now so that we can go through the material together, or you can study at your own pace or even postpone it for later if you don't have enough time right now.

Either way, I'll be asking (*) and answering questions about stuff related to the courses. I'll post notifications about my progress and I'll be available for discussion even after I've finished a course.

(*) Just to clarify, I'll ask questions when I don't understand something and I need an answer.

Posts in Reddit ""disappear"" very fast, so I'm going to remind the community of my initiative from time to time, if that's not a problem for you.",20,95,False,self,,,,,
105,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,20,63dfun,arxiv.org,[R][1704.00028] Improved Training of Wasserstein GANs,https://www.reddit.com/r/MachineLearning/comments/63dfun/r170400028_improved_training_of_wasserstein_gans/,ajmooch,1491304103,,46,64,False,default,,,,,
106,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,20,63dfy9,davidbarber.github.io,Evolutionary Optimization as a Variational Method,https://www.reddit.com/r/MachineLearning/comments/63dfy9/evolutionary_optimization_as_a_variational_method/,[deleted],1491304144,[deleted],0,1,False,default,,,,,
107,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,20,63dhfc,davidbarber.github.io,[R] Evolutionary Optimization as a Variational Method,https://www.reddit.com/r/MachineLearning/comments/63dhfc/r_evolutionary_optimization_as_a_variational/,alexbotev,1491304787,,8,26,False,default,,,,,
108,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,20,63dlka,getpocket.com,How Can Internet of Things Improve Your Day to Day Productivity Levels,https://www.reddit.com/r/MachineLearning/comments/63dlka/how_can_internet_of_things_improve_your_day_to/,manojrawat1222,1491306371,,0,1,False,default,,,,,
109,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,21,63dqps,self.MachineLearning,"Job search engine, Keywords extraction, city extraction",https://www.reddit.com/r/MachineLearning/comments/63dqps/job_search_engine_keywords_extraction_city/,fofiedelly,1491308239,[removed],0,1,False,default,,,,,
110,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,22,63e7sp,self.MachineLearning,VGG Image Annotator (VIA) 1.0.0,https://www.reddit.com/r/MachineLearning/comments/63e7sp/vgg_image_annotator_via_100/,[deleted],1491313869,[removed],0,1,False,default,,,,,
111,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,23,63ehio,self.MachineLearning,VGG Image Annotator (VIA) 1.0.0,https://www.reddit.com/r/MachineLearning/comments/63ehio/vgg_image_annotator_via_100/,thelinuxmaniac,1491316733,[removed],0,1,False,default,,,,,
112,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,23,63ehpv,wired.co.uk,Darktrace's machine learning is automatically stopping hacks,https://www.reddit.com/r/MachineLearning/comments/63ehpv/darktraces_machine_learning_is_automatically/,chlordane2501,1491316794,,0,1,False,default,,,,,
113,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,23,63ejon,robots.ox.ac.uk,VGG Image Annotator (VIA) 1.0.0,https://www.reddit.com/r/MachineLearning/comments/63ejon/vgg_image_annotator_via_100/,thelinuxmaniac,1491317347,,0,1,False,default,,,,,
114,MachineLearning,t5_2r3gv,2017-4-4,2017,4,4,23,63ekgh,pnas.org,"[R] Convolutional networks for fast, energy-efficient neuromorphic computing ""1,200 and 2,600 frames/s""",https://www.reddit.com/r/MachineLearning/comments/63ekgh/r_convolutional_networks_for_fast_energyefficient/,downtownslim,1491317571,,4,6,False,https://b.thumbs.redditmedia.com/DU9eQW-UScwtGH2h3bqq64h0D0-Oe3lZmMYyeBKAhFY.jpg,,,,,
115,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,0,63eqvu,self.MachineLearning,HMM sequence decoding,https://www.reddit.com/r/MachineLearning/comments/63eqvu/hmm_sequence_decoding/,Citopan,1491319243,[removed],0,1,False,default,,,,,
116,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,1,63f3uk,distill.pub,[R] Why Momentum Really Works,https://www.reddit.com/r/MachineLearning/comments/63f3uk/r_why_momentum_really_works/,gabrielgoh,1491322612,,44,436,False,https://b.thumbs.redditmedia.com/5Bep37KEQxKGT5y0cBQKyM8y1eH3XlFm4xNbgAHdl-g.jpg,,,,,
117,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,2,63fppt,jonolick.com,"DagNN - a ""deeper"" fully connected network",https://www.reddit.com/r/MachineLearning/comments/63fppt/dagnn_a_deeper_fully_connected_network/,[deleted],1491327993,[deleted],0,1,False,default,,,,,
118,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,3,63fwt7,arxiv.org,Deceiving Google's Cloud Video Intelligence API Built for Summarizing Videos,https://www.reddit.com/r/MachineLearning/comments/63fwt7/deceiving_googles_cloud_video_intelligence_api/,hosseinh,1491329697,,0,1,False,default,,,,,
119,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,3,63fymf,arxiv.org,[R] RobustFill: Neural Program Learning under Noisy I/O,https://www.reddit.com/r/MachineLearning/comments/63fymf/r_robustfill_neural_program_learning_under_noisy/,[deleted],1491330162,[deleted],1,1,False,default,,,,,
120,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,4,63genh,cs.cmu.edu,"[R] Deepdoggo: Learning the answer to ""Who'd a good dog?""",https://www.reddit.com/r/MachineLearning/comments/63genh/r_deepdoggo_learning_the_answer_to_whod_a_good_dog/,TangerineX,1491334181,,17,53,False,default,,,,,
121,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,4,63gkla,cs.cmu.edu,"Deep Doggo: Learning the Answer to ""Who's a Good Dog?""",https://www.reddit.com/r/MachineLearning/comments/63gkla/deep_doggo_learning_the_answer_to_whos_a_good_dog/,[deleted],1491335734,[deleted],0,1,False,default,,,,,
122,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,5,63gnvu,tryolabs.com,List of Machine Learning Conferences,https://www.reddit.com/r/MachineLearning/comments/63gnvu/list_of_machine_learning_conferences/,lasarten,1491336526,,0,1,False,default,,,,,
123,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,5,63gwx7,i.redd.it,me irl,https://www.reddit.com/r/MachineLearning/comments/63gwx7/me_irl/,FluxSeeds,1491338853,,0,1,False,default,,,,,
124,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,6,63h9se,self.MachineLearning,[D] Enabling LSTMs to be used on longer sequences than seen during training,https://www.reddit.com/r/MachineLearning/comments/63h9se/d_enabling_lstms_to_be_used_on_longer_sequences/,Pieranha,1491342297,"I have a large dataset containing short sentences that I use for pretraining my LSTM model. I'd like to finetune this model on a small dataset of much longer pieces of text. Due to the recurrent nature of LSTMs, the activations blow up when used on the larger dataset, making the model unable to learn when initialized from the pretrained data.

To prevent this and better enable the transfer learning I want to apply a technique that prevent the ""blow up"" of activations when used on longer sequences than the ones seen during training. I'm thinking of implementing the regularization technique from 'Regularizing RNNs by Stabilizing Activations' (ICLR 2016), https://arxiv.org/abs/1511.08400. However, I've not seen this technique used that much in practice. Is there another better method?",18,10,False,self,,,,,
125,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,6,63hcki,self.MachineLearning,[D] Semantic Segmentation Domain Adaptation,https://www.reddit.com/r/MachineLearning/comments/63hcki/d_semantic_segmentation_domain_adaptation/,miat123,1491343032,"I am trying to train a conv net for semantic image segmentation. The problem is that I have a synthetic dataset and a real one and there is an obvious domain shift. What would be a way to do a domain adaptation? I have successfully done the simplest approach where I use 4 mini-batches from the real and 4 mini-batches from the synthetic domain in the SGD optimization. 

I believe a more complicated approach would be better. ",3,2,False,self,,,,,
126,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,7,63hg6t,self.MachineLearning,What datasets do you need?,https://www.reddit.com/r/MachineLearning/comments/63hg6t/what_datasets_do_you_need/,danielgross1000,1491344020,[removed],0,1,False,default,,,,,
127,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,7,63hhrw,bigthink.com,Is Luna an AGI or just hype?,https://www.reddit.com/r/MachineLearning/comments/63hhrw/is_luna_an_agi_or_just_hype/,[deleted],1491344463,[deleted],0,1,False,default,,,,,
128,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,7,63hl4o,bigthink.com,[D] Is Luna an AGI or just hype?,https://www.reddit.com/r/MachineLearning/comments/63hl4o/d_is_luna_an_agi_or_just_hype/,[deleted],1491345414,[deleted],8,0,False,default,,,,,
129,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,10,63il27,self.MachineLearning,Question on mapping text labels to numerical representations with out causing Issues in training,https://www.reddit.com/r/MachineLearning/comments/63il27/question_on_mapping_text_labels_to_numerical/,lm0n,1491356381,[removed],0,1,False,default,,,,,
130,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,11,63ipug,listly.io,Data Extraction - Web page to Excel in seconds. No more Parsing code.,https://www.reddit.com/r/MachineLearning/comments/63ipug/data_extraction_web_page_to_excel_in_seconds_no/,changminc,1491357892,,0,1,False,default,,,,,
131,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,12,63j6kb,youtube.com,JCT food powder mixer horizontal ribbon mixer,https://www.reddit.com/r/MachineLearning/comments/63j6kb/jct_food_powder_mixer_horizontal_ribbon_mixer/,mixmachinery,1491363374,,1,1,False,default,,,,,
132,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,12,63j9ls,youtube.com,What is the protein powder mixer,https://www.reddit.com/r/MachineLearning/comments/63j9ls/what_is_the_protein_powder_mixer/,mixmachinery,1491364474,,1,1,False,default,,,,,
133,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,14,63jp7k,jonolick.com,"[R] DagNN - a ""deeper"" fully connected network",https://www.reddit.com/r/MachineLearning/comments/63jp7k/r_dagnn_a_deeper_fully_connected_network/,zelex,1491370699,,12,0,False,default,,,,,
134,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,14,63jr3o,self.MachineLearning,"How to Train a Neural Net ""Curator"" of Images?",https://www.reddit.com/r/MachineLearning/comments/63jr3o/how_to_train_a_neural_net_curator_of_images/,Motor_City_Cobra,1491371503,[removed],0,1,False,default,,,,,
135,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,15,63jtir,youtube.com,Have a look at operating high speed disperser for liquid mixing,https://www.reddit.com/r/MachineLearning/comments/63jtir/have_a_look_at_operating_high_speed_disperser_for/,JCT_Janice,1491372543,,0,1,False,default,,,,,
136,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,15,63jtt4,beyondmachine.com,"water bottling plant, filling machine , juice filling Machine, bottle Blowing machine , 5 gallon filling machine",https://www.reddit.com/r/MachineLearning/comments/63jtt4/water_bottling_plant_filling_machine_juice/,[deleted],1491372661,[deleted],0,1,False,default,,,,,
137,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,15,63jwog,researchweb.iiit.ac.in,[R] Colonel Density Estimation (SIGBOVIK 2017),https://www.reddit.com/r/MachineLearning/comments/63jwog/r_colonel_density_estimation_sigbovik_2017/,nisprateek,1491374025,,1,3,False,default,,,,,
138,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,15,63jwq3,beyondmachine.com,"[D] water bottling plant, filling machine , juice filling Machine, bottle Blowing machine , 5 gallon filling machine",https://www.reddit.com/r/MachineLearning/comments/63jwq3/d_water_bottling_plant_filling_machine_juice/,BarrazaCarylon,1491374047,,0,0,False,default,,,,,
139,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,16,63k1ol,blogs.technet.microsoft.com,Microsoft's CNTK is out of beta,https://www.reddit.com/r/MachineLearning/comments/63k1ol/microsofts_cntk_is_out_of_beta/,hoaphumanoid,1491376369,,0,1,False,default,,,,,
140,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,17,63kd31,argmin.net,[R] Nesterov's Punctuated Equilibrium,https://www.reddit.com/r/MachineLearning/comments/63kd31/r_nesterovs_punctuated_equilibrium/,davmre,1491382247,,1,7,False,default,,,,,
141,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,18,63kec0,journal.frontiersin.org,[D] Future Directions in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/63kec0/d_future_directions_in_machine_learning/,nocortex,1491382858,,0,5,False,https://b.thumbs.redditmedia.com/yrUWEXB7O_Brp2zY9HEyK952QtkPTRShFTkV1U9zhOA.jpg,,,,,
142,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,18,63kf1h,re-work.co,Security &amp;amp; Privacy is Vital For Machine Learning to Succeed,https://www.reddit.com/r/MachineLearning/comments/63kf1h/security_amp_privacy_is_vital_for_machine/,nikitaljohnson,1491383186,,0,1,False,default,,,,,
143,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,18,63khkh,self.MachineLearning,Calculating the 95% CIs for an ROC AUC value from a binary SVM classification.,https://www.reddit.com/r/MachineLearning/comments/63khkh/calculating_the_95_cis_for_an_roc_auc_value_from/,[deleted],1491384397,[removed],0,1,False,default,,,,,
144,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,19,63knm5,self.MachineLearning,Benchmark denoising autoencoder on CIFAR-10,https://www.reddit.com/r/MachineLearning/comments/63knm5/benchmark_denoising_autoencoder_on_cifar10/,hyperqube12,1491387367,[removed],0,1,False,default,,,,,
145,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,20,63kv8u,self.MachineLearning,Annotation in COCO dataset,https://www.reddit.com/r/MachineLearning/comments/63kv8u/annotation_in_coco_dataset/,lvbu,1491390774,[removed],0,1,False,default,,,,,
146,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,20,63l0sn,self.MachineLearning,[D] Input propagation through a general recurrent neural network in case of reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/63l0sn/d_input_propagation_through_a_general_recurrent/,differenti,1491392924,"Hello!

I am trying to evolve neural networks using the NEAT (Neuroevolution for Augmenting Topologies) algorithm for a reinforcement learning task. However, I'm confused as to how the input will propagate through a recurrent network evolved through this process.

NEAT does not discriminate between looping and non-looping edges (I remember reading a comment somewhere in the original code) unlike a typical backprop trained RNN which does. So when allowed to evolve recurrent networks, we must use a synchronous approach to propagate forward:

	For each timestep:
		temp = getNewOutputs(current_outputs_of_nodes, new_inputs_to_network) for each node
		setOutputs(temp) for each node

That is, the new outputs are calculated from a snapshot of the current outputs, and then the outputs are updated simultaneously for all neurons. Am I correct here? I don't see any other way to do a forward prop without discriminating between looping and non-looping edges. Here, each neuron calculates output at time = t with the inputs from other neurons being their outputs at time = t-1. In contrast, a typical RNN forward propagates in a topological sorted manner (ignoring the looping edges) and only for the looping edges the t-1 values are used.

However, for a reinforcement learning task, let's say the input vectors are v1, v2, v3 ... vn, where the number represents the time unit. Now assume that we are at time t, and the inputs to network changes to vt. The output, however, doesn't immediately get this information in one time step as the updates are synchronous. In other words, the information of input change hops only one edge in one time-step so the outputs won't reflect this immediately. Will this delayed response not make the system perform poorly? Or am I missing something?

Any help will be appreciated. TIA.

Edit: Formatting.",4,0,False,self,,,,,
147,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,20,63l0up,self.MachineLearning,"[D] So I'm a machine learning hobbyist, who happens to have a background in linear algebra, stats, differential equations. How do I more utilize this background in my projects?",https://www.reddit.com/r/MachineLearning/comments/63l0up/d_so_im_a_machine_learning_hobbyist_who_happens/,[deleted],1491392949,[deleted],5,0,False,default,,,,,
148,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,20,63l1zl,self.MachineLearning,[R] Calculating the 95% CIs for an ROC AUC value from a binary SVM classification.,https://www.reddit.com/r/MachineLearning/comments/63l1zl/r_calculating_the_95_cis_for_an_roc_auc_value/,FishingInScotland,1491393345,"Hi all,

I'm not sure I'm doing this correctly - would appreciate some advice.
I'm using Matlab and LibSVM - got my decimal values from the SVM output, which I can threshold in a loop with small increments to create a plot of how the True Positive Rate and False Positive Rates vary. I can then calculate the area under the curve.

However, I'm not quite sure that I'm calculating the associated confidence intervals correctly.
The solution I was able to find was here: http://www.matlab-cookbook.com/recipes/0100_Statistics/010_sem.html

Basically - calculate the standard error of the mean, and multiply by 1.96 to get the confidence interval.

Is this the correct way of calculating the 95% CI for an AUC performance measure?",4,0,False,self,,,,,
149,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,22,63lgzi,self.MachineLearning,why does validation loss start to increase too early?,https://www.reddit.com/r/MachineLearning/comments/63lgzi/why_does_validation_loss_start_to_increase_too/,hazarapet,1491398481,[removed],0,1,False,default,,,,,
150,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,23,63luux,self.MachineLearning,Looking for a C++ library with LSTM and RProp,https://www.reddit.com/r/MachineLearning/comments/63luux/looking_for_a_c_library_with_lstm_and_rprop/,[deleted],1491402555,[removed],0,1,False,default,,,,,
151,MachineLearning,t5_2r3gv,2017-4-5,2017,4,5,23,63lzp3,self.MachineLearning,Poker rule induction machine learning,https://www.reddit.com/r/MachineLearning/comments/63lzp3/poker_rule_induction_machine_learning/,Ozzymandias1893,1491403931,[removed],0,1,False,default,,,,,
152,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,0,63m2pc,youtu.be,Fast Artistic Style Transfer for Videos based on AdaIN-style,https://www.reddit.com/r/MachineLearning/comments/63m2pc/fast_artistic_style_transfer_for_videos_based_on/,[deleted],1491404745,[deleted],0,1,False,default,,,,,
153,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,0,63m2s8,self.MachineLearning,Multi-classification of poker hands.,https://www.reddit.com/r/MachineLearning/comments/63m2s8/multiclassification_of_poker_hands/,Ozzymandias1893,1491404771,[removed],0,1,False,default,,,,,
154,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,0,63mdgp,self.MachineLearning,"Simple Questions Thread April 05, 2017",https://www.reddit.com/r/MachineLearning/comments/63mdgp/simple_questions_thread_april_05_2017/,AutoModerator,1491407564,[removed],0,1,False,default,,,,,
155,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,1,63mfba,nextplatform.com,First In-Depth Look at the Google Tensor Processing Unit (TPU) Architecture,https://www.reddit.com/r/MachineLearning/comments/63mfba/first_indepth_look_at_the_google_tensor/,[deleted],1491408034,[deleted],0,1,False,default,,,,,
156,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,1,63mgoz,arxiv.org,Community detection in networks: A user guide,https://www.reddit.com/r/MachineLearning/comments/63mgoz/community_detection_in_networks_a_user_guide/,choob314,1491408389,,0,1,False,default,,,,,
157,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,1,63mgup,self.MachineLearning,[D] Reference Request: Incorporate Uncertainty in NNs / Learning Dynamics/Models for RL by using NNs ?,https://www.reddit.com/r/MachineLearning/comments/63mgup/d_reference_request_incorporate_uncertainty_in/,xingdongrobotics,1491408427,"This post is asking help for suggestions of references about two following topics.

1. Incorporate Uncertainty for Neural Networks

2. In RL settings, learning dynamics/models by using Neural Networks. ",5,9,False,self,,,,,
158,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,1,63mhq7,youtube.com,"[R] Bruno Olshausen, UC Berkeley: Learning Representations for Active Vision",https://www.reddit.com/r/MachineLearning/comments/63mhq7/r_bruno_olshausen_uc_berkeley_learning/,downtownslim,1491408660,,0,19,False,https://b.thumbs.redditmedia.com/y71QIoHBZWSeXQYuqg-gKRG1rcwlETQbpQuxlxUp-EM.jpg,,,,,
159,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,1,63mjfk,self.MachineLearning,Formulas for parameter values,https://www.reddit.com/r/MachineLearning/comments/63mjfk/formulas_for_parameter_values/,sputknick,1491409096,[removed],0,1,False,default,,,,,
160,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,1,63mne2,cloudplatform.googleblog.com,"[D] Quantifying the performance of the TPU, our first machine learning chip",https://www.reddit.com/r/MachineLearning/comments/63mne2/d_quantifying_the_performance_of_the_tpu_our/,wei_jok,1491410068,,68,175,False,https://b.thumbs.redditmedia.com/sllRkpLI6VaAm0PylRv6ejT7rO8itWu_1y46bA2r4Sg.jpg,,,,,
161,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,1,63mr3l,self.MachineLearning,Looking for suggestions for partners for commercial deep learning trial,https://www.reddit.com/r/MachineLearning/comments/63mr3l/looking_for_suggestions_for_partners_for/,tronfela,1491410967,[removed],0,1,False,default,,,,,
162,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,2,63mtz7,self.MachineLearning,Recommender and Ranking systems Ethnography,https://www.reddit.com/r/MachineLearning/comments/63mtz7/recommender_and_ranking_systems_ethnography/,jeremiepoiroux,1491411690,[removed],0,1,False,default,,,,,
163,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,2,63myi3,drive.google.com,[R] Google's Paper on Tensor Processing Unit,https://www.reddit.com/r/MachineLearning/comments/63myi3/r_googles_paper_on_tensor_processing_unit/,nisprateek,1491412802,,6,39,False,https://b.thumbs.redditmedia.com/xO2WsLxoQlzQQEnxnz4HszZimWe5Jxcn4IDNObMBHgg.jpg,,,,,
164,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,2,63n0oe,self.MachineLearning,What type of statistics does machine learning use? Regression? Anova? Hypothesis testing?,https://www.reddit.com/r/MachineLearning/comments/63n0oe/what_type_of_statistics_does_machine_learning_use/,johnnyboyfart,1491413368,[removed],25,0,False,default,,,,,
165,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,3,63ncuw,kendricktan.github.io,[P] Draw like Bob Ross with Pytorch!,https://www.reddit.com/r/MachineLearning/comments/63ncuw/p_draw_like_bob_ross_with_pytorch/,kendrick__,1491416337,,2,24,False,https://b.thumbs.redditmedia.com/j8olMRYcicK4sC_Rm2dDNU2UhumCiGBWHdDSf2nSbVY.jpg,,,,,
166,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,3,63neez,imgur.com,Animated style transfer experiments,https://www.reddit.com/r/MachineLearning/comments/63neez/animated_style_transfer_experiments/,gecko39,1491416731,,2,2,False,default,,,,,
167,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,3,63nfqz,github.com,Neural network trained to autocomplete neural network code,https://www.reddit.com/r/MachineLearning/comments/63nfqz/neural_network_trained_to_autocomplete_neural/,pvkooten,1491417063,,0,1,False,default,,,,,
168,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,3,63niv2,github.com,Notes on an Introduction to Computational Learning Theory,https://www.reddit.com/r/MachineLearning/comments/63niv2/notes_on_an_introduction_to_computational/,[deleted],1491417854,[deleted],0,1,False,default,,,,,
169,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,4,63nqng,self.MachineLearning,Language Model for Child Language?,https://www.reddit.com/r/MachineLearning/comments/63nqng/language_model_for_child_language/,YourWelcomeOrMine,1491419812,[removed],0,1,False,default,,,,,
170,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,4,63nwvi,github.com,"CVPR 2017 ""Age Progression/Regression by Conditional Adversarial Autoencoder"" source code",https://www.reddit.com/r/MachineLearning/comments/63nwvi/cvpr_2017_age_progressionregression_by/,jefferysusan,1491421399,,0,1,False,default,,,,,
171,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,4,63o0d8,self.MachineLearning,"Tensorflow, Windows vs Linux Benchmarks",https://www.reddit.com/r/MachineLearning/comments/63o0d8/tensorflow_windows_vs_linux_benchmarks/,idg101,1491422339,[removed],0,1,False,default,,,,,
172,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,5,63o78i,insights.ap.org,"[N] The Future of Augmented Journalism, A guide for newsrooms in the age of smart machines.",https://www.reddit.com/r/MachineLearning/comments/63o78i/n_the_future_of_augmented_journalism_a_guide_for/,julian88888888,1491424082,,2,6,False,default,,,,,
173,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,6,63ofis,youtu.be,[R] Fast Artistic Style Transfer for Videos based on AdaIN-style,https://www.reddit.com/r/MachineLearning/comments/63ofis/r_fast_artistic_style_transfer_for_videos_based/,gsssrao,1491426277,,1,5,False,https://b.thumbs.redditmedia.com/xX7PUlyRz9hh6WIvdj7RL831ycn5fcIuLGaphNUtTWo.jpg,,,,,
174,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,6,63oii1,self.MachineLearning,"What should i do if my validation and test error are reducing, as the number of iterations are increasing?",https://www.reddit.com/r/MachineLearning/comments/63oii1/what_should_i_do_if_my_validation_and_test_error/,chkslry,1491427097,[removed],0,1,False,default,,,,,
175,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,8,63pb96,self.MachineLearning,What is some of the latest research in Person Tracking?,https://www.reddit.com/r/MachineLearning/comments/63pb96/what_is_some_of_the_latest_research_in_person/,Greendogo,1491435403,[removed],0,1,False,default,,,,,
176,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,8,63pff9,self.MachineLearning,Keras/Deep Learning Batch Size + Cookbook for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/63pff9/kerasdeep_learning_batch_size_cookbook_for_deep/,[deleted],1491436682,[removed],0,1,False,default,,,,,
177,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,9,63piiy,self.MachineLearning,[D] Soft targets for transfer learning and Softmax temperature,https://www.reddit.com/r/MachineLearning/comments/63piiy/d_soft_targets_for_transfer_learning_and_softmax/,Pieranha,1491437602,"I'm interesting in transferring knowledge between networks along the lines of Hinton's paper: https://www.cs.toronto.edu/~hinton/absps/distillation.pdf

It's not clear to me, however, why a high temperature is needed in the Softmax. Could anyone elaborate on that? Also, is there any rule of thumb on what value this ""high temperature"" should be?
",3,2,False,self,,,,,
178,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,9,63pok4,self.MachineLearning,For those of you with machines online - what are they learning?,https://www.reddit.com/r/MachineLearning/comments/63pok4/for_those_of_you_with_machines_online_what_are/,ThatSocio,1491439404,[removed],0,1,False,default,,,,,
179,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,10,63q056,self.MachineLearning,[D] What do interns do at OpenAI?,https://www.reddit.com/r/MachineLearning/comments/63q056/d_what_do_interns_do_at_openai/,gsjbjt,1491443052,"OpenAI notably seems to one of the few major AI players hiring non-PhD research interns (and sometimes even those who don't have substantial experience in the field, optimizing for ""potential,"" according to their website).

What do they do? Are they held to the same (1) interview standards (2) contribution standards?",14,40,False,self,,,,,
180,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,11,63q57i,arxiv.org,Learning to Generate Reviews and Discovering Sentiment (OpenAI),https://www.reddit.com/r/MachineLearning/comments/63q57i/learning_to_generate_reviews_and_discovering/,[deleted],1491444653,[deleted],0,1,False,default,,,,,
181,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,11,63q744,arxiv.org,[R] Learning to Generate Reviews and Discovering Sentiment,https://www.reddit.com/r/MachineLearning/comments/63q744/r_learning_to_generate_reviews_and_discovering/,desku,1491445267,,24,35,False,default,,,,,
182,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,11,63q8mm,self.MachineLearning,Anime Faces Dataset?,https://www.reddit.com/r/MachineLearning/comments/63q8mm/anime_faces_dataset/,alexmlamb,1491445765,[removed],0,1,False,default,,,,,
183,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,11,63q9gn,self.MachineLearning,[D] The Role of 3D Artists in Developing Machine Learning,https://www.reddit.com/r/MachineLearning/comments/63q9gn/d_the_role_of_3d_artists_in_developing_machine/,m5tuff,1491446027,"Hello /r/MachineLearning,
I have been following the subreddit for a while, thank you for covering the many developments happening in the area.
I am currently studying for a bachelor in general 3D pipeline, specializing in VFX and also touching on realtime content.
I would like to contribute to the research and development of Machine Learning and apply my acquired skills to the field, though I am not sure what areas of Machine Learning can make use of a 3D artists.
What are your thoughts on this?

Thank you,",5,0,False,self,,,,,
184,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,12,63qnz3,fas.org,Perspectives on Research in Artificial Intelligence and Artificial General Intelligence Relevant to DoD,https://www.reddit.com/r/MachineLearning/comments/63qnz3/perspectives_on_research_in_artificial/,FourFingeredMartian,1491450981,,0,1,False,default,,,,,
185,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,14,63r31q,self.MachineLearning,[D] What topic or idea in Deep Learning that requires not too much computational power but is still fertile for new development?,https://www.reddit.com/r/MachineLearning/comments/63r31q/d_what_topic_or_idea_in_deep_learning_that/,bubiche,1491456911,[removed],0,1,False,default,,,,,
186,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,14,63r44c,youtube.com,Decision Tree Explained From Scratch (A Complete Guide),https://www.reddit.com/r/MachineLearning/comments/63r44c/decision_tree_explained_from_scratch_a_complete/,pooja_edureka,1491457418,,0,1,False,default,,,,,
187,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,14,63r63e,self.MachineLearning,Diabetic Retinopathy detection,https://www.reddit.com/r/MachineLearning/comments/63r63e/diabetic_retinopathy_detection/,Zakoootaa,1491458272,[removed],0,2,False,default,,,,,
188,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,15,63r74n,venturebeat.com,Understanding the limits of deep learning,https://www.reddit.com/r/MachineLearning/comments/63r74n/understanding_the_limits_of_deep_learning/,mks_repi,1491458704,,2,3,False,default,,,,,
189,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,15,63rbko,manavsehgal.com,Speed Reading On Machine Learning  Manav Sehgal,https://www.reddit.com/r/MachineLearning/comments/63rbko/speed_reading_on_machine_learning_manav_sehgal/,manavsehgal,1491460734,,0,0,False,default,,,,,
190,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,15,63rbls,self.MachineLearning,Which machine learning algorithm and features to be used for my problem ?,https://www.reddit.com/r/MachineLearning/comments/63rbls/which_machine_learning_algorithm_and_features_to/,SwapnilBhosale,1491460753,[removed],0,1,False,default,,,,,
191,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,15,63rbsy,self.MachineLearning,Facebook profile augmented by A.I.,https://www.reddit.com/r/MachineLearning/comments/63rbsy/facebook_profile_augmented_by_ai/,KidFireX,1491460843,[removed],0,1,False,default,,,,,
192,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,15,63rd7z,cloud.google.com,[D] AXA Japan used simple TensorFlow network to price driver insurance premiums.,https://www.reddit.com/r/MachineLearning/comments/63rd7z/d_axa_japan_used_simple_tensorflow_network_to/,wei_jok,1491461549,,0,1,False,default,,,,,
193,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,16,63refd,self.MachineLearning,Facebook profile augmented by A.I.,https://www.reddit.com/r/MachineLearning/comments/63refd/facebook_profile_augmented_by_ai/,KidFireX,1491462115,[removed],0,1,False,default,,,,,
194,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,16,63rk04,slashdot.org,What about the advantages from stainless steel jacketed reactor manufacturer?,https://www.reddit.com/r/MachineLearning/comments/63rk04/what_about_the_advantages_from_stainless_steel/,JCT_Janice,1491464827,,0,0,False,default,,,,,
195,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,17,63rlzp,self.MachineLearning,Facebook profile augmented by Artificial Intelligence. What do you guys think?,https://www.reddit.com/r/MachineLearning/comments/63rlzp/facebook_profile_augmented_by_artificial/,KidFireX,1491465829,[removed],0,1,False,default,,,,,
196,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,18,63rz8c,shotblasting.org.in,Get Shot Blasting Machine @ Best Prices in India,https://www.reddit.com/r/MachineLearning/comments/63rz8c/get_shot_blasting_machine_best_prices_in_india/,shotblasting1,1491472647,,0,1,False,default,,,,,
197,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,19,63s49h,quantinsti.com,Forecasting Markets using eXtreme Gradient Boosting (XGBoost),https://www.reddit.com/r/MachineLearning/comments/63s49h/forecasting_markets_using_extreme_gradient/,NitinThapar,1491474971,,0,1,False,default,,,,,
198,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,19,63s666,arxiv.org,[R] [1703.05051] Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG,https://www.reddit.com/r/MachineLearning/comments/63s666/r_170305051_deep_learning_with_convolutional/,robintibor,1491475838,,10,74,False,default,,,,,
199,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,19,63s71g,self.MachineLearning,Does any ML lends itself to dynamic / structured data? (Prof. Andrew Ng Stanford based approach),https://www.reddit.com/r/MachineLearning/comments/63s71g/does_any_ml_lends_itself_to_dynamic_structured/,the_crowz,1491476207,[removed],0,1,False,default,,,,,
200,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,22,63sxqi,stamacaustralia.tumblr.com,Machinery Relocations in AU,https://www.reddit.com/r/MachineLearning/comments/63sxqi/machinery_relocations_in_au/,stamac,1491485613,,0,1,False,default,,,,,
201,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,22,63szps,scikit-learn.org,[P] Probability calibration,https://www.reddit.com/r/MachineLearning/comments/63szps/p_probability_calibration/,pmigdal,1491486247,,7,20,False,https://b.thumbs.redditmedia.com/FKa063mClzNSPGaRB69GxcPneikLAkcj0W1WUA0lXkQ.jpg,,,,,
202,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,22,63t1tl,self.MachineLearning,Is keras trying to make enemies with Microsoft?,https://www.reddit.com/r/MachineLearning/comments/63t1tl/is_keras_trying_to_make_enemies_with_microsoft/,idg101,1491486869,[removed],0,1,False,default,,,,,
203,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,22,63t2t1,nvidia.com,TITAN Xp Graphics Card with Pascal Architecture,https://www.reddit.com/r/MachineLearning/comments/63t2t1/titan_xp_graphics_card_with_pascal_architecture/,[deleted],1491487164,[deleted],0,1,False,default,,,,,
204,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,23,63t2y2,inference.vc,[D] Evolution Strategies: Variational Optimization and Natural ES,https://www.reddit.com/r/MachineLearning/comments/63t2y2/d_evolution_strategies_variational_optimization/,fhuszar,1491487200,,9,32,False,https://b.thumbs.redditmedia.com/h3Ywj15PBWXC4MwDJdiZU7q-ebWlKF8FwQY_WVonNTE.jpg,,,,,
205,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,23,63t5r6,nvidia.com,TITAN Xp Graphics Card with Pascal Architecture,https://www.reddit.com/r/MachineLearning/comments/63t5r6/titan_xp_graphics_card_with_pascal_architecture/,[deleted],1491487955,[deleted],0,1,False,default,,,,,
206,MachineLearning,t5_2r3gv,2017-4-6,2017,4,6,23,63tbws,arxiv.org,[R] Neural Message Passing for Quantum Chemistry,https://www.reddit.com/r/MachineLearning/comments/63tbws/r_neural_message_passing_for_quantum_chemistry/,wei_jok,1491489684,,1,17,False,default,,,,,
207,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,0,63tmae,self.MachineLearning,Weird parameter in fastText (lenght of word ngram),https://www.reddit.com/r/MachineLearning/comments/63tmae/weird_parameter_in_fasttext_lenght_of_word_ngram/,SuperCComplex,1491492450,[removed],0,1,False,default,,,,,
208,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,0,63tohs,nvidia.com,TITAN Xp Card - New contender for speedy deep learning,https://www.reddit.com/r/MachineLearning/comments/63tohs/titan_xp_card_new_contender_for_speedy_deep/,soulslicer0,1491493023,,0,1,False,default,,,,,
209,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,1,63tx0w,blog.openai.com,A neural network teaches itself to analyze sentiment after only being trained to predict the next character,https://www.reddit.com/r/MachineLearning/comments/63tx0w/a_neural_network_teaches_itself_to_analyze/,Wireworld,1491495161,,1,2,False,default,,,,,
210,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,1,63tygb,extremetech.com,"Googles dedicated TensorFlow processor, or TPU, crushes Intel, Nvidia in inference workloads",https://www.reddit.com/r/MachineLearning/comments/63tygb/googles_dedicated_tensorflow_processor_or_tpu/,nikvaidya,1491495515,,1,1,False,default,,,,,
211,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,1,63u2xa,self.MachineLearning,[D] Any advice on end-to-end document structure analysis?,https://www.reddit.com/r/MachineLearning/comments/63u2xa/d_any_advice_on_endtoend_document_structure/,gecko39,1491496660,"I'm trying to parse pictures of restaurant menus and I'm looking for some advice about how to approach the problem. 
Are there any end-to-end approaches to document structure analysis? ( maybe different terminology )

The papers I found were pre deep learning era, and all seem to use hand crafted algorithms to analyze document structure. 
The only end-to-end approach I've seen is im2markup ( https://github.com/harvardnlp/im2markup )

Thanks for any advice!

",0,4,False,self,,,,,
212,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,1,63u3bz,magenta.tensorflow.org,Google Brain Magenta's NSynth: Neural Network Synthesizer and Music Dataset,https://www.reddit.com/r/MachineLearning/comments/63u3bz/google_brain_magentas_nsynth_neural_network/,[deleted],1491496762,[deleted],0,3,False,default,,,,,
213,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,2,63uacd,arxiv.org,"[1704.01547] Comment on ""Biologically inspired protection of deep networks from adversarial attacks""",https://www.reddit.com/r/MachineLearning/comments/63uacd/170401547_comment_on_biologically_inspired/,alexmlamb,1491498484,,0,1,False,default,,,,,
214,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,2,63ue4v,magenta.tensorflow.org,[R] Google Brain Magenta's NSynth: Neural Network Synthesizer and Music Dataset,https://www.reddit.com/r/MachineLearning/comments/63ue4v/r_google_brain_magentas_nsynth_neural_network/,cinjon,1491499464,,22,50,False,https://b.thumbs.redditmedia.com/Q7LdY47wmdN5aAGvmptKGGD_YDN0yVuLZAu1oOb_MOY.jpg,,,,,
215,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,3,63ur6f,shop.oreilly.com,O'Reilly's book on Machine Learning with Scikit-Learn and TensorFlow is out. Has anyone tried it yet?,https://www.reddit.com/r/MachineLearning/comments/63ur6f/oreillys_book_on_machine_learning_with/,[deleted],1491502700,[deleted],0,1,False,default,,,,,
216,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,3,63uvzq,shop.oreilly.com,[N] O'Reilly's book on Machine Learning with Scikit-Learn and TensorFlow is out. Has anyone tried it yet?,https://www.reddit.com/r/MachineLearning/comments/63uvzq/n_oreillys_book_on_machine_learning_with/,SorollmefurtherBitch,1491503910,,53,433,False,https://b.thumbs.redditmedia.com/SO2MjcWjQnfmx-zzXRlYUkk1I-ULSl4irQXdr3nYpZQ.jpg,,,,,
217,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,3,63uw9r,techcrunch.com,NVIDIA Releases Titan Xp Card,https://www.reddit.com/r/MachineLearning/comments/63uw9r/nvidia_releases_titan_xp_card/,PM_YOUR_NIPS_PAPER,1491503982,,0,1,False,default,,,,,
218,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,4,63v4i5,blog.openai.com,Unsupervised sentiment neuron,https://www.reddit.com/r/MachineLearning/comments/63v4i5/unsupervised_sentiment_neuron/,[deleted],1491506053,[deleted],0,1,False,default,,,,,
219,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,4,63v9vz,self.MachineLearning,h2o &amp; Random Forest,https://www.reddit.com/r/MachineLearning/comments/63v9vz/h2o_random_forest/,[deleted],1491507448,[removed],0,1,False,default,,,,,
220,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,5,63vfst,self.MachineLearning,[D] Google Brain Residency Results,https://www.reddit.com/r/MachineLearning/comments/63vfst/d_google_brain_residency_results/,MetricSpade007,1491508977,Has anyone heard final decisions from the Residency program yet?,24,10,False,self,,,,,
221,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,5,63vs97,github.com,Boundary Equilibrium GAN Implementation in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/63vs97/boundary_equilibrium_gan_implementation_in/,[deleted],1491512205,[deleted],0,2,False,default,,,,,
222,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,6,63vulj,github.com,[P] Boundary Equilibrium GAN Implementation in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/63vulj/p_boundary_equilibrium_gan_implementation_in/,agolio,1491512804,,1,22,False,https://b.thumbs.redditmedia.com/WdlcC-2BqSXtJKL_7E6ljU3uOIwa6GAB2sQqONxT0CI.jpg,,,,,
223,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,7,63wc6y,peerj.com,[R] Accelerating the XGBoost algorithm using GPU computing,https://www.reddit.com/r/MachineLearning/comments/63wc6y/r_accelerating_the_xgboost_algorithm_using_gpu/,ramitchellnz,1491517555,,0,7,False,default,,,,,
224,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,8,63wl92,blog.openai.com,[R] Unsupervised sentiment neuron,https://www.reddit.com/r/MachineLearning/comments/63wl92/r_unsupervised_sentiment_neuron/,clbam8,1491520201,,13,16,False,https://a.thumbs.redditmedia.com/rz9EHGJc-b1uR2AnG8tUr6KWhNryDokUlhs1G7_REs4.jpg,,,,,
225,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,9,63x16u,github.com,"[P] Tensorflow: imperative programming (like pytorch, chainer, numpy) now available",https://www.reddit.com/r/MachineLearning/comments/63x16u/p_tensorflow_imperative_programming_like_pytorch/,downtownslim,1491525014,,11,15,False,https://b.thumbs.redditmedia.com/HuS3FZy2pxBv9EOMqVNN0Is_qaV2-wBvViRWFCvdccI.jpg,,,,,
226,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,9,63x3rs,research.googleblog.com,Federated Learning: Collaborative Machine Learning without Centralized Training Data,https://www.reddit.com/r/MachineLearning/comments/63x3rs/federated_learning_collaborative_machine_learning/,[deleted],1491525820,[deleted],0,1,False,default,,,,,
227,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,11,63xm87,analyticbridge.com,Factoring Massive Numbers: Machine Learning Approach - Why and How,https://www.reddit.com/r/MachineLearning/comments/63xm87/factoring_massive_numbers_machine_learning/,psangrene,1491531360,,0,1,False,default,,,,,
228,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,11,63xox4,redhat.com,The people behind OpenAI,https://www.reddit.com/r/MachineLearning/comments/63xox4/the_people_behind_openai/,[deleted],1491532214,[deleted],0,1,False,default,,,,,
229,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,12,63xv6o,guillaumegenthial.github.io,[P] Sequence Tagging with Tensorflow (using CRF),https://www.reddit.com/r/MachineLearning/comments/63xv6o/p_sequence_tagging_with_tensorflow_using_crf/,[deleted],1491534184,[deleted],0,1,False,default,,,,,
230,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,12,63xvmx,cv-tricks.com,"When you run Deep learning on Raspberry Pi and other devices for embedded vision, use this technique to improve speed upto 4 times without compromising on accuracy(0.3% increase in top-5 error)",https://www.reddit.com/r/MachineLearning/comments/63xvmx/when_you_run_deep_learning_on_raspberry_pi_and/,sankit123,1491534321,,0,1,False,default,,,,,
231,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,12,63xwyd,guillaumegenthial.github.io,[P] Sequence Tagging with Tensorflow (using CRF),https://www.reddit.com/r/MachineLearning/comments/63xwyd/p_sequence_tagging_with_tensorflow_using_crf/,omoindrot,1491534730,,2,9,False,https://b.thumbs.redditmedia.com/NzY-5_epaHamAKlchpCTFzHEUEcIpWqU_4USjsSxZpg.jpg,,,,,
232,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,12,63xymf,research.googleblog.com,Federated Learning: Collaborative Machine Learning without Centralized Training Data,https://www.reddit.com/r/MachineLearning/comments/63xymf/federated_learning_collaborative_machine_learning/,[deleted],1491535285,[deleted],0,1,False,default,,,,,
233,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,13,63y98n,self.MachineLearning,[D] Interesting ML competition websites besides kaggle?,https://www.reddit.com/r/MachineLearning/comments/63y98n/d_interesting_ml_competition_websites_besides/,teflonmusk,1491539009,"Saw [this photo prediction competition](http://live.unpossib.ly/instagram) and was wondering if any of you guys know of any other good machine learning competition websites out there that have interesting comps like that?

I know Kaggle is probably the main one but just wondering if anyone else knows any others since the kaggle ones are so popular it makes it super competitive (still good practice, but pretty much no chance to win anything etc) ",16,32,False,self,,,,,
234,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,13,63ya38,research.googleblog.com,[R] Federated Learning: Collaborative Machine Learning without Centralized Training Data,https://www.reddit.com/r/MachineLearning/comments/63ya38/r_federated_learning_collaborative_machine/,[deleted],1491539332,,13,38,False,https://b.thumbs.redditmedia.com/A-xsO0BElV8Fehr-80O-y0L-nD-fwgr4QIkscuLhlUc.jpg,,,,,
235,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,14,63yn7x,itenterprise.co.uk,Machine Learning,https://www.reddit.com/r/MachineLearning/comments/63yn7x/machine_learning/,itenterprise09,1491544741,,0,1,False,default,,,,,
236,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,16,63yz23,arxiv.org,"[R]Comment on ""Biologically inspired protection of deep networks from adversarial attacks""",https://www.reddit.com/r/MachineLearning/comments/63yz23/rcomment_on_biologically_inspired_protection_of/,throwaway_nips_user,1491550151,,3,1,False,default,,,,,
237,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,18,63zd2o,mixmachinery.com,How much can I spend buying the vertical ribbon screw blender?,https://www.reddit.com/r/MachineLearning/comments/63zd2o/how_much_can_i_spend_buying_the_vertical_ribbon/,mixmachinery,1491557196,,1,1,False,default,,,,,
238,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,18,63zehi,arxiv.org,[R] [1611.03131] Diverse Neural Network Learns True Target Functions,https://www.reddit.com/r/MachineLearning/comments/63zehi/r_161103131_diverse_neural_network_learns_true/,TheFlyingDrildo,1491557921,,1,8,False,default,,,,,
239,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,19,63zkko,research.googleblog.com,[R] Federated Learning: Collaborative Machine Learning without Centralized Training Data,https://www.reddit.com/r/MachineLearning/comments/63zkko/r_federated_learning_collaborative_machine/,[deleted],1491560719,[deleted],0,1,False,default,,,,,
240,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,20,63zvbs,hpcwire.com,Google Pulls Back the Covers on Its First Machine Learning Chip,https://www.reddit.com/r/MachineLearning/comments/63zvbs/google_pulls_back_the_covers_on_its_first_machine/,mllosab,1491565425,,0,1,False,default,,,,,
241,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,20,63zwu5,self.MachineLearning,https://github.com/janishar/mit-deep-learning-book-pdf,https://www.reddit.com/r/MachineLearning/comments/63zwu5/httpsgithubcomjanisharmitdeeplearningbookpdf/,janishar,1491566047,[removed],0,1,False,default,,,,,
242,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,21,64018c,self.MachineLearning,[D] RL study group,https://www.reddit.com/r/MachineLearning/comments/64018c/d_rl_study_group/,Kiuhnm,1491567672,"I added a study group for Deep Reinforcement Learning at Kiuhnm's University.

You can sign up here: [link](https://www.piazza.com/kiuhnms_university/spring2017/ku702).
**The code is the last part of *url*.**

Here's the complete [description](https://www.piazza.com/kiuhnms_university/spring2017/ku702/home) for the study group:

---

This is not a real course, but more of a study group for learning graduate level (Deep) Reinforcement Learning.

The roadmap is:

1. RL Book by Sutton &amp; Barto, 2nd edition
http://incompleteideas.net/sutton/book/bookdraft2016sep.pdf

2. Lectures by D. Silver:
https://www.youtube.com/playlist?list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT

3. Berkeley course (2017):
http://rll.berkeley.edu/deeprlcourse/

The book should give us a good foundation in RL. Then going through D. Silver's lectures should be very easy. Finally, Berkeley course is the most complete and includes many recent topics.

From time to time, I'll post announcement about my progress (what chapter I'm reading, what lecture I'm watching, etc...).

We'll use Polls to monitor the global progress of this study group. Please vote and update your votes when your status changes.

If you're serious about Deep Reinforcement Learning, don't hesitate to join!

---

BTW, there's also a class for Optimization. See my [previous post](https://www.reddit.com/r/MachineLearning/comments/63d8p2/d_study_group_on_piazza/).

Here's the link for the Optimization study group: [link](http://piazza.com/kiuhnms_university/spring2017/ku701). As before, **the code is the last part of the url**.",6,13,False,self,,,,,
243,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,21,6401v6,kaonashi-tyc.github.io,zi2zi: Master Chinese Calligraphy with Conditional Adversarial Networks [Code Included],https://www.reddit.com/r/MachineLearning/comments/6401v6/zi2zi_master_chinese_calligraphy_with_conditional/,[deleted],1491567897,[deleted],0,1,False,default,,,,,
244,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,21,64036g,kaonashi-tyc.github.io,[P] zi2zi: Master Chinese Calligraphy with Conditional Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/64036g/p_zi2zi_master_chinese_calligraphy_with/,mimighost,1491568367,,14,45,False,https://a.thumbs.redditmedia.com/uVouexOzzrCytBwV8dFDZeSMJIPTNUgzOqua--qIm-0.jpg,,,,,
245,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,21,640406,arxiv.org,[1703.06241] RoomNet: End-to-End Room Layout Estimation,https://www.reddit.com/r/MachineLearning/comments/640406/170306241_roomnet_endtoend_room_layout_estimation/,[deleted],1491568641,[deleted],0,1,False,default,,,,,
246,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,21,64042a,arxiv.org,[R] [1703.06241] RoomNet: End-to-End Room Layout Estimation,https://www.reddit.com/r/MachineLearning/comments/64042a/r_170306241_roomnet_endtoend_room_layout/,NicolasGuacamole,1491568660,,1,1,False,default,,,,,
247,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,22,6407yg,wsiukweb.soup.io,Top Notch Deburring and Chamfering Tools - The Advanced Technology for Industrial Fabrication,https://www.reddit.com/r/MachineLearning/comments/6407yg/top_notch_deburring_and_chamfering_tools_the/,wsiukweb,1491570040,,0,1,False,default,,,,,
248,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,22,64080u,deepsense.io,[P] Region of interest pooling explained (with TensorFlow implementation),https://www.reddit.com/r/MachineLearning/comments/64080u/p_region_of_interest_pooling_explained_with/,pmigdal,1491570058,,2,3,False,https://b.thumbs.redditmedia.com/2NECfrftR_gSrXDlPlHgC5tcKK_WzbTeON6-EhFF2oU.jpg,,,,,
249,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,22,640ad1,deepmind.com,[N] Open sourcing Sonnet - a new library for constructing neural networks,https://www.reddit.com/r/MachineLearning/comments/640ad1/n_open_sourcing_sonnet_a_new_library_for/,lopespm,1491570817,,61,204,False,https://a.thumbs.redditmedia.com/PRr5JaOELVPMrwARYSHezFabQBHxLjxCP6eLo1lE1X4.jpg,,,,,
250,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,22,640cqq,self.MachineLearning,Are there any CNN + RNN implementations for video classification out there ?,https://www.reddit.com/r/MachineLearning/comments/640cqq/are_there_any_cnn_rnn_implementations_for_video/,ynssyd,1491571585,[removed],0,1,False,default,,,,,
251,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,22,640d42,youtube.com,What do you think of detergent ribbon mixer,https://www.reddit.com/r/MachineLearning/comments/640d42/what_do_you_think_of_detergent_ribbon_mixer/,JCT_Janice,1491571693,,0,1,False,default,,,,,
252,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,22,640hba,self.MachineLearning,[N] Visual Doom Competition 2017,https://www.reddit.com/r/MachineLearning/comments/640hba/n_visual_doom_competition_2017/,johny_cauchy,1491572957,"The second Visual Doom Competition (@ CIG 2017) is accepting submissions. 

**Goal**: to develop an agent that plays Doom from pixels. Our [ViZDoom framework](https://github.com/mwydmuch/ViZDoom) gives a real-time access to the Doom's screen buffer. The winner of the competition will be determined by a multiplayer deathmatch tournament.

Reinforcement Learning submissions are welcomed.

Two tracks: i) known map, and ii) unknown map.

Deadlines:

* 31.05.2017 - Warm-up deathmatch submission

* 31.06.2017 - Elimination round submission

* 31.07.2017 - Final round submission

Details at http://vizdoom.cs.put.edu.pl/competition-cig-2017",14,30,False,self,,,,,
253,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,22,640i1l,youtube.com,Machine Learning with Python - Interesting Stuff!,https://www.reddit.com/r/MachineLearning/comments/640i1l/machine_learning_with_python_interesting_stuff/,pooja_edureka,1491573156,,0,1,False,default,,,,,
254,MachineLearning,t5_2r3gv,2017-4-7,2017,4,7,23,640rnp,spikefinder.codeneuro.org,[N] SpikeFinder competition,https://www.reddit.com/r/MachineLearning/comments/640rnp/n_spikefinder_competition/,nocortex,1491575851,,0,1,False,default,,,,,
255,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,1,6419kw,github.com,Domain Separation Networks implementation in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/6419kw/domain_separation_networks_implementation_in/,[deleted],1491580848,[deleted],0,1,False,default,,,,,
256,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,1,641fwc,github.com,[P] Domain Separation Networks implementation in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/641fwc/p_domain_separation_networks_implementation_in/,bousmalis,1491582528,,0,31,False,https://b.thumbs.redditmedia.com/_z24xRS1p29Gfq9nSsWhV4jSEd6fY8CHg7R2-3RNrwg.jpg,,,,,
257,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,1,641kpf,self.MachineLearning,[D] Any reason why Python 2.7 (not 3.x) is the default version for machine learning?,https://www.reddit.com/r/MachineLearning/comments/641kpf/d_any_reason_why_python_27_not_3x_is_the_default/,pmigdal,1491583831,"In machine learning when there is a new library or framework, it often supports only Python 2.7 (see e.g. [deepmind/sonnet](https://github.com/deepmind/sonnet) ""This installation is compatible with Linux/Mac OS X and Python 2.7"").

The opposite case (only Python 3.x support) is virtually non-existing. In case of many libraries lack of support for Python 3.x is a trivial as `print` with no brackets.

So, is there a particular reason why Python 2.7 is being preferred in ML?",14,2,False,self,,,,,
258,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,2,641xv2,medium.com,[N] A peak at trends in machine learning,https://www.reddit.com/r/MachineLearning/comments/641xv2/n_a_peak_at_trends_in_machine_learning/,[deleted],1491587286,[deleted],0,1,False,default,,,,,
259,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,2,641y2k,medium.com,[N] A peek at trends in machine learning,https://www.reddit.com/r/MachineLearning/comments/641y2k/n_a_peek_at_trends_in_machine_learning/,clbam8,1491587340,,9,34,False,https://b.thumbs.redditmedia.com/PtDPMxKsIqHfF7rgFrGXORdnnn0d-NKBw5rF2VQtaIM.jpg,,,,,
260,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,3,6423dm,deeplearning.net,Datasets  Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6423dm/datasets_deep_learning/,kapom,1491588728,,0,1,False,default,,,,,
261,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,3,6424g9,self.MachineLearning,Question regarding Probabilistic Matrix Factorisation - Help Really Appreciated,https://www.reddit.com/r/MachineLearning/comments/6424g9/question_regarding_probabilistic_matrix/,chasefrench1,1491588997,[removed],0,1,False,default,,,,,
262,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,3,6428wi,research.googleblog.com,[R] Predicting properties of molecules with machine learning,https://www.reddit.com/r/MachineLearning/comments/6428wi/r_predicting_properties_of_molecules_with_machine/,clbam8,1491590199,,6,32,False,https://b.thumbs.redditmedia.com/H3EDD_L69SBUYX-sTZUzTxy_y72SyESabzyWCb91f0M.jpg,,,,,
263,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,4,642ls5,self.MachineLearning,Are there Deep Learning oriented software recruiters?,https://www.reddit.com/r/MachineLearning/comments/642ls5/are_there_deep_learning_oriented_software/,MLRecruit,1491593657,[removed],0,1,False,default,,,,,
264,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,4,642m2a,github.com,Modified Adversarial Autoencoder - Truly separating style from class (on MNIST),https://www.reddit.com/r/MachineLearning/comments/642m2a/modified_adversarial_autoencoder_truly_separating/,g_patrick,1491593730,,0,4,False,default,,,,,
265,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,6,6435qx,self.MachineLearning,[D] Are there Deep Learning oriented software recruiters?,https://www.reddit.com/r/MachineLearning/comments/6435qx/d_are_there_deep_learning_oriented_software/,MLRecruit,1491599287,I would like to find work applying new deep learning concepts on text and am looking for a recruiter who focuses on this in the bay area ... does this make sense or should I go to major recruiting firms and ask if they have clients looking for this skill set? I'm hoping there is a specialist as that would be much easier for me.,3,1,False,self,,,,,
266,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,7,643kn3,youtube.com,[P] Deep Reinforcement Learning: Playing a Racing Game - Talk + Slides,https://www.reddit.com/r/MachineLearning/comments/643kn3/p_deep_reinforcement_learning_playing_a_racing/,lopespm,1491603668,,0,0,False,https://b.thumbs.redditmedia.com/8kqFUct6Rc1GBNL9C8P35XfJ0apGLXJfQl5IjFFXwEw.jpg,,,,,
267,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,7,643l08,github.com,Halp please understand multi-neat neuron model implementation.,https://www.reddit.com/r/MachineLearning/comments/643l08/halp_please_understand_multineat_neuron_model/,[deleted],1491603777,[deleted],0,1,False,default,,,,,
268,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,8,643sy9,nbviewer.jupyter.org,[P] Visualizing titles of accepted ACL 2017 papers,https://www.reddit.com/r/MachineLearning/comments/643sy9/p_visualizing_titles_of_accepted_acl_2017_papers/,jasonskessler,1491606292,,0,2,False,default,,,,,
269,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,8,643y05,sciencealert.com,Scientists Have Created an Artificial Synapse That Can Learn Autonomously - ScienceAlert,https://www.reddit.com/r/MachineLearning/comments/643y05/scientists_have_created_an_artificial_synapse/,Grumbit,1491607980,,0,1,False,default,,,,,
270,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,9,6446tf,healthitsecurity.com,"How to Crush the Health Sectors Ransomware Pandemic: The Machine Learning Based Artificial Intelligence Revolution Starts Now! that machine learning based AI throughout the Internet of Things (IoT) microcosm could help detect, respond to, and predict threats",https://www.reddit.com/r/MachineLearning/comments/6446tf/how_to_crush_the_health_sectors_ransomware/,sani_sam,1491610900,,0,1,False,default,,,,,
271,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,9,64481s,youtube.com,How to Win Slot Machines - Intro to Deep Learning,https://www.reddit.com/r/MachineLearning/comments/64481s/how_to_win_slot_machines_intro_to_deep_learning/,funtwo2,1491611336,,0,1,False,default,,,,,
272,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,9,6449b8,self.MachineLearning,Where can I find an all-in-one plain transcript of all trump or obama speeches to feed into my LSTM?,https://www.reddit.com/r/MachineLearning/comments/6449b8/where_can_i_find_an_allinone_plain_transcript_of/,[deleted],1491611829,[removed],0,1,False,default,,,,,
273,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,9,644bt1,adgefficiency.com,[P] energy_py - reinforcement learning for energy systems,https://www.reddit.com/r/MachineLearning/comments/644bt1/p_energy_py_reinforcement_learning_for_energy/,ADGEfficiency,1491612686,,1,38,False,https://b.thumbs.redditmedia.com/nQpRDo2eTHw2r-45iStFjYEl5MlIezf4k4Z1K6WYpyY.jpg,,,,,
274,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,10,644hk6,self.MachineLearning,[D] A3C with experience replay implementation,https://www.reddit.com/r/MachineLearning/comments/644hk6/d_a3c_with_experience_replay_implementation/,innixma,1491614821,"As introduced in the paper ""Sample Efficient Actor-Critic With Experience Replay"": https://arxiv.org/pdf/1611.01224.pdf

Does anyone know of a public implementation of the ACER algorithm?",5,16,False,self,,,,,
275,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,10,644mit,github.com,DeepMind DQN 3.0 source code for Nature paper,https://www.reddit.com/r/MachineLearning/comments/644mit/deepmind_dqn_30_source_code_for_nature_paper/,Real_Data_Sci,1491616640,,1,1,False,default,,,,,
276,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,13,645b32,blog.paralleldots.com,List of some less known Machine Learning libraries.,https://www.reddit.com/r/MachineLearning/comments/645b32/list_of_some_less_known_machine_learning_libraries/,muktabh,1491626452,,0,1,False,default,,,,,
277,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,16,645xhi,analyticsvidhya.com,Deep Learning vs. Machine Learning - the essential differences you need to know!,https://www.reddit.com/r/MachineLearning/comments/645xhi/deep_learning_vs_machine_learning_the_essential/,ankit_123,1491637647,,0,1,False,default,,,,,
278,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,17,64604y,blog.paralleldots.com,Some Lesser-Known Machine Learning Libraries,https://www.reddit.com/r/MachineLearning/comments/64604y/some_lesserknown_machine_learning_libraries/,gargisharmapd,1491639159,,0,1,False,default,,,,,
279,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,17,6461ji,genetic-programming-lab.blogspot.com,"[P] Introducing GP.Lab, a personal GP research project",https://www.reddit.com/r/MachineLearning/comments/6461ji/p_introducing_gplab_a_personal_gp_research_project/,IsleOfTheKakapo,1491640047,,0,1,False,default,,,,,
280,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,17,6463z0,edoarad.wordpress.com,[D] On the security of Google's Federated Learning,https://www.reddit.com/r/MachineLearning/comments/6463z0/d_on_the_security_of_googles_federated_learning/,edoarad,1491641535,,7,3,False,https://b.thumbs.redditmedia.com/op3EAP4nzanB1Lgnl6XBbC6hEvplELi0ZOqm9Yy0HZA.jpg,,,,,
281,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,17,6464cf,mediafire.com,Sheet Metal Parts Manufacturers,https://www.reddit.com/r/MachineLearning/comments/6464cf/sheet_metal_parts_manufacturers/,stamac,1491641773,,0,1,False,default,,,,,
282,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,17,6464hb,www.datascienceconferences.com,Data Science conferences schedule,https://www.reddit.com/r/MachineLearning/comments/6464hb/data_science_conferences_schedule/,REDDIT_VISITOR_,1491641858,,0,1,False,default,,,,,
283,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,20,646mcz,self.MachineLearning,Alternative scikit-learn host?,https://www.reddit.com/r/MachineLearning/comments/646mcz/alternative_scikitlearn_host/,jfmorrison,1491651937,[removed],0,1,False,default,,,,,
284,MachineLearning,t5_2r3gv,2017-4-8,2017,4,8,23,6476kj,soundcloud.com,"[Project]Music generated using my RNN + some bach chorales, what do you think?",https://www.reddit.com/r/MachineLearning/comments/6476kj/projectmusic_generated_using_my_rnn_some_bach/,electricjimi,1491660475,,39,67,False,https://a.thumbs.redditmedia.com/vx5IjDf7R9WkAYaXAFz6KyIuNkOJsCosXa-KIUECfu8.jpg,,,,,
285,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,0,647nfn,youtube.com,Automatic Paint machine launch in India,https://www.reddit.com/r/MachineLearning/comments/647nfn/automatic_paint_machine_launch_in_india/,preetrk,1491666152,,0,1,False,default,,,,,
286,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,0,647oj5,artificialbrain.xyz,Life in 2030: Humankind and the Machine,https://www.reddit.com/r/MachineLearning/comments/647oj5/life_in_2030_humankind_and_the_machine/,Mussem17,1491666501,,0,1,False,default,,,,,
287,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,1,647qtk,self.MachineLearning,[D] Building ad ata annotation platform. What do you think?,https://www.reddit.com/r/MachineLearning/comments/647qtk/d_building_ad_ata_annotation_platform_what_do_you/,TalkingJellyFish,1491667242,"Hi all, 
I've run a  few annotation projects in the past to get data to train on. We've used excel, Brat/Anafora and rolled our own ad hoc solution at different times. 
I want a solution that is web based and cloud native, with a straightforward way to define annotation schemas  etc. 
I haven't found one yet and am thinking of building one. Before I do, I thought I'd ask here if anyone else would found something like this useful? 
Also, 

What are your current pain points in annotating data ? 
Would you/ your organisation annotate more if it were easier? 
Anything else you think I should think of ? 

What I know so far
I've used Anafora and Brat, which both offer nice front ends but 
aren't cloud native so it's not trivial to scale annotation efforts inside / outside of the organisation. Also, the fact that they write/read from files requires extra work to integrate with the rest of our pipeline. 

What do you think? ",4,0,False,self,,,,,
288,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,1,647stz,self.MachineLearning,Pre-built caffe on raspberry pi 3,https://www.reddit.com/r/MachineLearning/comments/647stz/prebuilt_caffe_on_raspberry_pi_3/,LoulouMonster,1491667846,[removed],0,1,False,default,,,,,
289,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,1,647t6v,youtube.com,NEW TECHNOLOGY saag Cutter Shiva machine,https://www.reddit.com/r/MachineLearning/comments/647t6v/new_technology_saag_cutter_shiva_machine/,preetrk,1491667949,,0,1,False,default,,,,,
290,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,1,647tyn,machinebox.io,Learning faces with Machine Box (Inexpensive machine learning in a Docker container),https://www.reddit.com/r/MachineLearning/comments/647tyn/learning_faces_with_machine_box_inexpensive/,matryer,1491668193,,0,1,False,default,,,,,
291,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,1,647v6d,self.MachineLearning,Feel confused about the matrix differential.,https://www.reddit.com/r/MachineLearning/comments/647v6d/feel_confused_about_the_matrix_differential/,serenade4,1491668570,[removed],0,1,False,default,,,,,
292,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,1,6481kr,aioptify.com,"Top 16 ML, NLP, and Data Mining Books",https://www.reddit.com/r/MachineLearning/comments/6481kr/top_16_ml_nlp_and_data_mining_books/,kjahan,1491670538,,1,1,False,default,,,,,
293,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,2,648al4,self.MachineLearning,[D] Inquiry (/Request for help) regarding washed out colors of the results of my attempt to recreate CycleGAN,https://www.reddit.com/r/MachineLearning/comments/648al4/d_inquiry_request_for_help_regarding_washed_out/,[deleted],1491673247,[deleted],0,1,False,default,,,,,
294,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,4,648yb5,self.MachineLearning,[P] Project on Sports Engineering,https://www.reddit.com/r/MachineLearning/comments/648yb5/p_project_on_sports_engineering/,[deleted],1491680486,[deleted],1,0,False,default,,,,,
295,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,5,6498rm,self.MachineLearning,[P] Training a car classifier to recognize trim level?,https://www.reddit.com/r/MachineLearning/comments/6498rm/p_training_a_car_classifier_to_recognize_trim/,thevidyy,1491683840,"I'm quite new to ML, but ultimately I want to apply these techniques to an idea I have which stemmed from this paper: https://cseweb.ucsd.edu/classes/wi08/cse190-a/reports/scheung.pdf. Recognizing the make and model of an image of a car. I couldn't find much on this topic - it doesn't seem like much has been done on this area where very specific features + details of a car could be learned to detect the specific trims of a car (Honda Civic LX vs. Honda Civic EX, for example). 

The CNN approach seems like it would be a good idea for this, but if anyone has better insight into how this could be done, I'm all ears. :)

But one specific question I have to start out with is on the data I would have to gather - what would the training data have to look like to undergo this task? Would this data be any different if I decided that instead of CNN's, I'll use SVM's instead?",3,5,False,self,,,,,
296,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,5,6499bs,self.MachineLearning,[D] Reinforcement learning without MDPs?,https://www.reddit.com/r/MachineLearning/comments/6499bs/d_reinforcement_learning_without_mdps/,heart_on,1491684025,Are all reinforcement learning tasks formulated as Markov Decision Processes? Are there alternative formulations for these problems? ,16,8,False,self,,,,,
297,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,6,649dt1,self.MachineLearning,(1 million+ rows) rows of health care data,https://www.reddit.com/r/MachineLearning/comments/649dt1/1_million_rows_rows_of_health_care_data/,floating_on_a_wave,1491685466,[removed],0,1,False,default,,,,,
298,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,6,649ejr,self.MachineLearning,[D] Help remembering url of learning resource,https://www.reddit.com/r/MachineLearning/comments/649ejr/d_help_remembering_url_of_learning_resource/,Eddyaknow,1491685719,A couple of months back there was this website posted on here that listed almost any ML and DL topic with the associated prerequisites needed represented as nodes connected by edges. I've been looking for days but still didn't find it again. If anyone knows what I'm talking about please share the link.,2,2,False,self,,,,,
299,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,7,649p2o,medium.com,Introducing the Deep Learning Canvas  Intuition Machine,https://www.reddit.com/r/MachineLearning/comments/649p2o/introducing_the_deep_learning_canvas_intuition/,based2,1491689199,,0,1,False,default,,,,,
300,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,11,64atgy,techcrunch.com,Google DeepMind open sources Sonnet,https://www.reddit.com/r/MachineLearning/comments/64atgy/google_deepmind_open_sources_sonnet/,[deleted],1491703658,[deleted],0,1,False,default,,,,,
301,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,12,64b22h,medium.com,[P] Learning to Learn by Gradient Descent by Gradient Descent as simple as possible in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/64b22h/p_learning_to_learn_by_gradient_descent_by/,LionJones,1491707036,,17,26,False,https://b.thumbs.redditmedia.com/KSCv1TV5VwlQ9MGS1aj5ahYvnZ7KviMoFgh1WqCRkdk.jpg,,,,,
302,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,12,64b6qd,youtube.com,[R] RI Seminar: Sergey Levine : Deep Robotic Learning,https://www.reddit.com/r/MachineLearning/comments/64b6qd/r_ri_seminar_sergey_levine_deep_robotic_learning/,Buck-Nasty,1491708938,,0,1,False,default,,,,,
303,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,13,64bbby,self.MachineLearning,"Any work similar to ""Natural Language Processing (almost) from Scratch"" more recently ?",https://www.reddit.com/r/MachineLearning/comments/64bbby/any_work_similar_to_natural_language_processing/,wavelander,1491710850,[removed],0,1,False,default,,,,,
304,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,13,64bdk6,self.MachineLearning,DDPG code for TORCS does not converge to an optimal policy,https://www.reddit.com/r/MachineLearning/comments/64bdk6/ddpg_code_for_torcs_does_not_converge_to_an/,Amir_AI,1491711807,[removed],0,1,False,default,,,,,
305,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,13,64bhck,self.MachineLearning,[D] Using neural networks in Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/64bhck/d_using_neural_networks_in_reinforcement_learning/,chain20,1491713510,"Neural networks to approximate value functions or generate policies have been giving me trouble consistently ever since I started playing with RL. 

For instance, here is a Policy Gradient implementation for Gym CartPole problem that never learns a good policy and I don't know why.
https://gist.github.com/anonymous/9db5fba2f8cc7793c096404779ab79a2

I have also implemented value function approximators using neural networks with and without experience replay and those networks don't converge either. Is there a trick to making Neural networks work?

PS: I also posted a similar question in the r/MLQuestions, but did not get any response.",13,3,False,self,,,,,
306,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,14,64bnqs,self.MachineLearning,Any big discovery in AI will be hidden as AI is the most academically and commercially competitive field in existence due to effect on every industry and human state of being.,https://www.reddit.com/r/MachineLearning/comments/64bnqs/any_big_discovery_in_ai_will_be_hidden_as_ai_is/,onvalleysilic,1491716522,[removed],0,1,False,default,,,,,
307,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,16,64bxv9,arxiv.org,Best Practices for Applying Deep Learning to Novel Applications,https://www.reddit.com/r/MachineLearning/comments/64bxv9/best_practices_for_applying_deep_learning_to/,based2,1491722013,,1,1,False,default,,,,,
308,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,18,64ccux,sigarch.org,The Unreasonable Ineffectiveness of Machine Learning in Computer Systems Research,https://www.reddit.com/r/MachineLearning/comments/64ccux/the_unreasonable_ineffectiveness_of_machine/,Barbas,1491731223,,0,1,False,default,,,,,
309,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,19,64cft6,self.MachineLearning,On the Optimal Learning Rate of a Neuron (it seems there's a closed-form solution),https://www.reddit.com/r/MachineLearning/comments/64cft6/on_the_optimal_learning_rate_of_a_neuron_it_seems/,[deleted],1491733045,[removed],0,1,False,default,,,,,
310,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,19,64chxq,gananath.github.io,DrugAI-Gen.py: Genereate drug like molecules using LSTM Network,https://www.reddit.com/r/MachineLearning/comments/64chxq/drugaigenpy_genereate_drug_like_molecules_using/,[deleted],1491734306,[deleted],0,1,False,default,,,,,
311,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,19,64civ1,gananath.github.io,[P] DrugAI-Gen.py: Generate drug like molecules using LSTM Network,https://www.reddit.com/r/MachineLearning/comments/64civ1/p_drugaigenpy_generate_drug_like_molecules_using/,gananath,1491734914,,22,51,False,default,,,,,
312,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,20,64cl3v,medium.com,Machine Learning A-Z: Hands-On Python &amp;amp; R In Data Science,https://www.reddit.com/r/MachineLearning/comments/64cl3v/machine_learning_az_handson_python_amp_r_in_data/,vasira,1491736207,,0,1,False,default,,,,,
313,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,21,64cqpg,self.MachineLearning,[P] Training AlexNet using Keras and Theano,https://www.reddit.com/r/MachineLearning/comments/64cqpg/p_training_alexnet_using_keras_and_theano/,[deleted],1491739219,[deleted],0,1,False,default,,,,,
314,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,21,64cs0a,self.MachineLearning,[P] Releasing codes for training AlexNet using Keras,https://www.reddit.com/r/MachineLearning/comments/64cs0a/p_releasing_codes_for_training_alexnet_using_keras/,drahul39,1491739840,"Opensourcing my codes for training AlexNet using Keras, in three useful scenarios :-

1. Training from scratch
2. Finetuning a pre-trained model
3. Extracting features from a specific layer

Github link : https://github.com/duggalrahul/AlexNet-Experiments-Keras

Blog post   : https://rahulduggal2608.wordpress.com/2017/04/02/alexnet-in-keras/

Would love to take up suggestions/critical comments. Please report any bugs/issues under the issues section on the github project webpage.

Thanks,
Rahul Duggal",18,11,False,self,,,,,
315,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,21,64curp,self.MachineLearning,[D] On the Optimal Learning Rate of a Neuron (with closed-form solutions),https://www.reddit.com/r/MachineLearning/comments/64curp/d_on_the_optimal_learning_rate_of_a_neuron_with/,cheshirecat426,1491741174,[removed],0,1,False,default,,,,,
316,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,22,64d07a,deburringandchamferingmachine.wordpress.com,How to Avail all the Industrial Machines Tools from the Professional Vendors,https://www.reddit.com/r/MachineLearning/comments/64d07a/how_to_avail_all_the_industrial_machines_tools/,wsiukweb,1491743668,,0,1,False,default,,,,,
317,MachineLearning,t5_2r3gv,2017-4-9,2017,4,9,22,64d1o6,wsiukweb.soup.io,Find Out More about High Quality Packaging Manufacturer,https://www.reddit.com/r/MachineLearning/comments/64d1o6/find_out_more_about_high_quality_packaging/,wsiukweb,1491744309,,0,1,False,default,,,,,
318,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,0,64dkcf,self.MachineLearning,How does pruning work conceptually?,https://www.reddit.com/r/MachineLearning/comments/64dkcf/how_does_pruning_work_conceptually/,dejormo,1491751303,[removed],0,1,False,default,,,,,
319,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,1,64dtk3,self.MachineLearning,[D] Is it normal to have washed out colors on the results of CycleGAN?,https://www.reddit.com/r/MachineLearning/comments/64dtk3/d_is_it_normal_to_have_washed_out_colors_on_the/,danieltan07,1491754381,"Hi, I am student trying to study deep learning and GANs. I am new to both and I wanted to try recreating the CycleGAN paper in order to understand it more. (https://arxiv.org/pdf/1703.10593.pdf)

I am using tensorflow and I used their open sourced code as a guide. However, after training for 200 epochs, my results looked low quality and the colors are washed out unlike their results. I also tried training it a bit longer but I did not see any difference. I used their summer-winter yosemite dataset. There are some semblance of the transformations so I think I am not too far off. 

Is this normal or am I doing something wrong?

Here is the link to my code: https://github.com/danieltan07/tensorflow-cycle-gan


Sample Results of the code: 

http://tinyimg.io/i/pITQS9z.png


http://tinyimg.io/i/FdzZbbO.png


http://tinyimg.io/i/E0BQA8p.png


UPDATE: Thank you for the help. The problem really was the way I was normalizing the data. I fixed it now. =)",12,16,False,self,,,,,
320,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,1,64dzra,self.MachineLearning,"[P] Prediction of store, product, supply and price / News Vendor Problem",https://www.reddit.com/r/MachineLearning/comments/64dzra/p_prediction_of_store_product_supply_and_price/,TheCocoanaut,1491756370,"Hi there!

So I'm working on this quite interesting but also very difficult (for me at least) problem.

I have a fixed number of products (&lt;&lt; 100). At the beginning of the month I purchase a number of each of these products (not part of my problem).  I then have to predict the supply, the price and the product type and store location per day for one month.

I have a lot of data about the store, demand, supply, demand bid, supply bid, prices and so on, and my target is to generate a plan of supplies with a price that optimizes the sales for all my stores, without loosing any products at the end of the month.

Some constraints:

* I *cannot* sell more than I have, so the sum of all supplies of a month for *all* stores must not exceed the number of products I purchased at the beginning of the month
* I supply the stores from the initial stock that I purchased at the beginning of the month
* I only care about a one month forecast
* The stores have no interdependency between each other w.r.t. supply/demand


My thoughts: I can reduce the model by creating one per product. My plan was to do a two-step prediction, one with a simple forecast for the prices of the product (maybe even per store), and then predict the supply I have to stock per month. But especially due to the constraints and my lack of statistical modeling in econometrics I can't come up with a model (really, I haven't even tried a simple one).

The literature on the field  sucks. Sorry to be so bold, but the papers are of low quality and are almost exclusively behind paywalls, which I despise.
Some important/good papers I think:

* [Applying Deep Learning to the Newsvendor Problem](https://arxiv.org/abs/1607.02177)
(Lacks complexity, because it only predicts the demand of a number of products in one store, I think. Also no code available.)
* [The Big Data Newsvendor](https://dspace.mit.edu/bitstream/handle/1721.1/81412/SWP_5032-13_BigDataNewsVendor_7Oct13.pdf?sequence=5)
(I have absolutely no idea what they are doing.)

Some hints in *any* direction are much appreciated. I just need some general hints on how to approach this problem. Cheers!",2,3,False,self,,,,,
321,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,1,64e043,self.MachineLearning,[D] I run a dating app called Sapio. I'm looking for some help telling interesting stories with my data.,https://www.reddit.com/r/MachineLearning/comments/64e043/d_i_run_a_dating_app_called_sapio_im_looking_for/,[deleted],1491756474,[deleted],0,0,False,default,,,,,
322,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,1,64e0an,github.com,[P] Predicting Horse Racing Results using SVR,https://www.reddit.com/r/MachineLearning/comments/64e0an/p_predicting_horse_racing_results_using_svr/,dplouffe,1491756533,,10,41,False,https://b.thumbs.redditmedia.com/Oiape2AmmD7utmj8VhBAc38vcEoYkYmNDb1Zl-L8uFE.jpg,,,,,
323,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,5,64fbs1,github.com,iNaturalist 2017 - Large scale image classification featuring 5000 species and 675K images.,https://www.reddit.com/r/MachineLearning/comments/64fbs1/inaturalist_2017_large_scale_image_classification/,fgvc2017,1491771143,,18,30,False,https://b.thumbs.redditmedia.com/8-_chEpNdF12LI7sinlOs6ANRvKXcVJbRkX7tCl3xZE.jpg,,,,,
324,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,6,64fnya,self.MachineLearning,"[D] Machine Learning masters decision in Europe. Aalto, Edinburgh, UCL",https://www.reddit.com/r/MachineLearning/comments/64fnya/d_machine_learning_masters_decision_in_europe/,noraizon,1491775022,"Hello everyone!  
I'm an undergrad student aiming for a masters programme next year in ML or Artificial Intelligence focused on ML. However as an indecisive person I'd like to read others' opinions too.  
First and foremost, I want to study in a place that teaches me well. I'm sick of mediocre teachers in my country. If the place has recognition it's also welcome, it could help when someone read my CV. I don't know if I want to go for a PhD after that but I wouldn't rule it out.  

After a lot of research here is my selection:

+ Aalto University. Machine Learning and Data Mining. 2y. [Page](http://www.aalto.fi/en/studies/education/programme/machine_learning_and_data_mining/) and [programme](http://studyguides.aalto.fi/2017-ccis/majors/machine-learning-and-data-mining.html).
+ The University of Edinburgh. Artificial Intelligence (""specialist area"" of Machine Learning). 1y. [Page](http://www.ed.ac.uk/studying/postgraduate/degrees?id=107&amp;r=site/view) and [programme](http://web.inf.ed.ac.uk/infweb/student-services/ito/students/taught-msc-2016/programme-guide/specialist-areas/machine-learning)
+ Barcelona School of Informatics. Master in Artificial Intelligence (Knowledge Engineering and Machine Learning ""intensification"") 1.5y. [Page](http://www.fib.upc.edu/en/studies/masters/master-artificial-intelligence) and [programme](http://www.fib.upc.edu/en/studies/masters/master-artificial-intelligence/degree-subject-curriculum)

More things to consider. I've got an offer in Aalto. I haven't yet applied to Edinburgh but about to. I've already applied to Barcelona, waiting for response. I know about UCL but I think it's to late by now. Plus annoying my referees so that they can send them their form about me and the 75 fee so that they just look at my application really pisses me off.

&amp;nbsp;

I'd like to know your opinion on these universities so I can finally make up my mind. And/or hear about other suggestions.  
Thank you so much.

&amp;nbsp;

Edit: Thanks to /u/biodecus for Edinburgh programme link.",24,14,False,self,,,,,
325,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,7,64fpxx,reddit.com,"Is my neural network right, can't converge it",https://www.reddit.com/r/MachineLearning/comments/64fpxx/is_my_neural_network_right_cant_converge_it/,[deleted],1491775645,[deleted],0,1,False,default,,,,,
326,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,9,64gdjv,self.MachineLearning,Keras 2.0 Memory Leak?,https://www.reddit.com/r/MachineLearning/comments/64gdjv/keras_20_memory_leak/,butWhoWasBee,1491783513,[removed],0,1,False,default,,,,,
327,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,9,64gfer,self.MachineLearning,Got masters admits. Need some help deciding if what I'm pursuing is viable,https://www.reddit.com/r/MachineLearning/comments/64gfer/got_masters_admits_need_some_help_deciding_if/,[deleted],1491784137,[removed],0,1,False,default,,,,,
328,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,9,64ghen,self.MachineLearning,[D] Got admits. Need help deciding whether what I'm trying to pursue is viable.,https://www.reddit.com/r/MachineLearning/comments/64ghen/d_got_admits_need_help_deciding_whether_what_im/,zephyrppt,1491784806,"I've been admitted to two masters programmes for fall - EE in Columbia and CE in TAMU. I have an undergraduate degree in electronics and am interested in researching specialized neuro-morphic/cognitive processors for ML and NN. My reasoning was that since AI is getting prevalent im modern applications, it would make sense to have a dedicated processor for such tasks in portable machines (similar to GPUs for graphics). My question is what is the state of research in this field. This would effectively help decide which program to pursue. Do companies which work in this field, such as qualcomm, IBM, HP, hire masters, or do they look for PhD candidates. If they are fine with masters, I might opt for Columbia as it will give me an opportunity to work for these companies and pay off any hefty loan I'd have to take. Otherwise, if PhD candidates are preferred, TAMU would be better as it would allow me to not be under too much financial burden and I can then work on pursuing a PhD. I've already talked to a few people studying in these programmes, but was looking for a few insights on what people working in the industry think.",16,7,False,self,,,,,
329,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,10,64go2l,self.MachineLearning,Why doesn't CycleGAN cite DiscoGAN? Aren't they basically the same?,https://www.reddit.com/r/MachineLearning/comments/64go2l/why_doesnt_cyclegan_cite_discogan_arent_they/,LK1234KL,1491787019,[removed],0,1,False,default,,,,,
330,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,11,64h13h,medium.com,Machines capable of Reasoning and Abstracting,https://www.reddit.com/r/MachineLearning/comments/64h13h/machines_capable_of_reasoning_and_abstracting/,virene,1491791564,,0,1,False,default,,,,,
331,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,12,64h6p5,fishfeedmachine.com,Comparison between Single &amp; Twin Screw Feed Pellet Extruder,https://www.reddit.com/r/MachineLearning/comments/64h6p5/comparison_between_single_twin_screw_feed_pellet/,fishfoodmachine,1491793434,,0,1,False,default,,,,,
332,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,12,64h9p2,gist.github.com,[P] Keras implementation of new kind of RNN using attention mechanism,https://www.reddit.com/r/MachineLearning/comments/64h9p2/p_keras_implementation_of_new_kind_of_rnn_using/,jostmey,1491794511,,13,27,False,https://b.thumbs.redditmedia.com/OcWWr4cuG-hyS8ZK1vOnZDJomdupffRlqNEjcNTMX-I.jpg,,,,,
333,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,12,64hdid,youtube.com,Hey! How do adhesive dispensing equipment operating,https://www.reddit.com/r/MachineLearning/comments/64hdid/hey_how_do_adhesive_dispensing_equipment_operating/,mixmachinery,1491795982,,1,1,False,default,,,,,
334,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,13,64him0,self.MachineLearning,Where to find machine learning engineers/scientists?,https://www.reddit.com/r/MachineLearning/comments/64him0/where_to_find_machine_learning_engineersscientists/,artificialridge,1491797952,[removed],0,1,False,default,,,,,
335,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,14,64hpdl,forbes.com,The Great Strengths and Important Limitations Of Google's Machine Learning Chip,https://www.reddit.com/r/MachineLearning/comments/64hpdl/the_great_strengths_and_important_limitations_of/,Intuz_Solutions,1491800767,,0,1,False,default,,,,,
336,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,14,64hvl6,arxiv.org,Particle physics application: identifying top quarks with DNNs,https://www.reddit.com/r/MachineLearning/comments/64hvl6/particle_physics_application_identifying_top/,logisticQuark,1491803551,,0,1,False,default,,,,,
337,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,15,64hyes,self.MachineLearning,[D] Machine Learning masters in UK,https://www.reddit.com/r/MachineLearning/comments/64hyes/d_machine_learning_masters_in_uk/,mlmlmlmlmlaway,1491804870,"Hi everyone,

I intend to study Machine Learning starting from autumn this year. I've applied to and received offers from 3 universities and need help picking between the 3.

I did my bachelors in electrical engineering at Imperial and have been working for a tech consulting company for a year and a half. During my time at Imperial, I did a research placement optimising machine learning algorithms using GPUs. Other than that I do not have much formal training in ML.

The three offers that I have are:

- UCL CSML: I quite like the flexibility of this course. They accepted me without any interviews whatsoever which makes me think having this degree might not differentiate me from the rest of the crowd.

- Oxford MSc CompSci: General computer science course can allow me to explore other areas but will also mean I am less likely to better skilled in ML. Quantum computing course looks interesting though.

- Cambridge MPhil ML, Speech and Language Technology: In depth focus on ML and NLP. The downside is there is little flexibility.

My future career plan is to continue with a PhD. Since I am a non-EU student, it would be more likely for me to find a funded programme in the US and will likely apply there. If I don't make it, I'll try for Entrepreneur First to try and establish an ML startup. Barring that, I'd like to work for some sort of ML consulting firm like Quantum Black or Palantir or go back to a better consulting company.

I'm currently leaning towards Cambridge. I believe this course will provide me with sufficient ML knowledge unlike the Oxford course. Cambridge degrees are generally valued a bit more over UCL and as a foreigner I would also get an extra 6 months under the new tier 4 visa pilot scheme if I go with Cambridge or Oxford. Plus there are lots of cool tech startups in Cambridge.",2,3,False,self,,,,,
338,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,15,64hzj9,youtube.com,CNN-SLAM: Real-time dense monocular SLAM with learned depth prediction,https://www.reddit.com/r/MachineLearning/comments/64hzj9/cnnslam_realtime_dense_monocular_slam_with/,bboyjkang,1491805393,,1,1,False,default,,,,,
339,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,16,64i8mo,deepmind.com,[N] Next AlphaGo Match announced,https://www.reddit.com/r/MachineLearning/comments/64i8mo/n_next_alphago_match_announced/,Paranaix,1491809956,,28,287,False,https://b.thumbs.redditmedia.com/4YMeKIOE8xt48OA0sGFG7WzFuVXKXdjY9XWKIRuT44k.jpg,,,,,
340,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,17,64idyn,self.MachineLearning,Real time face segmentation and key points detection,https://www.reddit.com/r/MachineLearning/comments/64idyn/real_time_face_segmentation_and_key_points/,mafail,1491812879,[removed],0,1,False,default,,,,,
341,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,18,64ii11,allsolutionproducts.com,gear deburring,https://www.reddit.com/r/MachineLearning/comments/64ii11/gear_deburring/,wsiukweb,1491815048,,0,1,False,default,,,,,
342,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,20,64j4kk,arxiv.org,[R] Adversarial Generator-Encoder Networks,https://www.reddit.com/r/MachineLearning/comments/64j4kk/r_adversarial_generatorencoder_networks/,dmitry_ulyanov,1491825392,,7,9,False,default,,,,,
343,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,21,64jbiw,self.MachineLearning,Goal Representation,https://www.reddit.com/r/MachineLearning/comments/64jbiw/goal_representation/,Birzhanm,1491827941,[removed],0,1,False,default,,,,,
344,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,22,64jk3p,self.MachineLearning,[P] identifying hand usage through pressure data,https://www.reddit.com/r/MachineLearning/comments/64jk3p/p_identifying_hand_usage_through_pressure_data/,Stripes96,1491830817,"I have data for pressure on various points on a hand as they vary with time, but am a tad confused in terms of feature selection. As it stands I want to design a decision tree which will take in a 5 second sample of pressure data from all 18 sensors and effectively decide whether it's high/medium/low intensity.

I'm trying to work out which features to use, and am trying to avoid using ""max value"" since this can so easily be thrown by a single ""rogue"" reading or even noise.

I've come up with

Median/mean/mode of overall hand, of each area(fingers,palm thumb), or indeed of each individual sensor

percentiles of overall/each area/each sensor - similar to max/min but slightly more robust

Most used sensor (highest integral)

Number of sensors actually used

This seems like a huge huge number of features to then analyse(too many) - how should I decide?!",1,2,False,self,,,,,
345,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,22,64jonw,datasciencechallenge.org,UK Government releases Kaggle-like data science challenge platform to solve intelligence problems with machine learning,https://www.reddit.com/r/MachineLearning/comments/64jonw/uk_government_releases_kagglelike_data_science/,[deleted],1491832272,[deleted],2,3,False,default,,,,,
346,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,23,64js5f,self.MachineLearning,[D] dropout marriage,https://www.reddit.com/r/MachineLearning/comments/64js5f/d_dropout_marriage/,godspeed_china,1491833294,[removed],0,0,False,default,,,,,
347,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,23,64jwde,self.MachineLearning,[D] Machine Learning - WAYR (What Are You Reading) - Week 22,https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/,Mandrathax,1491834515,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|
|----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted paper last week :

[Python Machine Learning](https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130) (Amazon link for lack of better)

[Hierarchical Temporal Memory](https://numenta.org/htm-school/)

Besides that, there are no rules, have fun.
",11,16,False,self,,,,,
348,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,23,64jyp7,d10genes.github.io,[P] Forecasting pollen counts with RNNs,https://www.reddit.com/r/MachineLearning/comments/64jyp7/p_forecasting_pollen_counts_with_rnns/,wcb10,1491835190,,5,6,False,default,,,,,
349,MachineLearning,t5_2r3gv,2017-4-10,2017,4,10,23,64k1af,self.MachineLearning,I can't tell how good IBM Watson is. Please help.,https://www.reddit.com/r/MachineLearning/comments/64k1af/i_cant_tell_how_good_ibm_watson_is_please_help/,datatatatata,1491835920,[removed],0,1,False,default,,,,,
350,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,3,64lcth,youtube.com,[R] Yejin Choi: Representation Learning of Grounded Language and Knowledge: with and without End-to-End Learning,https://www.reddit.com/r/MachineLearning/comments/64lcth/r_yejin_choi_representation_learning_of_grounded/,downtownslim,1491848653,,0,15,False,https://b.thumbs.redditmedia.com/aDRp3FanwQjwAW9KdFVV9W-H7XdyT-iRYf7Mmln2UKM.jpg,,,,,
351,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,3,64lkry,rylanschaeffer.github.io,[D] Explanation of DeepMind's Neural Turing Machine,https://www.reddit.com/r/MachineLearning/comments/64lkry/d_explanation_of_deepminds_neural_turing_machine/,RSchaeffer,1491850751,,23,147,False,https://a.thumbs.redditmedia.com/IZHl-VKWLk6B-JLjpGlqi3bWY9dAxOeazE6LILgpEd0.jpg,,,,,
352,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,5,64m8ru,nbviewer.jupyter.org,[P] Modern NLP in Python - What you can learn about food by analyzing a million Yelp reviews,https://www.reddit.com/r/MachineLearning/comments/64m8ru/p_modern_nlp_in_python_what_you_can_learn_about/,pmigdal,1491857033,,9,51,False,https://b.thumbs.redditmedia.com/_OOPpbo9DKuUkHeXyhV1FaDIVpYDHstudJK2I-nZATo.jpg,,,,,
353,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,6,64movl,self.MachineLearning,Using reddit to crowdsource classification microtasks - is it viable?,https://www.reddit.com/r/MachineLearning/comments/64movl/using_reddit_to_crowdsource_classification/,Arktic,1491861520,[removed],0,1,False,default,,,,,
354,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,9,64nm1p,knovigator.com,Using machine learning to improve search relevance - annotated with inspired research,https://www.reddit.com/r/MachineLearning/comments/64nm1p/using_machine_learning_to_improve_search/,metamitya,1491871424,,0,2,False,default,,,,,
355,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,11,64o579,arxiv.org,"[R] ""Bayesian Recurrent Neural Networks"", Fortunato et al 2017",https://www.reddit.com/r/MachineLearning/comments/64o579/r_bayesian_recurrent_neural_networks_fortunato_et/,gwern,1491877537,,13,93,False,default,,,,,
356,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,11,64o7yd,arxiv.org,[R] Using Human Brain Activity to Guide Machine Learning,https://www.reddit.com/r/MachineLearning/comments/64o7yd/r_using_human_brain_activity_to_guide_machine/,clbam8,1491878425,,4,8,False,default,,,,,
357,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,14,64oxdi,investopedia.com,Google's Machine Learning Chips Beat Intel and Nvidia,https://www.reddit.com/r/MachineLearning/comments/64oxdi/googles_machine_learning_chips_beat_intel_and/,Angelica1331,1491887762,,0,1,False,default,,,,,
358,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,14,64p11q,self.MachineLearning,Need help in building a solid Deep learning Rig,https://www.reddit.com/r/MachineLearning/comments/64p11q/need_help_in_building_a_solid_deep_learning_rig/,samizquest,1491889382,[removed],0,1,False,default,,,,,
359,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,14,64p2pb,arxiv.org,"[R] Privacy-Preserving Visual Learning Using Doubly Permuted Homomorphic Encryption, Yonetani et.al. Federated Learning with Homomorphic Encryption.",https://www.reddit.com/r/MachineLearning/comments/64p2pb/r_privacypreserving_visual_learning_using_doubly/,VishDev,1491890098,,1,4,False,default,,,,,
360,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,15,64p3jp,self.MachineLearning,Easy to Use Machine Learning Engine,https://www.reddit.com/r/MachineLearning/comments/64p3jp/easy_to_use_machine_learning_engine/,[deleted],1491890457,[removed],0,1,False,default,,,,,
361,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,15,64p57f,self.MachineLearning,[D] Easy to Use Machine Learning Engine,https://www.reddit.com/r/MachineLearning/comments/64p57f/d_easy_to_use_machine_learning_engine/,[deleted],1491891166,[removed],2,0,False,default,,,,,
362,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,15,64p6l4,mixmachinery.com,What do you think of strong tile adhesive glue mixing tank?,https://www.reddit.com/r/MachineLearning/comments/64p6l4/what_do_you_think_of_strong_tile_adhesive_glue/,mixmachinery,1491891817,,1,1,False,default,,,,,
363,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,16,64pddn,journal.frontiersin.org,[N] Machine Learning Methods for High-Level Cognitive Capabilities in Robotics,https://www.reddit.com/r/MachineLearning/comments/64pddn/n_machine_learning_methods_for_highlevel/,nocortex,1491894989,,0,4,False,https://b.thumbs.redditmedia.com/V6gsCwxBfW0w955tAef8N3CT5fhVjifRykutGCn3PyY.jpg,,,,,
364,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,16,64pf65,54.174.116.134,Custom feature attributes combined with historical minute-by-minute stock datasets,https://www.reddit.com/r/MachineLearning/comments/64pf65/custom_feature_attributes_combined_with/,[deleted],1491895843,[deleted],0,1,False,default,,,,,
365,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,16,64pfut,ocadotechnology.com,Building ML models is hard. Deploying them in real business environments is harder.,https://www.reddit.com/r/MachineLearning/comments/64pfut/building_ml_models_is_hard_deploying_them_in_real/,alexvoica,1491896186,,0,1,False,default,,,,,
366,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,16,64pibk,54.174.116.134,[R] Custom feature attributes combined with historical minute-by-minute stock datasets,https://www.reddit.com/r/MachineLearning/comments/64pibk/r_custom_feature_attributes_combined_with/,[deleted],1491897483,[deleted],0,0,False,default,,,,,
367,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,17,64pj72,machine-rockstars.com,German Autolabs Assistent Chris,https://www.reddit.com/r/MachineLearning/comments/64pj72/german_autolabs_assistent_chris/,flezzfx,1491897904,,0,1,False,default,,,,,
368,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,17,64pkm8,self.MachineLearning,How to ensemble object detectors?,https://www.reddit.com/r/MachineLearning/comments/64pkm8/how_to_ensemble_object_detectors/,Dagusiu,1491898641,[removed],0,1,False,default,,,,,
369,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,18,64pr4m,arxiv.org,[R] [1704.02966] Loss Max-Pooling for Semantic Image Segmentation,https://www.reddit.com/r/MachineLearning/comments/64pr4m/r_170402966_loss_maxpooling_for_semantic_image/,NicolasGuacamole,1491901997,,3,1,False,default,,,,,
370,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,18,64pswe,arxiv.org,Beyond triplet loss: a deep quadruplet network for person re-identification,https://www.reddit.com/r/MachineLearning/comments/64pswe/beyond_triplet_loss_a_deep_quadruplet_network_for/,lightningCAS,1491902893,,0,1,False,default,,,,,
371,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,18,64pv8a,medium.com,Why I hate current recommendation systems,https://www.reddit.com/r/MachineLearning/comments/64pv8a/why_i_hate_current_recommendation_systems/,sharkasy,1491904068,,0,1,False,default,,,,,
372,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,18,64pvcg,self.MachineLearning,Resources on insurance fraud detection,https://www.reddit.com/r/MachineLearning/comments/64pvcg/resources_on_insurance_fraud_detection/,[deleted],1491904129,[removed],0,1,False,default,,,,,
373,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,20,64qaq8,self.MachineLearning,Fisher information,https://www.reddit.com/r/MachineLearning/comments/64qaq8/fisher_information/,jackdaniels79,1491910954,[removed],0,1,False,default,,,,,
374,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,20,64qby3,arxiv.org,[R] [1704.02071] Convolutional Neural Pyramid for Image Processing,https://www.reddit.com/r/MachineLearning/comments/64qby3/r_170402071_convolutional_neural_pyramid_for/,NicolasGuacamole,1491911448,,14,0,False,default,,,,,
375,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,21,64qdl1,github.com,AWSLambdaFace: CNN based face recognition that you deploy on AWS lambda.,https://www.reddit.com/r/MachineLearning/comments/64qdl1/awslambdaface_cnn_based_face_recognition_that_you/,computer-visionary,1491912070,,0,1,False,default,,,,,
376,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,21,64qe2v,newsroom.intel.com,Intel starts collaboration with Chainer developers,https://www.reddit.com/r/MachineLearning/comments/64qe2v/intel_starts_collaboration_with_chainer_developers/,DanielleMolloy,1491912236,,0,1,False,default,,,,,
377,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,21,64qjx4,arxiv.org,[R] Optical Flow Requires Multiple Strategies (but only one network),https://www.reddit.com/r/MachineLearning/comments/64qjx4/r_optical_flow_requires_multiple_strategies_but/,ofirpress,1491914323,,2,8,False,default,,,,,
378,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,22,64qo1y,self.MachineLearning,Markov Chain Monte Carlo for Container Ship origin tracking,https://www.reddit.com/r/MachineLearning/comments/64qo1y/markov_chain_monte_carlo_for_container_ship/,V12dbs,1491915706,[removed],0,1,False,default,,,,,
379,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,23,64r4sg,soundcloud.com,[PODCAST] on Chatbots - Interview with Stefan Kojouharov from Chatbot's Life and more,https://www.reddit.com/r/MachineLearning/comments/64r4sg/podcast_on_chatbots_interview_with_stefan/,fastephi,1491920760,,0,1,False,default,,,,,
380,MachineLearning,t5_2r3gv,2017-4-11,2017,4,11,23,64rayf,blog.heuritech.com,[R] BEGAN: State of the art generation of faces with Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/64rayf/r_began_state_of_the_art_generation_of_faces_with/,felardos_loris,1491922441,,20,53,False,https://b.thumbs.redditmedia.com/HKIp3c1FDMkS34KVJxuvjC2CpoMj6rYmDi_83wO3iBY.jpg,,,,,
381,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,0,64rlv3,youtube.com,[P] Platform for subjective comparisons of video/image processing algorithms,https://www.reddit.com/r/MachineLearning/comments/64rlv3/p_platform_for_subjective_comparisons_of/,merofeev,1491925336,,1,3,False,https://b.thumbs.redditmedia.com/hjx3VWSWHAyMxKbP4bus6d30FSDjkmoQicp-rSsQ-yc.jpg,,,,,
382,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,0,64rnaq,clickbait-challenge.org,Clickbait Detection Challenge,https://www.reddit.com/r/MachineLearning/comments/64rnaq/clickbait_detection_challenge/,DanielleMolloy,1491925712,,0,1,False,default,,,,,
383,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,0,64ro95,devblogs.nvidia.com,[D] Recursive Neural Networks with PyTorch,https://www.reddit.com/r/MachineLearning/comments/64ro95/d_recursive_neural_networks_with_pytorch/,evc123,1491925969,,31,93,False,https://a.thumbs.redditmedia.com/9epyPVq0h3o3tDJ8ixukZRIfgc83ufdCkf0iKia5go4.jpg,,,,,
384,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,0,64rpje,nlp.yvespeirsman.be,"[D] Anything2Vec, or How Word2Vec Conquered NLP",https://www.reddit.com/r/MachineLearning/comments/64rpje/d_anything2vec_or_how_word2vec_conquered_nlp/,yvespeirsman,1491926301,,27,71,False,https://b.thumbs.redditmedia.com/Nr8zDfOkjo5gGyiUNQQw2B3uM2lPStEXcbT_vvaB4xc.jpg,,,,,
385,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,3,64sk8t,re-work.co,"How Deep Learning is Expected to Develop in 2017 [with insights from Baidu, OpenAI &amp; more]",https://www.reddit.com/r/MachineLearning/comments/64sk8t/how_deep_learning_is_expected_to_develop_in_2017/,reworksophie,1491934116,,0,1,False,default,,,,,
386,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,3,64skgn,re-work.co,Cognitive Robotics: Learning Environment Perception,https://www.reddit.com/r/MachineLearning/comments/64skgn/cognitive_robotics_learning_environment_perception/,reworksophie,1491934170,,0,1,False,default,,,,,
387,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,3,64snnn,blog.monkeylearn.com,Creating machine learning models to analyze startup news,https://www.reddit.com/r/MachineLearning/comments/64snnn/creating_machine_learning_models_to_analyze/,numbrow,1491934939,,0,1,False,default,,,,,
388,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,3,64sou6,medium.freecodecamp.com,[P] Big Picture Machine Learning: Classifying Text with Neural Networks and TensorFlow,https://www.reddit.com/r/MachineLearning/comments/64sou6/p_big_picture_machine_learning_classifying_text/,dbrhm,1491935226,,1,12,False,https://b.thumbs.redditmedia.com/cVMY7lB9KubNumPEVKrtnS97aVy2ctf2rZPucbBALFE.jpg,,,,,
389,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,3,64stmk,datascience.com,[P] This tool easily visualizes trends in GitHub activity for open source machine learning libraries.,https://www.reddit.com/r/MachineLearning/comments/64stmk/p_this_tool_easily_visualizes_trends_in_github/,DataScienceInc,1491936441,,0,1,False,default,,,,,
390,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,4,64sy1z,self.MachineLearning,Weka problem,https://www.reddit.com/r/MachineLearning/comments/64sy1z/weka_problem/,Wrap6462,1491937493,[removed],0,1,False,default,,,,,
391,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,4,64t9wj,self.MachineLearning,Learning long term dependencies while only providing short sequences to an LSTM : is it possible ?,https://www.reddit.com/r/MachineLearning/comments/64t9wj/learning_long_term_dependencies_while_only/,xGQ6YXJaSpGUCUAg,1491940449,[removed],0,1,False,default,,,,,
392,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,5,64tbkl,topbots.com,Understanding The Limits Of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/64tbkl/understanding_the_limits_of_deep_learning/,conradcreates,1491940877,,0,1,False,default,,,,,
393,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,5,64tga4,self.MachineLearning,Training a Softmax Linear Classifier on Android,https://www.reddit.com/r/MachineLearning/comments/64tga4/training_a_softmax_linear_classifier_on_android/,QHCG,1491942155,[removed],0,1,False,default,,,,,
394,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,5,64tk9x,self.MachineLearning,[D] Difference between Bayesian Program Learning and a model fitted using MCMC,https://www.reddit.com/r/MachineLearning/comments/64tk9x/d_difference_between_bayesian_program_learning/,ml234234,1491943220,"Hello, I recently found the paper:

Human-level concept learning through probabilistic program induction
http://web.mit.edu/cocosci/Papers/Science-2015-Lake-1332-8.pdf

But I am having trouble understanding the difference between the proposed model and fitting a bayesian model with MCMC. Can someone help me with that?

Ty",1,2,False,self,,,,,
395,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,6,64tta4,self.MachineLearning,Technical beginner question about reinforcement.,https://www.reddit.com/r/MachineLearning/comments/64tta4/technical_beginner_question_about_reinforcement/,[deleted],1491945628,[removed],0,1,False,default,,,,,
396,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,6,64tv5x,self.MachineLearning,[Discussion] seq2seq with char embeddings is not overfitting but the same model with word embeddings is overfitting a lot even after reducing model complexity and introducing dropout. What might be the reason and how to debug this problem?,https://www.reddit.com/r/MachineLearning/comments/64tv5x/discussion_seq2seq_with_char_embeddings_is_not/,cvikasreddy,1491946143,,2,1,False,self,,,,,
397,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,6,64tvwq,self.MachineLearning,What parameters are user-defined in Reinforcement Learning?,https://www.reddit.com/r/MachineLearning/comments/64tvwq/what_parameters_are_userdefined_in_reinforcement/,ptnov,1491946343,[removed],0,1,False,default,,,,,
398,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,6,64txf1,self.MachineLearning,[Discussion] Summary of Yann LeCun's perspectives on AI @ Princeton,https://www.reddit.com/r/MachineLearning/comments/64txf1/discussion_summary_of_yann_lecuns_perspectives_on/,[deleted],1491946772,[deleted],2,14,False,default,,,,,
399,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,6,64txy9,self.MachineLearning,"[P] Hi, we're a PRAXIS Lab from the University of Utah! We've made a game to help explain the",https://www.reddit.com/r/MachineLearning/comments/64txy9/p_hi_were_a_praxis_lab_from_the_university_of/,[deleted],1491946920,[deleted],0,1,False,default,,,,,
400,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,7,64u5bj,self.MachineLearning,"[P] We're a PRAXIS Lab from the University of Utah, and we made a game to help explain the process of machine learning.",https://www.reddit.com/r/MachineLearning/comments/64u5bj/p_were_a_praxis_lab_from_the_university_of_utah/,JUSTICEXE,1491948999,"Hello! Were whats called a PRAXIS Lab, from the University of Utahs Honors College.

Praxis is a greek word which more or less means applying theory to action, and a PRAXIS Lab is a yearlong course wherein a small cohort of students and professors from various majors and departments work together to apply theory we have learned to a project that will help our community.

This year the Honors College has 4 praxis labs, and ours is titled When Machines Decide: The promise peril of living in a data-driven society

During the first semester, we focused primarily on research into the world of decision making algorithms, machine learning, and their place in todays society. We also had the chance to speak with professional and academic experts in the fields of economics, data science, medicine, policing, and law, about how algorithms affect and influence their fields.

At the end of the first semester, when we were coming up with our project, we decided the most impactful thing we could do with our time and resources, was to raise the awareness of the general public on the existence algorithms, and their ubiquity in our daily lives. From day to day events like what we watch on Netflix or buy on Amazon, to more consequential things like if youre a reliable tenant or not, if youre a desirable employee or one likely to change jobs within the next year, if youre at risk for not graduating from college, and whether or not youre granted bail.

Actually, we took a special interest to algorithms as they pertain to the criminal justice system, and have used that as a focus for our project. Since our cohort has a wide range of abilities, we thought it best to use each student and professor to the best of their ability, and so have created 4 parts to our project.

1.	Justice.exe, a game we created to help our peers and other lay people gain a basic understanding of how machine learning works
2.	A 1-2 week long mini-course on machine learning and ethics geared toward college students, that can be taught in a variety of departments from data science, to business, to law, and more.
3.	Our LibGuide, an online public recourse guide that weve compiled and used to educate ourselves on the subject of decision making algorithms.
4.	A list of Best Practices for policy makers, lay public, as well as data science students.

What wed like to do is spend some time on that first one, JUSTICE.EXE.

We wanted to make this game for 2 reasons,

1.	a good portion of the class are a bunch of nerds who like making video games,
2.	we wanted to make a tool to more easily explain how algorithms learn and make their decisions

The game is not intended to replicate the actual process of how something like this would work, its purpose is instead to illustrate how machine learning works to a lay audience

In JUSTICE.EXE you take on the role of a judge and are given 50 convicts to sentence. Youre given a list of information for each convict, and asked to make a decision on whether to give them a minimum or maximum sentence for their crime. However, over time the algorithm learns what information it thinks is pertinent to your decision and removes information it believes to be inconsequential to you. This process continues until youre left with only 2 pieces of information to base your decision on, when finally, the algorithm has decided Its figured out your thought process and proceeds to sentence the last few people on it's own.

You can download the game and try it out for yourselves here: 

Android:https://play.google.com/store/apps/details?id=com.WhenMachinesDecide.Justicexe

iOS: https://itunes.apple.com/us/app/justice-exe/id1221500487?ls=1&amp;mt=8

**TL:DR** We made a game about algorithms in the criminal justice system.

Feel free to ask us any questions about the game, our project, and our class in general!

",10,22,False,self,,,,,
401,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,8,64uk36,jonolick.com,[R] DagNN vs Standard 2-Layer fully connected networks,https://www.reddit.com/r/MachineLearning/comments/64uk36/r_dagnn_vs_standard_2layer_fully_connected/,zelex,1491953310,,9,0,False,https://b.thumbs.redditmedia.com/DZTbQBL164_Z2GZKEKEO9Fx4ilRlZrRzDMNZ3xLtruA.jpg,,,,,
402,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,8,64umu8,arnabgho.github.io,MAD-GANs obtain highly diverse Generative Models,https://www.reddit.com/r/MachineLearning/comments/64umu8/madgans_obtain_highly_diverse_generative_models/,arnabgho,1491954162,,0,2,False,default,,,,,
403,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,9,64uv6l,arxiv.org,[R] struc2vec: Learning Node Representations from Structural Identity,https://www.reddit.com/r/MachineLearning/comments/64uv6l/r_struc2vec_learning_node_representations_from/,give_me_tensors,1491956769,,5,5,False,default,,,,,
404,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,9,64v0zr,self.MachineLearning,[P] How to classify a bunch of job descriptions?,https://www.reddit.com/r/MachineLearning/comments/64v0zr/p_how_to_classify_a_bunch_of_job_descriptions/,thevidyy,1491958643,"Has this been done before? If I had a database of job descriptions, how would I go about classifying these job descriptions based on job category (health, IT, education, etc.)? Would a good first step be performing unsupervised learning to cluster out the categories before performing the actual classification (maybe Naive Bayes or a random forest decision tree)? Any tips, pointers, or papers related to this task is welcome.",5,2,False,self,,,,,
405,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,10,64v1km,arxiv.org,[R] [1703.00788] A Robust Adaptive Stochastic Gradient Method for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/64v1km/r_170300788_a_robust_adaptive_stochastic_gradient/,xingdongrobotics,1491958831,,2,6,False,default,,,,,
406,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,10,64v4g4,controldesign.com,New technology pushes machine smarts to the edge,https://www.reddit.com/r/MachineLearning/comments/64v4g4/new_technology_pushes_machine_smarts_to_the_edge/,veca_dove,1491959730,,0,1,False,default,,,,,
407,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,10,64v74h,self.MachineLearning,Reinforcement learning for complex game AI,https://www.reddit.com/r/MachineLearning/comments/64v74h/reinforcement_learning_for_complex_game_ai/,Skarwild,1491960605,[removed],0,1,False,default,,,,,
408,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,13,64vy89,joshpeng.github.io,[P] CNN trained to be a Motorcycle Lean Assist,https://www.reddit.com/r/MachineLearning/comments/64vy89/p_cnn_trained_to_be_a_motorcycle_lean_assist/,joshpeng,1491969849,,30,61,False,https://b.thumbs.redditmedia.com/k8BhoFNXuk8wKccPcgQTKqB5FxjGfRkPpjT3-z98B_k.jpg,,,,,
409,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,13,64w0gz,rajarsheem.wordpress.com,Question Answering using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/64w0gz/question_answering_using_deep_learning/,rajarsheem,1491970714,,0,1,False,default,,,,,
410,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,13,64w269,self.MachineLearning,[D] Learning Inverse Map of Generator after training GAN?,https://www.reddit.com/r/MachineLearning/comments/64w269/d_learning_inverse_map_of_generator_after/,TheFlyingDrildo,1491971350,"I've seen the ALI and BiGAN frameworks.  But I was curious to why one doesn't first finish training their preferred flavor of GAN to convergence before doing the following: generate a few million noise vectors Z, use G to map Z to X, create a new network to learn G^(-1) since we have X and Z.

This seems like it would be computationally cheaper than trying to learn the inverse mapping simultaneously with the GAN objective.  But I don't really hear of people doing this, and it seems so simple, so I suspect there might be a flaw in my logic.  

I further realize that integrating learning of the inverse map with the GAN objective can lead to better learned features in the latent space as described in the papers, but several new GAN frameworks (WGAN, BEGAN, LS-GAN, etc...) have popped up since that time.  I was wondering if anybody had explored whether the advantages in representation brought about by BiGAN/ALI could be achieved simply by moving to a better, newer GAN framework?  I think the better question might be if BiGAN/ALI on top of a newer GAN would have better representations than just a newer GAN by itself.  If the answer is no, I think an argument can be made for training the inverse mapping after GAN convergence.",13,8,False,self,,,,,
411,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,17,64wwkh,self.MachineLearning,"Keras and Performance, tf graph inner logics",https://www.reddit.com/r/MachineLearning/comments/64wwkh/keras_and_performance_tf_graph_inner_logics/,[deleted],1491985444,[removed],0,1,False,default,,,,,
412,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,17,64wxn9,self.MachineLearning,[Discussion] Online resources to test popular CNN architectures,https://www.reddit.com/r/MachineLearning/comments/64wxn9/discussion_online_resources_to_test_popular_cnn/,varadg,1491986050,"Are there any services that allow uploading data and run training on the same using popular pre-existing architectures like AlexNet, GoogLeNet etc. I have already done the same on my personal machine but wanted to check out if there were any resources available with this setup already available to save the (albeit little) effort of coding up the framework around pretrained networks.",0,2,False,self,,,,,
413,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,18,64x5i6,self.MachineLearning,Looking for Suitable System for Deep Learning tasks,https://www.reddit.com/r/MachineLearning/comments/64x5i6/looking_for_suitable_system_for_deep_learning/,PraiseTheSingularity,1491990183,[removed],0,1,False,default,,,,,
414,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,19,64x88c,self.MachineLearning,word2vec gensim - most similar by cosine similarity rather than top notation?,https://www.reddit.com/r/MachineLearning/comments/64x88c/word2vec_gensim_most_similar_by_cosine_similarity/,SuperCComplex,1491991392,[removed],0,1,False,default,,,,,
415,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,19,64xalr,opensource.googleblog.com,[N] Google open sources a seq2seq framework in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/64xalr/n_google_open_sources_a_seq2seq_framework_in/,wb14123,1491992478,,14,142,False,https://a.thumbs.redditmedia.com/Y_mltIVoN2xPpzhftDjNf2eiAUwBTF_ZMuvoNkbd-n8.jpg,,,,,
416,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,19,64xe8p,blog.paralleldots.com,Some Lesser-Known Deep Learning Libraries,https://www.reddit.com/r/MachineLearning/comments/64xe8p/some_lesserknown_deep_learning_libraries/,gargisharmapd,1491994109,,0,1,False,default,,,,,
417,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,21,64xqqi,medium.com,"Designing Voice Experiences: Promise, Potential, Pain &amp; A Plan",https://www.reddit.com/r/MachineLearning/comments/64xqqi/designing_voice_experiences_promise_potential/,dougiebuckets,1491999067,,0,1,False,default,,,,,
418,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,22,64y7lf,self.MachineLearning,MIT 6.036 Machine Learning,https://www.reddit.com/r/MachineLearning/comments/64y7lf/mit_6036_machine_learning/,AlexisS15,1492004584,[removed],0,1,False,default,,,,,
419,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,23,64ycnn,nextplatform.com,A Look at Facebooks Interactive Neural Network Visualization System,https://www.reddit.com/r/MachineLearning/comments/64ycnn/a_look_at_facebooks_interactive_neural_network/,[deleted],1492006038,[deleted],0,1,False,default,,,,,
420,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,23,64yjn7,arxiv.org,[R][1704.03453] The Space of Transferable Adversarial Examples,https://www.reddit.com/r/MachineLearning/comments/64yjn7/r170403453_the_space_of_transferable_adversarial/,bobchennan,1492007965,,4,9,False,default,,,,,
421,MachineLearning,t5_2r3gv,2017-4-12,2017,4,12,23,64ylh3,self.MachineLearning,Keras burning out SSDs,https://www.reddit.com/r/MachineLearning/comments/64ylh3/keras_burning_out_ssds/,realSatanAMA,1492008464,[removed],0,1,False,default,,,,,
422,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,0,64yyyd,self.MachineLearning,Best knows ML methods per class of problems,https://www.reddit.com/r/MachineLearning/comments/64yyyd/best_knows_ml_methods_per_class_of_problems/,cantbelieveitsbacon,1492012072,[removed],0,1,False,default,,,,,
423,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,0,64z00g,self.MachineLearning,"Simple Questions Thread April 12, 2017",https://www.reddit.com/r/MachineLearning/comments/64z00g/simple_questions_thread_april_12_2017/,AutoModerator,1492012355,[removed],0,1,False,default,,,,,
424,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,1,64z24x,deepsense.io,[P] Deep learning for satellite imagery via image segmentation (4th place at in Kaggle Dstl competition),https://www.reddit.com/r/MachineLearning/comments/64z24x/p_deep_learning_for_satellite_imagery_via_image/,[deleted],1492012907,[deleted],0,1,False,default,,,,,
425,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,1,64z4uc,deepsense.io,[P] Deep learning for satellite imagery via image segmentation (4th place in Kaggle Dstl competition),https://www.reddit.com/r/MachineLearning/comments/64z4uc/p_deep_learning_for_satellite_imagery_via_image/,arnowaczynski,1492013605,,10,41,False,https://b.thumbs.redditmedia.com/tIeXwlaMtNkAAJAfnwYVdqmajL6btt6iWSnHzGGCf4Q.jpg,,,,,
426,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,1,64z7gx,self.MachineLearning,Can somebody please help me understand this quick/simple LSTM derivative?,https://www.reddit.com/r/MachineLearning/comments/64z7gx/can_somebody_please_help_me_understand_this/,[deleted],1492014279,[removed],0,1,False,default,,,,,
427,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,1,64z7wh,wired.com,"Googles Dueling Neural Networks Spar to Get Smarter, No Humans Required",https://www.reddit.com/r/MachineLearning/comments/64z7wh/googles_dueling_neural_networks_spar_to_get/,[deleted],1492014389,[deleted],0,1,False,default,,,,,
428,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,1,64z8ww,self.MachineLearning,Can somebody please help me understand this quick/simple LSTM derivative?,https://www.reddit.com/r/MachineLearning/comments/64z8ww/can_somebody_please_help_me_understand_this/,[deleted],1492014669,[removed],0,1,False,default,,,,,
429,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,1,64zb9t,self.MachineLearning,[D] Can somebody please help me understand this quick/simple LSTM derivative?,https://www.reddit.com/r/MachineLearning/comments/64zb9t/d_can_somebody_please_help_me_understand_this/,[deleted],1492015267,[deleted],5,1,False,default,,,,,
430,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,1,64zbov,nbc.com,Ian goodfellow look-alike,https://www.reddit.com/r/MachineLearning/comments/64zbov/ian_goodfellow_lookalike/,[deleted],1492015385,[deleted],0,1,False,default,,,,,
431,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,1,64zbw9,wired.com,"[N] Googles Dueling Neural Networks Spar to Get Smarter, No Humans Required",https://www.reddit.com/r/MachineLearning/comments/64zbw9/n_googles_dueling_neural_networks_spar_to_get/,squarerootof-1,1492015440,,0,0,False,default,,,,,
432,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,2,64zi2l,medium.com,"Google, Facebook, Microsoft, IBM, Baidu and others just invested $80m into every AI company",https://www.reddit.com/r/MachineLearning/comments/64zi2l/google_facebook_microsoft_ibm_baidu_and_others/,[deleted],1492017045,[deleted],0,1,False,default,,,,,
433,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,2,64zl50,medium.com,"[D] Google, Facebook, Microsoft, IBM, Baidu and others just invested $80m into every AI company",https://www.reddit.com/r/MachineLearning/comments/64zl50/d_google_facebook_microsoft_ibm_baidu_and_others/,ben-blume,1492017846,,5,0,False,default,,,,,
434,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,2,64zpa7,self.MachineLearning,University of Helsinki or Aalto University for Computer Science,https://www.reddit.com/r/MachineLearning/comments/64zpa7/university_of_helsinki_or_aalto_university_for/,ruathudo,1492018848,[removed],0,1,False,default,,,,,
435,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,2,64zpk1,thinkerfeed.net,New Collaborative Learning Community - Uses Collective Sharing And Ranking to Build Knowledge Repositories,https://www.reddit.com/r/MachineLearning/comments/64zpk1/new_collaborative_learning_community_uses/,[deleted],1492018920,[deleted],0,1,False,default,,,,,
436,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,2,64zpnq,self.MachineLearning,Detecting Trustworthy Domains  Flipboard Engineering,https://www.reddit.com/r/MachineLearning/comments/64zpnq/detecting_trustworthy_domains_flipboard/,[deleted],1492018945,[removed],0,1,False,default,,,,,
437,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,2,64zs0b,engineering.flipboard.com,Detecting Trustworthy Domains  Flipboard Engineering,https://www.reddit.com/r/MachineLearning/comments/64zs0b/detecting_trustworthy_domains_flipboard/,[deleted],1492019548,[deleted],0,2,False,default,,,,,
438,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,2,64ztjt,self.MachineLearning,360 video stream prediction,https://www.reddit.com/r/MachineLearning/comments/64ztjt/360_video_stream_prediction/,[deleted],1492019957,[removed],0,1,False,default,,,,,
439,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,3,64zvbf,engineering.flipboard.com,[P] Detecting Trustworthy Domains  Flipboard Engineering,https://www.reddit.com/r/MachineLearning/comments/64zvbf/p_detecting_trustworthy_domains_flipboard/,mvcflip,1492020395,,7,12,False,https://b.thumbs.redditmedia.com/P0edN5ZW7JlYIpTu_ECYqPpD1Hlh4gMpSfyac0RSv7I.jpg,,,,,
440,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,3,64zw3x,self.MachineLearning,[P] 360 video stream prediction,https://www.reddit.com/r/MachineLearning/comments/64zw3x/p_360_video_stream_prediction/,janez01,1492020603,"I'm currently tasked with creating neural network that should predict what direction will user look at in the certain point of time.

I want to split the 360 video in the 15 degree chunks (total user view angle is 60 degrees) and create network that would predict and preload certain chunks of video. Entire 360 video will be streamed with lowest quality apart from that 60 degree user is looking at.

I have dataset which contains data for 60 seconds long video and recorded user behavior:

Example:

    session_id|time|view focal point
    :--:|:--:|:--:
    s1489657649x33f872685a2b0ex37846277|1.902058|8
    s1489657649x33f872685a2b0ex37846277|2.000838|12
    s1489657649x33f872685a2b0ex37846277|2.101868|16
    s1489657649x33f872685a2b0ex37846277|2.200833|16
    s1489657649x33f872685a2b0ex37846277|2.300319|18
    s1489657649x33f872685a2b0ex37846277|2.402479|18
    s1489657649x33f872685a2b0ex37846277|2.500449|18
    s1489657649x33f872685a2b0ex37846277|2.650183|18
    s1489657649x33f872685a2b0ex37846277|2.752058|18


My problem is that there is no fixed point in time for this recording intervals of behavior and I have no idea what methods to use or how to model the network.

I'm asking for any kind of pointers in regard what type of network this should be and how would one model it.
",3,6,False,self,,,,,
441,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,3,64zwt1,self.MachineLearning,[D] Does the Generative/Discriminative dichotomy extend to unsupervised learning?,https://www.reddit.com/r/MachineLearning/comments/64zwt1/d_does_the_generativediscriminative_dichotomy/,mostafa-samir,1492020777,"In supervised learning, we can make two equivalent statements of what each of the generative and discriminative models represent.

**Generative models:**

* *[Verbal statement]* models that represent how the data is generated.
* *[Mathematical statement]* models that estimate the joint distribution P(X,Y)

**Discriminative models:** 

* *[Verbal statement]* models that discriminate between the data.
* *[Mathematical statement]* models that estimate the conditional distribution P(Y|X)


In unsupervised learning, it's clear that the mathematical statements do not hold; because there is no Y in this case. However, can the verbal statements of generative/discriminative models hold in an unsupervised context?


My first thought was K-means vs Gaussian Mixture Model (GMM). K-means may practically seem like a discriminative model, as the end goal is usually to assign (aka discriminate) data points into specific clusters, while in GMMs we explicitly model P(X) and then use it to assign data points to clusters. But K-means is just a special case of GMMs where the covariance of the Gaussians is fixed and uniform mixing coefficients is assumed, so the dichotomy may not be valid in this case.


But what about something like PCA vs Probabilistic PCA? Can the dichotomy hold in that case? and In general, through the whole realm of ""not that well-defined"" unsupervised problems, is there's a place for the generative/discriminative dichotomy?   ",3,4,False,self,,,,,
442,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,3,64zxmt,self.MachineLearning,Clickme.ai: Weekly gift card prizes for improving AI. Make some money and help some researchers!,https://www.reddit.com/r/MachineLearning/comments/64zxmt/clickmeai_weekly_gift_card_prizes_for_improving/,svenlover123,1492020997,[removed],0,1,False,default,,,,,
443,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,3,65005v,self.MachineLearning,[D] Why is the derivative of the LSTM cell state w.r.t. to the previous cell state equal to the forget gate?,https://www.reddit.com/r/MachineLearning/comments/65005v/d_why_is_the_derivative_of_the_lstm_cell_state/,sup6978,1492021653,"I keep seeing this online, on Quora and this subreddit but I don't get it. Here's some basic math to show otherwise:

We use the equation: c\_t = f  c\_t-1 + i  g

Now, we want to compute dc\_t/dc\_t-1. Apparently it's equal to the forget gate.

First of all, how can this be so if we have the i and g gates, and i and g are both dependent on the previous hidden state, which is in turn dependent on the previous cell state? Chain rule would extend for longer and we'd have more derivative terms in there.

Now, even if we were to ignore i and g, and simplify some of our expressions for convenience sake, what about this:

d/dc (c  f) = d/dc(f)

since f is also dependent on the previous hidden state and thus previous cell state:

= d/dc(sigmoid(w * h))

= sigmoid(w * h) * w * d/dc(h)

= sigmoid(w * h) * w * d/dc(tanh(o * c))

= sigmoid(w * h) * w * o * tanh(o * c))

Not nearly ""f"", which is sigmoid(w * h)

You can assume w denotes w_fh, and that there's no input at this timestep nor bias, or something",12,3,False,self,,,,,
444,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,4,650k0o,self.MachineLearning,Anyone know any good simple exercises/challenges at the intersection of Artificial intelligence and Interaction Design,https://www.reddit.com/r/MachineLearning/comments/650k0o/anyone_know_any_good_simple_exerciseschallenges/,vijayprabhakar,1492026862,[removed],0,1,False,default,,,,,
445,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,5,650ref,viva64.com,War of the Machines: PVS-Studio vs TensorFlow,https://www.reddit.com/r/MachineLearning/comments/650ref/war_of_the_machines_pvsstudio_vs_tensorflow/,Resistor510,1492028776,,0,1,False,default,,,,,
446,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,5,650ug2,nat.org,"[N] AIGrant: Get $5,000 for your open source AI project",https://www.reddit.com/r/MachineLearning/comments/650ug2/n_aigrant_get_5000_for_your_open_source_ai_project/,nataigrant,1492029547,,35,227,False,https://b.thumbs.redditmedia.com/ZdCk6qk_VfJo3XQvyXvIRtu5Gc-sol2RphdDhLq5-xM.jpg,,,,,
447,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,5,650yvh,self.MachineLearning,[P] Recommendation Engine for MTG,https://www.reddit.com/r/MachineLearning/comments/650yvh/p_recommendation_engine_for_mtg/,anubis_dragoon,1492030716,"I've done a little dabbling with ML for neural networks in a supervised learning scenario, but I've finally decided on a personal project to pursue and was looking for advice.  I want to build a recommendation engine for Magic the Gathering cards:  If I pick a color, ability, or even a card, I want to see cards that it associates with those cards as useful counter parts that are synergistic.  I'm thinking this would be an unsupervised situation, I basically want to use the full database of cards as my data to train on.  In theory I could pull from deck building sites for more supervised data, showing cards that others have decided work well, I'm not opposed to that, I'm still very early in the planning phases.  For anyone with mtg experience, my goal is to build this around the Commander/EDH format, as that's what I play most, so I can pretty much utilize the entirety of the MTG database of cards.  
I'm not sure off hand what approach I should take (ensembles, neural networks, SVM, etc) and I was hoping people might have some ideas on what might be a logical starting place for that.  I've considered going the recommendation engine route along with using external built deck data from various sites as my training data, which might be better than trying to just do the unsupervised approach of feeding it all of the cards as a data source.  So any advice would be greatly appreciated!",3,1,False,self,,,,,
448,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,6,6515b8,self.MachineLearning,What is the point cloud/deep learning state-of-art?,https://www.reddit.com/r/MachineLearning/comments/6515b8/what_is_the_point_clouddeep_learning_stateofart/,gpolaert,1492032503,[removed],0,1,False,default,,,,,
449,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,6,6515g6,self.MachineLearning,"[D] Any positive experiences with ML VM images, especially on AWS?",https://www.reddit.com/r/MachineLearning/comments/6515g6/d_any_positive_experiences_with_ml_vm_images/,MathAndProgramming,1492032539,"I've seen a couple sources for AWS images that claim to have preconfigured all the hardware drivers and popular libraries. Has anybody made use of these? Any recommendations?

I do contract work for a few different clients, so for me generally the easiest thing is to spin up an AWS instance for that client and get things training 24/7. Once I'm finished I can just give them the image and some docs along with a report/outputs/code so they don't have to deal with yet again installing numpy on another ubuntu machine (what are those apt-get dependencies again?) or yet again installing cuda and figuring out your nvidia login so you can download cudnn etc.

Anyway, I was curious if anybody has a process they like so they don't have to do this basic configuration over and over.
",7,5,False,self,,,,,
450,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,8,651v64,arxiv.org,[1704.03003] Automated Curriculum Learning for Neural Networks,https://www.reddit.com/r/MachineLearning/comments/651v64/170403003_automated_curriculum_learning_for/,[deleted],1492039778,[deleted],0,1,False,default,,,,,
451,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,8,651vrq,arxiv.org,"[R][1704.03003] Automated Curriculum Learning for Neural Networks, Graves et al. 2017",https://www.reddit.com/r/MachineLearning/comments/651vrq/r170403003_automated_curriculum_learning_for/,[deleted],1492039971,[deleted],1,1,False,default,,,,,
452,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,8,651xox,self.MachineLearning,RNN Sanity Check?,https://www.reddit.com/r/MachineLearning/comments/651xox/rnn_sanity_check/,guyfrom7up,1492040570,[removed],1,1,False,default,,,,,
453,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,8,651y0w,youtube.com,How to Beat Pong Using Policy Gradients (LIVE),https://www.reddit.com/r/MachineLearning/comments/651y0w/how_to_beat_pong_using_policy_gradients_live/,ackstazya,1492040681,,0,1,False,default,,,,,
454,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,9,6521n0,arxiv.org,[R] A Neural Representation of Sketch Drawings,https://www.reddit.com/r/MachineLearning/comments/6521n0/r_a_neural_representation_of_sketch_drawings/,hardmaru,1492041863,,4,29,False,default,,,,,
455,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,9,65229b,self.MachineLearning,How bad would a Jetson TX2 be for training CNNs or similar?,https://www.reddit.com/r/MachineLearning/comments/65229b/how_bad_would_a_jetson_tx2_be_for_training_cnns/,[deleted],1492042084,[removed],0,1,False,default,,,,,
456,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,9,652b5a,self.MachineLearning,[P] Identifying false submissions,https://www.reddit.com/r/MachineLearning/comments/652b5a/p_identifying_false_submissions/,[deleted],1492044841,[deleted],2,1,False,default,,,,,
457,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,12,65311h,self.MachineLearning,Best auto-ML toolkit?,https://www.reddit.com/r/MachineLearning/comments/65311h/best_automl_toolkit/,ddebarr,1492053298,[removed],0,1,False,default,,,,,
458,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,12,6535j7,vimeo.com,Video Examples From New Style Transfer Technique,https://www.reddit.com/r/MachineLearning/comments/6535j7/video_examples_from_new_style_transfer_technique/,manimal-ai,1492054823,,0,1,False,default,,,,,
459,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,14,653ner,self.MachineLearning,Is there any point doing batch normalisation on an embedding layer?,https://www.reddit.com/r/MachineLearning/comments/653ner/is_there_any_point_doing_batch_normalisation_on/,[deleted],1492061781,[removed],0,1,False,default,,,,,
460,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,15,653t5n,self.MachineLearning,[P] Viability of a Jetson TX2 to train relatively simple ML algorithms,https://www.reddit.com/r/MachineLearning/comments/653t5n/p_viability_of_a_jetson_tx2_to_train_relatively/,[deleted],1492064350,[deleted],4,2,False,default,,,,,
461,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,17,6548ou,arxiv.org,A Neural Parametric Singing Synthesizer,https://www.reddit.com/r/MachineLearning/comments/6548ou/a_neural_parametric_singing_synthesizer/,samim23,1492072061,,0,1,False,default,,,,,
462,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,17,6549m6,medium.com,Overview of the Artificial Intelligence industry in Ireland.,https://www.reddit.com/r/MachineLearning/comments/6549m6/overview_of_the_artificial_intelligence_industry/,roryg101,1492072538,,0,1,False,default,,,,,
463,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,17,654bmv,self.MachineLearning,[D] Advice for an undergrad looking to get into the field of Machine Learning or AI research.,https://www.reddit.com/r/MachineLearning/comments/654bmv/d_advice_for_an_undergrad_looking_to_get_into_the/,Partridge1,1492073555,"Hey everyone, I'm currently a second year math major thinking about switching to a cognitive science major with a focus in machine learning with neural computation and a math minor. Would this degree be useful in getting a job in AI research or the ML industry, or is it only good for grad school? A CS degree isn't an option for me at this point and I was just wondering if anyone here has advice for making this a useful bachelors degree to pursue. So far I plan on learning Java and Python to supplement my potential major courses which consist of math through advanced stochastic processes and probability and stats as well as 3 or 4 AI, algorithm, and natural computation classes. Thanks in advance for any help.",10,1,False,self,,,,,
464,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,20,654wbe,self.MachineLearning,The Receptive Field size with transpose layers and checkerboard artifacts,https://www.reddit.com/r/MachineLearning/comments/654wbe/the_receptive_field_size_with_transpose_layers/,CompNeuroMSc,1492083146,[removed],0,1,False,default,,,,,
465,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,21,655513,mlnotebook.github.io,Convolutional Neural Networks - Basics,https://www.reddit.com/r/MachineLearning/comments/655513/convolutional_neural_networks_basics/,physrr,1492086397,,0,1,False,default,,,,,
466,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,22,655ho4,raais.co,"3rd Research and Applied AI Summit - London, June 30th",https://www.reddit.com/r/MachineLearning/comments/655ho4/3rd_research_and_applied_ai_summit_london_june/,nb410,1492090445,,0,1,False,default,,,,,
467,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,22,655iih,self.MachineLearning,[D] Why doesn't LSTM forget gate cause a vanishing/dying gradient?,https://www.reddit.com/r/MachineLearning/comments/655iih/d_why_doesnt_lstm_forget_gate_cause_a/,sup6978,1492090700,"I put together some math to show what I'm talking about: https://drive.google.com/file/d/0BwbWRPtraa2zeDhaUWFUVl94ZUk/view?usp=sharing

TL;DR: the earlier the timestep, the more number of forget gate terms present in our derivative that multiply together. If one of these is equal or close to 0, then the whole gradient dies. How is this not an issue, if we train the forget gate [weights] simultaneously? Even if we set a really large forget bias, as the training progresses it'll correct this and make the forget gate at a timestep closer to what is optimal. Eg. if learn that f_10 should be 0, then the whole thing dies, even though we're still making contributions albeit small.

Am I missing something here?
",13,20,False,self,,,,,
468,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,22,655jvi,github.com,[P] Google's BEGAN implemention in tensorflow. Check the result and discuss about Women's face bias and Hole problem,https://www.reddit.com/r/MachineLearning/comments/655jvi/p_googles_began_implemention_in_tensorflow_check/,Kiheumi,1492091101,,14,25,False,https://a.thumbs.redditmedia.com/PuQ0DuV9CTyoa-1nw7EY93FRlGVWmGHS43lb5Cohj90.jpg,,,,,
469,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,23,655qw7,self.MachineLearning,What sort of algorithm is used for generative design?,https://www.reddit.com/r/MachineLearning/comments/655qw7/what_sort_of_algorithm_is_used_for_generative/,hugababoo,1492093118,[removed],0,1,False,default,,,,,
470,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,23,655t5q,self.MachineLearning,"[D] Advice for a Computer/Data Science grad student, how can I contribute towards/learn about open source GMO/Gene editing or CRISPR/Cas9 projects if there are any?",https://www.reddit.com/r/MachineLearning/comments/655t5q/d_advice_for_a_computerdata_science_grad_student/,rulerofthehell,1492093778,"Hello everyone, I'm a CS grad student who is looking forward to specializing in Machine Learning and would love to learn more about its application in this field. I don't have enough knowledge of the microbiology side of the topic, I most probably can choose it as a minor, but that's about it. I was wondering if there are some good projects about which I can learn about or contribute to. Thanks in advanced!",8,8,False,self,,,,,
471,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,23,655tvn,self.MachineLearning,[D] How common is truncated cell state backprop with LSTMs?,https://www.reddit.com/r/MachineLearning/comments/655tvn/d_how_common_is_truncated_cell_state_backprop/,[deleted],1492093991,[deleted],2,5,False,default,,,,,
472,MachineLearning,t5_2r3gv,2017-4-13,2017,4,13,23,655vpp,arxiv.org,[R][1704.03732] Learning from Demonstrations for Real World Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/655vpp/r170403732_learning_from_demonstrations_for_real/,bobchennan,1492094506,,2,16,False,default,,,,,
473,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,1,656dne,petroleum-economist.com,"Automation, machine learning and AI are transforming the oil industry. The robots are coming",https://www.reddit.com/r/MachineLearning/comments/656dne/automation_machine_learning_and_ai_are/,PetroleumEconomist,1492099317,,0,1,False,default,,,,,
474,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,1,656e5l,khronos.org,Neural Network Exchange Format - does this have a future?,https://www.reddit.com/r/MachineLearning/comments/656e5l/neural_network_exchange_format_does_this_have_a/,Neural_Ned,1492099444,,0,1,False,default,,,,,
475,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,1,656kkz,github.com,[P] My (slightly modified) Keras implementation of RankNet.,https://www.reddit.com/r/MachineLearning/comments/656kkz/p_my_slightly_modified_keras_implementation_of/,[deleted],1492101119,[deleted],1,4,False,default,,,,,
476,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,1,656pdi,dtic.upf.edu,A Neural Parametric Singing Synthesizer (wow),https://www.reddit.com/r/MachineLearning/comments/656pdi/a_neural_parametric_singing_synthesizer_wow/,finallyifoundvalidUN,1492102372,,0,1,False,default,,,,,
477,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,1,656ppr,ayearofai.com,The most comprehensive yet simple and fun recurrent neural network/LSTM tutorial on the Internet.,https://www.reddit.com/r/MachineLearning/comments/656ppr/the_most_comprehensive_yet_simple_and_fun/,[deleted],1492102455,[deleted],0,1,False,default,,,,,
478,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,1,656pvf,ayearofai.com,[P] The most comprehensive yet simple and fun RNN/LSTM tutorial on the Internet.,https://www.reddit.com/r/MachineLearning/comments/656pvf/p_the_most_comprehensive_yet_simple_and_fun/,sup6978,1492102502,,58,230,False,https://b.thumbs.redditmedia.com/IcbW64fIc8zG7_aQ4ZokgZPdoWoOJb4lj10aGzQNlTg.jpg,,,,,
479,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,1,656q8u,self.MachineLearning,[D] Looking for a review of visual CNNs where one of the last layers is popped off and retrained on a new task.,https://www.reddit.com/r/MachineLearning/comments/656q8u/d_looking_for_a_review_of_visual_cnns_where_one/,trashacount12345,1492102601,"Title covers it mostly. I'd like a review that I could send an older researcher not in Machine Learning when they say ""machine learning isn't really learning."" The fact that CNNs often learn features that can be used in entirely different contexts (not included in the original training data) is a good start, and a review of how easy it is to do that would be even better. ",5,0,False,self,,,,,
480,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,2,656r4r,linkedin.com,Machine Learning: Linear Regression,https://www.reddit.com/r/MachineLearning/comments/656r4r/machine_learning_linear_regression/,kirfuchs,1492102832,,0,1,False,default,,,,,
481,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,2,656r5o,research.googleblog.com,[R] Teaching Machines to Draw,https://www.reddit.com/r/MachineLearning/comments/656r5o/r_teaching_machines_to_draw/,inarrears,1492102838,,8,27,False,https://b.thumbs.redditmedia.com/B7UfB14XhX1o3H5kugMC5KDhJOxWGbOGzUqOIIwt05U.jpg,,,,,
482,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,3,657f02,github.com,Inpainting with GAN for image completion in Torch,https://www.reddit.com/r/MachineLearning/comments/657f02/inpainting_with_gan_for_image_completion_in_torch/,[deleted],1492108949,[deleted],0,1,False,default,,,,,
483,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,3,657gku,arxiv.org,On the Properties of the Softmax Function with Application in Game Theory and Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/657gku/on_the_properties_of_the_softmax_function_with/,[deleted],1492109390,[deleted],0,1,False,default,,,,,
484,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,4,657s42,github.com,[P] Inpainting with GAN for image completion in Torch,https://www.reddit.com/r/MachineLearning/comments/657s42/p_inpainting_with_gan_for_image_completion_in/,fonfonx,1492112418,,0,9,False,https://a.thumbs.redditmedia.com/it_zVc-b34YKmp6bzUtkaLSaeegv7ppUpXHhIxs8Mi0.jpg,,,,,
485,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,4,657tsi,self.MachineLearning,"What is a self-adaptive neural network, and how does it work?",https://www.reddit.com/r/MachineLearning/comments/657tsi/what_is_a_selfadaptive_neural_network_and_how/,alexshiro,1492112867,[removed],0,1,False,default,,,,,
486,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,5,657ycj,self.MachineLearning,[P] Mario Kart Environment,https://www.reddit.com/r/MachineLearning/comments/657ycj/p_mario_kart_environment/,[deleted],1492114083,[deleted],2,1,False,default,,,,,
487,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,5,657yto,dtic.upf.edu,[R] A Neural Parametric Singing Synthesizer (paper in comments),https://www.reddit.com/r/MachineLearning/comments/657yto/r_a_neural_parametric_singing_synthesizer_paper/,downtownslim,1492114217,,20,48,False,default,,,,,
488,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,6,658d8x,self.MachineLearning,How long does deep reinforcement learning take to train for a simple game?,https://www.reddit.com/r/MachineLearning/comments/658d8x/how_long_does_deep_reinforcement_learning_take_to/,rasen58,1492118153,[removed],0,1,False,default,,,,,
489,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,8,6595ve,self.MachineLearning,Convolutional layer messes up things in WGAN,https://www.reddit.com/r/MachineLearning/comments/6595ve/convolutional_layer_messes_up_things_in_wgan/,warmsnail,1492126667,"So I'm kind of pulling my hair over this problem and I've been trying to pin it down for quite some time.

**TLDR**; Introduction of a convolutional layer in the critic of WGAN architecture seems to mess things up. Fully connected WGAN works, 
convolutional layers in generator work, autoencoder with an almost identical convolutional architecture works (except it's reversed). Something strange is happening and I need your superpowers.
I'm using Tensorflow and code is available [here](https://github.com/bgavran/AMDS_FER/tree/master/src).

**Not TLDR;**

I'm trying to play around with WGAN for quite some time to generate faces. I first started implementing the deep convolutional version right away, but since nothing worked like it should I decided to incrementally build up the model.
I've actually implemented the Improved WGAN paper but its just because I thought it'd help me fix the problems I developed (it didn't). So both methods of enforcing the Lipschitz constraint have the same problem which means that's *probably* not it.

I ended up creating a functional version of basic WGAN which has one fully connected layer in the generator and two fc layers in the critic. After just a short time, it generates wonderful images like you can see [here](http://imgur.com/a/wwftw) (the image on the left side, the right one is the problematic one).
However, after replacing the:

            image = tf.reshape(image, [-1, self.img_size * self.img_size * 3])
            image = tf.layers.dense(image, 512, tf.nn.relu)
            image = tf.layers.dense(image, 1)
            return image


with: 

            image = tf.layers.conv2d(image, filters=128, **kwargs)
            image = tf.reshape(image, [-1, 16 * 16 * 128])
            image = tf.layers.dense(image, 1)
            return image

all hell broke loose.
Here the **kwargs are

            kwargs = {""kernel_size"": (4, 4), ""strides"": (4, 4), ""padding"": ""valid"", ""activation"": tf.nn.relu}

The image created is the right one in the previous link and [here's](http://imgur.com/a/Px74B) one more picture for reference.
What you can notice straight away is that the general structure of the image is all right (it resembles the face), but the low level textures (4x4 patches) are completely messed up. To me this is a clear indicator that the problem has strictly to do with convolution. Adding more convolutional layers just disguises the problem even more. 

**What I've tried:**

* A big number of architectures, number of filters, numbers of layers, padding, activation functions
* Letting it train for a longer time with many of the above architectures. The results always take longer and look worse than FC
* Creating an convolutional autoencoder which I train normally (MSE error) and which has the ""encoder as the discriminator and decoder as the critic"". What I mean by that is that the architectures of those are very similar and the autoencoder works flawlessly.
* Some potentially useful hint: I get a NaN in tensorboard visualization and a completely red image when I have a low number of filters in IWGAN (never had the problem with regular WGAN)

I hope I'm not missing something obvious.
",19,9,False,self,,,,,
490,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,8,6597dm,omegaprofessionaldoors.com,Porte per Garage Portoni a Libro Omega Professional Doors SRL Roma,https://www.reddit.com/r/MachineLearning/comments/6597dm/porte_per_garage_portoni_a_libro_omega/,enriquetaqqgood,1492127141,,0,1,False,default,,,,,
491,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,9,659ams,self.MachineLearning,[D] I am currently about to finish graduating as computer engineer.I am thinking about pursuing masters degree in data science/machine learning.,https://www.reddit.com/r/MachineLearning/comments/659ams/d_i_am_currently_about_to_finish_graduating_as/,joker2895,1492128270,"Any recommendations for programs that have admission criteria which are not gpa-centric since my GPA is quite low?
However I have presented a couple papers in IEEE conferences.",0,0,False,self,,,,,
492,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,9,659bic,theguardian.com,"AI programs exhibit racial and gender biases, research reveals",https://www.reddit.com/r/MachineLearning/comments/659bic/ai_programs_exhibit_racial_and_gender_biases/,cturnr,1492128563,,0,1,False,default,,,,,
493,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,10,659tsb,self.MachineLearning,Can we use skip-connection to the rnn?,https://www.reddit.com/r/MachineLearning/comments/659tsb/can_we_use_skipconnection_to_the_rnn/,longinglove,1492134585,[removed],0,1,False,default,,,,,
494,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,13,65ajmb,self.MachineLearning,Neural style transfer with a pre-trained ResNet50 as base model,https://www.reddit.com/r/MachineLearning/comments/65ajmb/neural_style_transfer_with_a_pretrained_resnet50/,thebluebloo,1492144044,[removed],0,1,False,default,,,,,
495,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,13,65an38,medium.com,three different hierarchical clusterings of NYC neighborhoods,https://www.reddit.com/r/MachineLearning/comments/65an38/three_different_hierarchical_clusterings_of_nyc/,coldshot00,1492145401,,0,1,False,default,,,,,
496,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,14,65aoos,nature.com,[P] Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records,https://www.reddit.com/r/MachineLearning/comments/65aoos/p_deep_patient_an_unsupervised_representation_to/,maruchanr,1492146047,,32,125,False,https://b.thumbs.redditmedia.com/Ccu8D3mQzNI-ttSBQPpb3sYB_gDTKHEK-51onhMN2lc.jpg,,,,,
497,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,14,65aplv,self.MachineLearning,[D] What's that paper that opens with a conversation between a student and his adviser about potential ideas?,https://www.reddit.com/r/MachineLearning/comments/65aplv/d_whats_that_paper_that_opens_with_a_conversation/,machines_learning,1492146391,"It was a speech (or NLP) paper I think, and instead of the conventional intro, it was the series of discussions that led to the idea in the paper. I'm blanking out here!",7,4,False,self,,,,,
498,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,15,65b0ej,youtube.com,"Mineral water plant, water bottle filling machine, drinking water bottling plant cost",https://www.reddit.com/r/MachineLearning/comments/65b0ej/mineral_water_plant_water_bottle_filling_machine/,stevenwangfilling,1492151226,,0,1,False,default,,,,,
499,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,15,65b18x,technologyreview.com,The Dark Secret at the Heart of AI,https://www.reddit.com/r/MachineLearning/comments/65b18x/the_dark_secret_at_the_heart_of_ai/,_alphamaximus_,1492151648,,0,1,False,default,,,,,
500,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,15,65b4ck,self.MachineLearning,Deep learning algorithms and it's relationship with datasets descriptors for assessing architecture,https://www.reddit.com/r/MachineLearning/comments/65b4ck/deep_learning_algorithms_and_its_relationship/,[deleted],1492153195,[removed],0,1,False,default,,,,,
501,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,16,65b5a2,self.MachineLearning,[D]ADs from NG's new job: Ryskamp Learning Machine,https://www.reddit.com/r/MachineLearning/comments/65b5a2/dads_from_ngs_new_job_ryskamp_learning_machine/,[deleted],1492153608,[deleted],9,0,False,default,,,,,
502,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,20,65bz1z,automatonlearning.net,Finite State Automata for Autonomous Driving,https://www.reddit.com/r/MachineLearning/comments/65bz1z/finite_state_automata_for_autonomous_driving/,Iplaythekeyboard,1492169089,,0,1,False,default,,,,,
503,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,20,65c1fk,youtube.com,Machine Learning(sklearn pandas) and Deep Learning (Keras) Tutorials,https://www.reddit.com/r/MachineLearning/comments/65c1fk/machine_learningsklearn_pandas_and_deep_learning/,[deleted],1492170147,[deleted],0,1,False,default,,,,,
504,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,21,65c4bo,self.MachineLearning,Why doesn't letting gradients flow through gates in LSTMs (with cell state derivatives) cause textbook vanishing gradients?,https://www.reddit.com/r/MachineLearning/comments/65c4bo/why_doesnt_letting_gradients_flow_through_gates/,[deleted],1492171370,[removed],0,1,False,default,,,,,
505,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,21,65c597,stamacsheetmetalmachinery.blogspot.com,Schlebach Profiling Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/65c597/schlebach_profiling_machine_for_sale/,stamac,1492171743,,0,1,False,default,,,,,
506,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,21,65c7nf,self.MachineLearning,"[D] Why doesn't vanishing gradients occur with modern implementations of LSTMs -- after doing the math, it seems like it must?",https://www.reddit.com/r/MachineLearning/comments/65c7nf/d_why_doesnt_vanishing_gradients_occur_with/,[deleted],1492172678,[deleted],0,6,False,default,,,,,
507,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,21,65cd4s,plus.google.com,Sale Service and Maintenance,https://www.reddit.com/r/MachineLearning/comments/65cd4s/sale_service_and_maintenance/,stamac,1492174748,,0,1,False,default,,,,,
508,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,22,65cevy,slideserve.com,Variobend Double Bender Australia,https://www.reddit.com/r/MachineLearning/comments/65cevy/variobend_double_bender_australia/,stamac,1492175351,,0,1,False,default,,,,,
509,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,23,65cxlv,self.MachineLearning,Rule learning in Recommendation Systems,https://www.reddit.com/r/MachineLearning/comments/65cxlv/rule_learning_in_recommendation_systems/,nieuwperspectief,1492181297,[removed],0,1,False,default,,,,,
510,MachineLearning,t5_2r3gv,2017-4-14,2017,4,14,23,65cy0l,self.MachineLearning,Machine Learning Discord Server,https://www.reddit.com/r/MachineLearning/comments/65cy0l/machine_learning_discord_server/,atorisha,1492181412,[removed],0,1,False,default,,,,,
511,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,0,65d3lt,ismll.uni-hildesheim.de,[R] Factorization Machines (2010) - a classic paper in recommender systems,https://www.reddit.com/r/MachineLearning/comments/65d3lt/r_factorization_machines_2010_a_classic_paper_in/,pmigdal,1492182990,,7,40,False,default,,,,,
512,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,1,65djev,self.MachineLearning,Software engineering masters -&gt; ML PhD?,https://www.reddit.com/r/MachineLearning/comments/65djev/software_engineering_masters_ml_phd/,philosolobster1999,1492187407,[removed],0,1,False,default,,,,,
513,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,1,65dn6r,github.com,[P] A self-organizing prediction algorithm,https://www.reddit.com/r/MachineLearning/comments/65dn6r/p_a_selforganizing_prediction_algorithm/,inboble,1492188442,,22,52,False,https://b.thumbs.redditmedia.com/nEFs1YTQbEqb9N3Ng4dLViYi9tEYbw_pcLoRLpn2MvM.jpg,,,,,
514,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,2,65dq2s,arxiv.org,[R][1704.00805] On the Properties of the Softmax Function with Application in Game Theory and Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/65dq2s/r170400805_on_the_properties_of_the_softmax/,RyanNet,1492189246,,2,28,False,default,,,,,
515,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,2,65dr93,youtube.com,Surprising result of recursive neural network trained on song slices. - Dubstep Science Institute,https://www.reddit.com/r/MachineLearning/comments/65dr93/surprising_result_of_recursive_neural_network/,raver1975,1492189533,,0,1,False,default,,,,,
516,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,2,65dtm3,self.MachineLearning,What architecture do you use for large text sentences?,https://www.reddit.com/r/MachineLearning/comments/65dtm3/what_architecture_do_you_use_for_large_text/,cvikasreddy,1492190178,[removed],0,1,False,default,,,,,
517,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,2,65dwlm,vllab1.ucmerced.edu,[P] LapSRN - Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution,https://www.reddit.com/r/MachineLearning/comments/65dwlm/p_lapsrn_deep_laplacian_pyramid_networks_for_fast/,theredknight,1492190961,,9,57,False,https://b.thumbs.redditmedia.com/zUePGm0guPMOaXzluZNT1GbjsGLP6CDxChoRNAJyAYg.jpg,,,,,
518,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,3,65e7sk,youtube.com,Deep Learning Tutorials with Keras,https://www.reddit.com/r/MachineLearning/comments/65e7sk/deep_learning_tutorials_with_keras/,[deleted],1492193917,[deleted],0,1,False,default,,,,,
519,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,3,65e91x,self.MachineLearning,[D] How can I perform multi-label classification if many labels are missing?,https://www.reddit.com/r/MachineLearning/comments/65e91x/d_how_can_i_perform_multilabel_classification_if/,antirabbit,1492194266,"I have a large set of documents, usually 500-2,000 words each, and for several different labels, there are about 20-100 samples with those labels, and hundreds to millions more that should be labeled but do not have that label. Over time, I expect new labels to be created and new documents to be added to the data set, although relatively few old labels added to any documents. It is possible that some documents will have many labels or possibly no labels. It is also possible for a label to be a subclass of another label, though not manually indicated.

I have a keyword tagging system in place that utilizes TF-IDF metrics to extract ngrams from the documents, which is my current feature set from them.

My initial thought is to use Naive Bayes classifiers (one for each label) and perform ROC analysis to see how well it classifies the category. However, if, say, 5% of the data should actually be labeled with Label A, and the amount of data supplied with Label A amounts to 1% of the data, then I would expect an ideal false discovery rate of 80%. On top of that, since the prior distribution is unknown, dealing with this issue is even more difficult.

Another idea I had is to use the vectors of word/ngram counts and look at the distribution of the cosine similarities of the documents within the sample and use a simple one-sided significance test with p-values to determine if they are similar enough. This relies heavily on the idea that the ngram vectors for each label are dissimilar enough to consider this form of hypothesis testing. A big problem with this is that I am heavily relying on the assumption that similarity is a highly discriminative metric, and because labels can be extremely unbalanced (by up to 5 orders of magnitude), I may need to employ additional methods, such as limiting the number of labels (perhaps by only taking the top N labels by p-value).

The training portion of the algorithm does not need to be extremely fast, but the labeling portion should be very quick once the document is parsed/tokenized.

There is a greater penalty for mislabeling a document than leaving it unlabeled, but future, human-feedback data may be provided to indicate incorrect labels. I will not have access to anything of the sort in the meantime, though.",8,2,False,self,,,,,
520,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,3,65e9ij,youtube.com,Keras Tutorials for Deep Learning.,https://www.reddit.com/r/MachineLearning/comments/65e9ij/keras_tutorials_for_deep_learning/,[deleted],1492194383,[deleted],0,1,False,default,,,,,
521,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,3,65ecce,youtube.com,Create Chatbot using LSTM in Keras.,https://www.reddit.com/r/MachineLearning/comments/65ecce/create_chatbot_using_lstm_in_keras/,mesutOz,1492195134,,0,1,False,default,,,,,
522,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,4,65ekzh,self.MachineLearning,[D] Industrial IoT machine learning examples,https://www.reddit.com/r/MachineLearning/comments/65ekzh/d_industrial_iot_machine_learning_examples/,BrightWolfIIoT,1492197496,"Are you working on .. or do you know of.. any applications of machine learning to industrial machine &amp; equipment health?
Ex. Using sensor data to train a model to classify failure modes or predict remaining useful life.

I have found several hyped up marketing pieces, but very few real-world examples.... even fewer where the dataset has been made public so that you can repeat their results.

Here are the best two papers I've come across...  Know of anything similar?

https://www.researchgate.net/publication/261282496_Sensorless_drive_diagnosis_using_automated_feature_extraction_significance_ranking_and_reduction

https://zenodo.org/record/55227#.WKYIXhIrKV4",9,23,False,self,,,,,
523,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,4,65enso,youtube.com,Patrick Harrison | Modern NLP in Python,https://www.reddit.com/r/MachineLearning/comments/65enso/patrick_harrison_modern_nlp_in_python/,[deleted],1492198257,[deleted],0,1,False,default,,,,,
524,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,4,65er35,renorm.complexityexplorer.org,The easiest way to learn Renormalization - Dr. Simon DeDeo's reform tutorial on Complexity Explorer,https://www.reddit.com/r/MachineLearning/comments/65er35/the_easiest_way_to_learn_renormalization_dr_simon/,[deleted],1492199160,[deleted],0,1,False,default,,,,,
525,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,5,65evio,fastforwardlabs.com,Visualizing the movie preferences of a community of movie-lovers using t-SNE (xpost /r/dataisbeautiful),https://www.reddit.com/r/MachineLearning/comments/65evio/visualizing_the_movie_preferences_of_a_community/,bikkhu42,1492200371,,0,1,False,default,,,,,
526,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,5,65ezz8,self.MachineLearning,Train an equation from a data set,https://www.reddit.com/r/MachineLearning/comments/65ezz8/train_an_equation_from_a_data_set/,Beau_Nerr,1492201646,[removed],0,1,False,default,,,,,
527,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,5,65f3w3,youtube.com,"The best one hour lecture connecting information theory, likelihood, and loss functions",https://www.reddit.com/r/MachineLearning/comments/65f3w3/the_best_one_hour_lecture_connecting_information/,pete0273,1492202756,,0,1,False,default,,,,,
528,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,7,65fq5h,self.MachineLearning,[D] Binary encoding and activation functions,https://www.reddit.com/r/MachineLearning/comments/65fq5h/d_binary_encoding_and_activation_functions/,DiproIV,1492209481,"I'm very new to Neural Networks but I've managed to create a character level RNN which uses 1-of-K encoding using the Sigmoid function and softmax at the final layer to get the probability of the next character based on http://karpathy.github.io/2015/05/21/rnn-effectiveness/

What I'm trying to understand is that instead of using 1-of-K encoding method for each possible character, what if I used binary encoding to reduce the input layer size, but then at the output layer I'd need a method of allowing a binary encoded output.

E.g. 
 - Convert the ascii code for ""A"" (65) to binary (01000001) and use that as input data. 
 - Then I want to train it to output B in binary for the ascii code which would be (01000010). 

However by using softmax only 1 output node would be set to 1, removing the possibility of (01000010).

I've considered using ReLu but I'm not sure if that would work? Also I'm using no python libraries for machine learning, and would like to maintain that.

Any advice would be appreciated! I'm very new to this.",7,1,False,self,,,,,
529,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,8,65fyxs,cso.com.au,"Properly applied, artificial intelligence and machine learning could crush the ransomware pandemic, especially in the health sector.",https://www.reddit.com/r/MachineLearning/comments/65fyxs/properly_applied_artificial_intelligence_and/,doni_coni,1492212309,,0,1,False,default,,,,,
530,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,8,65g2b0,secnews24.com,Can AI and ML slay the healthcare ransomware dragon?,https://www.reddit.com/r/MachineLearning/comments/65g2b0/can_ai_and_ml_slay_the_healthcare_ransomware/,Paco_co,1492213451,,0,1,False,default,,,,,
531,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,9,65g50r,self.MachineLearning,[P] Help Teaching Game Driver to Drive,https://www.reddit.com/r/MachineLearning/comments/65g50r/p_help_teaching_game_driver_to_drive/,[deleted],1492214415,[deleted],13,2,False,default,,,,,
532,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,11,65gt34,youtube.com,How to Generate Images - Intro to Deep Learning,https://www.reddit.com/r/MachineLearning/comments/65gt34/how_to_generate_images_intro_to_deep_learning/,ackstazya,1492223050,,0,1,False,default,,,,,
533,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,15,65hs86,self.MachineLearning,Image classification with Tensorflow,https://www.reddit.com/r/MachineLearning/comments/65hs86/image_classification_with_tensorflow/,[deleted],1492238181,[removed],0,1,False,default,,,,,
534,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,15,65htdk,github.com,"[P] Image classification with Tensorflow, supports 4 network architectures.",https://www.reddit.com/r/MachineLearning/comments/65htdk/p_image_classification_with_tensorflow_supports_4/,ug96,1492238790,,0,27,False,https://a.thumbs.redditmedia.com/LCDyTnRSMKD3FcZOB95mdwwY5oJW2-2voIXf0LLQPh8.jpg,,,,,
535,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,17,65i6k0,self.MachineLearning,[Discussion] What architecture do you use for large text sentences?,https://www.reddit.com/r/MachineLearning/comments/65i6k0/discussion_what_architecture_do_you_use_for_large/,cvikasreddy,1492246318,"I have reviews that have upto 5000 words and instead of passing word vectors as inputs to the LSTM I am passing sentence embeddings(skip-thought vectors) as inputs to the LSTM.

Is there any standard architecture that can be used for such long text data?",18,15,False,self,,,,,
536,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,18,65i8ae,self.MachineLearning,[D] ICML 2017 reviews discussion thread,https://www.reddit.com/r/MachineLearning/comments/65i8ae/d_icml_2017_reviews_discussion_thread/,nonap_,1492247332,"""What kind of reviews did you get?"" and other related topics...",28,26,False,self,,,,,
537,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,18,65i8vv,github.com,"Fictional city name to lat,lng regressor",https://www.reddit.com/r/MachineLearning/comments/65i8vv/fictional_city_name_to_latlng_regressor/,flezzfx,1492247711,,0,1,False,default,,,,,
538,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,21,65irxc,self.MachineLearning,Predictive Analytics,https://www.reddit.com/r/MachineLearning/comments/65irxc/predictive_analytics/,punchypanda,1492258225,[removed],0,1,False,default,,,,,
539,MachineLearning,t5_2r3gv,2017-4-15,2017,4,15,23,65jelb,self.MachineLearning,[D] Live loss plots inside Jupyter Notebook for Keras?,https://www.reddit.com/r/MachineLearning/comments/65jelb/d_live_loss_plots_inside_jupyter_notebook_for/,pmigdal,1492267484,"Is there some reasonably easy way to have live plots of training parameters (e.g. loss, accuracy, validation loss, validation accuracy), that is, ones being updated each epoch?

Sure, there are built-in progress bar (and even some more Jupyter Notebook ones [keras-tqdm](https://github.com/bstriner/keras-tqdm)), but what I miss is some plot on how it changes (rather than plotting from `history` *after* training a model).

Vide (not yet answered): [How do I get Bokeh to update a plot displaying some measure vs epoch when using keras fit_generator? - Stack Overflow](http://stackoverflow.com/questions/43121986/how-do-i-get-bokeh-to-update-a-plot-displaying-some-measure-vs-epoch-when-using).

EDIT:

* [Live loss plots in Jupyter Notebook for Keras](https://gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e) (a notebook, not yet a library or PR)

EDIT2:

* ...and actually might turn in a Keras feature: [Issue #1101](https://github.com/fchollet/keras/issues/1101)",26,49,False,self,,,,,
540,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,0,65jrj9,self.MachineLearning,Question on preparing lyrics (Python),https://www.reddit.com/r/MachineLearning/comments/65jrj9/question_on_preparing_lyrics_python/,orangejuicem,1492271717,[removed],0,1,False,default,,,,,
541,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,1,65jwms,self.MachineLearning,[P] Help with starting Variational-LSTM-Autoencoders,https://www.reddit.com/r/MachineLearning/comments/65jwms/p_help_with_starting_variationallstmautoencoders/,curious_neuron,1492273262,"Hi, as part of my final project for a ML course I'm trying to implement Variational LSTM Autoencoders as described in this [paper](https://arxiv.org/abs/1511.06349). At first I wanted to use tensorflow and tried to follow their tutorials on RNN and Seq2Seq but the library the tutorial uses (tensorflow/tensorflow/python/ops/seq2seq.py) seems to be deprecated and the recently open-sourced tf-seq2seq is too black box for my purposes. **My question is should I use the deprecated seq2seq library or is it possible to implement VLAE in tf-seq2seq specifically with control over the variational approximation or should I go in a different direction (look below)?**

I found a [torch implementation](https://github.com/cheng6076/Variational-LSTM-Autoencoder) but it's in torch and lua both of which I'm new to. I'm comfortable in python and would've liked to work with pytorch or tensorflow. I don't want to learn torch because it seems pytorch is taking over torch now but with my situation and tensorflow's decisions of changing seq2seq puts me in a frustrating situation.

Thank you for reading!

P.S. Was it only me or tensorflow's tutorial/documentation on RNN very infuriating to follow? ",12,15,False,self,,,,,
542,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,1,65jymy,artificialbrain.xyz,Machine Learning APIs by Example: Sara Robinson,https://www.reddit.com/r/MachineLearning/comments/65jymy/machine_learning_apis_by_example_sara_robinson/,Mussem17,1492273875,,0,1,False,default,,,,,
543,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,2,65k5cj,arxiv.org,A Robust Adaptive Stochastic Gradient Method for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/65k5cj/a_robust_adaptive_stochastic_gradient_method_for/,[deleted],1492275908,[deleted],0,1,False,default,,,,,
544,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,2,65k7ex,self.MachineLearning,[P] defining thresholds for continuous features in a decision tree,https://www.reddit.com/r/MachineLearning/comments/65k7ex/p_defining_thresholds_for_continuous_features_in/,Stripes96,1492276527,"I have engineered several (40) features for use in building a decision tree.
I have three output classes.
I need to define the thresholds for the nodes - e.g. is attribute 1 greater than threshold or not?
I want to use ID3
I can do this either by simply visualising the attributes and seeing what thresholds best split the data, or the other idea I had was to undertake the threshold decision process whilst building the tree. Rather than just measuring entropy reduction for each attribute I can measure entropy reduction for each attribute at a variety of thresholds. Am I oversimplifying this or overlooking anything?
Thanks!",1,3,False,self,,,,,
545,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,2,65ka85,self.MachineLearning,"Identifying ""questionable"" (low confidence) classifications in a ML system",https://www.reddit.com/r/MachineLearning/comments/65ka85/identifying_questionable_low_confidence/,HarleyThrowMeAway,1492277389,[removed],0,1,False,default,,,,,
546,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,2,65kbf1,youtu.be,Text Editor - How to Create new file on a Mac without Terminal,https://www.reddit.com/r/MachineLearning/comments/65kbf1/text_editor_how_to_create_new_file_on_a_mac/,bigmikegamesllc,1492277761,,1,1,False,default,,,,,
547,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,3,65khn6,self.MachineLearning,Can someone explain why TensorFlow RNN models use scope?,https://www.reddit.com/r/MachineLearning/comments/65khn6/can_someone_explain_why_tensorflow_rnn_models_use/,[deleted],1492279645,[removed],0,1,False,default,,,,,
548,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,3,65kivu,self.MachineLearning,[D] Does anyone else find TensorFlow's variable scope as it applies to RNN models confusing?,https://www.reddit.com/r/MachineLearning/comments/65kivu/d_does_anyone_else_find_tensorflows_variable/,jostmey,1492280012,"I am trying to wrap my mind around why TensorFlow uses variable scope. For example, the [TensorFlow RNN models](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py) all use scope. I think this means that if I create a LSTM object and then another LSTM object, the two models will share the same weights by default. The only way I can change this behavior is to define separate scopes for each object.

Does anyone else have experience with this? Why does the scope even exist in the first place? I am trying to implement [my own RNN](https://github.com/jostmey/cas/blob/master/RWACell.py) model using TensorFlow's framework, and the scope issue is driving me mad. I am so confused with TensorFlow's scope I am thinking of switching over to Pytorch, which seems to do a much better job at deploying RNN models.",35,32,False,self,,,,,
549,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,3,65kq8d,self.MachineLearning,Can a pure GAN be used for super-resolution?,https://www.reddit.com/r/MachineLearning/comments/65kq8d/can_a_pure_gan_be_used_for_superresolution/,RenegadeReddit,1492282258,[removed],0,1,False,default,,,,,
550,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,4,65kzi7,medium.com,"Thinking beyond datasets &amp; competitions for Computer Vision research, Visual Data Network for enabling frictionless data sharing [D]",https://www.reddit.com/r/MachineLearning/comments/65kzi7/thinking_beyond_datasets_competitions_for/,aub3cornell,1492285161,,2,11,False,https://a.thumbs.redditmedia.com/gFA-vVV6uKwz2c_UvIJBWQE2ReAQLGWTnfhfY7OAIk4.jpg,,,,,
551,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,6,65ljyz,self.MachineLearning,"With these grades, is a masters program in ML possible?",https://www.reddit.com/r/MachineLearning/comments/65ljyz/with_these_grades_is_a_masters_program_in_ml/,[deleted],1492291809,[removed],0,1,False,default,,,,,
552,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,8,65m19y,self.MachineLearning,"[D] What's your set up? Computer, computer specs, software, programming language, libraries, etc.",https://www.reddit.com/r/MachineLearning/comments/65m19y/d_whats_your_set_up_computer_computer_specs/,hubbahubba111,1492297643,,25,5,False,self,,,,,
553,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,9,65mdo1,self.MachineLearning,What's the proper crop for 64x64 CelebA?,https://www.reddit.com/r/MachineLearning/comments/65mdo1/whats_the_proper_crop_for_64x64_celeba/,[deleted],1492301980,[removed],0,1,False,default,,,,,
554,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,9,65me2d,self.MachineLearning,[D] Proper crop for CelebA?,https://www.reddit.com/r/MachineLearning/comments/65me2d/d_proper_crop_for_celeba/,rui_,1492302129,"A bit of a silly question, but I've yet to figure out what is the standard crop for CelebA. So far, I've seen at least four different approaches:

1) https://github.com/mila-udem/fuel/blob/566e5fa867efe1098e3f2a0726a31e1ac4f4f467/fuel/converters/celeba.py#L149

2) https://github.com/andersbll/autoencoding_beyond_pixels/blob/24aa0f20f1a73a3886551e065bbda818ad139ac2/dataset/celeba.py#L40 

3) https://github.com/Heumi/BEGAN-tensorflow/blob/master/Data/face_detect.py 

4) https://github.com/carpedm20/BEGAN-tensorflow/blob/dabe126ddac8577aae3d0efecfd3f3c4b4380c09/data_loader.py#L44 

All of them yield somewhat different results. Which should I use if, say, I wanted to write a GAN paper? Help appreciated.",1,4,False,self,,,,,
555,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,10,65ms7x,rylanschaeffer.github.io,[D] Explanation of DeepMind's One-Shot Learning with MANNs,https://www.reddit.com/r/MachineLearning/comments/65ms7x/d_explanation_of_deepminds_oneshot_learning_with/,RSchaeffer,1492307424,,13,132,False,https://b.thumbs.redditmedia.com/sSn4wcqjt6JDZNHuoALO-tPtRjCtiI8Vc6EGmt5cMuo.jpg,,,,,
556,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,12,65n6ab,techcrunch.com,RASA NLU gives developers an open source solution for natural language processing,https://www.reddit.com/r/MachineLearning/comments/65n6ab/rasa_nlu_gives_developers_an_open_source_solution/,GrabAHamLincoln,1492313005,,0,1,False,default,,,,,
557,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,14,65noyy,arxiv.org,Two-Pathway GAN: Photorealistic and Identity Preserving Frontal View Synthesis,https://www.reddit.com/r/MachineLearning/comments/65noyy/twopathway_gan_photorealistic_and_identity/,axelixon,1492321219,,2,2,False,default,,,,,
558,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,14,65nozz,self.MachineLearning,CNC Machine Parts,https://www.reddit.com/r/MachineLearning/comments/65nozz/cnc_machine_parts/,CarolGPalmieri,1492321233,[removed],0,1,False,default,,,,,
559,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,15,65nwpr,self.MachineLearning,How important is bandwidth speed of a video card to ML(or Deep Learning)?,https://www.reddit.com/r/MachineLearning/comments/65nwpr/how_important_is_bandwidth_speed_of_a_video_card/,[deleted],1492325312,[removed],0,1,False,default,,,,,
560,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,16,65nz7l,youtu.be,The Terminator is here,https://www.reddit.com/r/MachineLearning/comments/65nz7l/the_terminator_is_here/,kreateq,1492326803,,0,1,False,default,,,,,
561,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,16,65nzu8,self.MachineLearning,Categorical &amp; Continuous independent variable. Trying to find what causes the dependent variable to increase or decrease.,https://www.reddit.com/r/MachineLearning/comments/65nzu8/categorical_continuous_independent_variable/,hanifansari,1492327188,[removed],0,1,False,default,,,,,
562,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,17,65o60h,self.MachineLearning,Using ML on input/output prediction,https://www.reddit.com/r/MachineLearning/comments/65o60h/using_ml_on_inputoutput_prediction/,markgg84,1492330948,[removed],0,1,False,default,,,,,
563,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,18,65ob3b,self.MachineLearning,[Idea] Machine Learning For Generating Fake Nudes From Clothed Pictures,https://www.reddit.com/r/MachineLearning/comments/65ob3b/idea_machine_learning_for_generating_fake_nudes/,mcpiston,1492334196,[removed],1,1,False,default,,,,,
564,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,19,65of6u,self.MachineLearning,What is the simplest C++ library for running an LSTM?,https://www.reddit.com/r/MachineLearning/comments/65of6u/what_is_the_simplest_c_library_for_running_an_lstm/,Tampere100,1492336820,[removed],0,1,False,default,,,,,
565,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,19,65oj2b,medium.com,Image Recommendation for Multilingual User Texts,https://www.reddit.com/r/MachineLearning/comments/65oj2b/image_recommendation_for_multilingual_user_texts/,anuragvermaknn,1492339048,,1,1,False,default,,,,,
566,MachineLearning,t5_2r3gv,2017-4-16,2017,4,16,21,65oxhl,self.MachineLearning,Tensor based algorithm on MNIST performance,https://www.reddit.com/r/MachineLearning/comments/65oxhl/tensor_based_algorithm_on_mnist_performance/,110110111011101,1492346682,[removed],0,1,False,default,,,,,
567,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,0,65poop,scientist1642.github.io,How to build your own dashboard for Deep Learning using Visdom and SQLite,https://www.reddit.com/r/MachineLearning/comments/65poop/how_to_build_your_own_dashboard_for_deep_learning/,scientist1642,1492356958,,0,1,False,default,,,,,
568,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,1,65pt57,self.MachineLearning,[P] Yast - Yet Another Sequence Transcoder,https://www.reddit.com/r/MachineLearning/comments/65pt57/p_yast_yet_another_sequence_transcoder/,razer54,1492358437,"Hi everyone.

Working recently on NLP with spacy, I've came with a problem. It's not trivial to get a list of word vectors from a sentence.

Tool like spacy provided me all the tools needed but i had to script a bit to get what i want.

Then i thought, i must not be the only one in this case, and i wrote [Yast](https://github.com/PPACI/yast).

[Yast](https://github.com/PPACI/yast) is a CLI written in python for one shot transcoding of sentence to **vector of word vector**.

If anyone want a specific feature, don't hesitate to use this thread, i will follow it.

Also, a pip version is on the road but **yast** is already taken. What would you prefer ? 

* pip install pyyast
* pip install yastvector
* pip install yasttranscoder
* idea ?

Thank you guys !",5,14,False,self,,,,,
569,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,1,65q03n,youtu.be,Neural network digit recognition in real time,https://www.reddit.com/r/MachineLearning/comments/65q03n/neural_network_digit_recognition_in_real_time/,[deleted],1492360717,[deleted],0,1,False,default,,,,,
570,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,2,65q9oc,arxiv.org,"Comment on ""Biologically inspired protection of deep networks from adversarial attacks"" (Bethge)",https://www.reddit.com/r/MachineLearning/comments/65q9oc/comment_on_biologically_inspired_protection_of/,[deleted],1492363790,[deleted],0,1,False,default,,,,,
571,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,2,65qazi,self.MachineLearning,[P] A better approach for face recognition.,https://www.reddit.com/r/MachineLearning/comments/65qazi/p_a_better_approach_for_face_recognition/,sid3695,1492364187,"I implemented face recognition through EigenFaces and PCA. On a set of personal images it doesnt work that well, the accuracy is nearly 55-60%.

I am just a beginner in this field, so what are the other alternatives i can look forward to? ",6,0,False,self,,,,,
572,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,4,65qy8y,yashk2810.github.io,Applying Convolutional Neural Network on the MNIST dataset,https://www.reddit.com/r/MachineLearning/comments/65qy8y/applying_convolutional_neural_network_on_the/,rgbimbochamp,1492371476,,0,1,False,default,,,,,
573,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,5,65r4t1,self.MachineLearning,How to apply auto-encoders and then LTSM to a graph-structure input data ?,https://www.reddit.com/r/MachineLearning/comments/65r4t1/how_to_apply_autoencoders_and_then_ltsm_to_a/,yazriel0,1492373505,[removed],0,1,False,default,,,,,
574,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,6,65re4q,youtu.be,[P] Neural network digit recognition in real time,https://www.reddit.com/r/MachineLearning/comments/65re4q/p_neural_network_digit_recognition_in_real_time/,Flowx08,1492376497,,0,1,False,default,,,,,
575,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,6,65rfpr,self.MachineLearning,LSTM training pattern,https://www.reddit.com/r/MachineLearning/comments/65rfpr/lstm_training_pattern/,erosandras,1492376990,[removed],0,1,False,default,,,,,
576,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,6,65rnyj,i.redd.it,[D]Why does learning curve of my model shows large variance in training error? How to fix it?,https://www.reddit.com/r/MachineLearning/comments/65rnyj/dwhy_does_learning_curve_of_my_model_shows_large/,breadFTD,1492379712,,36,45,False,https://b.thumbs.redditmedia.com/qmRbs96ZsfNOH9Cqc1qCn9hjTauWfAh8wZ6odeq7Rxw.jpg,,,,,
577,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,9,65sfj3,arxiv.org,[R] On Generalized Bellman Equations and Temporal-Difference Learning,https://www.reddit.com/r/MachineLearning/comments/65sfj3/r_on_generalized_bellman_equations_and/,MetricSpade007,1492389000,,1,17,False,default,,,,,
578,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,10,65sn08,cameron.cf,A small project in searching Wikipedia pages' text using word vectors.,https://www.reddit.com/r/MachineLearning/comments/65sn08/a_small_project_in_searching_wikipedia_pages_text/,[deleted],1492391596,[deleted],0,1,False,default,,,,,
579,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,10,65stsf,self.MachineLearning,How Could I Train a Neural Net to Learn My Tastes in Photos of Paintings or Architecture?,https://www.reddit.com/r/MachineLearning/comments/65stsf/how_could_i_train_a_neural_net_to_learn_my_tastes/,Motor_City_Cobra,1492393908,[removed],0,1,False,default,,,,,
580,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,11,65szst,medium.com,Hybrid Model for Unsupervised Learning,https://www.reddit.com/r/MachineLearning/comments/65szst/hybrid_model_for_unsupervised_learning/,virene,1492396004,,0,1,False,default,,,,,
581,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,11,65t24t,self.MachineLearning,[D] What are the most important computer specs for running ML stuff. RAM? SSD?,https://www.reddit.com/r/MachineLearning/comments/65t24t/d_what_are_the_most_important_computer_specs_for/,SpiderFan,1492396830,"Would replacing my HDD with a SDD make much of a difference?

How about adding more RAM?",11,3,False,self,,,,,
582,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,11,65t4sh,self.MachineLearning,[D] Academic papers that demonstrate the power of deep learning/machine learning in a variety of fields?,https://www.reddit.com/r/MachineLearning/comments/65t4sh/d_academic_papers_that_demonstrate_the_power_of/,[deleted],1492397807,[removed],0,1,False,default,,,,,
583,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,13,65tg5n,self.MachineLearning,arxiv-link.org : reddit + arXiv + github,https://www.reddit.com/r/MachineLearning/comments/65tg5n/arxivlinkorg_reddit_arxiv_github/,aviniumau,1492402045,"Inspired by [John Carmack](https://twitter.com/ID_AA_Carmack/status/806241065787269120)*, I've knocked together [arxiv-link.org](http://arxiv-link.org), a quick proof-of-concept that might be interesting to people here. 

In short, I wanted to bring together discussions, related papers and repositories for each paper on arXiv.org. You can paste in any arxiv.org link on the front page, or try a few examples [here](http://arxiv-link.org/?url=https%3A%2F%2Farxiv.org%2Fabs%2F1606.02492) and [here](http://arxiv-link.org/?url=https%3A%2F%2Farxiv.org%2Fabs%2F1602.01783).

Currently this only ingests submissions/comments from /r/machinelearning in the past year, but we could easily expand this if there's sufficient interest. It's based on the reddit search API, which is a touch unreliable, so unfortunately it's not guaranteed to pick up every submission. 

\* there is actually an ulterior motive at play here. We're scoping a similar solution for the government at the moment. If we can come up with a good idea to commercialize this type of information aggregation/feedback platform, we've got a good shot at securing additional funding. If anyone has any thoughts or suggestions for how this might be useful in other contexts (or even within academia), please let us know! More than happy to entertain any and all feature requests too.",5,5,False,self,,,,,
584,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,15,65u37d,thewindowsclub.com,What is Machine Learning and how it is different from Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/65u37d/what_is_machine_learning_and_how_it_is_different/,russionblur,1492412298,,0,1,False,default,,,,,
585,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,18,65ukie,i.redd.it,[P] Implemented BEGAN and saw a cute face at iteration 168k. Haven't seen her since :(,https://www.reddit.com/r/MachineLearning/comments/65ukie/p_implemented_began_and_saw_a_cute_face_at/,rui_,1492421411,,120,385,False,https://b.thumbs.redditmedia.com/fzbWqEkxSXlnPdS1iP4zKP5iGEnYwIXh2i5nrwYjuaM.jpg,,,,,
586,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,19,65urmu,sites.google.com,7 loi qun o khng nn cho vo my git - Trung tm sa my git ti H Ni,https://www.reddit.com/r/MachineLearning/comments/65urmu/7_loi_qun_o_khng_nn_cho_vo_my_git_trung/,NhaTrang102,1492424987,,0,1,False,default,,,,,
587,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,21,65v6va,self.MachineLearning,Machine Learning for Bachelor Project,https://www.reddit.com/r/MachineLearning/comments/65v6va/machine_learning_for_bachelor_project/,cretu97,1492431367,[removed],0,1,False,default,,,,,
588,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,22,65vhxv,medium.com,Analysis of TensorFlow source code,https://www.reddit.com/r/MachineLearning/comments/65vhxv/analysis_of_tensorflow_source_code/,Coder_CPP,1492435225,,0,1,False,default,,,,,
589,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,22,65vj0b,youtube.com,How is soap making production line,https://www.reddit.com/r/MachineLearning/comments/65vj0b/how_is_soap_making_production_line/,mixmachinery,1492435566,,0,1,False,default,,,,,
590,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,23,65vqj2,self.MachineLearning,[P] Face detection working on Windows but not on Mac OS,https://www.reddit.com/r/MachineLearning/comments/65vqj2/p_face_detection_working_on_windows_but_not_on/,Princess_crimson,1492437960,[removed],1,0,False,default,,,,,
591,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,23,65vv5w,self.MachineLearning,[P] Optimal positioning of threshold in decision tree,https://www.reddit.com/r/MachineLearning/comments/65vv5w/p_optimal_positioning_of_threshold_in_decision/,Stripes96,1492439344,"When deciding on the value of a threshold for continuous valued attributes in a decision tree there will be infinitely many thresholds giving the same information gain.

E.g. if class one has attribute values 4 4.5 5 and class two has values 6 9 12 14, any threshold between 5 and 6 will give the same information gain.

My question is what is the optimum value of the threshold - is it simply 5.5 since this puts it equidistant from the nearest two neighbours? Or is it closer towards 6 since class one has more values of attributes closer to the boundary?

Does the fact that I have different sized training sets for each class affect it?

Cheers",11,1,False,self,,,,,
592,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,23,65vzgr,self.MachineLearning,Performance of 1080TI compared to Pascal Titan X for Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/65vzgr/performance_of_1080ti_compared_to_pascal_titan_x/,nickshahml,1492440564,[removed],0,1,False,default,,,,,
593,MachineLearning,t5_2r3gv,2017-4-17,2017,4,17,23,65w15r,github.com,[P] midi-rnn: train from and generate monophonic midi files,https://www.reddit.com/r/MachineLearning/comments/65w15r/p_midirnn_train_from_and_generate_monophonic_midi/,brannondorsey,1492441065,,0,3,False,https://b.thumbs.redditmedia.com/qnaQ9Fmwg6rv677wFUOoGG25pY14prp8I5KgLq2pmQE.jpg,,,,,
594,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,0,65wdnd,self.MachineLearning,[P] Automated 2D to 3D conversion using pix2pix,https://www.reddit.com/r/MachineLearning/comments/65wdnd/p_automated_2d_to_3d_conversion_using_pix2pix/,thepancake1,1492444494,"This is my first post here, so if I've done anything wrong, let me know!

I got curious whether pix2pix could handle generation of a stereographic pair from a single image. It worked, much to my surprise.

I was interested in Deep3D, but seeing that it produced blurry results inspired me to work on this project. 

Here's an album containing gifs showing the original image and the predicted right view. I used the same images as Deep3D here to show a direct comparison.

(RES seems to have a problem showing the gifs correctly. Go to the album page instead.)

[Predicted 3D views](http://imgur.com/a/VzTsd)

[Anaglyph 3D views](http://imgur.com/a/iFWPj)

Despite the model producing images at only 256x256, which is smaller than Deep3D's size, it seems to preserve sharp detail better. 

Notes:

* As my computer is pretty slow, I had to lower the amount of filters on the generator and discriminator of pix2pix to 32 each. 
* I used a much smaller amount of training data compared to Deep3D. I only used about 1 hour of 3D footage.


As a test, I put it to work on a video.

[Automated 3D conversion - Wholock](https://youtu.be/wekB-E__YI8)


It works pretty well for an automatic method! The generated frames aren't very consistent and are a bit wobbly, though. I think this is because it's only looking at the video one frame at a time, versus looking at the current frame and the last ten frames or something like that.

If you'd like the trained model, just let me know! Just, be patient. I'd have uploaded it already if it didn't take a few hours.

Lastly, to check how well the network has generalized, I tested it on anime/manga pictures, and it works pretty well! 

[Anime/Manga Anaglyphs](http://imgur.com/a/lVBEj)",9,15,False,self,,,,,
595,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,1,65wi3l,shashwatverma.com,All the hype about Artificial Intelligence and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/65wi3l/all_the_hype_about_artificial_intelligence_and/,therumsticks,1492445629,,1,1,False,default,,,,,
596,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,1,65wnp1,self.MachineLearning,[P] Benchmarking a denoising autoencoder.,https://www.reddit.com/r/MachineLearning/comments/65wnp1/p_benchmarking_a_denoising_autoencoder/,hyperqube12,1492447068,"I am working on a denoising autoencoder and my very first problem is that every paper I've looked at so far does not provide any kind of measure to compare against. For example, if you have a classifier, you can compare classification accuracy, but with denoising autoencoders I found exactly nothing. 

Does anyone know what measures are used for benchmarking a denoising autoencoder? Also do you have a recent paper that provides such a measure to test against? ",8,2,False,self,,,,,
597,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,1,65wotc,netsys.cs.stonybrook.edu,PrIA: A Private Intelligent Assistant,https://www.reddit.com/r/MachineLearning/comments/65wotc/pria_a_private_intelligent_assistant/,[deleted],1492447373,[deleted],0,1,False,default,,,,,
598,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,1,65wpgs,arxiv.org,[R] [1704.04289] Stochastic Gradient Descent as Approximate Bayesian Inference,https://www.reddit.com/r/MachineLearning/comments/65wpgs/r_170404289_stochastic_gradient_descent_as/,Mandrathax,1492447545,,14,62,False,default,,,,,
599,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,1,65wpwf,youtube.com,[P] Super Hexagon A3C/ACER AI,https://www.reddit.com/r/MachineLearning/comments/65wpwf/p_super_hexagon_a3cacer_ai/,innixma,1492447649,,1,3,False,https://b.thumbs.redditmedia.com/7Dvx0x_oSDZXfQRT-iZp-ofUVeJgnkQ5UrQYANKvAaI.jpg,,,,,
600,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,1,65wq1o,self.MachineLearning,[D] Ways to bring down validation cost in multilayer LSTM training,https://www.reddit.com/r/MachineLearning/comments/65wq1o/d_ways_to_bring_down_validation_cost_in/,wencc,1492447689,"I am using LSTM in tensorflow to address a seq2seq problem where input is 1000-length sequence data and outputting 1000-length corresponding values as predictions. 

My current architecture has 5 LSTM layers as we found accuracy improved with number of layers. and right now I have [200, 100, 50, 25, 10] as cell sizes for these 5 layers. Here is a [plot!](http://imgur.com/XKxzg7F) of training and val cost (MSE). We first use dropout keep_prob of 0.5 at each layer, we trained to a point where the training cost plateau at 0.01. Then I changed dropout keep_prob to 0.8, the training cost decreased to 0.003. However, the test cost has been at 0.014 for a while. I was wondering if there is anything I can do to bring down the val cost a bit more? Or that you think the val cost is about as low as it should be (Is there a statistical way to justify this)? 

Thanks.",4,1,False,self,,,,,
601,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,1,65wrdp,netsys.cs.stonybrook.edu,[R] PrIA: Private Intelligent Assistance,https://www.reddit.com/r/MachineLearning/comments/65wrdp/r_pria_private_intelligent_assistance/,theciank,1492448027,,1,2,False,default,,,,,
602,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,1,65wskb,self.MachineLearning,[P] advantage of nesting two decision trees rather than using single larger one,https://www.reddit.com/r/MachineLearning/comments/65wskb/p_advantage_of_nesting_two_decision_trees_rather/,Stripes96,1492448337,"I have 3 classes which data will be classified into.

Class B and C are fairly similar, Class A is very different.

Is there any advantage in running a decision tree to seperate (A) or (B and C) first, then building a decision tree to run on (B and C) rather than trying to seperate them all in one go?

I'm using ID3, and would just call B and C a single group if I were to run the two decision tree approach, then split them after I have taken A out of the picture.

(I'm right that the calculation for entropy can be extended for 3 classes right?)",2,2,False,self,,,,,
603,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,2,65wstt,haifengl.github.io,Machine learning on JVM,https://www.reddit.com/r/MachineLearning/comments/65wstt/machine_learning_on_jvm/,pdsminer,1492448401,,0,1,False,default,,,,,
604,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,2,65wzoj,ben.bolte.cc,Decoding Gibberish using Neural Networks,https://www.reddit.com/r/MachineLearning/comments/65wzoj/decoding_gibberish_using_neural_networks/,code_kansas,1492450182,,0,1,False,default,,,,,
605,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,3,65x7pg,deeplearningsandbox.com,Simple code tutorial for image recognition using Keras,https://www.reddit.com/r/MachineLearning/comments/65x7pg/simple_code_tutorial_for_image_recognition_using/,[deleted],1492452255,[deleted],0,1,False,default,,,,,
606,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,3,65x80d,self.MachineLearning,[D] LSTM and Output Nodes,https://www.reddit.com/r/MachineLearning/comments/65x80d/d_lstm_and_output_nodes/,[deleted],1492452334,[deleted],0,1,False,default,,,,,
607,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,3,65xcmp,self.MachineLearning,[D] Need help building a desktop deep learning rig,https://www.reddit.com/r/MachineLearning/comments/65xcmp/d_need_help_building_a_desktop_deep_learning_rig/,inexion,1492453529,"Hey all just looking to build a desktop rig for deep learning (mostly tensorflow) purposes, as opposed to spending 500$ a month on a GCE instance, I'd like to just build one I can access remotely anywhere (i.e. headless most likely).

I've used multiple posts to determine what may set me in the right direction, [this](http://timdettmers.com/2017/04/09/which-gpu-for-deep-learning/) being one of the best and most detailed.

So far, I'm thinking that a 1080 ti would be fine, and the Titan XP is only marginally better.

As far as system board and CPU, I'm wondering if Ryzen and X370 would work, but it's so new that it may be unstable.

I saw [this](https://hackaday.io/project/12070-32-tflop-deep-learning-gpu-box) project but it's a year old now and I know this stuff changes very quickly.

I'm also aware of [NVIDIAs current software](https://developer.nvidia.com/deep-learning-software) for developers and would consider multiple GPUs but it doesn't seem necessary initially. I'd just like to get a stable build going first.

Any thoughts appreciated, thank you!",10,9,False,self,,,,,
608,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,4,65xny6,self.MachineLearning,"What are some games/scenarios that Machine Learning has yet to master, what is your prediction for when they will?",https://www.reddit.com/r/MachineLearning/comments/65xny6/what_are_some_gamesscenarios_that_machine/,AlienContext,1492456505,[removed],0,1,False,default,,,,,
609,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,5,65yah7,self.MachineLearning,[D] LSTM Output Layer - Memory cells to output Nodes,https://www.reddit.com/r/MachineLearning/comments/65yah7/d_lstm_output_layer_memory_cells_to_output_nodes/,DiproIV,1492462449,"When the hidden layer memory cells output values, are the values to be passed through another set of weights connected to the output nodes?",2,3,False,self,,,,,
610,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,6,65yhb1,gab41.lab41.org,Doc2Vec to Assess Semantic Similarity in Source Code,https://www.reddit.com/r/MachineLearning/comments/65yhb1/doc2vec_to_assess_semantic_similarity_in_source/,[deleted],1492464339,[deleted],0,1,False,default,,,,,
611,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,6,65yiui,gab41.lab41.org,[N] Doc2Vec to Assess Semantic Similarity in Source Code,https://www.reddit.com/r/MachineLearning/comments/65yiui/n_doc2vec_to_assess_semantic_similarity_in_source/,amplifier_khan,1492464757,,0,1,False,default,,,,,
612,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,7,65ypg9,self.MachineLearning,How to train a model to play a game,https://www.reddit.com/r/MachineLearning/comments/65ypg9/how_to_train_a_model_to_play_a_game/,rodrigo-silveira,1492466570,[removed],0,1,False,default,,,,,
613,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,8,65za0p,medium.com,[P] Install OpenAI Gym on MacOS with one command,https://www.reddit.com/r/MachineLearning/comments/65za0p/p_install_openai_gym_on_macos_with_one_command/,taroth,1492472672,,1,0,False,https://b.thumbs.redditmedia.com/xG5PYj22JBfRSwoZnEMe2awaOJY6pKBRhZE1JuK3qbo.jpg,,,,,
614,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,9,65ziju,self.MachineLearning,"[Question-Beginner] I am trying classification using Neural Nets. The output layer is very large(same as the number of classes.) Is there a way to reduce the size of the output layer, without messing up the softmax?",https://www.reddit.com/r/MachineLearning/comments/65ziju/questionbeginner_i_am_trying_classification_using/,trollinginmyskin,1492475327,[removed],0,1,False,default,,,,,
615,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,10,65zsmv,medium.com,[D] I have tried to write summary of a paper based on RNNs in layman terms,https://www.reddit.com/r/MachineLearning/comments/65zsmv/d_i_have_tried_to_write_summary_of_a_paper_based/,nishnik,1492478492,,0,4,False,https://b.thumbs.redditmedia.com/jcFIMUhZIFN0_g3Nwu_Y8Ctsxa5EqWFC_BQ-ZkpWVeQ.jpg,,,,,
616,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,11,66072j,self.MachineLearning,[D] What do you guys do during NN training?,https://www.reddit.com/r/MachineLearning/comments/66072j/d_what_do_you_guys_do_during_nn_training/,JamminJames921,1492483080,"After weeks of reading, writing code, debugging, shouting my arse off on the rooftop, I started training my deep learning models.

We all know that training models can take hours, days, and even weeks. I am just curious, what do you often do during these moments of waiting (and praying that there's no undetected bug buried inside your code)?",11,4,False,self,,,,,
617,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,12,660bwb,arxiv.org,[R] [1704.04651] The Reactor: A Sample-Efficient Actor-Critic Architecture,https://www.reddit.com/r/MachineLearning/comments/660bwb/r_170404651_the_reactor_a_sampleefficient/,evc123,1492484685,,1,8,False,default,,,,,
618,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,13,660ms4,self.MachineLearning,[D] binary-cross entropy label value question,https://www.reddit.com/r/MachineLearning/comments/660ms4/d_binarycross_entropy_label_value_question/,anericanohuang,1492488522,"Hi, I'm new to machine learning field and was looking at autoencoder in this blog https://blog.keras.io/building-autoencoders-in-keras.html

I'm a little confused about why using binary cross entropy as cost function. 

In the training data, each value is between 0 and 1. But what I understand is when using binary cross entropy, the label is 0 or 1.

Can anyone correct me if I am wrong?

Thanks",2,4,False,self,,,,,
619,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,13,660nv1,self.MachineLearning,Any good recommendations on the intuition for reading/understanding mathematical formulae?,https://www.reddit.com/r/MachineLearning/comments/660nv1/any_good_recommendations_on_the_intuition_for/,elejuan2,1492488925,[removed],0,1,False,default,,,,,
620,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,13,660ukn,github.com,Implementation of Convolutional Neural Networks for Steady Flow Approximation. [Project],https://www.reddit.com/r/MachineLearning/comments/660ukn/implementation_of_convolutional_neural_networks/,yoyosarian,1492491551,,0,2,False,https://b.thumbs.redditmedia.com/Jc2oFkZVC8J9B4iWgb6EH7u9J6kwo8b4Ppm3VWIuQXQ.jpg,,,,,
621,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,15,6618m4,abigailsee.com,[R] Taming Recurrent Neural Networks for Better Summarization,https://www.reddit.com/r/MachineLearning/comments/6618m4/r_taming_recurrent_neural_networks_for_better/,wei_jok,1492497694,,22,192,False,https://b.thumbs.redditmedia.com/Fl1hOCJctr_AldWMctmK3hhwvH6uQ93DWB0c-a7ZTrM.jpg,,,,,
622,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,16,661epb,mixmachinery.com,How about car paint mixing disperser?,https://www.reddit.com/r/MachineLearning/comments/661epb/how_about_car_paint_mixing_disperser/,mixmachinery,1492500583,,0,1,False,default,,,,,
623,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,17,661ita,darkforte.github.io,[D] How to derive gradients in backprop without knowing matrix calculus,https://www.reddit.com/r/MachineLearning/comments/661ita/d_how_to_derive_gradients_in_backprop_without/,darkzero_reddit,1492502682,,4,0,False,default,,,,,
624,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,18,661qr0,github.com,[Project] Predicting 30-day ICU readmissions from the MIMIC-III database,https://www.reddit.com/r/MachineLearning/comments/661qr0/project_predicting_30day_icu_readmissions_from/,SphericalSpiral,1492506903,,5,8,False,https://a.thumbs.redditmedia.com/TFbP8-cdVE6kyrLw0NsHdDFzi4qppJj68zVMLsZsky4.jpg,,,,,
625,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,19,661x0t,brage.bibsys.no,"[R] Tree Boosting With XGBoost - Why Does XGBoost Win ""Every"" Machine Learning Competition?",https://www.reddit.com/r/MachineLearning/comments/661x0t/r_tree_boosting_with_xgboost_why_does_xgboost_win/,Aqwis,1492509981,,13,61,False,default,,,,,
626,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,19,6622db,eliasvansteenkiste.github.io,[P] Predicting lung cancer from CT scans (9th place at Kaggle),https://www.reddit.com/r/MachineLearning/comments/6622db/p_predicting_lung_cancer_from_ct_scans_9th_place/,pmigdal,1492512271,,5,58,False,https://b.thumbs.redditmedia.com/mL-6GY7TvWFPrW195fRpiaBxi3oZ3-YJKKPiIakP3cw.jpg,,,,,
627,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,20,6627du,self.MachineLearning,[D] How do you determine if a function is convex or not?,https://www.reddit.com/r/MachineLearning/comments/6627du/d_how_do_you_determine_if_a_function_is_convex_or/,[deleted],1492514396,[deleted],0,0,False,default,,,,,
628,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,20,6627k4,arxiv.org,Google's new MobileNet model architecture for small and scalable image classifiers is out,https://www.reddit.com/r/MachineLearning/comments/6627k4/googles_new_mobilenet_model_architecture_for/,[deleted],1492514464,[deleted],0,1,False,default,,,,,
629,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,20,6628lh,self.MachineLearning,Lift formula,https://www.reddit.com/r/MachineLearning/comments/6628lh/lift_formula/,[deleted],1492514886,[removed],0,1,False,default,,,,,
630,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,20,662ded,cameron.cf,[P] A small project in searching Wikipedia pages' text using word vectors.,https://www.reddit.com/r/MachineLearning/comments/662ded/p_a_small_project_in_searching_wikipedia_pages/,cameronfrz,1492516779,,6,12,False,https://b.thumbs.redditmedia.com/LpmjcK4McsC0zHA_kblJsrpHOHL7GZgt0kYbHkMHyHk.jpg,,,,,
631,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,22,662rzo,self.MachineLearning,[P] Using tied weights in PyTorch,https://www.reddit.com/r/MachineLearning/comments/662rzo/p_using_tied_weights_in_pytorch/,hyperqube12,1492521659,"Is there a way to enforce a layer to use the transpose of the weights of a previous layer? I know tf.slim has this, but it should somehow be possible in pytorch. Any ideas?",3,5,False,self,,,,,
632,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,22,662xor,backchannel.com,[N] Our Machines Now Have Knowledge Well Never Understand,https://www.reddit.com/r/MachineLearning/comments/662xor/n_our_machines_now_have_knowledge_well_never/,mirandaBC,1492523436,,1,1,False,default,,,,,
633,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,23,6630pe,arxiv.org,[R] [1502.02362] Counterfactual Risk Minimization: Learning from Logged Bandit Feedback,https://www.reddit.com/r/MachineLearning/comments/6630pe/r_150202362_counterfactual_risk_minimization/,TheFlyingDrildo,1492524343,,1,10,False,default,,,,,
634,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,23,6631m7,rodneybrooks.com,Patrick Winston Explains Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6631m7/patrick_winston_explains_deep_learning/,iamkeyur,1492524588,,0,1,False,default,,,,,
635,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,23,6635hl,sciencemag.org,AI beats doctors at predicting heart attacks,https://www.reddit.com/r/MachineLearning/comments/6635hl/ai_beats_doctors_at_predicting_heart_attacks/,pete0273,1492525704,,0,1,False,default,,,,,
636,MachineLearning,t5_2r3gv,2017-4-18,2017,4,18,23,6636cd,yashk2810.github.io,Convolutional Neural Network on the MNIST dataset,https://www.reddit.com/r/MachineLearning/comments/6636cd/convolutional_neural_network_on_the_mnist_dataset/,yashkatariya,1492525934,,0,1,False,default,,,,,
637,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,0,663m43,arxiv.org,[R] [1704.04861] MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,https://www.reddit.com/r/MachineLearning/comments/663m43/r_170404861_mobilenets_efficient_convolutional/,tim_anglade,1492530181,,12,19,False,default,,,,,
638,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,0,663muf,self.MachineLearning,Human Activity Recognition,https://www.reddit.com/r/MachineLearning/comments/663muf/human_activity_recognition/,Zannhs,1492530375,[removed],0,1,False,default,,,,,
639,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,2,6646jf,self.MachineLearning,question: Do you see a future with Numenta/HTM?,https://www.reddit.com/r/MachineLearning/comments/6646jf/question_do_you_see_a_future_with_numentahtm/,lovebes,1492535414,[removed],0,1,False,default,,,,,
640,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,2,6647u3,blog.sigopt.com,Expected Improvement vs. Knowledge Gradient,https://www.reddit.com/r/MachineLearning/comments/6647u3/expected_improvement_vs_knowledge_gradient/,alexcmu,1492535748,,0,1,False,default,,,,,
641,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,2,664cjk,github.com,AI assisted tagging tool for generating Fast-RCNN and YOLO training data,https://www.reddit.com/r/MachineLearning/comments/664cjk/ai_assisted_tagging_tool_for_generating_fastrcnn/,nadavbar,1492536958,,0,3,False,default,,,,,
642,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,3,664qve,ftp.math.ucla.edu,[R] Connections between non-convex optimization in deep learning to the theory of partial differential equations,https://www.reddit.com/r/MachineLearning/comments/664qve/r_connections_between_nonconvex_optimization_in/,poorasian,1492540531,,2,14,False,default,,,,,
643,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,3,664tvf,caffe2.ai,[D] Facebook releases new Caffe 2 deep learning framework,https://www.reddit.com/r/MachineLearning/comments/664tvf/d_facebook_releases_new_caffe_2_deep_learning/,[deleted],1492541286,[deleted],0,1,False,default,,,,,
644,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,3,664ufi,caffe2.ai,"[N] Facebook releases new deep learning framework, Caffe 2",https://www.reddit.com/r/MachineLearning/comments/664ufi/n_facebook_releases_new_deep_learning_framework/,whoeverwhatever,1492541433,,89,258,False,https://b.thumbs.redditmedia.com/SJzDNufAfO8SfxqkGUXOuOodGjtOmCXnQwAQeEVHFko.jpg,,,,,
645,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,4,664xk4,self.MachineLearning,How detect change points in data-streams from arff-files using MOA (or better library/interface),https://www.reddit.com/r/MachineLearning/comments/664xk4/how_detect_change_points_in_datastreams_from/,ML_TAway,1492542259,[removed],0,1,False,default,,,,,
646,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,4,664xo0,self.MachineLearning,Deep learning based speech enhacement,https://www.reddit.com/r/MachineLearning/comments/664xo0/deep_learning_based_speech_enhacement/,lvbu,1492542283,[removed],0,1,False,default,,,,,
647,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,4,664zh8,blog.revolutionanalytics.com,"[P] Comparing subreddits, with Latent Semantic Analysis in R",https://www.reddit.com/r/MachineLearning/comments/664zh8/p_comparing_subreddits_with_latent_semantic/,theciank,1492542760,,0,3,False,https://b.thumbs.redditmedia.com/-xnmSC4mAiFj1GyNYqwYAQ49r7KqPAh2WwyUEheTTTE.jpg,,,,,
648,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,4,6651w2,miguelgfierro.com,"[P] Image classification API with CNTK, Flask and CherryPy",https://www.reddit.com/r/MachineLearning/comments/6651w2/p_image_classification_api_with_cntk_flask_and/,hoaphumanoid,1492543390,,1,7,False,https://b.thumbs.redditmedia.com/sSuAiVWl8N0IHuFwlVviXAr9rrxrX5frFQjahN5xEuo.jpg,,,,,
649,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,4,66525s,theguardian.com,[N] Jrgen Schmidhuber on the robot future: They will pay as much attention to us as we do to ants' | Technology - By far the best profile and interview of Juergen Schmidhuber (even probably any AI researcher),https://www.reddit.com/r/MachineLearning/comments/66525s/n_jrgen_schmidhuber_on_the_robot_future_they/,metacurse,1492543460,,9,12,False,https://b.thumbs.redditmedia.com/zoJk-VZR6heRRC_EWCMQTP8q0d8rVH_WR9qUp0V_2bc.jpg,,,,,
650,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,4,6653ri,self.MachineLearning,Simple Question About Calculating the Error in the Hidden Layer of a Neural Network,https://www.reddit.com/r/MachineLearning/comments/6653ri/simple_question_about_calculating_the_error_in/,[deleted],1492543888,[removed],0,1,False,default,,,,,
651,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,5,665dzl,caffe2.ai,Caffe2 Open Source Brings Cross Platform Machine Learning Tools to Developers,https://www.reddit.com/r/MachineLearning/comments/665dzl/caffe2_open_source_brings_cross_platform_machine/,figurelover,1492546557,,0,1,False,default,,,,,
652,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,5,665e9f,youtu.be,Interesting video about connectomes.,https://www.reddit.com/r/MachineLearning/comments/665e9f/interesting_video_about_connectomes/,jkg1993,1492546633,,0,1,False,default,,,,,
653,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,5,665flm,self.MachineLearning,"[P] Self-driving car course with Python, TensorFlow, OpenCV, and Grand Theft Auto 5",https://www.reddit.com/r/MachineLearning/comments/665flm/p_selfdriving_car_course_with_python_tensorflow/,sentdex,1492546980,"I've put out a so far 13-part series on creating a self driving vehicle with Grand Theft Auto 5. 

**[A brief taste of what we're doing](https://twitter.com/Sentdex/status/854394799104962561)**

..or check out the latest video in the series: **[a more interesting self-driving AI](https://www.youtube.com/watch?v=nWJZ4w0HKz8)**, especially near the end. 

This is by no means a serious look into self-driving vehicles, it's just for fun, and so far the latest project has been to make a motorcycle that speeds through traffic, attempting to stay on the road and evading all the other slow drivers. 

We do all of this with basic(ish...) tools and concepts. We're reading the screen by taking screenshots with pywin32, seeing about 20 FPS with the neural network, sending keys with direct input, and then doing some analysis with OpenCV, otherwise also training with a convolutional neural network in TensorFlow. 

The goal of the series is more to show you how you can take just about whatever game you want, mapping the screen to inputs, training a neural network, and then letting the network play the game. 

It's an ongoing project, and is also **[open-source](https://github.com/sentdex/pygta5/)**

Here's a link to the **[self-driving tutorials](https://pythonprogramming.net/game-frames-open-cv-python-plays-gta-v/)**, which starts at the beginning. We start to use the neural network in **[part 9](https://pythonprogramming.net/self-driving-car-neural-network-training-data-python-plays-gta-v/)**

That's all for now, more AI in GTA to come.",14,353,False,self,,,,,
654,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,5,665le8,self.MachineLearning,[D] Creating gradients from beam search,https://www.reddit.com/r/MachineLearning/comments/665le8/d_creating_gradients_from_beam_search/,[deleted],1492548515,[deleted],5,1,False,default,,,,,
655,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,6,665u9o,mail-archives.apache.org,Apache Mahout 0.13.0 Release,https://www.reddit.com/r/MachineLearning/comments/665u9o/apache_mahout_0130_release/,based2,1492550906,,0,1,False,default,,,,,
656,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,7,6663be,github.com,Minimal and Clean Reinforcement Learning Examples,https://www.reddit.com/r/MachineLearning/comments/6663be/minimal_and_clean_reinforcement_learning_examples/,[deleted],1492553385,[deleted],0,1,False,default,,,,,
657,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,7,666425,github.com,[P] Minimal and Clean Reinforcement Learning Examples,https://www.reddit.com/r/MachineLearning/comments/666425/p_minimal_and_clean_reinforcement_learning/,[deleted],1492553595,[deleted],0,0,False,default,,,,,
658,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,7,6667xv,quora.com,How does Quora use machine learning in 2017?,https://www.reddit.com/r/MachineLearning/comments/6667xv/how_does_quora_use_machine_learning_in_2017/,nikhilbd,1492554688,,0,1,False,default,,,,,
659,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,7,666aw1,self.MachineLearning,Feature selection in neural networks / RNN,https://www.reddit.com/r/MachineLearning/comments/666aw1/feature_selection_in_neural_networks_rnn/,enavarro_DL,1492555540,[removed],0,1,False,default,,,,,
660,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,7,666bqg,techrepublic.com,Will cloud vendors like Cloudera dominate machine learning?,https://www.reddit.com/r/MachineLearning/comments/666bqg/will_cloud_vendors_like_cloudera_dominate_machine/,dataengconf,1492555793,,0,1,False,default,,,,,
661,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,9,666q7i,medium.com,Building Artificial Intelligence Together  Anand Sampat  Medium,https://www.reddit.com/r/MachineLearning/comments/666q7i/building_artificial_intelligence_together_anand/,datmo_io,1492560285,,0,1,False,default,,,,,
662,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,9,666qsd,self.MachineLearning,[D] Sentiment analysis of social media posts using deep learning,https://www.reddit.com/r/MachineLearning/comments/666qsd/d_sentiment_analysis_of_social_media_posts_using/,wnbhckr,1492560474,"I wanted to do something interesting as my master's thesis so I chose sentiment analysis with deep learning, but now I'm a bit stuck and have motivation problems due to (in my opinion) high entry barrier of the field. My supervisor wanted me to dig in academic journals, but I have a feeling it's very hard to teach yourself from academic papers, since authors don't share (one exception I found is OpenAI) all of their work, but only some vague description, comparison tables and charts, conclusions/summary.

I think I get the gist of what sentiment analysis is, but don't exactly know what could I aim for with my research as a newbie. For now I don't even have a clue how to glue sentiment analysis with deep learning. I guess extraction of opinions about specific aspects of subjects mentioned in post would be too much.

It's worth mentioning I'm also new to deep learning, however I know the basics of neural nets and had to do with reinforcement learning a little.

Fortunately, programming skills aren't a problem.

I'm looking for advice how to get started, get hyped, so I'd want to explore and experiment more on my own. All resources which you think are valuable are welcome. Thank you for your time.",8,4,False,self,,,,,
663,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,10,6674u0,self.MachineLearning,Neural Net to Recognize Faces,https://www.reddit.com/r/MachineLearning/comments/6674u0/neural_net_to_recognize_faces/,[deleted],1492564842,[removed],0,1,False,default,,,,,
664,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,10,6675kx,infoq.com,FB: Machine Learning at Scale,https://www.reddit.com/r/MachineLearning/comments/6675kx/fb_machine_learning_at_scale/,mikeyt21,1492565080,,0,1,False,default,,,,,
665,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,10,6676d9,self.MachineLearning,Is anyone here participating in the General AI challenge?,https://www.reddit.com/r/MachineLearning/comments/6676d9/is_anyone_here_participating_in_the_general_ai/,hugababoo,1492565326,[removed],0,1,False,default,,,,,
666,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,10,6676g2,self.MachineLearning,[D] What are the possible reasons why model loss is not decreasing fast?,https://www.reddit.com/r/MachineLearning/comments/6676g2/d_what_are_the_possible_reasons_why_model_loss_is/,commafighter,1492565351,I have a RNN model which I trained for 15 hrs. At the start of training the loss was about 2.9 but after 15 hrs of training the loss was about 2.2. What are the possible reasons for this slow movement of loss and how can I accelerate it? Should I add more additional RNN layers?,8,2,False,self,,,,,
667,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,10,6677vr,arxiv.org,[R] Attention-based Extraction of Structured Information from Street View Imagery,https://www.reddit.com/r/MachineLearning/comments/6677vr/r_attentionbased_extraction_of_structured/,kluikens,1492565820,,1,5,False,default,,,,,
668,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,13,667z28,self.MachineLearning,[D] Which Machine Learning Framework Is The Best?,https://www.reddit.com/r/MachineLearning/comments/667z28/d_which_machine_learning_framework_is_the_best/,[deleted],1492574926,[removed],0,1,False,default,,,,,
669,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,14,668bze,self.MachineLearning,Machine Learning and Clash Royale,https://www.reddit.com/r/MachineLearning/comments/668bze/machine_learning_and_clash_royale/,[deleted],1492580018,[removed],0,1,False,default,,,,,
670,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,14,668ddy,self.MachineLearning,[P] Machine Learning and Clash Royale,https://www.reddit.com/r/MachineLearning/comments/668ddy/p_machine_learning_and_clash_royale/,mofoss,1492580646,"Hey guys, I've been studying machine learning for a year-ish, have been programming for almost 2 years now, so I'm no expert or anything. To get my hands dirty with fun/unique projects I figured I'd try something on my own. 

If you guys know the mobile game Supercell's Clash Royale, where two users have a deck of 8 cards each and battle one another. Here's how a match works, https://www.youtube.com/watch?v=c48G9XPT88M

There are roughly 73 playable cards in the game, each having their own perks - ground troops, aerial troops, spells, etc. So each player creates their deck of 8 cards using various perks of each troop/card to form a strong deck. 

Hence given deck information of player A and player B, my goal was to predict who would win, 1 if A won, 0 if B won. 

Each data sample (X,Y) was an input data sample was a 1x32 vector, and label data was 1x1: 

X = [Defense_A, Brawlers_A, Flying_A, ElixerCost_A, ... Defense_B, Brawlers_B, Flying_B, ElixerCost_B] (16 deck attributes for each player)

Y = [Winner]

For example if player X had 2 cards with high health in his deck and 1 flying card, then Defense_X = 2, and Flying_X = 1. Winner is 1 if X won, and 0 if Y won. The app constantly posts new battles between players in the world, and that's where I can collect data (decks both players used, and who won).

So far I have about 50ish samples, and have used the Theano Neural Net with crappy results (50-60%, not surprised).

- What is your insight on this project?
- How many data points would I need to see 'something'?
- Is this too difficult? - mainly using deck attributes of players to determine the winner since it ignores the realtime play of the match itself
-Is my data structure poor?

Thanks :)",15,8,False,self,,,,,
671,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,14,668e60,youtube.com,"Amazing Machines In The World Heavy Machinery, Cutter Excavator, Big Cut...",https://www.reddit.com/r/MachineLearning/comments/668e60/amazing_machines_in_the_world_heavy_machinery/,balunirakesh,1492580989,,0,1,False,default,,,,,
672,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,15,668j2j,leafscience.org,[R] Dr. Alex Zhavoronkov  A.I. Versus Aging,https://www.reddit.com/r/MachineLearning/comments/668j2j/r_dr_alex_zhavoronkov_ai_versus_aging/,MichaelTen,1492583181,,8,17,False,https://b.thumbs.redditmedia.com/_QQQjTuywrchURLmXdsFGGF6m2AsJnnonERRWRNCwQo.jpg,,,,,
673,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,15,668jmg,techrevel.com,Google has launched its first Machine learning chip,https://www.reddit.com/r/MachineLearning/comments/668jmg/google_has_launched_its_first_machine_learning/,ankit24007,1492583429,,0,1,False,default,,,,,
674,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,17,668wmg,darpa.mil,[N] DARPAs new Lifelong Learning Machines (L2M) program comes in.,https://www.reddit.com/r/MachineLearning/comments/668wmg/n_darpas_new_lifelong_learning_machines_l2m/,nocortex,1492589769,,5,22,False,https://b.thumbs.redditmedia.com/Ia7b8CevbirptkH6gvPeUPhK6yOv-p2tAfvP-s3hHaE.jpg,,,,,
675,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,18,66931r,medium.com,Run Object Detection using Deep Learning on Raspberry Pi 3,https://www.reddit.com/r/MachineLearning/comments/66931r/run_object_detection_using_deep_learning_on/,ThisisNing,1492593031,,0,1,False,default,,,,,
676,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,19,669bgj,github.com,"[P] BatchUp: a mini-batch iteration library for Python, also looking for feedback (a bit like Fuel but simpler)",https://www.reddit.com/r/MachineLearning/comments/669bgj/p_batchup_a_minibatch_iteration_library_for/,Britefury,1492597133,,13,12,False,https://b.thumbs.redditmedia.com/qn2TvMKkUtb9aDr9L6kCXVox-y3Utfzhy4zx3wX6wcA.jpg,,,,,
677,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,22,66a7j4,tryolabs.com,[P] List of Machine Learning &amp; Deep Learning conferences to attend in 2017,https://www.reddit.com/r/MachineLearning/comments/66a7j4/p_list_of_machine_learning_deep_learning/,thesameoldstories,1492608861,,8,16,False,https://b.thumbs.redditmedia.com/i6wFp3U2umZmwZ-U301htbxBA8MAZnHO713h45auz_Y.jpg,,,,,
678,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,22,66abhe,arxiv.org,[R] - Unsupervised Learning by Predicting Noise,https://www.reddit.com/r/MachineLearning/comments/66abhe/r_unsupervised_learning_by_predicting_noise/,senorstallone,1492610033,,14,60,False,default,,,,,
679,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,23,66acvy,arxiv.org,[1704.05051] Google&amp;amp;#x27;s Cloud Vision API Is Not Robust To Noise,https://www.reddit.com/r/MachineLearning/comments/66acvy/170405051_googleampx27s_cloud_vision_api_is_not/,[deleted],1492610457,[deleted],0,1,False,default,,,,,
680,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,23,66aczd,arxiv.org,[1704.05051] Google's Cloud Vision API Is Not Robust To Noise,https://www.reddit.com/r/MachineLearning/comments/66aczd/170405051_googles_cloud_vision_api_is_not_robust/,Bardelaz,1492610485,,0,1,False,default,,,,,
681,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,23,66aehr,pinchofintelligence.com,Simple Introduction to Tensorboard Embedding Visualisation,https://www.reddit.com/r/MachineLearning/comments/66aehr/simple_introduction_to_tensorboard_embedding/,[deleted],1492610897,[deleted],0,1,False,default,,,,,
682,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,23,66aemt,pinchofintelligence.com,[P] Simple Introduction to Tensorboard Embedding Visualisation,https://www.reddit.com/r/MachineLearning/comments/66aemt/p_simple_introduction_to_tensorboard_embedding/,Dutchcheesehead,1492610929,,1,29,False,https://b.thumbs.redditmedia.com/__3CXtCUz4ZLwxucM3HXRAuk4KzbctfkKTGAZ1R0wcQ.jpg,,,,,
683,MachineLearning,t5_2r3gv,2017-4-19,2017,4,19,23,66agtt,stanfy.com,A Match Made in HeavenChatbots and Insurance Services,https://www.reddit.com/r/MachineLearning/comments/66agtt/a_match_made_in_heavenchatbots_and_insurance/,bogsformer,1492611523,,0,1,False,default,,,,,
684,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,0,66b265,self.MachineLearning,"Simple Questions Thread April 19, 2017",https://www.reddit.com/r/MachineLearning/comments/66b265/simple_questions_thread_april_19_2017/,AutoModerator,1492617153,[removed],0,1,False,default,,,,,
685,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,1,66b437,self.MachineLearning,Do VAEs require batching?,https://www.reddit.com/r/MachineLearning/comments/66b437/do_vaes_require_batching/,[deleted],1492617651,[removed],0,1,False,default,,,,,
686,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,1,66b4x5,self.MachineLearning,"Is it possible to user clustering, possibly supervised, on a list of items (in this case alternate/interchangeable materials) and then train a classifier/recommender on the clustering data-- or is this a bad idea?",https://www.reddit.com/r/MachineLearning/comments/66b4x5/is_it_possible_to_user_clustering_possibly/,[deleted],1492617843,[removed],0,1,False,default,,,,,
687,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,1,66b8c2,self.MachineLearning,"Simple Questions Thread April 19, 2017",https://www.reddit.com/r/MachineLearning/comments/66b8c2/simple_questions_thread_april_19_2017/,[deleted],1492618714,[removed],0,1,False,default,,,,,
688,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,1,66bab3,self.MachineLearning,[D] Would it be a bad idea to use clustering to create recommendations based on a DB of materials with ten categories of (continuous) characteristics by finding clusters items with similar characteristics?,https://www.reddit.com/r/MachineLearning/comments/66bab3/d_would_it_be_a_bad_idea_to_use_clustering_to/,oxmpbeta,1492619198,"I'm not new to machine learning, but frankly, I've never really dealt with clustering before-- ie: unsupervised learning-- and I'm trying to figure out how best to create a list/clustering of items from a large DB that have similar characteristics and then use that as a recommendation engine, or to feed in to a classifier as a training set.

More simply put-- I have a list of materials with about 10 to 15 different characteristics (tensile strength, etc) and I want to be able to cluster them in such a way that the system could recommend alternative materials with similar characteristics for use in the same application.  Example: material A is either too expensive or unavailable, but here's some other similar materials you should look in to.

I come from the supervised learning realm (XGBoosted trees, neural nets-- things where you have a dataset that is pre-processed for training) so I'm trying to figure out if I'm over thinking this or if there an easier way to do what I want?  From what I can gather, clustering is by and large completely unsupervised so you have to potentially do a lot of tuning to get it right, and potentially apply feature extraction like PCA first-- and at the end of the day it's useless unless you get something out of it you didn't already know.  But the problem here is less one of inference, and more one of automation (with a bit of machine learning ""inference"" used in the process.)  

Even beyond training a classifier, I could just use the clustering as the recommendation, after the results are verified of course... but while it might seem like it would be easy to build these clusters by hand this is for a large number of items and I want to potentially find clusterings that I might not have been able to come up with.",0,2,False,self,,,,,
689,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,1,66bbl4,technologyreview.com,[N] Baidu will release a free operating system for self-driving cars,https://www.reddit.com/r/MachineLearning/comments/66bbl4/n_baidu_will_release_a_free_operating_system_for/,wei_jok,1492619551,,37,143,False,https://b.thumbs.redditmedia.com/6n0HwqxxzkMHOvcapV6Ns0iNAQe1kQRUHTIhQ6ZEYUU.jpg,,,,,
690,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,1,66bgmf,self.MachineLearning,[D] Why are opensource projects supporting propietary CUDA? It is because nvidia leverage on them? nvidias knows that by tying opensource projects to them gains them huge profits in the future,https://www.reddit.com/r/MachineLearning/comments/66bgmf/d_why_are_opensource_projects_supporting/,Mgladiethor,1492620815,So why are opensource projects letting themselves become nvidias bitch?,83,14,False,self,,,,,
691,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,2,66bkzc,self.MachineLearning,Deep Learning Toolbox for Torch,https://www.reddit.com/r/MachineLearning/comments/66bkzc/deep_learning_toolbox_for_torch/,[deleted],1492621937,[removed],0,1,False,default,,,,,
692,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,4,66cd8j,digitalglobe.github.io,Bag of Visual Words,https://www.reddit.com/r/MachineLearning/comments/66cd8j/bag_of_visual_words/,geodawg,1492628977,,0,1,False,default,,,,,
693,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,4,66cdxw,self.MachineLearning,"Would you say that a lot of the Statistics you use in Machine Learning is picked up ""on the job"" or based off of concepts you learned in college?",https://www.reddit.com/r/MachineLearning/comments/66cdxw/would_you_say_that_a_lot_of_the_statistics_you/,whateverisok,1492629154,[removed],0,1,False,default,,,,,
694,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,5,66cuud,youtube.com,How to Generate Images with Tensorflow (LIVE),https://www.reddit.com/r/MachineLearning/comments/66cuud/how_to_generate_images_with_tensorflow_live/,ackstazya,1492633476,,0,1,False,default,,,,,
695,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,5,66cyng,self.MachineLearning,[D] Commercial OCR vs other solutions,https://www.reddit.com/r/MachineLearning/comments/66cyng/d_commercial_ocr_vs_other_solutions/,Param-eter,1492634478,"How do commercial OCR solutions fare compared to using more easily available things like the tesseract library? It's not an area i'm familiar with, but i'm interested to know how the best python and r libraries for this compare with commercial solutions when the goal is to scan text.",10,2,False,self,,,,,
696,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,6,66d6vx,self.MachineLearning,[LF] Neural Network Tutor,https://www.reddit.com/r/MachineLearning/comments/66d6vx/lf_neural_network_tutor/,nickbuch,1492636653,[removed],0,1,False,default,,,,,
697,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,7,66dhk9,github.com,DeepMind open sourced their DNC architecture,https://www.reddit.com/r/MachineLearning/comments/66dhk9/deepmind_open_sourced_their_dnc_architecture/,repeatuntil,1492639575,,1,1,False,default,,,,,
698,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,7,66dhmv,devblogs.nvidia.com,Caffe2: Portable High-Performance Deep Learning Framework from Facebook,https://www.reddit.com/r/MachineLearning/comments/66dhmv/caffe2_portable_highperformance_deep_learning/,[deleted],1492639592,[deleted],0,1,False,default,,,,,
699,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,7,66djjv,devblogs.nvidia.com,Caffe2: Portable High-Performance Deep Learning Framework from Facebook | Parallel Forall,https://www.reddit.com/r/MachineLearning/comments/66djjv/caffe2_portable_highperformance_deep_learning/,harrism,1492640149,,0,2,False,default,,,,,
700,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,8,66e127,self.MachineLearning,[D] Does my learning curve indicate I need more training data?,https://www.reddit.com/r/MachineLearning/comments/66e127/d_does_my_learning_curve_indicate_i_need_more/,iamiamwhoami,1492645193,"I'm training a RandomForestClassifier with 17 features to predict 10 classes. Here's the learning curve for my model https://imgur.com/a/kEPK0. To me it looks like I'm overfitting the training, and more training data could help. Is that correct?",24,4,False,self,,,,,
701,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,9,66eged,self.MachineLearning,Deep RL with external knowledge,https://www.reddit.com/r/MachineLearning/comments/66eged/deep_rl_with_external_knowledge/,Skarwild,1492649908,[removed],0,1,False,default,,,,,
702,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,10,66emiu,github.com,[P] Collection of Minimal Reinforcement Learning Implementations,https://www.reddit.com/r/MachineLearning/comments/66emiu/p_collection_of_minimal_reinforcement_learning/,kwk236,1492651843,,27,93,False,https://b.thumbs.redditmedia.com/RTMP-QG1n77bHQxtNIzK4pQezNS64mgYhQKyDC9id7g.jpg,,,,,
703,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,13,66fifu,lukeoakdenrayner.wordpress.com,[D] The End of Human Doctors  Pt 1 (blogpost series),https://www.reddit.com/r/MachineLearning/comments/66fifu/d_the_end_of_human_doctors_pt_1_blogpost_series/,drlukeor,1492662571,,14,19,False,https://b.thumbs.redditmedia.com/QoNM_q0grgQ5htxW_q59zVjriBSwSMOBOoDePEABfeY.jpg,,,,,
704,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,13,66fjh4,self.MachineLearning,Translating the Notes of CS229 to Chinese,https://www.reddit.com/r/MachineLearning/comments/66fjh4/translating_the_notes_of_cs229_to_chinese/,CycleUser,1492662958,[removed],0,1,False,default,,,,,
705,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,13,66fl38,self.MachineLearning,Training videos for sheet extrusion?,https://www.reddit.com/r/MachineLearning/comments/66fl38/training_videos_for_sheet_extrusion/,Zaba_zaba,1492663588,[removed],0,1,False,default,,,,,
706,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,15,66fwiz,arxiv.org,[R] Beating Atari with Natural Language Guided Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/66fwiz/r_beating_atari_with_natural_language_guided/,Devilsbabe,1492668209,,6,10,False,default,,,,,
707,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,15,66fzjp,medium.com,Machine Learning: Back to the Future,https://www.reddit.com/r/MachineLearning/comments/66fzjp/machine_learning_back_to_the_future/,Gamooga,1492669556,,0,1,False,default,,,,,
708,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,15,66g3ge,youtube.com,BEYOND Complete line production line,https://www.reddit.com/r/MachineLearning/comments/66g3ge/beyond_complete_line_production_line/,beyondmachine,1492671309,,0,1,False,default,,,,,
709,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,17,66ged1,self.MachineLearning,Deep Neural Network from scratch,https://www.reddit.com/r/MachineLearning/comments/66ged1/deep_neural_network_from_scratch/,[deleted],1492676494,[removed],0,1,False,default,,,,,
710,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,17,66gfj0,matrices.io,"[P] Deep Neural Network from scratch (Data pre processing, Forward propagation, Backward propagation, Bias, Regularization, Gradient descent)",https://www.reddit.com/r/MachineLearning/comments/66gfj0/p_deep_neural_network_from_scratch_data_pre/,theflofly,1492677096,,2,3,False,default,,,,,
711,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,18,66gjf6,self.MachineLearning,Starting my first deep learning project: What sort of potential data cleaning and preparation problems should I be aware of?,https://www.reddit.com/r/MachineLearning/comments/66gjf6/starting_my_first_deep_learning_project_what_sort/,[deleted],1492678984,[removed],0,1,False,default,,,,,
712,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,18,66gmpy,self.MachineLearning,What experiments can be done to argue that a GAN isn't simply memorising and retrieving the data?,https://www.reddit.com/r/MachineLearning/comments/66gmpy/what_experiments_can_be_done_to_argue_that_a_gan/,trollinginmyskin,1492680588,[removed],0,1,False,default,,,,,
713,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,20,66h195,self.MachineLearning,Help with time series clustering,https://www.reddit.com/r/MachineLearning/comments/66h195/help_with_time_series_clustering/,xen-m-rph,1492687090,[removed],0,1,False,default,,,,,
714,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,20,66h2nq,github.com,[EASY to READ] Deep Convolutional Generative Adversarial Networks - TensorFlow,https://www.reddit.com/r/MachineLearning/comments/66h2nq/easy_to_read_deep_convolutional_generative/,zsdh123,1492687661,,0,1,False,default,,,,,
715,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,20,66h4qx,github.com,Generative Adversarial Text to Image Synthesis in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/66h4qx/generative_adversarial_text_to_image_synthesis_in/,zsdh123,1492688458,,0,1,False,default,,,,,
716,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,21,66h9as,arxiv.org,[R][1704.05588] Learning to Fly by Crashing,https://www.reddit.com/r/MachineLearning/comments/66h9as/r170405588_learning_to_fly_by_crashing/,ajmooch,1492690086,,15,49,False,default,,,,,
717,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,21,66hbcm,self.MachineLearning,[HIRING] Deep Learning Specialist required for Altruistic AI Startup!,https://www.reddit.com/r/MachineLearning/comments/66hbcm/hiring_deep_learning_specialist_required_for/,[deleted],1492690760,[removed],0,1,False,default,,,,,
718,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,21,66hfdi,arxiv.org,[1704.05420v1] Diagonal RNNs in Symbolic Music Modeling,https://www.reddit.com/r/MachineLearning/comments/66hfdi/170405420v1_diagonal_rnns_in_symbolic_music/,BadGoyWithAGun,1492692121,,1,1,False,default,,,,,
719,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,22,66hszh,self.MachineLearning,[P] - Deep Learning Toolbox for Torch,https://www.reddit.com/r/MachineLearning/comments/66hszh/p_deep_learning_toolbox_for_torch/,dmarnerides,1492696268,"I've created [this toolbox](https://github.com/dmarnerides/dlt) to learn Lua and Torch.

Currently supports multi-GPU training (DPT), multi-threaded data loading, easy experiment creation, multiple training modes (simple, GAN, WGAN, BEGAN), creation of SLURM scripts for HPC facilities, easy dispatching of self-contained experiments, checkpointing, logging of training losses, colorspace conversions for XYZ, IPT, LMS, L.

Also includes some data loaders (MNIST,CIFAR,CelebA,Places,pix2pix) and some pre-implemented standard networks.

Some features are possibly buggy. Let me know what you think if you try and use it.",0,25,False,self,,,,,
720,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,23,66huyy,self.MachineLearning,best network for extracting image descriptors,https://www.reddit.com/r/MachineLearning/comments/66huyy/best_network_for_extracting_image_descriptors/,freynolds0000,1492696853,[removed],0,1,False,default,,,,,
721,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,23,66huzs,self.MachineLearning,[Research] Neural network with multiple sensors,https://www.reddit.com/r/MachineLearning/comments/66huzs/research_neural_network_with_multiple_sensors/,ProjectPsygma,1492696858,"Hi r/MachineLearning,

I am currently completing some research into neural networks with multiple sensor data streams for the purposes of classification. I have a photo (JPG), an audio recording (WAV), a metal detector reading (time series or boolean), and scale weight (float) for each sample. I plan on building the neural network using Tensorflow, and extract features from the photo via the last layer of Google's Inception model for feature learning. Librosa will be used to extract features like MFCC and Chromagram from the audio recording. I have a scale fitted to take weight readings which will presumably remain in floating point format. Finally, I have a metal detector that has a timeseries reading for fluctuations in inductive frequency.

My question are; 
a. Is it feasible to combine all of these features into a single neural network for classification? 
b. Would using inception for feature learning work? 
c. What suggestions would you guys have for the design of the neural network as a whole?",2,6,False,self,,,,,
722,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,23,66hz91,self.MachineLearning,Reclassifying messy data,https://www.reddit.com/r/MachineLearning/comments/66hz91/reclassifying_messy_data/,pankswork,1492697992,[removed],0,1,False,default,,,,,
723,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,23,66i2ix,github.com,Framework for building complex recurrent neural networks with Keras (new API),https://www.reddit.com/r/MachineLearning/comments/66i2ix/framework_for_building_complex_recurrent_neural/,abhaikollara,1492698860,,0,1,False,default,,,,,
724,MachineLearning,t5_2r3gv,2017-4-20,2017,4,20,23,66i4xe,medium.com,So what is Machine Learning good for anyway?,https://www.reddit.com/r/MachineLearning/comments/66i4xe/so_what_is_machine_learning_good_for_anyway/,D33B,1492699496,,0,1,False,default,,,,,
725,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,0,66i90u,self.MachineLearning,"Standard/commonly-used ""toy"" image dataset for CNN regression problems?",https://www.reddit.com/r/MachineLearning/comments/66i90u/standardcommonlyused_toy_image_dataset_for_cnn/,Shianiawhite,1492700560,[removed],0,1,False,default,,,,,
726,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,0,66ikg1,people.eecs.berkeley.edu,[R] Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization,https://www.reddit.com/r/MachineLearning/comments/66ikg1/r_hyperband_a_novel_banditbased_approach_to/,theciank,1492703459,,3,63,False,default,,,,,
727,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,1,66imms,arxiv.org,[R] [1704.05831] Learning to Generate Long-term Future via Hierarchical Prediction,https://www.reddit.com/r/MachineLearning/comments/66imms/r_170405831_learning_to_generate_longterm_future/,evc123,1492704013,,6,19,False,default,,,,,
728,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,1,66in95,deephunt.in,[P] The complete list of all named Generative Adversarial Networks (GANs) till date :),https://www.reddit.com/r/MachineLearning/comments/66in95/p_the_complete_list_of_all_named_generative/,hindupuravinash,1492704154,,18,94,False,https://b.thumbs.redditmedia.com/nwL1hk0z9ya_SDCyT9HlcRQ-xgDCnhOxKLsFi6hiY0k.jpg,,,,,
729,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,1,66isyn,self.MachineLearning,"[D] Access to computation at DeepMind, FAIR, OpenAI, Brain, Microsoft, etc.?",https://www.reddit.com/r/MachineLearning/comments/66isyn/d_access_to_computation_at_deepmind_fair_openai/,changingourworld,1492705558,"Does every research scientist have access to N (e.g. 4) GPUs at any point in time? 

Do you need to request access and wait until they're open? If so, what's the typical wait time?

Could a research scientist use 64 GPUs for the next 6 months 24/7?
",5,10,False,self,,,,,
730,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,1,66iuv7,medium.com,[P] How to autoencode your Pokemon,https://www.reddit.com/r/MachineLearning/comments/66iuv7/p_how_to_autoencode_your_pokemon/,sinseption,1492706048,,10,16,False,default,,,,,
731,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,1,66iv4l,eklitzke.org,[P] Pinning GPU Memory in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/66iv4l/p_pinning_gpu_memory_in_tensorflow/,blubprogrammer,1492706111,,1,15,False,default,,,,,
732,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,1,66iznb,scientificamerican.com,Apollo Project,https://www.reddit.com/r/MachineLearning/comments/66iznb/apollo_project/,dendisuhubdy,1492707218,,0,1,False,default,,,,,
733,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,2,66j2i4,madebyollin.com,[P] Isolating vocals from music with a ConvNet,https://www.reddit.com/r/MachineLearning/comments/66j2i4/p_isolating_vocals_from_music_with_a_convnet/,madebyollin,1492707910,,16,41,False,default,,,,,
734,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,3,66jq3y,self.MachineLearning,Mask RCNN 5 FPS?,https://www.reddit.com/r/MachineLearning/comments/66jq3y/mask_rcnn_5_fps/,learning_machine42,1492713712,[removed],0,1,False,default,,,,,
735,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,4,66jzhl,medium.com,Benchmarking Tensorflow Performance and Cost Across Different GPU Options,https://www.reddit.com/r/MachineLearning/comments/66jzhl/benchmarking_tensorflow_performance_and_cost/,[deleted],1492716116,[deleted],0,2,False,default,,,,,
736,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,4,66k291,self.MachineLearning,How to improve F1 score with skewed classes?,https://www.reddit.com/r/MachineLearning/comments/66k291/how_to_improve_f1_score_with_skewed_classes/,hansaw,1492716797,[removed],0,1,False,default,,,,,
737,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,4,66k4r8,medium.com,[N] Benchmarking Tensorflow Performance and Cost Across Different GPU Options,https://www.reddit.com/r/MachineLearning/comments/66k4r8/n_benchmarking_tensorflow_performance_and_cost/,vincechu,1492717426,,6,32,False,https://b.thumbs.redditmedia.com/cbWro0Gi62WBWYEEeEvtH1_2WMMhqU1BWhrdGRPCAUg.jpg,,,,,
738,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,5,66kah9,self.MachineLearning,[D] GUI for scikit-learn or Keras?,https://www.reddit.com/r/MachineLearning/comments/66kah9/d_gui_for_scikitlearn_or_keras/,pplonski,1492718830,[removed],0,1,False,default,,,,,
739,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,5,66kaw7,datawhatnow.com,Feature importance and why its important,https://www.reddit.com/r/MachineLearning/comments/66kaw7/feature_importance_and_why_its_important/,Weenkus,1492718931,,0,2,False,default,,,,,
740,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,6,66krdu,artificialbrain.xyz,A Quest for Visual Intelligence in Computers: Googles Fei-Fei Li,https://www.reddit.com/r/MachineLearning/comments/66krdu/a_quest_for_visual_intelligence_in_computers/,Mussem17,1492723093,,0,1,False,default,,,,,
741,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,6,66krrq,self.MachineLearning,Please help give me a reality check for buying my new dream PC.,https://www.reddit.com/r/MachineLearning/comments/66krrq/please_help_give_me_a_reality_check_for_buying_my/,[deleted],1492723191,[removed],0,1,False,default,,,,,
742,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,7,66l2ug,self.MachineLearning,Sick and Tired of the Way the Keras Dev Treats Others,https://www.reddit.com/r/MachineLearning/comments/66l2ug/sick_and_tired_of_the_way_the_keras_dev_treats/,[deleted],1492726212,[removed],0,1,False,default,,,,,
743,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,7,66layy,self.MachineLearning,Framework that best parallels theory?,https://www.reddit.com/r/MachineLearning/comments/66layy/framework_that_best_parallels_theory/,DullPointerException,1492728529,[removed],0,1,False,default,,,,,
744,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,9,66lt1a,devblogs.nvidia.com,Photo Editing with Generative Adversarial Networks (Part 1),https://www.reddit.com/r/MachineLearning/comments/66lt1a/photo_editing_with_generative_adversarial/,harrism,1492733975,,0,1,False,default,,,,,
745,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,9,66lu44,youtube.com,How Amazon's AI-based Alexa is Monopolizing Retail &amp; Entertainment Industry? The Voice Control!,https://www.reddit.com/r/MachineLearning/comments/66lu44/how_amazons_aibased_alexa_is_monopolizing_retail/,scidem,1492734330,,0,1,False,default,,,,,
746,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,10,66m1c8,arxiv.org,[R] Softmax GAN,https://www.reddit.com/r/MachineLearning/comments/66m1c8/r_softmax_gan/,wei_jok,1492736559,,5,21,False,default,,,,,
747,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,11,66mcef,arxiv.org,[R] Predicting cognitive decline with deep CNN of multimodal PET images,https://www.reddit.com/r/MachineLearning/comments/66mcef/r_predicting_cognitive_decline_with_deep_cnn_of/,chy1000,1492740059,,1,6,False,default,,,,,
748,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,13,66n26i,deeppavlov.github.io,The Conversational Intelligence Challenge,https://www.reddit.com/r/MachineLearning/comments/66n26i/the_conversational_intelligence_challenge/,shagunsodhani,1492748835,,0,1,False,default,,,,,
749,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,14,66n79v,youtube.com,[D] Fb's Thought2Thought (bci + sensory substitution) presentation,https://www.reddit.com/r/MachineLearning/comments/66n79v/d_fbs_thought2thought_bci_sensory_substitution/,evc123,1492750891,,0,2,False,https://b.thumbs.redditmedia.com/nBi32teP0_ab-3Sn0Dea9t0eHvNA4JRAMToKLpw5bsc.jpg,,,,,
750,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,14,66ndeo,self.MachineLearning,Android Project,https://www.reddit.com/r/MachineLearning/comments/66ndeo/android_project/,BeastjungleNA,1492753535,[removed],0,1,False,default,,,,,
751,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,16,66ntlk,github.com,[P] Value Iteration Networks full-stack pure Python + Pytorch implementation (model and gridworld),https://www.reddit.com/r/MachineLearning/comments/66ntlk/p_value_iteration_networks_fullstack_pure_python/,kentsommer,1492761059,,1,5,False,https://a.thumbs.redditmedia.com/vqoPLekTu1Y2sBBx2R5N3XSt0NRGC3OIm0DoUL_6YE0.jpg,,,,,
752,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,16,66nts4,4shared.com,Variobend Double Bender Australia,https://www.reddit.com/r/MachineLearning/comments/66nts4/variobend_double_bender_australia/,stamac,1492761156,,0,1,False,default,,,,,
753,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,17,66nurt,self.MachineLearning,"Open access for Esteva, et al. Nature algorithm?",https://www.reddit.com/r/MachineLearning/comments/66nurt/open_access_for_esteva_et_al_nature_algorithm/,Gwdata,1492761687,[removed],0,1,False,default,,,,,
754,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,17,66nwkz,self.MachineLearning,Any companies hiring interns for deep learning or machine learning? (asking as a first year phd student),https://www.reddit.com/r/MachineLearning/comments/66nwkz/any_companies_hiring_interns_for_deep_learning_or/,udungoofedbrah,1492762659,[removed],0,1,False,default,,,,,
755,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,17,66nzi8,academia.edu,Maintaining Industrial Equipments,https://www.reddit.com/r/MachineLearning/comments/66nzi8/maintaining_industrial_equipments/,stamac,1492764142,,0,1,False,default,,,,,
756,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,18,66o3ku,github.com,How to learn AI,https://www.reddit.com/r/MachineLearning/comments/66o3ku/how_to_learn_ai/,emilwallner,1492766197,,1,1,False,default,,,,,
757,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,18,66o4u3,self.MachineLearning,[D] Why does the SSD network need an specific input size?,https://www.reddit.com/r/MachineLearning/comments/66o4u3/d_why_does_the_ssd_network_need_an_specific_input/,huuuynh,1492766819,"Hello fellow redditors!
Usually before using an image as an input for the Single Shot Multibox Detector (SSD) the image gets cropped/warped into the desired input size. Wide images like the one of the KITTI dataset will get squeezed a lot and therefor lose some information. 
I am wondering why the Single Shot Multibox Detector needs a specific input size of 300x300/512x512. Wouldn't it be more efficient if the network was able process wide images without squeezing them as well?",8,0,False,self,,,,,
758,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,19,66obrb,self.MachineLearning,"[D] Weight normalization vs. layer normalization, has anyone done benchmarks?",https://www.reddit.com/r/MachineLearning/comments/66obrb/d_weight_normalization_vs_layer_normalization_has/,carlthome,1492770026,"Batch normalization is the norm ~~(pun intended)~~ but for RNNs or small batch sizes [layer normalization](https://arxiv.org/abs/1607.06450) and [weight normalization](https://arxiv.org/abs/1602.07868) look like attractive alternatives. 

In [the NIPS submission for weight normalization](https://papers.nips.cc/paper/6114-weight-normalization-a-simple-reparameterization-to-accelerate-training-of-deep-neural-networks.pdf), they have the layer normalization paper listed as a reference (although never cited in the text), but it has since been removed. This got me thinking about pros/cons of the respective methods. Has anyone done benchmarks comparing weight normalization to layer normalization (particularly for ResNets or RNNs)?

PS: [Recurrent batch normalization](https://arxiv.org/abs/1603.09025) is memory intensive and should be avoided IMO, but that too would be interesting to benchmark.

PPS: I have no clue how to initialize weights smartly so I rely on normalization.",8,24,False,self,,,,,
759,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,19,66odni,blog.photoeditorsdk.com,[P] Deep Learning for Photo Editing,https://www.reddit.com/r/MachineLearning/comments/66odni/p_deep_learning_for_photo_editing/,padschneider,1492770895,,16,100,False,https://b.thumbs.redditmedia.com/NBhJ79SYMe22m03ySW2av07sTGkBF5XZv6fysoKDlqE.jpg,,,,,
760,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,21,66orae,arxiv.org,[R] A Framework for Parallel and Distributed Training of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/66orae/r_a_framework_for_parallel_and_distributed/,scardax88,1492776230,,1,2,False,default,,,,,
761,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,22,66p6h9,github.com,simple deep digit detector implemented using SVHN-dataset,https://www.reddit.com/r/MachineLearning/comments/66p6h9/simple_deep_digit_detector_implemented_using/,[deleted],1492781350,[deleted],0,1,False,default,,,,,
762,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,22,66p8ih,github.com,[P] Deep digit detector using SVHN dataset,https://www.reddit.com/r/MachineLearning/comments/66p8ih/p_deep_digit_detector_using_svhn_dataset/,penny4860,1492781965,,0,1,False,https://b.thumbs.redditmedia.com/qYIs6asn9a1IWKhCKvMcZaRb1JHGzE1z1FO7h8TJynY.jpg,,,,,
763,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,23,66pd3s,inference.vc,"[R] Review of ""Unsupervised Learning by Predicting Noise"": an Information Maximization Perspective",https://www.reddit.com/r/MachineLearning/comments/66pd3s/r_review_of_unsupervised_learning_by_predicting/,fhuszar,1492783309,,3,44,False,https://b.thumbs.redditmedia.com/zzphZY0Lu7qe_eGxe_ZG_0E_jDhIVHUJb1wa6TMxhos.jpg,,,,,
764,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,23,66pfwv,self.MachineLearning,[R] Datasets of Vincent et.al. (2007) missing.,https://www.reddit.com/r/MachineLearning/comments/66pfwv/r_datasets_of_vincent_etal_2007_missing/,hyperqube12,1492784102,"I am trying to reproduce the results of [Vincent et.al. (2007) ](http://machinelearning.org/archive/icml2008/papers/592.pdf), but the link they provide for the datasets, namely 

&gt; All the datasets for these problems are available at
http://www.iro.umontreal.ca/lisa/icml2007.

does not work. I badly need those datasets. Anyone know an alternate source? ",4,1,False,self,,,,,
765,MachineLearning,t5_2r3gv,2017-4-21,2017,4,21,23,66ph8o,arxiv.org,[R] Representing Sentences as Low Rank Subspaces,https://www.reddit.com/r/MachineLearning/comments/66ph8o/r_representing_sentences_as_low_rank_subspaces/,visarga,1492784472,,4,6,False,default,,,,,
766,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,0,66q3bh,evernote.com,Elon Musk's newest idea: Neuralink. Human/Artificial Intelligence Integration.,https://www.reddit.com/r/MachineLearning/comments/66q3bh/elon_musks_newest_idea_neuralink_humanartificial/,[deleted],1492790365,[deleted],0,1,False,default,,,,,
767,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,1,66q5td,self.MachineLearning,Best algorithm to use for a newbie project,https://www.reddit.com/r/MachineLearning/comments/66q5td/best_algorithm_to_use_for_a_newbie_project/,[deleted],1492791010,[removed],0,1,False,default,,,,,
768,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,1,66q6pg,self.MachineLearning,[D] Does anybody know why GTA V integration with OpenAI's Universe was removed?,https://www.reddit.com/r/MachineLearning/comments/66q6pg/d_does_anybody_know_why_gta_v_integration_with/,sup6978,1492791230,Could OpenAI and Rockstar be doing some work together? (I know this _may_ not be the correct sub to ask.),9,30,False,self,,,,,
769,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,1,66q7tf,self.MachineLearning,Why are many folks critical of Keras?,https://www.reddit.com/r/MachineLearning/comments/66q7tf/why_are_many_folks_critical_of_keras/,testingTestingIBS,1492791511,[removed],0,1,False,default,,,,,
770,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,1,66q8tb,self.MachineLearning,[D] Feature learning to transform variable length sequential data into fixed length feature vectors,https://www.reddit.com/r/MachineLearning/comments/66q8tb/d_feature_learning_to_transform_variable_length/,brannondorsey,1492791783,"I'm looking for the best way to do feature learning on variable length sequences that will produce a learned feature embedding of a fixed length. Forgive my if this is obvious, but is that one use of a sequence to sequence autoencoder? Is a sequential encoder-decoder network an autoencoder?

Say I've got a folder of 100 MIDI files of variable length and I want to learn an optimal fixed length feature embedding for each of them of say, 50 dimensions. For each MIDI file would I run it through a sequential encoder-decoder model, wait for it to converge on some optimum (essentially overfitting or memorizing that one MIDI file), and then take the 50 dimensional output of my encoder network (simply the frozen weight at the last layer) and save that as my learned feature vector? Then repeat that process for each of the 100 MIDI files, re-initializing the weights of my model each time before learning a feature vector for the next file? Or is my understanding flawed and there is a better way to achieve this goal?

Thanks!
",10,4,False,self,,,,,
771,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,1,66qgiu,self.MachineLearning,Combining keras and kaldi,https://www.reddit.com/r/MachineLearning/comments/66qgiu/combining_keras_and_kaldi/,215_215,1492793819,[removed],0,1,False,default,,,,,
772,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,2,66qojt,self.MachineLearning,Help with the machine learning course by Andrew Ng,https://www.reddit.com/r/MachineLearning/comments/66qojt/help_with_the_machine_learning_course_by_andrew_ng/,krishamehta,1492795830,[removed],0,1,False,default,,,,,
773,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,2,66qtor,self.MachineLearning,"In a two stream network, when should you have shared weights and when separate?",https://www.reddit.com/r/MachineLearning/comments/66qtor/in_a_two_stream_network_when_should_you_have/,mgudur,1492797101,[removed],0,1,False,default,,,,,
774,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,3,66qwju,self.MachineLearning,[D] Do you believe Machine Learning is overhyped?,https://www.reddit.com/r/MachineLearning/comments/66qwju/d_do_you_believe_machine_learning_is_overhyped/,StanfordMLPhD,1492797814,[removed],26,4,False,default,,,,,
775,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,3,66r1qe,artificialbrain.xyz,"Future Intelligent Systems, Machine Learning software design: Googles Peter Norvig",https://www.reddit.com/r/MachineLearning/comments/66r1qe/future_intelligent_systems_machine_learning/,Mussem17,1492799108,,0,1,False,default,,,,,
776,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,3,66r2bs,microsoft.com,[R] Deep Learning for Program Synthesis - Microsoft Research,https://www.reddit.com/r/MachineLearning/comments/66r2bs/r_deep_learning_for_program_synthesis_microsoft/,MetricSpade007,1492799263,,23,72,False,https://b.thumbs.redditmedia.com/3XXb7Tb1OWu3ByDP4iQZKF1C6HdExpkdTAPD46do8FM.jpg,,,,,
777,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,3,66r447,cnbc.com,"[N] Several Google engineers have left one of its most secretive AI projects to form a stealth start-up, Groq Inc.",https://www.reddit.com/r/MachineLearning/comments/66r447/n_several_google_engineers_have_left_one_of_its/,SuperImprobable,1492799682,,85,191,False,https://b.thumbs.redditmedia.com/_JKCWzAcmw5AWpMFHWDsWgQ7AExCz6tFcvOg7YD89Cg.jpg,,,,,
778,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,4,66rhde,self.MachineLearning,Fellow scientist,https://www.reddit.com/r/MachineLearning/comments/66rhde/fellow_scientist/,KuriosityKilleddKat,1492803259,[removed],0,1,False,default,,,,,
779,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,4,66rhrv,self.MachineLearning,Gtx 780 used or what gpu to buy for kaggle beginner?,https://www.reddit.com/r/MachineLearning/comments/66rhrv/gtx_780_used_or_what_gpu_to_buy_for_kaggle/,LorD-U-n0-Po0,1492803381,[removed],0,1,False,default,,,,,
780,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,4,66rj9h,waitbutwhy.com,Elon Musk's Idea: Human:Artificial Intelligence Integration,https://www.reddit.com/r/MachineLearning/comments/66rj9h/elon_musks_idea_humanartificial_intelligence/,Just_Molecules,1492803789,,0,1,False,default,,,,,
781,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,4,66rmba,self.MachineLearning,"[D] Comparing the growth of machine learning to that of the internet around 2000, what year are we in right now?",https://www.reddit.com/r/MachineLearning/comments/66rmba/d_comparing_the_growth_of_machine_learning_to/,StanfordMLPhD,1492804616,[removed],3,0,False,default,,,,,
782,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,5,66rriz,self.MachineLearning,[D] RNN's Are Much Faster in PyTorch than TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/66rriz/d_rnns_are_much_faster_in_pytorch_than_tensorflow/,nickshahml,1492806079,"I've done some language bench marking experiments and for language modeling on PTB, i'm getting the following results for training:

On both 980 TI and old Titan X:

**PyTorch**
0.543 sec per batch -- batch size of 64, hidden size of 2048 units, 2 layers LSTM, 60 timesteps

**TensorFlow**
1.243 sec per batch -- batch size of 64, hidden size of 2048 units, 2 layers LSTM, 60 timesteps

Has anyone else experienced such drastic time differences for the RNN domain? Any clue as to why this is the case?",32,26,False,self,,,,,
783,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,5,66rusw,ki-blog.de,#MLDD Machine Learning Meetup in Dresden,https://www.reddit.com/r/MachineLearning/comments/66rusw/mldd_machine_learning_meetup_in_dresden/,flezzfx,1492806988,,0,1,False,default,,,,,
784,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,6,66s1pv,arxiv.org,[R] A Syntactic Neural Model for General-Purpose Code Generation &lt;= State Of The Art Program Gen,https://www.reddit.com/r/MachineLearning/comments/66s1pv/r_a_syntactic_neural_model_for_generalpurpose/,The_Man_of_Science,1492808914,,1,6,False,default,,,,,
785,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,8,66sqo0,self.MachineLearning,Feature Selection Using tf-idf for text classification,https://www.reddit.com/r/MachineLearning/comments/66sqo0/feature_selection_using_tfidf_for_text/,bluestriker89,1492816453,[removed],0,1,False,default,,,,,
786,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,8,66srfg,arxiv.org,[R] Recurrent Environment Simulators (videos in comments),https://www.reddit.com/r/MachineLearning/comments/66srfg/r_recurrent_environment_simulators_videos_in/,modeless,1492816715,,2,7,False,default,,,,,
787,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,8,66sttg,self.MachineLearning,Want to pursue a career in AI. Is a beginner's course in ML the right way to go?,https://www.reddit.com/r/MachineLearning/comments/66sttg/want_to_pursue_a_career_in_ai_is_a_beginners/,unknownharris,1492817492,[removed],0,1,False,default,,,,,
788,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,9,66t0b3,self.MachineLearning,[D] Career prospects for ML academics,https://www.reddit.com/r/MachineLearning/comments/66t0b3/d_career_prospects_for_ml_academics/,[deleted],1492819730,[deleted],12,4,False,default,,,,,
789,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,10,66ta4b,self.MachineLearning,Atlantic Causal Inference Conference Data Analysis Challenge,https://www.reddit.com/r/MachineLearning/comments/66ta4b/atlantic_causal_inference_conference_data/,prhahn,1492823092,[removed],0,1,False,default,,,,,
790,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,12,66tvk9,self.MachineLearning,Go back to school or build a portfolio?,https://www.reddit.com/r/MachineLearning/comments/66tvk9/go_back_to_school_or_build_a_portfolio/,[deleted],1492830976,[removed],0,1,False,default,,,,,
791,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,12,66twji,cv-tricks.com,This very popular Tensorflow tutorial has been shared more than 700 times. Hope it helps someone here.,https://www.reddit.com/r/MachineLearning/comments/66twji/this_very_popular_tensorflow_tutorial_has_been/,sankit123,1492831352,,0,1,False,default,,,,,
792,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,12,66u20q,youtube.com,Artificial Intelligence: It starts to create Art and is growing exponentially.,https://www.reddit.com/r/MachineLearning/comments/66u20q/artificial_intelligence_it_starts_to_create_art/,scidem,1492833520,,0,1,False,default,,,,,
793,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,13,66u2kz,self.MachineLearning,[D] University of Phoenix and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/66u2kz/d_university_of_phoenix_and_machine_learning/,[deleted],1492833715,[removed],0,0,False,default,,,,,
794,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,13,66u3wc,youtube.com,How to Generate Video - Intro to Deep Learning,https://www.reddit.com/r/MachineLearning/comments/66u3wc/how_to_generate_video_intro_to_deep_learning/,funtwo2,1492834235,,0,1,False,default,,,,,
795,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,16,66utqd,self.MachineLearning,[D] Any pretrained models for carpedm20/DCGAN-tensorflow?,https://www.reddit.com/r/MachineLearning/comments/66utqd/d_any_pretrained_models_for/,anonDogeLover,1492846757,Has anyone trained this codebase on anything other than mnist/celebA and still have the json output?,0,0,False,self,,,,,
796,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,17,66uwxg,self.MachineLearning,Building a recommender system - what I need to know?,https://www.reddit.com/r/MachineLearning/comments/66uwxg/building_a_recommender_system_what_i_need_to_know/,niujin,1492848615,[removed],0,1,False,default,,,,,
797,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,18,66v2f5,self.MachineLearning,PyTorch vs Sonnet?,https://www.reddit.com/r/MachineLearning/comments/66v2f5/pytorch_vs_sonnet/,andyandy16,1492851871,[removed],0,1,False,default,,,,,
798,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,19,66vbbe,self.MachineLearning,[D] How can one additional convolutional layer decrease accuracy dramatically?,https://www.reddit.com/r/MachineLearning/comments/66vbbe/d_how_can_one_additional_convolutional_layer/,undefdev,1492857058,"Sorry about posting this here, but I don't know where else to find an answer. I tried /r/learnmachinelearning as well, but without success.

Besides, if anyone can recommend an irc channel or another real time channel where one can lurk and ask binary questions and hope for an answer, please do - because I feel like opening reddit posts for this seems undesirable, but have there's the hope of helping you progress when you're stuck.

-----------------------------------8&lt;--------------------------------------

 
I'm experimenting with ConvNets on MNIST and encounter the following problem:
When I use two convolutional layers I get a precision of ~99.3%, but when I add a third the precision drops to ~11%.


I think this might be the vanishing gradient problem, but I find it surprising that it happens that abruptly and with such strong effect.
The reason why I believe this is because the accuracy of the net and the weights of the first layer don't really change each epoch.

This is how my network architechture looks like:

(conv 5x5 layer -&gt; relu -&gt; maxpool)-&gt; (conv 3x3 layer -&gt; relu -&gt; maxpool)* **n** -&gt; fully-connected -&gt; relu -&gt; fully-connected -&gt; softmax

The 5x5 layer uses 20 filters, and the 3x3 layers use 50 filters and a zero padding of 1.

This works well for n=1 but not for n=2.



So my question is, what's the reason for the sudden decrease in accuracy? I thought much deeper ConvNets were common, so the idea that this is the vanishing gradient problem surprises me.
Are there any examples of ConvNets with more layers that work well on MNIST?",11,8,False,self,,,,,
799,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,20,66vl5v,forbes.com,How Does Quora Use Machine Learning In 2017?,https://www.reddit.com/r/MachineLearning/comments/66vl5v/how_does_quora_use_machine_learning_in_2017/,mandyboso,1492862185,,0,1,False,default,,,,,
800,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,23,66w3st,self.MachineLearning,Msc in machine learning - is it worth it?,https://www.reddit.com/r/MachineLearning/comments/66w3st/msc_in_machine_learning_is_it_worth_it/,amjw,1492869838,[removed],0,1,False,default,,,,,
801,MachineLearning,t5_2r3gv,2017-4-22,2017,4,22,23,66wa4r,vendingworld.com,"Refurbished Vending Machines, Vending business, vending parts",https://www.reddit.com/r/MachineLearning/comments/66wa4r/refurbished_vending_machines_vending_business/,davidwilcox09,1492872018,,0,1,False,default,,,,,
802,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,0,66wg8p,medium.com,Natural Language Processing on multiple columns in python,https://www.reddit.com/r/MachineLearning/comments/66wg8p/natural_language_processing_on_multiple_columns/,data_science_rules,1492874060,,0,1,False,default,,,,,
803,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,0,66wnoi,github.com,Multilingual word vectors in 78 languages,https://www.reddit.com/r/MachineLearning/comments/66wnoi/multilingual_word_vectors_in_78_languages/,[deleted],1492876414,[deleted],0,1,False,default,,,,,
804,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,1,66x02v,self.MachineLearning,[D] RL: GANs as MCTS environment simulator for deep model-based planning?,https://www.reddit.com/r/MachineLearning/comments/66x02v/d_rl_gans_as_mcts_environment_simulator_for_deep/,gwern,1492880231,"Apropos of the [news on AlphaGo](https://www.youtube.com/watch?v=ZyUFy29z3Cw), [""Recurrent Environment Simulators""](https://arxiv.org/abs/1704.02254), [Guo et al 2014](http://papers.nips.cc/paper/5421-deep-learning-for-real-time-atari-game-play-using-offline-monte-carlo-tree-search-planning.pdf ""Deep Learning for Real-Time Atari Game Play Using Offline Monte Carlo Tree Search [MCTS] Planning"")/[Desai &amp; Bannerjee 2017](https://nihit.github.io/resources/spaceinvaders.pdf ""Deep Reinforcement Learning to play Space Invaders""), [Mathieu et al 2017](https://arxiv.org/abs/1511.05440 ""Deep multi-scale video prediction beyond mean square error""), and [LeCun's talk on unsupervised learning/RL](https://simons.berkeley.edu/talks/yann-lecun-2017-3-30), I have been wondering something: has anyone proposed or done any work on using Generative Adversarial Networks for forward planning such as in a tree search method like Monte Carlo Tree Search? It seems like what people are working towards when they bring up GANs in RL-related talks, but I don't recall anyone explicitly suggesting *how* GANs would be useful or this specific approach, and [some searching](https://scholar.google.com/scholar?q=%28%22GAN%22+OR+%22generative+adversarial+network%22%29+AND+%28%22MCTS%22+OR+%22Monte+Carlo+tree+search%22%29+-gallium+-methylene+-LED+-disease+-diode+-electrophoresis+-tumor+-dental+-nanoparticle&amp;btnG=&amp;hl=en&amp;as_sdt=0%2C21&amp;as_ylo=2016) doesn't turn it up for me either. So here goes:

GANs [approximate a data distribution](https://arxiv.org/abs/1701.07875 ""'Wasserstein GAN', Arjovsky et al 2017""), so drawing samples from a GAN trained on data from sequential timesteps should constitute a distribution over the true environment data distribution, weighted by likelihood; with this sampling, one could combine it with MCTS to evaluate deeply the decision tree, estimate the value of each action, and choose optimal next actions. A MCTS+GAN RL agent would inherit most of the strengths of GANs and MCTS: simple implementations, able to learn from off-policy transition samples, create a deep environment model, do long-term planning, quantify its uncertainty for better exploration, provide any-time estimates, run in parallel, etc. This could be extended by using [dropout-trained](http://mlg.eng.cam.ac.uk/yarin/blog_2248.html) GANs or [bootstrapped](https://arxiv.org/abs/1703.07608 ""'Deep Exploration via Randomized Value Functions', Osband et al 2017"") GANs for deep exploration by training the GAN, taking actions in the true environment based on MCTS+GAN estimates, and using the newly collected samples to retrain the GAN. The MCTS+GAN value estimates could also be used to distill down into or pre-train a fast reactive deep RL agent like DQN or A3C by providing high-quality transition samples or a highly accurate advantage function.

(Note: I'm not sure GAN use here is strictly necessary. PixelCNN appears to be competitive with GANs for modeling visual data distributions, so perhaps that approach would also work.)

So to go back to LeCun's talk: one of his points is that for RL, we want some sort of model-based planning for look ahead. Model-free or non-planning is too sample-inefficient to get anywhere, although it tends to be very fast and have advantages; so in humans we see a fairly clear looking difference between immediate System I reflexes and intuition, and slower System II explicit planning and 'thinking through' possible futures by exploring a little model of the environment in our heads. But how do you have a deep model predict the future? He shows an example with cars. You can take a CNN and have it predict subsequent frames using something like RMSE loss and autoencoders, but this leads to blurry images immediately as it averages each pixel over all possible futures; this is not very helpful for planning since a blur doesn't tell you anything about what actions to take. The future is very multimodal, but the autoencoder will just produce the average. Then LeCun demonstrates GANs for predicting next frames - the sample is very sharp, as it picks out one possible future and depicts it as exactly as possible. But this isn't useful either: while it's probably the future with the highest likelihood, the maximum likelihood is still very unlikely, and the more steps out, the more that *exact* sequence becomes vanishingly unlikely, plus it ignores the expected value of the slightly-less-likely alternatives. What we need is planning over the entire distribution, not a single sample from it. Fortunately, a GAN does provide us the entire distribution of futures weighted by their likelihood, via the z-vector: we just create, say, 1000 unique sets of uniform deviates and feed them into the GAN and we will get an approximation of the distribution of futures, each one sharp; if in 500 futures the car continues forward, then on average 500 of the samples will have slight variants of the car moving forward, then perhaps another 250 have it turning left and another 250 have it turning right; with this, we can start doing planning and note that there's a 25% chance of it turning towards us and coming unacceptably close with potentially huge negative rewards, so we should slow down. This is not something we would get from an autoencoder (which would just show an expanding blur of grayness) or a single sample from a GAN (which would usually safely show the turn going straight or turning away from us). To account for actions changing the environment and turn it from a predictive model to a causal model, you would make the GAN conditional: in addition to the z-vector, provide an action. If there are immediate rewards rather than just terminal rewards, then the GAN prediction is both the new environment state and that state's immediate reward (which doesn't require knowledge of the total value of that state or the policy that was being followed, since the future agent's will be done by working backwards from an eventual terminal state and summing all the discounted 1-step rewards).

If you have a sharp simulator of the environment, what do you do with it? Well, you plug it into a decision tree: enumerate all possible sequences of actions and stochastic outcomes, and do backwards induction to figure out the optimal action at any outcome. That's too hard? You approximate it with MCTS. The simulator provides the possible outcomes for each action, which can then be fed back into the simulator to explore another ply down, and so on until hitting the depth limit and exploring randomly until a terminal state, at which point the cumulative rewards for each node are estimated, and another rollout begins.

So the whole algorithm goes:

1. create a dataset of environment+reward+action samples (perhaps from following a random policy in an ALE game or from expert human trajectories)
2. train until convergence a GAN (like [Improved WGAN](https://arxiv.org/abs/1704.00028 ""'Improved Training of Wasserstein GANs', Gulrajani et al 2017"")) to approximate the distribution of new environments conditional on old environment, action, and noise z-vector
3. for _n_ games in parallel:
   - initialize the RL agent in the environment
   - until termination, take each action according to MCTS using the GAN as environment simulator by drawing a relatively small number such as 5-100 samples (similar to Go's branching factor), while adding all environment transitions+rewards+actions to the dataset
4. go to #2

This could probably be implemented fairly easily using Gym+Improved WGAN.

This is:

- parallelizable, since the agents act independently and stochastically while the GAN can be trained in parallel on the 'experience replay buffer'
- can learn off-policy, since the GAN is focused only on the immediate state transition and reward, which doesn't depend on any successive actions following a better or worse policy - the full value is estimated only during the MCTS search by backwards induction
- keeps maintaining sharp environment states, since each individual GAN sample represents 1 possible future, not an ensemble or average
- capable of exploring deeply, using MCTS to prioritize promising lines of action
- capable of handling all environments that DQN/A3C do now like the ALE, and further capable of handling sequence data given the recent work on Improved WGAN and other GANs on discrete and sequential data
- anytime, since each rollout updates value estimates incrementally

The major weakness is that I'm not sure how well the MCTS part would handle continuous actions. This hybrid algorithm seems to fall closer to DQN than A3C in the taxonomy. There is also the potential for curse of dimensionality here - many of the drawn GAN samples will be morally equivalent in that they are the GAN reflecting the same basic causal change but with slight appearance differences, which despite MCTS's usual ability to handle extremely high branching factors like in Go, might wind up killing the approach.",26,28,False,self,,,,,
805,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,2,66x39m,self.MachineLearning,What are your thoughts on MLaaS ?,https://www.reddit.com/r/MachineLearning/comments/66x39m/what_are_your_thoughts_on_mlaas/,[deleted],1492881184,[deleted],0,2,False,default,,,,,
806,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,2,66x5bg,openreview.net,Is fixed point training insufficient for deep nets? (big implications for Nervana and other DL accelerators),https://www.reddit.com/r/MachineLearning/comments/66x5bg/is_fixed_point_training_insufficient_for_deep/,darkconfidantislife,1492881796,,1,1,False,default,,,,,
807,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,4,66xpdg,blog.athelas.com,[R] A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN,https://www.reddit.com/r/MachineLearning/comments/66xpdg/r_a_brief_history_of_cnns_in_image_segmentation/,dhruv-partha,1492887759,,10,127,False,https://b.thumbs.redditmedia.com/Mrws5z7ewR9rm3It_Gq9VVaizZ8e4POIxwJ1u9O7cfo.jpg,,,,,
808,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,4,66xr40,openreview.net,[R] Is fixed point training insufficient for deep nets? (big implications for Nervana and other DL accelerators),https://www.reddit.com/r/MachineLearning/comments/66xr40/r_is_fixed_point_training_insufficient_for_deep/,darkconfidantislife,1492888298,,8,3,False,default,,,,,
809,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,5,66y252,self.MachineLearning,EMNIST in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/66y252/emnist_in_tensorflow/,[deleted],1492891658,[removed],0,1,False,default,,,,,
810,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,6,66yip3,stackoverflow.com,Tensorflow question. Anyone knows how to correctly calculate tf.nn.weighted_cross_entropy_with_logits pos_weight variable?,https://www.reddit.com/r/MachineLearning/comments/66yip3/tensorflow_question_anyone_knows_how_to_correctly/,nsx9891,1492896818,,0,1,False,default,,,,,
811,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,6,66yl6d,self.MachineLearning,[D] State-of-art for sensor's anomaly detection,https://www.reddit.com/r/MachineLearning/comments/66yl6d/d_stateofart_for_sensors_anomaly_detection/,dejormo,1492897584,"Hi guys, I am working on anomaly detection problem and I need your help and expertise. I have a sensor that records episodic time series data. For example, once in a while, the sensor activates for 10 seconds and records values at millisecond interval. My task is to identify whether the recorded pattern is not normal. In other words, I need to detect anomalies in that pattern compared to others. 

What would be the state-of-the art approaches to that?",10,7,False,self,,,,,
812,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,7,66yx2d,self.MachineLearning,[D] Questions about training a more efficient training algorithm,https://www.reddit.com/r/MachineLearning/comments/66yx2d/d_questions_about_training_a_more_efficient/,qazzquimby,1492901386,"I don't have confidence that this idea holds water. Please explain any conceptual or practical flaws it has.

Idea is to train an algorithm (evolutionary programming?) that effectively trains for novel problems.

Fitness score is the average success the algorithm has at a large set of problems after being given a set amount of time to train for each one. End result should be an algorithm which can detect qualities of the problem (size of problem space, relative quantity of training data, etc) to modify the method by which it trains.

I imagine this is not feasible due to the enormous amount of computational power required to simulate many generations of these, where each simulation would take ~hours, and the rate of growth through algorithm modification would probably be extremely slow.

Would this be theoretically possible? Could it lead to something like exponential intelligence?",9,1,False,self,,,,,
813,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,8,66z4l7,self.MachineLearning,Multi-GPU GPGPU API for C# projects. This may help some custom artificial intelligence programs.,https://www.reddit.com/r/MachineLearning/comments/66z4l7/multigpu_gpgpu_api_for_c_projects_this_may_help/,tugrul_ddr,1492903938,[removed],0,1,False,default,,,,,
814,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,9,66zg7n,self.MachineLearning,Computer vision techniques for photo undressing and NSFW content generation,https://www.reddit.com/r/MachineLearning/comments/66zg7n/computer_vision_techniques_for_photo_undressing/,[deleted],1492907997,[removed],0,1,False,default,,,,,
815,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,9,66zgvf,self.MachineLearning,Accuracy gets worse the longer I train. Any advice would be greatly appreciated.,https://www.reddit.com/r/MachineLearning/comments/66zgvf/accuracy_gets_worse_the_longer_i_train_any_advice/,Beau_Nerr,1492908224,[removed],0,1,False,default,,,,,
816,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,9,66zhzm,self.MachineLearning,GANs for photo undressing,https://www.reddit.com/r/MachineLearning/comments/66zhzm/gans_for_photo_undressing/,throwaway801512,1492908628,[removed],0,1,False,default,,,,,
817,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,10,66zsuf,robert-frost-s-tensorflow-ltsm-poetry-party.bitballoon.com,[P] Robert Frost Poetry Generated by a Tensorflow LTSM (First Attempt),https://www.reddit.com/r/MachineLearning/comments/66zsuf/p_robert_frost_poetry_generated_by_a_tensorflow/,esotericGames,1492912600,,1,0,False,default,,,,,
818,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,14,670rlb,demo.visualdialog.org,Cool Visual Chatbot demo,https://www.reddit.com/r/MachineLearning/comments/670rlb/cool_visual_chatbot_demo/,[deleted],1492926821,[deleted],0,1,False,default,,,,,
819,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,16,671157,github.com,Coloring t-SNE mappings,https://www.reddit.com/r/MachineLearning/comments/671157/coloring_tsne_mappings/,cast42,1492931627,,0,1,False,default,,,,,
820,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,16,6713zj,self.MachineLearning,Batch Normalization in Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/6713zj/batch_normalization_in_reinforcement_learning/,[deleted],1492933239,[removed],0,1,False,default,,,,,
821,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,16,671455,self.MachineLearning,[D] Batch Normalization in Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/671455/d_batch_normalization_in_reinforcement_learning/,innixma,1492933331,Does anyone know if Batch Normalization will work in RL algorithms such as DQN and A3C? When I implemented it with A3C in Keras/TensorFlow it seemed to become less stable.,8,8,False,self,,,,,
822,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,16,6715w6,self.MachineLearning,[R] Mechanical manufacturing processes used in industry today?,https://www.reddit.com/r/MachineLearning/comments/6715w6/r_mechanical_manufacturing_processes_used_in/,agujr1,1492934351,[removed],0,0,False,default,,,,,
823,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,20,671sh1,github.com,[R] Multilingual word vectors in 78 languages,https://www.reddit.com/r/MachineLearning/comments/671sh1/r_multilingual_word_vectors_in_78_languages/,sls56,1492947258,,4,120,False,https://b.thumbs.redditmedia.com/c-m2FOLOh3SvVPO5wWbG-lumQHYhgKbzAzi4eNJlvAw.jpg,,,,,
824,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,20,671szq,sites.google.com,[R] Learning to Generate Long-term Future via Hierarchical Prediction,https://www.reddit.com/r/MachineLearning/comments/671szq/r_learning_to_generate_longterm_future_via/,mmattym,1492947545,,0,9,False,https://b.thumbs.redditmedia.com/-FN88a42BeVvFyukkoAWZl8S5iB6cpt5uMBP35sz3Lk.jpg,,,,,
825,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,21,671vfi,self.MachineLearning,Mechanical manufacturing processes used in industry today?,https://www.reddit.com/r/MachineLearning/comments/671vfi/mechanical_manufacturing_processes_used_in/,agujr1,1492948802,[removed],0,1,False,default,,,,,
826,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,21,671wtr,self.MachineLearning,[R] Mechanical manufacturing processes used by industry today?,https://www.reddit.com/r/MachineLearning/comments/671wtr/r_mechanical_manufacturing_processes_used_by/,agujr1,1492949402,[removed],1,0,False,default,,,,,
827,MachineLearning,t5_2r3gv,2017-4-23,2017,4,23,22,6729ri,soundcloud.com,[PROJECT] New results from my RNN for midi generation.,https://www.reddit.com/r/MachineLearning/comments/6729ri/project_new_results_from_my_rnn_for_midi/,electricjimi,1492954913,,8,7,False,https://b.thumbs.redditmedia.com/NHy869hXffEgWXJwmGeZ8RLGxCNYD_GEWYYXKqRh6xs.jpg,,,,,
828,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,1,6736ra,seq2seq.bergpalm.dk,I made a neural date parser and made a web interface for it. Have fun :),https://www.reddit.com/r/MachineLearning/comments/6736ra/i_made_a_neural_date_parser_and_made_a_web/,rasmusbergpalm,1492965523,,0,1,False,default,,,,,
829,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,1,673784,arxiv.org,"State-of-the-Art review of Computer Vision for Autonomous Vehicles. Survey of recognition, reconstruction, motion estimation, tracking, scene understanding and end-to-end learning.",https://www.reddit.com/r/MachineLearning/comments/673784/stateoftheart_review_of_computer_vision_for/,[deleted],1492965674,[deleted],0,1,False,default,,,,,
830,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,1,6737ru,arxiv.org,"[R] State-of-the-Art review of Computer Vision for Autonomous Vehicles. Survey of recognition, reconstruction, motion estimation, tracking, scene understanding and end-to-end learning.",https://www.reddit.com/r/MachineLearning/comments/6737ru/r_stateoftheart_review_of_computer_vision_for/,TotemCaster,1492965828,,2,41,False,default,,,,,
831,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,2,673cha,seq2seq.bergpalm.dk,[P] i made a seq2seq date parser with a web interface. Have fun :),https://www.reddit.com/r/MachineLearning/comments/673cha/p_i_made_a_seq2seq_date_parser_with_a_web/,rasmusbergpalm,1492967218,,11,14,False,default,,,,,
832,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,2,673f74,self.MachineLearning,Is there a place to submit and browse already trained neural networks and their weights?,https://www.reddit.com/r/MachineLearning/comments/673f74/is_there_a_place_to_submit_and_browse_already/,TinFinJin,1492967997,[removed],0,1,False,default,,,,,
833,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,3,673ncg,demo.visualdialog.org,Visual Chatbot,https://www.reddit.com/r/MachineLearning/comments/673ncg/visual_chatbot/,[deleted],1492970401,[deleted],0,1,False,default,,,,,
834,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,3,673nu6,self.MachineLearning,Usefulness of deep fully connected nets?,https://www.reddit.com/r/MachineLearning/comments/673nu6/usefulness_of_deep_fully_connected_nets/,hundley10,1492970535,[removed],0,1,False,default,,,,,
835,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,4,6741jc,self.MachineLearning,[D] Is perfect image reconstruction possible through an AutoEncoder?,https://www.reddit.com/r/MachineLearning/comments/6741jc/d_is_perfect_image_reconstruction_possible/,NeuroBoss31,1492974432,"I am working on a project that involves reconstructing a scene (so this is more complex than MNIST digits), after I pass the scene through a VGG-Net. So far I have a mirrored VGG-Net that decodes the features from the forward pass from the VGG-Net back to the image domain, but while I get a very close approximate to the image, I do not get a perfect full reconstruction. Is getting a perfect reconstruction theoretically possible?  Or is my problem that I have not trained my decoder with enough scenes? I am using an L2-loss to minimize the difference between input and output image.",14,4,False,self,,,,,
836,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,4,674331,self.MachineLearning,[D] Machine Learning - WAYR (What Are You Reading) - Week 23,https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1492974870,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|
|----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers last week:

/u/ajmooch:

[Uncertainty in Deep Learning](http://mlg.eng.cam.ac.uk/yarin/blog_2248.html)

/u/poorasian:

http://www-personal.umich.edu/~romanv/papers/HDP-book/HDP-book.html#

/u/zxxv:

[madGAN](https://arxiv.org/pdf/1704.02906.pdf)

Besides that, there are no rules, have fun.",18,19,False,self,,,,,
837,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,5,674jwr,self.MachineLearning,"Difference between Data Analytics, ML and AI",https://www.reddit.com/r/MachineLearning/comments/674jwr/difference_between_data_analytics_ml_and_ai/,AI_acharya,1492979756,[removed],1,1,False,default,,,,,
838,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,5,674k2x,demo.visualdialog.org,[P] Visual Chatbot demo answers questions about your images,https://www.reddit.com/r/MachineLearning/comments/674k2x/p_visual_chatbot_demo_answers_questions_about/,drlukeor,1492979810,,7,5,False,https://b.thumbs.redditmedia.com/0lU3hMxUvclu8IzwmYrQPuZ5kJh9RpaJJdx7jhyFq5I.jpg,,,,,
839,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,10,6760f4,self.MachineLearning,Anomaly Detection and K-Means,https://www.reddit.com/r/MachineLearning/comments/6760f4/anomaly_detection_and_kmeans/,Ac130standingby_Cx,1492996103,[removed],0,1,False,default,,,,,
840,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,10,6762sa,arxiv.org,[R] [1704.06440] Equivalence Between Policy Gradients and Soft Q-Learning,https://www.reddit.com/r/MachineLearning/comments/6762sa/r_170406440_equivalence_between_policy_gradients/,evc123,1492996884,,3,29,False,default,,,,,
841,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,11,676cq7,self.MachineLearning,Interpreting weights and biases histograms of neural networks.,https://www.reddit.com/r/MachineLearning/comments/676cq7/interpreting_weights_and_biases_histograms_of/,[deleted],1493000211,[removed],0,1,False,default,,,,,
842,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,11,676g1u,blog.richardweiss.org,[P] Relevancy scoring reddit to find related subs,https://www.reddit.com/r/MachineLearning/comments/676g1u/p_relevancy_scoring_reddit_to_find_related_subs/,richardweiss,1493001362,,0,2,False,default,,,,,
843,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,11,676g9p,self.MachineLearning,[D] I am working on my first non-tutorial ML Project where I am going to teach a program to play 'The Legend of Zelda'. Any helpful hints/tips?,https://www.reddit.com/r/MachineLearning/comments/676g9p/d_i_am_working_on_my_first_nontutorial_ml_project/,TheLegendOfCode,1493001430,"I have been wanting to do my own AI/ML project for some time and I think I have a good amount of the knowledge I need to at least start.  As some context, I am going to try and make a neural net to play The Legend of Zelda.  I have an idea of what I need to use and what to look at, but I would like to see of anyone else recommends anything.  Here is what I know I am using already:

1: CV:  To view the screen, I am using the opencv library in Python.  This is going to send each frame which is going to be processed.

2: User Input Simulation: I already have a Python file to perform basic user input (movement, pressing the A and B buttons, and pressing start and select)

3: A Convolutional Neural Net:  The best way (at least that I could think of) for the images to be processed is a convolutional neural network.  This is because a CNN can perform reinforcement learning based on an agent-observation loop.  I knew by default that I was going to use Tensorflow, but how much would OpenAI's Gym library be of help?  Also, I am aware of the Deep Q Learner algorithm from DeepMind (https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner).  How helpful would this be?

What are some other libraries, tools, or concepts that I should also look into for this project?  Or is this project just a godspeed?  All and any input is appreciated.",9,0,False,self,,,,,
844,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,13,676vq7,chinacanaan.com,"High Shear Mixer, Bin Blender, Bin Washing, Fluid Bed Dryer, Station Factory &amp; Exporter China",https://www.reddit.com/r/MachineLearning/comments/676vq7/high_shear_mixer_bin_blender_bin_washing_fluid/,chinacanaan,1493007062,,1,1,False,default,,,,,
845,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,14,67741a,youtube.com,Machine Learning with Touhou [TensorFlow] [Day 1],https://www.reddit.com/r/MachineLearning/comments/67741a/machine_learning_with_touhou_tensorflow_day_1/,[deleted],1493010437,[deleted],0,1,False,default,,,,,
846,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,14,6774g8,analyticsvidhya.com,Practical Guide to deal with Imbalanced Classification Problems in R,https://www.reddit.com/r/MachineLearning/comments/6774g8/practical_guide_to_deal_with_imbalanced/,RankLord,1493010608,,0,1,False,default,,,,,
847,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,14,6774ic,lyrebird.ai,Lyrebird: Copy the voice of anyone,https://www.reddit.com/r/MachineLearning/comments/6774ic/lyrebird_copy_the_voice_of_anyone/,[deleted],1493010630,[deleted],0,1,False,default,,,,,
848,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,14,6776pf,lyrebird.ai,[D] Lyrebird: Copy the voice of anyone,https://www.reddit.com/r/MachineLearning/comments/6776pf/d_lyrebird_copy_the_voice_of_anyone/,jsotelo,1493011570,,90,250,False,default,,,,,
849,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,14,6778qg,self.MachineLearning,[D] Study group for MMDS online Course,https://www.reddit.com/r/MachineLearning/comments/6778qg/d_study_group_for_mmds_online_course/,dyps,1493012482,"Anyone interested in a study group for Stanford's MMDS course? I'm planning to cover the entire online course as well as the book for the next 2-3 months. 

I was thinking maybe a weekly virtual sync-up to check each other on progress/work on problem sets/clarify doubts if any. 

course link -&gt; https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+SelfPaced/about

book -&gt; http://infolab.stanford.edu/~ullman/mmds/book.pdf

edit: I'm from Bengaluru/Bangalore. We can also use our office space for discussions. ",5,8,False,self,,,,,
850,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,15,677g1x,self.MachineLearning,[Project] Star wars battlefront: X-wing self piloting programme,https://www.reddit.com/r/MachineLearning/comments/677g1x/project_star_wars_battlefront_xwing_self_piloting/,jimip6c12,1493015866,"Can the force be with AI to destroy death star by deep learning? This is a test of using supervised machine learning to self-pilot X-wing and travel back and forth in the battlefront.

Model developed using Tensorflow. -&gt;[Github Repo](https://github.com/Jimsparkle/AI_Starwars_X-wing)&lt;- 

**Highlight**

[X-wing entering the battle](https://gfycat.com/OnlyVengefulGelada)

[Manoeuvre and auto balancing](https://gfycat.com/HorribleFixedEidolonhelvum)

[Evading Tie fighter](https://gfycat.com/PastWelcomeArcherfish)

[Youtube video](https://www.youtube.com/watch?v=NMZph_X9e8o)

**Important citation here**

The idea and model are largely inspired by and modified from [Sentdex self-driving programme](https://github.com/sentdex/pygta5/). You can also see the [reddit post here](https://www.reddit.com/r/MachineLearning/comments/665flm/p_selfdriving_car_course_with_python_tensorflow/).

Screen capture code is developed by Frannecklp.

Key input tracking code is developed by [Box Of Hats](https://github.com/Box-Of-Hats).

**Summary**

The AI has been provided with only 1 hour of video of actual game play together with the corresponding keypress, and trained by tensorflow for 8 hours to pilot a X-Wing just by itself.

The AI achieves satisfactory result in preventing plane crash accident, while lacking capacity to deal effective damage to Imperial Tie fighter. This is far from perfect.

The model is still in development and expected to have a large change in the future.

****

This post will be cross-posted to [/r/StarWarsBattlefront](https://www.reddit.com/r/StarWarsBattlefront/)

Edit: Just adding the cross-post notification.",2,1,False,self,,,,,
851,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,18,677yud,cmec-hb.com,http://www.cmec-hb.com/FOTMA-CPCD120-12000kg-diesel-forklift-truck-pd6519565.html,https://www.reddit.com/r/MachineLearning/comments/677yud/httpwwwcmechbcomfotmacpcd12012000kgdieselforkliftt/,Rachel-Hu,1493025333,,0,1,False,default,,,,,
852,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,18,6780dx,self.MachineLearning,Use satellite data to track the human footprint in the Amazon rainforest,https://www.reddit.com/r/MachineLearning/comments/6780dx/use_satellite_data_to_track_the_human_footprint/,kingburrito666,1493026095,[removed],0,1,False,default,,,,,
853,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,19,6784xz,meetup.com,WEBINAR - General AI Challenge &amp; Creative AI - London TensorFlow Meetup,https://www.reddit.com/r/MachineLearning/comments/6784xz/webinar_general_ai_challenge_creative_ai_london/,ADGEfficiency,1493028298,,0,1,False,default,,,,,
854,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,19,6785fc,medium.com,[P] Woman teaches neural net to write sounding like her husband,https://www.reddit.com/r/MachineLearning/comments/6785fc/p_woman_teaches_neural_net_to_write_sounding_like/,flibertygibbet420,1493028493,,2,0,False,https://a.thumbs.redditmedia.com/ZDNYKLQvX8X2LST7EGgTdK7wxu04kutnD4fnRegP7y0.jpg,,,,,
855,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,19,6786cs,automatonlearning.net,[R] Automata learning as a satisfiability modulo theories problem,https://www.reddit.com/r/MachineLearning/comments/6786cs/r_automata_learning_as_a_satisfiability_modulo/,Iplaythekeyboard,1493028916,,0,6,False,https://b.thumbs.redditmedia.com/hE9WBXGupPRUHiwE5xa3RDxHFiHPU1kmmClh6l_xFxY.jpg,,,,,
856,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,20,678gxo,self.MachineLearning,Commercial usage of publicly available datasets for training models,https://www.reddit.com/r/MachineLearning/comments/678gxo/commercial_usage_of_publicly_available_datasets/,Kindlychung,1493033576,[removed],0,1,False,default,,,,,
857,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,20,678j6v,lukeoakdenrayner.wordpress.com,The End of Human Doctors  Understanding Medicine,https://www.reddit.com/r/MachineLearning/comments/678j6v/the_end_of_human_doctors_understanding_medicine/,[deleted],1493034481,[deleted],0,1,False,default,,,,,
858,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,20,678jrd,lukeoakdenrayner.wordpress.com,[D] The End of Human Doctors  Understanding Medicine,https://www.reddit.com/r/MachineLearning/comments/678jrd/d_the_end_of_human_doctors_understanding_medicine/,drlukeor,1493034701,,18,32,False,https://b.thumbs.redditmedia.com/VDbxFW2WXgkyEUZZHCAEEvd3oOrWmO1tCqeaJI1OPqk.jpg,,,,,
859,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,21,678ppt,self.MachineLearning,[D] IJCAI 2017 Reviews discussion thread,https://www.reddit.com/r/MachineLearning/comments/678ppt/d_ijcai_2017_reviews_discussion_thread/,Niourf,1493036804,"[IJCAI](http://ijcai-17.org/) acceptance notifications were just released. How did it went out for you?

As a more general discussion, are there some people here that are involved in AI research other than ML?",10,7,False,self,,,,,
860,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,21,678sw3,self.MachineLearning,"Those of you who do this for a career, what does your day-to-day look like?",https://www.reddit.com/r/MachineLearning/comments/678sw3/those_of_you_who_do_this_for_a_career_what_does/,Jaylow618,1493037900,[removed],0,1,False,default,,,,,
861,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,21,678urx,self.MachineLearning,Predict incident rates for an internet company,https://www.reddit.com/r/MachineLearning/comments/678urx/predict_incident_rates_for_an_internet_company/,abhi5025,1493038532,[removed],0,1,False,default,,,,,
862,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,22,678x5f,self.MachineLearning,Predict incident rates for an internet company,https://www.reddit.com/r/MachineLearning/comments/678x5f/predict_incident_rates_for_an_internet_company/,abhi5025,1493039299,[removed],0,1,False,default,,,,,
863,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,22,678zm1,self.MachineLearning,Semantic Role Labeling Datasets,https://www.reddit.com/r/MachineLearning/comments/678zm1/semantic_role_labeling_datasets/,[deleted],1493040081,[removed],0,1,False,default,,,,,
864,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,22,6793kv,self.MachineLearning,What are your thoughts on MLaaS ?,https://www.reddit.com/r/MachineLearning/comments/6793kv/what_are_your_thoughts_on_mlaas/,crashbundicoot,1493041300,"( reposting as previous thread got caught in the spam filter)

Suppose you wanted to do sentiment analytics on the reviews section of an E-commerce Website or if you wanted to do Attrition and Customer Churn Prediction. 

Would you build your own Machine Learning models ? Or Use the services provided by AzureML or AWS ? 


I see a lot of companies offering ""Analytics Platforms"" that can do popular machine Learning tasks.


I'd love to hear how companies today are using Machine learning for their Business. Are the MLaaS offerings mature enough and cost effective enough to forget about investing in dedicated ML / DataScience teams for popular Machine Learning tasks. ?",1,4,False,self,,,,,
865,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,23,679bxo,github.com,[TensorFLow] Unsupervised Image to Image Translation with Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/679bxo/tensorflow_unsupervised_image_to_image/,zsdh123,1493043717,,0,1,False,default,,,,,
866,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,23,679ffo,self.MachineLearning,"[D] Those of you who do this as a career, what does your day-to-day look like?",https://www.reddit.com/r/MachineLearning/comments/679ffo/d_those_of_you_who_do_this_as_a_career_what_does/,Jaylow618,1493044685,"I'm just curious what a machine learning engineer's day looks like. Whether you work for a small company or a corporation. 

Do you enjoy your job? What do you hours typically look like? Do you spend most of your time in front of a terminal or collaborating with teammates? Do you find yourself challenged on a daily basis, in a way that's satisfying or frustrating?",36,119,False,self,,,,,
867,MachineLearning,t5_2r3gv,2017-4-24,2017,4,24,23,679gpv,github.com,Torch implementation of Wasserstein GAN,https://www.reddit.com/r/MachineLearning/comments/679gpv/torch_implementation_of_wasserstein_gan/,[deleted],1493045054,[deleted],0,1,False,default,,,,,
868,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,0,679lc2,github.com,"[P] Implementation of ""Overcoming catastrophic forgetting in neural networks"" in Tensorflow by ariseff",https://www.reddit.com/r/MachineLearning/comments/679lc2/p_implementation_of_overcoming_catastrophic/,commafighter,1493046266,,5,11,False,https://a.thumbs.redditmedia.com/J-er7ymx6ldo3zDuiaBITZyCc3d4XvLgzWIhvHSdtL4.jpg,,,,,
869,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,0,679nwx,github.com,[P] Torch implementation of Wasserstein GAN,https://www.reddit.com/r/MachineLearning/comments/679nwx/p_torch_implementation_of_wasserstein_gan/,[deleted],1493046956,[deleted],0,1,False,default,,,,,
870,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,0,679pr8,medium.com,[D] Interesting rejected papers at ICLR17,https://www.reddit.com/r/MachineLearning/comments/679pr8/d_interesting_rejected_papers_at_iclr17/,nocortex,1493047449,,6,14,False,https://a.thumbs.redditmedia.com/N7KzuGiAN-dxBOgYVvDkjpA_FIClh8YVqFMkNatUq84.jpg,,,,,
871,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,0,679qqb,github.com,[P] Implementation of Wasserstein GAN in Torch,https://www.reddit.com/r/MachineLearning/comments/679qqb/p_implementation_of_wasserstein_gan_in_torch/,fonfonx,1493047694,,6,8,False,https://b.thumbs.redditmedia.com/XFM7Vj_8GGhQiURLXDUeJujQCEyUI9IBmZdwUUzXYgo.jpg,,,,,
872,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,0,679uo0,cnbc.com,"How does Autopilot's Forward Collision Warning work, in terms of machine learning ?",https://www.reddit.com/r/MachineLearning/comments/679uo0/how_does_autopilots_forward_collision_warning/,NikhilDoWhile,1493048727,,0,1,False,default,,,,,
873,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,1,679yia,self.MachineLearning,"Difference between Data Analytics, ML and AI",https://www.reddit.com/r/MachineLearning/comments/679yia/difference_between_data_analytics_ml_and_ai/,AI_acharya,1493049707,[removed],0,1,False,default,,,,,
874,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,2,67aekd,self.MachineLearning,"[Discussion] Difference between Data Analytics, ML and AI",https://www.reddit.com/r/MachineLearning/comments/67aekd/discussion_difference_between_data_analytics_ml/,AI_acharya,1493053736,"Hello, 
I was wondering whats the real difference between Data Analytics(DA), Machine Learning(ML) and Artificial intelligence(AI) OR how are they related.. I would request you guys to please shed some light on it as I am a beginner. As per what I understand, they are related in the following way... DA is analyzing a chunk of data and getting some conclusion from it as per our aim. Then we take action as per that conclusion. But taking action is not the part of DA, DA is just limited to analyzing the data. ML is quite similar to DA, but, in addition, it will take the conclusion from DA and take action on it too. Thus, ML = DA plus Action. AI, I find it almost similar to ML, really not able to differentiate between the two. Please help in the above question.
 
Thanks, 
Acharya",3,2,False,self,,,,,
875,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,2,67akf5,self.MachineLearning,Generate clasic music,https://www.reddit.com/r/MachineLearning/comments/67akf5/generate_clasic_music/,[deleted],1493055172,[removed],0,1,False,default,,,,,
876,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,2,67apcv,willwolf.io,Deriving the Softmax from First Principles,https://www.reddit.com/r/MachineLearning/comments/67apcv/deriving_the_softmax_from_first_principles/,cavaunpeu,1493056392,,0,1,False,default,,,,,
877,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,3,67awdl,self.MachineLearning,using reinforcement learning over different scenarios,https://www.reddit.com/r/MachineLearning/comments/67awdl/using_reinforcement_learning_over_different/,pinkfluffunicorns,1493058159,[removed],0,1,False,default,,,,,
878,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,3,67b04s,facebook.com,ICLR 2017 streams,https://www.reddit.com/r/MachineLearning/comments/67b04s/iclr_2017_streams/,[deleted],1493059076,[deleted],0,1,False,default,,,,,
879,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,3,67b0cb,facebook.com,[D] ICLR 2017 streams,https://www.reddit.com/r/MachineLearning/comments/67b0cb/d_iclr_2017_streams/,evc123,1493059121,,0,9,False,default,,,,,
880,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,4,67bbet,blog.conceptnet.io,"ConceptNet Numberbatch 17.04: better, less-stereotyped word vectors",https://www.reddit.com/r/MachineLearning/comments/67bbet/conceptnet_numberbatch_1704_better/,rspeer,1493061896,,0,1,False,default,,,,,
881,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,4,67bgf6,self.MachineLearning,[Supervised Learning?] Generate classical music,https://www.reddit.com/r/MachineLearning/comments/67bgf6/supervised_learning_generate_classical_music/,cretu97,1493063221,[removed],0,1,False,default,,,,,
882,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,4,67bihh,self.MachineLearning,"Google, TPU's and conversational AI",https://www.reddit.com/r/MachineLearning/comments/67bihh/google_tpus_and_conversational_ai/,silvaring,1493063748,[removed],0,1,False,default,,,,,
883,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,6,67c4b4,kkulma.github.io,[P] Determining Optimal Number Of Clusters In Your Data,https://www.reddit.com/r/MachineLearning/comments/67c4b4/p_determining_optimal_number_of_clusters_in_your/,pmigdal,1493069400,,2,15,False,https://b.thumbs.redditmedia.com/CZJJf44NwWFZYyS5tavuiaSlJ4juRPKx9PgxDN_3lxI.jpg,,,,,
884,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,7,67cftp,blog.filestack.com,[P] Realtime Machine Learning with PyTorch and Filestack,https://www.reddit.com/r/MachineLearning/comments/67cftp/p_realtime_machine_learning_with_pytorch_and/,[deleted],1493072539,[deleted],0,1,False,default,,,,,
885,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,7,67cg6d,blog.filestack.com,[P] Realtime Machine Learning with PyTorch and Filestack,https://www.reddit.com/r/MachineLearning/comments/67cg6d/p_realtime_machine_learning_with_pytorch_and/,Staturecrane,1493072628,,3,26,False,https://b.thumbs.redditmedia.com/Dy2um2RZpvlTzpAv5O0thCzvEblDrM1uUdpZL-BoPTs.jpg,,,,,
886,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,7,67cleh,github.com,[P] Attentional Seq2Sqeq model in DyNet,https://www.reddit.com/r/MachineLearning/comments/67cleh/p_attentional_seq2sqeq_model_in_dynet/,pmichel31415,1493074140,,1,13,False,https://a.thumbs.redditmedia.com/r4yMaxK8WRDg1by4VHa66yX6i5teU7VixfHjsdzkL88.jpg,,,,,
887,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,8,67cqhy,self.MachineLearning,Is machine learning overhyped?,https://www.reddit.com/r/MachineLearning/comments/67cqhy/is_machine_learning_overhyped/,[deleted],1493075638,[removed],0,1,False,default,,,,,
888,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,8,67cqz5,authstar.com,New machine learning model that detects fake news with 85% accuracy.,https://www.reddit.com/r/MachineLearning/comments/67cqz5/new_machine_learning_model_that_detects_fake_news/,thetall0ne1,1493075776,,0,1,False,default,,,,,
889,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,9,67d4eh,arxiv.org,Affect-LM: A Neural Language Model for Customizable Affective Text Generation,https://www.reddit.com/r/MachineLearning/comments/67d4eh/affectlm_a_neural_language_model_for_customizable/,[deleted],1493079787,[deleted],0,1,False,default,,,,,
890,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,9,67d5z6,searchbusinessanalytics.techtarget.com,Analytics Teams Eye Machine Learning Use Cases to Boost Business - What are examples of problems your data team has solved with ML?,https://www.reddit.com/r/MachineLearning/comments/67d5z6/analytics_teams_eye_machine_learning_use_cases_to/,dataengconf,1493080252,,0,1,False,default,,,,,
891,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,10,67ddc1,stats.stackexchange.com,Why do Recurrent Neural Networks (RNNs) combine the current input and previous state before the non-linearity and not after?,https://www.reddit.com/r/MachineLearning/comments/67ddc1/why_do_recurrent_neural_networks_rnns_combine_the/,real_pinocchio,1493082548,,0,1,False,default,,,,,
892,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,14,67ekvg,self.MachineLearning,[D] Research groups for a Machine Learning PhD,https://www.reddit.com/r/MachineLearning/comments/67ekvg/d_research_groups_for_a_machine_learning_phd/,embrace_singularity,1493097338,"Would anyone happen to know of research groups working in the following areas:

* (Deep) Neural Networks and building {speech, text, data}-specific models
* Theoretical underpinnings of deep learning
* Non-convex optimisation for neural networks
* Representation learning for {speech, text}

I'm going to finish my master's in CS from a top 10 US university and was considering pursuing a PhD. Almost everyone I spoke to say that it isn't worth it unless you find the right group/advisor. 
So any help would be appreciated! :) 

Thanks! ",7,3,False,self,,,,,
893,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,15,67eykn,self.MachineLearning,Word association with machine learning,https://www.reddit.com/r/MachineLearning/comments/67eykn/word_association_with_machine_learning/,mattematik,1493103314,[removed],0,1,False,default,,,,,
894,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,16,67ezl1,self.MachineLearning,"What ML methods would you suggest using on this kind of data set for nasdaq, nyse and otcbb stocks?",https://www.reddit.com/r/MachineLearning/comments/67ezl1/what_ml_methods_would_you_suggest_using_on_this/,[deleted],1493103783,[removed],0,1,False,default,,,,,
895,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,16,67f0hc,youtu.be,How to change washing machine dryer belt at home,https://www.reddit.com/r/MachineLearning/comments/67f0hc/how_to_change_washing_machine_dryer_belt_at_home/,anjal079,1493104171,,1,1,False,default,,,,,
896,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,16,67f1mo,self.MachineLearning,"[D] What ML methods would you suggest using on this kind of dataset for nasdaq, nyse and otcbb stocks and their pricing, fundamental and concept relationship data?",https://www.reddit.com/r/MachineLearning/comments/67f1mo/d_what_ml_methods_would_you_suggest_using_on_this/,iliconvalleys,1493104727,"Here's the dataset in [TSV format (21megs)](http://54.174.116.134/recommend/datasets/subscribers/free/supercolumns/helium_graphene_oil_china_korea-cmdb-nasdaq-nyse-otcbb-general-sp500-2017//supercolumns-helium_graphene_oil_china_korea-cmdb-nasdaq-nyse-otcbb-general-sp500-2017-01.tsv) or in [CSV format (27megs)](http://54.174.116.134/recommend/datasets/subscribers/free/supercolumns/helium_graphene_oil_china_korea-cmdb-nasdaq-nyse-otcbb-general-sp500-2017//supercolumns-helium_graphene_oil_china_korea-cmdb-nasdaq-nyse-otcbb-general-sp500-2017-01.csv)

-  Are there any deep learning approaches that might apply? My goal is determine what kind of signals or predictors I can uncover of course. 

Thank You.
",7,0,False,self,,,,,
897,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,16,67f5b0,self.MachineLearning,[D] light weighted DL framework,https://www.reddit.com/r/MachineLearning/comments/67f5b0/d_light_weighted_dl_framework/,godspeed_china,1493106440,"I found two light weighted DL framework:
tiny-dnn: https://github.com/tiny-dnn/tiny-dnn  
kann: https://github.com/attractivechaos/kann  
KANN is developed by Heng Li who is the god in bioinformatics. (I am a fan of him due to his great codes).  
is there any other light weighted frameworks? How to choose among those framework? and what is your opinions on those light weighted frameworks?  
Thanks!",7,8,False,self,,,,,
898,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,17,67f9ec,self.MachineLearning,Machine Learning Examples,https://www.reddit.com/r/MachineLearning/comments/67f9ec/machine_learning_examples/,itenterprise09,1493108544,[removed],0,1,False,default,,,,,
899,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,17,67faog,self.MachineLearning,Automatic Differentiation : I need help in understanding this,https://www.reddit.com/r/MachineLearning/comments/67faog/automatic_differentiation_i_need_help_in/,semester5,1493109222,[removed],0,1,False,default,,,,,
900,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,18,67fds7,self.MachineLearning,[D] How does DenseNet compare to ResNet and Inception?,https://www.reddit.com/r/MachineLearning/comments/67fds7/d_how_does_densenet_compare_to_resnet_and/,cbeak,1493110819,"Does anyone know of a comprehensive comparison of ConvNet architectures that includes DenseNet? In the [DenseNet paper](https://arxiv.org/abs/1608.06993) as well as on the [GitHub repository](https://github.com/liuzhuang13/DenseNet/issues/7) there are very promising graphs and tables, but then why don't we see DenseNet in winning Kaggle competitions and [vision](https://www.nature.com/nature/journal/v542/n7639/full/nature21056.html) [applications](https://arxiv.org/abs/1703.06870). Is it more costly to run, more data inefficient, more difficult to implement or is it simply too new?",6,43,False,self,,,,,
901,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,18,67fkog,github.com,[P] Goal-Oriented Knowledge Discovery in Multi-Agent Systems,https://www.reddit.com/r/MachineLearning/comments/67fkog/p_goaloriented_knowledge_discovery_in_multiagent/,[deleted],1493114222,[deleted],0,1,False,default,,,,,
902,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,18,67fkzx,github.com,A Goal-Oriented Approach to Knowledge Discovery in Multi-Agent Systems,https://www.reddit.com/r/MachineLearning/comments/67fkzx/a_goaloriented_approach_to_knowledge_discovery_in/,[deleted],1493114363,[deleted],0,1,False,default,,,,,
903,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,19,67fqv8,self.MachineLearning,[D]A3C performs badly in Mountain Car?,https://www.reddit.com/r/MachineLearning/comments/67fqv8/da3c_performs_badly_in_mountain_car/,darkzero_reddit,1493116983,"I tried out an implementation of A3C from Jaromiru's blog: https://github.com/jaara/AI-blog/blob/master/CartPole-A3C.py, in CartPole and MountainCar environments from Open AI gym respectively. In CartPole A3C works really well, taking less than 3 minutes to reach a cumulative reward of 475 and solved v1 environment.

However, when comes to MountainCar it performs badly. The policy network seems to converge so that the car always wants to go left/right in all situations, while DQN worked fairly well after training for about 10 minutes. 

Why does DQN performs better than A3C in MountainCar? Generally, in what kind of situations will DQN outperform A3C? I used to believe A3C is always better than DQN.

Thank you!
",12,14,False,self,,,,,
904,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,21,67gbb5,self.MachineLearning,Batch Normalization before or after ReLU?,https://www.reddit.com/r/MachineLearning/comments/67gbb5/batch_normalization_before_or_after_relu/,[deleted],1493124483,[removed],0,1,False,default,,,,,
905,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,22,67gkt0,self.MachineLearning,Help with extracting categories from a question. Is There an online service that offers such a thing?,https://www.reddit.com/r/MachineLearning/comments/67gkt0/help_with_extracting_categories_from_a_question/,iwanttodiequick,1493127401,[removed],0,1,False,default,,,,,
906,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,22,67glpy,self.MachineLearning,"[R] Are there studies about the ""preference"" of the ConvNets used in AlphaGo?",https://www.reddit.com/r/MachineLearning/comments/67glpy/r_are_there_studies_about_the_preference_of_the/,nipusa,1493127672,"By the ConvNets used in AlphaGo, I mean the network for prediction with 2D input, 2D output (~19*19) and many convolutional layers (&gt;10) in the middle. In this case, each entry of the 2D output can be influenced by a very large portion of the 2D input. Are there studies about how such a Convnet is different from, say, looking at the nearest neighbours in the input dataset? (For example, with the convnet, one might guess the input entry close to the output entry will have a heavier influence compared to the input entry which are far away)",1,1,False,self,,,,,
907,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,22,67glzh,vaibhavs10.github.io,Analysing past 10 years of news (India) [Latent Dirichlet Allocation],https://www.reddit.com/r/MachineLearning/comments/67glzh/analysing_past_10_years_of_news_india_latent/,vaibhavs10,1493127745,,0,1,False,default,,,,,
908,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,22,67gmhu,self.MachineLearning,What is the problem with back propagation in Neural Networks when the Activation function only outputs Positive values?,https://www.reddit.com/r/MachineLearning/comments/67gmhu/what_is_the_problem_with_back_propagation_in/,[deleted],1493127896,[removed],0,1,False,default,,,,,
909,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,22,67gn0b,self.MachineLearning,What is the problem with back propagation in Neural Networks when the Activation function only outputs Positive values?,https://www.reddit.com/r/MachineLearning/comments/67gn0b/what_is_the_problem_with_back_propagation_in/,ytgtfgfgg6667,1493128042,[removed],0,1,False,default,,,,,
910,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,22,67gonq,self.MachineLearning,[D] Batch Normalization before or after ReLU?,https://www.reddit.com/r/MachineLearning/comments/67gonq/d_batch_normalization_before_or_after_relu/,XalosXandrez,1493128523,"Hello all,
The original BatchNorm paper prescribes using BN before ReLU. The following is the exact text from the paper

&gt;We add the BN transform immediately before the nonlinearity, by normalizing x = Wu+ b. We could have also normalized the layer inputs u, but since u is likely the output of another nonlinearity, the shape of its distribution is likely to change during training, and constraining its first and second moments would not eliminate the covariate shift. In contrast, Wu + b is more likely to have a symmetric, non-sparse distribution, that is more Gaussian (Hyvarinen &amp; Oja, 2000); normalizing it is likely to produce activations with a stable distribution.



However, in practice I find that the opposite is true - BN after ReLU consistently performs better. I have found at least one other source claiming this to be true (https://github.com/gcr/torch-residual-networks/issues/5). Are there any other references for this? Has anybody here played around with this?

Edit: If anyone has come across any instances where BN before ReLU does better than BN after ReLU, please do share that as well. I have yet to come across any such instance.",30,94,False,self,,,,,
911,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,23,67gsa5,self.MachineLearning,Wasserstein GAN vs VAE : training time,https://www.reddit.com/r/MachineLearning/comments/67gsa5/wasserstein_gan_vs_vae_training_time/,s_daptardar,1493129546,[removed],0,1,False,default,,,,,
912,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,23,67gury,self.MachineLearning,New PC for machine learning with tensorflow,https://www.reddit.com/r/MachineLearning/comments/67gury/new_pc_for_machine_learning_with_tensorflow/,ml_nic,1493130239,[removed],0,1,False,default,,,,,
913,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,23,67gv7t,github.com,[P] A Goal-Oriented Approach to Knowledge Discovery in Multi-Agent Systems,https://www.reddit.com/r/MachineLearning/comments/67gv7t/p_a_goaloriented_approach_to_knowledge_discovery/,inboble,1493130369,,3,1,False,https://b.thumbs.redditmedia.com/xeuqugkPe2FytapVcE7wglxpwkIkWyxVP9mKgBCj-OA.jpg,,,,,
914,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,23,67h1tq,backchannel.com,[N] The Myth of a Superhuman AI,https://www.reddit.com/r/MachineLearning/comments/67h1tq/n_the_myth_of_a_superhuman_ai/,mirandaBC,1493132177,,0,1,False,default,,,,,
915,MachineLearning,t5_2r3gv,2017-4-25,2017,4,25,23,67h1uy,self.MachineLearning,An strange error in training RNN on language modelling task,https://www.reddit.com/r/MachineLearning/comments/67h1uy/an_strange_error_in_training_rnn_on_language/,yobichi,1493132185,[removed],2,1,False,default,,,,,
916,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,0,67h3dh,self.MachineLearning,[D] Thoughts on Donald Trump using machine learning and data mining to win the election?,https://www.reddit.com/r/MachineLearning/comments/67h3dh/d_thoughts_on_donald_trump_using_machine_learning/,[deleted],1493132574,[deleted],2,0,False,default,,,,,
917,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,0,67h4rs,self.MachineLearning,[Discussion] Looking for tools to prepare data for text classification,https://www.reddit.com/r/MachineLearning/comments/67h4rs/discussion_looking_for_tools_to_prepare_data_for/,vanhoa,1493132933,"Hi everyone. I just started learning about machine learning, some related libraries and basic nlp. 

I'm working in a project that uses SVM (Support Vector Machine) to classify sentiments into positive or negative categories. I'm looking for tools that help me to prepare dataset which consist of positive and negative sentiments (structured storage, visualize data, token statistics, detect duplicate data.....) and techniques need to be considered to make a good dataset. 

Any advice is appreciated. Thank.",0,0,False,self,,,,,
918,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,1,67hrhx,self.MachineLearning,Working with TIMIT data,https://www.reddit.com/r/MachineLearning/comments/67hrhx/working_with_timit_data/,[deleted],1493138696,[removed],0,1,False,default,,,,,
919,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,2,67i5j9,robots.ox.ac.uk,[R] [1704.0603] State-of-the-art tracking at high-speed and with teeny-tiny networks (600 kB),https://www.reddit.com/r/MachineLearning/comments/67i5j9/r_17040603_stateoftheart_tracking_at_highspeed/,bertinerd,1493142150,,10,28,False,default,,,,,
920,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,2,67i6ot,netguru.co,Smart Skill Distribution in Project Teams  Taking the Machine Learning Approach,https://www.reddit.com/r/MachineLearning/comments/67i6ot/smart_skill_distribution_in_project_teams_taking/,uyasinov,1493142435,,0,1,False,default,,,,,
921,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,2,67i714,youtube.com,Tinder Founder: Dating an Artificial Intelligence (AI)? Having Sex with Robots?,https://www.reddit.com/r/MachineLearning/comments/67i714/tinder_founder_dating_an_artificial_intelligence/,scidem,1493142508,,0,1,False,default,,,,,
922,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,2,67i9gn,shoutfuture.blogspot.in,Handy Guide to Machine Learning Algorithms for Beginners,https://www.reddit.com/r/MachineLearning/comments/67i9gn/handy_guide_to_machine_learning_algorithms_for/,ShoutFuture3,1493143101,,0,1,False,default,,,,,
923,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,3,67icz3,self.MachineLearning,How does real time data augmentation work in convolutional neural network,https://www.reddit.com/r/MachineLearning/comments/67icz3/how_does_real_time_data_augmentation_work_in/,Lukaskar,1493143961,[removed],0,1,False,default,,,,,
924,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,3,67ifmu,medium.com,[P] Medical Image Analysis with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/67ifmu/p_medical_image_analysis_with_deep_learning/,kluikens,1493144613,,3,15,False,https://b.thumbs.redditmedia.com/e2hCGOXUyxnQP1MMt2gdcopXGhtKzdvlMW1aK5U32bY.jpg,,,,,
925,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,3,67ii3p,machinelearning.technicacuriosa.com,"[P] My casual, beach-read, easygoing intro to linear regression and TensorFlow",https://www.reddit.com/r/MachineLearning/comments/67ii3p/p_my_casual_beachread_easygoing_intro_to_linear/,CarbonFire,1493145206,,3,22,False,https://b.thumbs.redditmedia.com/vgSU1iVO11RR-Yl0hcWjyS3yAGjmDfkqiWoHiZHTx6g.jpg,,,,,
926,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,4,67ipz3,nextplatform.com,Escher Erases Batching Lines for Efficient FPGA Deep Learning,https://www.reddit.com/r/MachineLearning/comments/67ipz3/escher_erases_batching_lines_for_efficient_fpga/,[deleted],1493147129,[deleted],0,1,False,default,,,,,
927,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,5,67j6ib,self.MachineLearning,pomegranate v0.7: Bayesian network edition [x-post from r/python],https://www.reddit.com/r/MachineLearning/comments/67j6ib/pomegranate_v07_bayesian_network_edition_xpost/,ants_rock,1493151303,[removed],0,1,False,default,,,,,
928,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,6,67jo3t,self.MachineLearning,"[D] Machine Learning specifically for Image Analysis, books, resources, recommendations?",https://www.reddit.com/r/MachineLearning/comments/67jo3t/d_machine_learning_specifically_for_image/,SirSharpest,1493155848,"Hello! 

&amp;nbsp;

I hope the title says most of what I'm hoping I can get some help with being pointed in the right direction. 

&amp;nbsp;

I have a decent knowledge of image analysis and processing (opencv, matlab etc) but I really let myself down by not knowing how to implement or understand machine learning for these applications. 

&amp;nbsp;

Could anyone recommend good learning resources specifically for machine learning and image analysis / processing for feature extraction, recognition etc? 

&amp;nbsp;

I've tried searching for a while now but a lot is out of date or has so many conflicting answers. So would really love your thoughts and recommendations.",3,0,False,self,,,,,
929,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,6,67jq23,self.MachineLearning,"In ""Strategic Attentive Writer for Learning Macro-Actions"", can anyone explain equation (2), ""write(e,\psi)"" in more detail?",https://www.reddit.com/r/MachineLearning/comments/67jq23/in_strategic_attentive_writer_for_learning/,AlexCoventry,1493156338,[removed],0,1,False,default,,,,,
930,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,6,67jtqm,plainflow.com,AI implications on SaaS products,https://www.reddit.com/r/MachineLearning/comments/67jtqm/ai_implications_on_saas_products/,caligolae,1493157353,,0,1,False,default,,,,,
931,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,8,67k9ip,self.MachineLearning,How to model Free will in Machine Learning and Agent-Based Systems?,https://www.reddit.com/r/MachineLearning/comments/67k9ip/how_to_model_free_will_in_machine_learning_and/,cudeep,1493161923,[removed],0,1,False,default,,,,,
932,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,9,67kp0t,github.com,[P] A system of intelligent agents that are driven by the need to learn,https://www.reddit.com/r/MachineLearning/comments/67kp0t/p_a_system_of_intelligent_agents_that_are_driven/,[deleted],1493166638,[deleted],0,1,False,default,,,,,
933,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,9,67kpjn,github.com,[P] A society of intelligent agents who want to discover new knowledge,https://www.reddit.com/r/MachineLearning/comments/67kpjn/p_a_society_of_intelligent_agents_who_want_to/,[deleted],1493166793,[deleted],0,0,False,default,,,,,
934,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,10,67kz2u,github.com,[P] A society of intelligent agents who want to discover new knowledge,https://www.reddit.com/r/MachineLearning/comments/67kz2u/p_a_society_of_intelligent_agents_who_want_to/,inboble,1493169786,,0,0,False,https://b.thumbs.redditmedia.com/zgh4hATCZ674f_aEycc1Fp1OR9fn_SRoImnWdL0SwCk.jpg,,,,,
935,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,10,67l0pj,self.MachineLearning,What branch of ML is Generative models?,https://www.reddit.com/r/MachineLearning/comments/67l0pj/what_branch_of_ml_is_generative_models/,[deleted],1493170292,[removed],0,1,False,default,,,,,
936,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,11,67l8lf,devblogs.nvidia.com,Photo Editing with Generative Adversarial Networks (Part 2),https://www.reddit.com/r/MachineLearning/comments/67l8lf/photo_editing_with_generative_adversarial/,harrism,1493172807,,0,1,False,default,,,,,
937,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,11,67l96o,re-work.co,Self-Driving Cars: the Tech &amp;amp; the Roadblocks,https://www.reddit.com/r/MachineLearning/comments/67l96o/selfdriving_cars_the_tech_amp_the_roadblocks/,teamrework,1493172983,,0,1,False,default,,,,,
938,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,11,67lcia,baohanhmaygiatelectrolux.com,Sa my git Electrolux,https://www.reddit.com/r/MachineLearning/comments/67lcia/sa_my_git_electrolux/,NhaTrang102,1493174050,,0,1,False,default,,,,,
939,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,11,67lg9y,backchannel.com,The Myth of a Superhuman AI  Kevin Kelly,https://www.reddit.com/r/MachineLearning/comments/67lg9y/the_myth_of_a_superhuman_ai_kevin_kelly/,[deleted],1493175282,[deleted],0,1,False,default,,,,,
940,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,11,67lgbg,backchannel.com,[D] The Myth of a Superhuman AI  Kevin Kelly,https://www.reddit.com/r/MachineLearning/comments/67lgbg/d_the_myth_of_a_superhuman_ai_kevin_kelly/,drlukeor,1493175296,,21,2,False,https://b.thumbs.redditmedia.com/J5jvvL6PDBzhC4kFkKrYI1uMzPBMwoNvceK5AUxix2I.jpg,,,,,
941,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,11,67lgfh,self.MachineLearning,What are the best recent ML breakthroughs which still don't have open source implementations?,https://www.reddit.com/r/MachineLearning/comments/67lgfh/what_are_the_best_recent_ml_breakthroughs_which/,[deleted],1493175331,[removed],0,1,False,default,,,,,
942,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,11,67lgvw,self.MachineLearning,[D] What are the best recent ML breakthroughs which still don't have open source implementations?,https://www.reddit.com/r/MachineLearning/comments/67lgvw/d_what_are_the_best_recent_ml_breakthroughs_which/,sour_losers,1493175485,I thought it would be a good idea to maintain a list so that people can take up the challenge.,55,175,False,self,,,,,
943,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,12,67lmx0,chatbotsmagazine.com,AI town in the middle of where?,https://www.reddit.com/r/MachineLearning/comments/67lmx0/ai_town_in_the_middle_of_where/,panchoTheEngineer,1493177492,,0,1,False,default,,,,,
944,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,12,67lnkt,youtube.com,[P] Saliency in Reinforcement Learning (ACER),https://www.reddit.com/r/MachineLearning/comments/67lnkt/p_saliency_in_reinforcement_learning_acer/,innixma,1493177737,,4,3,False,https://b.thumbs.redditmedia.com/qtNo6rN1bUO6WCf63KgewM96urpEpxnfDHHEMSm_6uY.jpg,,,,,
945,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,13,67m0y1,twosigma.com,"NIPS 2016: A survey of tutorials, papers, and workshops",https://www.reddit.com/r/MachineLearning/comments/67m0y1/nips_2016_a_survey_of_tutorials_papers_and/,carmichael561,1493182526,,0,1,False,default,,,,,
946,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,16,67mjuw,youtube.com,[D] Alternative interpretation of BatchNormalization by Ian Goodfellow. Reduces second-order stats not covariate shift.,https://www.reddit.com/r/MachineLearning/comments/67mjuw/d_alternative_interpretation_of/,sour_losers,1493190487,,7,11,False,https://b.thumbs.redditmedia.com/BtZW9pKmberGPQohesrJMleTdzz95u2NfvhOxk3pRRE.jpg,,,,,
947,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,16,67mly2,arxiv.org,[R] [1704.07804] SfM-Net: Learning of Structure and Motion from Video,https://www.reddit.com/r/MachineLearning/comments/67mly2/r_170407804_sfmnet_learning_of_structure_and/,huberloss,1493191473,,1,10,False,default,,,,,
948,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,17,67mvlx,self.MachineLearning,AI newb here: I have big datasets in Excel that are analyzed by humans every quarter. How could I try to automate this process?,https://www.reddit.com/r/MachineLearning/comments/67mvlx/ai_newb_here_i_have_big_datasets_in_excel_that/,berodrigues,1493196177,[removed],0,1,False,default,,,,,
949,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,18,67mzpy,self.MachineLearning,Path to ML expert,https://www.reddit.com/r/MachineLearning/comments/67mzpy/path_to_ml_expert/,[deleted],1493198164,[removed],0,1,False,default,,,,,
950,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,18,67n11k,mixmachinery.com,Which chemical process equipment can be used in melting oil based wax,https://www.reddit.com/r/MachineLearning/comments/67n11k/which_chemical_process_equipment_can_be_used_in/,mixmachinery,1493198823,,0,1,False,default,,,,,
951,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,19,67n91e,sdtimes.com,[D] The realities of machine learning systems,https://www.reddit.com/r/MachineLearning/comments/67n91e/d_the_realities_of_machine_learning_systems/,massiveattack778,1493202426,,1,12,False,https://b.thumbs.redditmedia.com/bIU7Vg09q2CPf8vPFdyopj5zRisqKebQxk_uqw9S_Kc.jpg,,,,,
952,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,19,67nbbn,self.MachineLearning,[D] I am currently recording all calls with my parents so that I can create an AI of them when they die. Thoughts?,https://www.reddit.com/r/MachineLearning/comments/67nbbn/d_i_am_currently_recording_all_calls_with_my/,melvingo,1493203381,"I will in other words be able to talk with ""them"" on the **phone**. It's not unreasonable that within 30 years we will have an AI that can:

* Perfectly mimic voices
* Look through information such as Facebook, sms and other text to mimic the personality
* Understand and give realistic answers when talked to

It is a little weird, but I think it's only natural to save more and more information about an individual. Today we save photos, videos and sound. Why not save their personalities?

I am afraid I will regret it if I don't.",77,9,False,self,,,,,
953,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,20,67ngs3,reportsandmarketsweb.wordpress.com,Raise Scaffold Market Research Report 2017,https://www.reddit.com/r/MachineLearning/comments/67ngs3/raise_scaffold_market_research_report_2017/,sudeshwd36,1493205605,,0,1,False,default,,,,,
954,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,21,67nr68,self.MachineLearning,Help me plan self study ML program,https://www.reddit.com/r/MachineLearning/comments/67nr68/help_me_plan_self_study_ml_program/,[deleted],1493209288,[removed],0,1,False,default,,,,,
955,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,21,67ntgu,self.MachineLearning,Reading pressure sensor in water flow to find if there is air bubbles in stream,https://www.reddit.com/r/MachineLearning/comments/67ntgu/reading_pressure_sensor_in_water_flow_to_find_if/,bojane-1,1493210027,[removed],0,1,False,default,,,,,
956,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,21,67nun3,web.cs.dal.ca,"[R] Emergent Tangled Graph Representations for Atari Game Playing Agents (EuroGP 2017 best paper, cf Mnih et al, 2015, Nature)",https://www.reddit.com/r/MachineLearning/comments/67nun3/r_emergent_tangled_graph_representations_for/,jmmcd,1493210412,,3,18,False,default,,,,,
957,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,22,67o5ox,sentiance.com,Predictive superpowers: Applying deep learning on mobile sensor data to predict human behavior,https://www.reddit.com/r/MachineLearning/comments/67o5ox/predictive_superpowers_applying_deep_learning_on/,[deleted],1493213774,[deleted],0,1,False,default,,,,,
958,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,23,67ogog,kdd.cs.ksu.edu,Call for Papers: 1st International Workshop on Affective Computing at IJCAI-2017,https://www.reddit.com/r/MachineLearning/comments/67ogog/call_for_papers_1st_international_workshop_on/,hlyates,1493216794,,1,1,False,default,,,,,
959,MachineLearning,t5_2r3gv,2017-4-26,2017,4,26,23,67oiiw,youtube.com,"Universal Basic Income in Era of Artificial Intelligence(AI), Automation and Robots",https://www.reddit.com/r/MachineLearning/comments/67oiiw/universal_basic_income_in_era_of_artificial/,scidem,1493217304,,0,1,False,default,,,,,
960,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,0,67oqi5,self.MachineLearning,What are the latest best practices for training LSTMs?,https://www.reddit.com/r/MachineLearning/comments/67oqi5/what_are_the_latest_best_practices_for_training/,Bardelaz,1493219380,[removed],0,1,False,default,,,,,
961,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,0,67oxj7,phys.org,Researchers build artificial synapse capable of autonomous learning,https://www.reddit.com/r/MachineLearning/comments/67oxj7/researchers_build_artificial_synapse_capable_of/,[deleted],1493221206,[deleted],0,1,False,default,,,,,
962,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,0,67p0g9,self.MachineLearning,"Simple Questions Thread April 26, 2017",https://www.reddit.com/r/MachineLearning/comments/67p0g9/simple_questions_thread_april_26_2017/,AutoModerator,1493221953,[removed],0,1,False,default,,,,,
963,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,0,67p0ve,sentiance.com,[P] Predictive superpowers: Applying deep learning on mobile sensor data to predict human behavior,https://www.reddit.com/r/MachineLearning/comments/67p0ve/p_predictive_superpowers_applying_deep_learning/,esurior,1493222068,,10,90,False,https://b.thumbs.redditmedia.com/6OXqHoQmTDgjJCJtrqhpKwcGd1G5MnyDhFEA5otF3ZU.jpg,,,,,
964,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,1,67p9ey,arxiv.org,Deep learning for image inpainting,https://www.reddit.com/r/MachineLearning/comments/67p9ey/deep_learning_for_image_inpainting/,throwaway801512,1493224163,,0,1,False,default,,,,,
965,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,1,67pal1,medium.com,Find similar landscaping plants with PCA,https://www.reddit.com/r/MachineLearning/comments/67pal1/find_similar_landscaping_plants_with_pca/,LastZactionHero,1493224458,,0,1,False,default,,,,,
966,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,1,67pb8b,github.com,VAE_GAN implemented in pytorch,https://www.reddit.com/r/MachineLearning/comments/67pb8b/vae_gan_implemented_in_pytorch/,seangal2,1493224606,,0,1,False,default,,,,,
967,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,2,67poif,medium.com,Writing travel blog posts with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/67poif/writing_travel_blog_posts_with_deep_learning/,goncalogordo,1493227897,,0,1,False,default,,,,,
968,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,2,67pruf,kaggle.com,Solar System and Earthquakes. Is relationship exists? The link points to a dataset you can use to answer the question: Is there any relationship between the position and other params of objects in our Solar System and Earthquakes?,https://www.reddit.com/r/MachineLearning/comments/67pruf/solar_system_and_earthquakes_is_relationship/,aradzhabov,1493228725,,0,1,False,default,,,,,
969,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,2,67ps9d,alexirpan.com,[D] On The Perils of Batch Norm,https://www.reddit.com/r/MachineLearning/comments/67ps9d/d_on_the_perils_of_batch_norm/,alexirpan,1493228818,,12,27,False,default,,,,,
970,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,3,67q36m,self.MachineLearning,Some detailed questions about the implementation of RNN model for text generation,https://www.reddit.com/r/MachineLearning/comments/67q36m/some_detailed_questions_about_the_implementation/,yobichi,1493231518,[removed],0,1,False,default,,,,,
971,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,3,67q4en,arxiv.org,[R][1704.06851] Affect-LM: A Neural Language Model for Customizable Affective Text Generation,https://www.reddit.com/r/MachineLearning/comments/67q4en/r170406851_affectlm_a_neural_language_model_for/,sergeyfukov,1493231823,,1,17,False,default,,,,,
972,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,3,67q8bd,self.MachineLearning,[HELP] Parameter Estimation Using Bayesian Inference,https://www.reddit.com/r/MachineLearning/comments/67q8bd/help_parameter_estimation_using_bayesian_inference/,MakeMeBeleive,1493232765,[removed],0,1,False,default,,,,,
973,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,4,67qifv,arxiv.org,[R] Rotting Bandits: Multi-Armed Bandits Framework,https://www.reddit.com/r/MachineLearning/comments/67qifv/r_rotting_bandits_multiarmed_bandits_framework/,theciank,1493235323,,2,5,False,default,,,,,
974,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,4,67qk9j,self.MachineLearning,"[D] Can I use clustering (k-means, etc) on a large set of data to automate the process of finding similarities and make recommendations?",https://www.reddit.com/r/MachineLearning/comments/67qk9j/d_can_i_use_clustering_kmeans_etc_on_a_large_set/,oxmpbeta,1493236055,"I know that clustering is used to tease out similarities that arent readily identifiable but, can I use clustering on a larger set of data to automate the process of binning items, based on similarity (ie: finding equivalents) so that I can make recommendations?  

Each one of these has approximately 15 different categories, all being continuous, and the sheer number of choices necessitates an automated approach, but I'd like to avoid having to use an expert if/then system.",17,34,False,self,,,,,
975,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,5,67qxfe,github.com,[P] Tffm: TensorFlow implementation of an arbitrary order Factorization Machine,https://www.reddit.com/r/MachineLearning/comments/67qxfe/p_tffm_tensorflow_implementation_of_an_arbitrary/,theciank,1493239497,,3,5,False,https://a.thumbs.redditmedia.com/BM8ma5mMRl867lT7CYSlXhCxYsas3fJLI6EKv68WmP0.jpg,,,,,
976,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,6,67r308,self.MachineLearning,How to generalize text (BOW) classifier with little data?,https://www.reddit.com/r/MachineLearning/comments/67r308/how_to_generalize_text_bow_classifier_with_little/,Nixonite,1493240903,[removed],0,1,False,default,,,,,
977,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,6,67r81s,self.MachineLearning,[D] What is the dimension of the sub-manifold of natural images?,https://www.reddit.com/r/MachineLearning/comments/67r81s/d_what_is_the_dimension_of_the_submanifold_of/,umutisik,1493242251,"Out of curiosity:
- Say I am looking at a data-set of 256x256 real-world images. How does one make an educated estimation of the dimension of the support of the distribution the images would have been sampled from?
- In general, what is a good way of estimating the local dimensionality of high-dimensional data-sets?",6,0,False,self,,,,,
978,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,7,67rigi,self.MachineLearning,[D] Interactive/Engaging machine learning projects,https://www.reddit.com/r/MachineLearning/comments/67rigi/d_interactiveengaging_machine_learning_projects/,beef__,1493245186,"Hey guys - I'm in high school and I run my school's programming club. Every thursday we have a short (~45 minute) meeting in the middle of the school day just to talk about projects / catch up - we usually don't actually program during these in-school meetings - I just go up to the board and show everyone something cool on the projector, we talk about it, etc. etc.

I'm looking for some neat interactive/engaging ML projects that I could show everyone - NVIDIA just recently sent me this developer board with a ton of gpu cores on it so I can do CUDA stuff.


Some projects we've done in the past that everyone really liked were:



* Neural Doodle - turn your 2 bit drawings into fine artworks; https://github.com/alexjc/neural-doodle




* Rapping Neural Network (I actually wrote this!) - Neural network/markov chain combo that generates and ""performs"" rap songs with text to speech; https://github.com/robbiebarrat/rapping-neural-network




* Neural Style transfer - I think everyone has seen this one, turns photographs into ""paintings"" based off of reference images - there are tons of implementations of this just google it if you're unfamiliar.




* DCGAN stuff - we looked at and messed around with a DCGAN to generate images - a lot of the images it generated looked really creepy so i just projected it up onto the board for a while and we talked about it. https://github.com/Newmu/dcgan_code


Does anyone know any other engaging ML/AI projects like these? It can really be anything - as long as you think that typical high-schoolers will find it interesting...
if all else fails i think I'll just show them lyrebird.ai (this super cool machine learning project that can like, mimic anyone's voice after hearing them talk for a minute or two) and we'll talk about the ethical implications of it - i just really need some suggestions! thanks!

**tl;dr what are some cool/engaging ML projects that would entertain high schoolers for about a half hour?**",5,10,False,self,,,,,
979,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,7,67rln1,self.MachineLearning,Graphs and diagrams for paper,https://www.reddit.com/r/MachineLearning/comments/67rln1/graphs_and_diagrams_for_paper/,[deleted],1493246105,[removed],0,1,False,default,,,,,
980,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,10,67slr2,medium.com,Deep Reinforcement Learning Tutorials (Episode 0),https://www.reddit.com/r/MachineLearning/comments/67slr2/deep_reinforcement_learning_tutorials_episode_0/,m_alzantot,1493257085,,0,1,False,default,,,,,
981,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,12,67t8ej,royalsociety.org,[N] Detailed report on the social and governance implications of machine learning by the Royal Society,https://www.reddit.com/r/MachineLearning/comments/67t8ej/n_detailed_report_on_the_social_and_governance/,drlukeor,1493264573,,2,9,False,default,,,,,
982,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,13,67thgk,arxiv.org,[1703.01827] All You Need is Beyond a Good Init -&gt; training very deep networks with neither shortcuts nor identity mappings,https://www.reddit.com/r/MachineLearning/comments/67thgk/170301827_all_you_need_is_beyond_a_good_init/,[deleted],1493267993,[deleted],0,1,False,default,,,,,
983,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,13,67thn4,arxiv.org,[R] All You Need is Beyond a Good Init -&gt; training very deep networks with neither shortcuts nor identity mappings,https://www.reddit.com/r/MachineLearning/comments/67thn4/r_all_you_need_is_beyond_a_good_init_training/,xternalz,1493268044,,6,38,False,default,,,,,
984,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,14,67tn9t,self.MachineLearning,[D] Diagrams and graphs in papers,https://www.reddit.com/r/MachineLearning/comments/67tn9t/d_diagrams_and_graphs_in_papers/,andyzth,1493270285,"Hi I wanted to know what the most commonly used graphing libraries/tools for academic papers are. Specifically how to generate a 3D diagram of convolutional layer (e.g. 
https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf).
and aesthetically pleasing graphs like fig. 6 in https://arxiv.org/pdf/1701.08734.pdf

Thanks for the advice
",8,21,False,self,,,,,
985,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,14,67tqem,youtu.be,Grinder support complete assembly,https://www.reddit.com/r/MachineLearning/comments/67tqem/grinder_support_complete_assembly/,[deleted],1493271640,[deleted],0,1,False,default,,,,,
986,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,16,67u7ov,github.com,tf-3dgan: Tensorflow implementation of 3D Generative Adversarial Network.,https://www.reddit.com/r/MachineLearning/comments/67u7ov/tf3dgan_tensorflow_implementation_of_3d/,3dgan,1493279490,,0,1,False,default,,,,,
987,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,16,67u8be,arxiv.org,[R] [1704.06933] Adversarial Neural Machine Translation,https://www.reddit.com/r/MachineLearning/comments/67u8be/r_170406933_adversarial_neural_machine_translation/,mimighost,1493279808,,5,31,False,default,,,,,
988,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,16,67u8nm,arxiv.org,Deep Text Classification Can be Fooled,https://www.reddit.com/r/MachineLearning/comments/67u8nm/deep_text_classification_can_be_fooled/,spidey-fan,1493279989,,0,1,False,default,,,,,
989,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,17,67uaxh,github.com,[N] An less-known strong AI develop gave up to build Strong-AI :),https://www.reddit.com/r/MachineLearning/comments/67uaxh/n_an_lessknown_strong_ai_develop_gave_up_to_build/,[deleted],1493281100,[deleted],1,0,False,default,,,,,
990,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,18,67ufwo,self.MachineLearning,"[D] Has anyone had any luck using word2vec to compare sentences, without using doc2vec?",https://www.reddit.com/r/MachineLearning/comments/67ufwo/d_has_anyone_had_any_luck_using_word2vec_to/,irrelevant_banana,1493283734,,18,36,False,self,,,,,
991,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,18,67umqp,github.com,[N] A less-known AGI developer gave up to build a strong-ai framework.,https://www.reddit.com/r/MachineLearning/comments/67umqp/n_a_lessknown_agi_developer_gave_up_to_build_a/,nocortex,1493286987,,27,0,False,default,,,,,
992,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,18,67umwt,self.MachineLearning,[D] How does FaceApp work?,https://www.reddit.com/r/MachineLearning/comments/67umwt/d_how_does_faceapp_work/,clbam8,1493287069,I came across this app on play store today called [FaceApp](https://www.faceapp.com/). Does anyone know how it works? I don't remember seeing any paper about this recently.,27,76,False,self,,,,,
993,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,20,67uz5t,self.MachineLearning,Why would i use classification for prediction if i can just use visualization?,https://www.reddit.com/r/MachineLearning/comments/67uz5t/why_would_i_use_classification_for_prediction_if/,hoosierpride1,1493292382,[removed],0,1,False,default,,,,,
994,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,20,67v15f,self.MachineLearning,E5-2699 v3 vs 1080 for tensorflow training,https://www.reddit.com/r/MachineLearning/comments/67v15f/e52699_v3_vs_1080_for_tensorflow_training/,flyingcomma,1493293144,[removed],0,1,False,default,,,,,
995,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,20,67v1c4,medium.com,Read to know why do we the democratization of Machine Learning and Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/67v1c4/read_to_know_why_do_we_the_democratization_of/,kailashahirwar12,1493293214,,1,1,False,default,,,,,
996,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,22,67vp2x,stats.stackexchange.com,Is there a term that encompasses all the different classifiers which do not consider the order of features?,https://www.reddit.com/r/MachineLearning/comments/67vp2x/is_there_a_term_that_encompasses_all_the/,Lopelh,1493300824,,0,1,False,default,,,,,
997,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,23,67vsmt,self.MachineLearning,What tools/libs could I use to highlight a region of a large image and find similar patterns in the same image?,https://www.reddit.com/r/MachineLearning/comments/67vsmt/what_toolslibs_could_i_use_to_highlight_a_region/,Otherones,1493301822,[removed],0,1,False,default,,,,,
998,MachineLearning,t5_2r3gv,2017-4-27,2017,4,27,23,67w022,self.MachineLearning,off-policy and on-policy networks in RL,https://www.reddit.com/r/MachineLearning/comments/67w022/offpolicy_and_onpolicy_networks_in_rl/,[deleted],1493303784,[removed],0,1,False,default,,,,,
999,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,0,67wg7b,self.MachineLearning,[D] Operation to make predictions from Softmax layer more confident,https://www.reddit.com/r/MachineLearning/comments/67wg7b/d_operation_to_make_predictions_from_softmax/,Pieranha,1493307955,"Label smoothing and similar techniques can be used to penalize confident predictions (see e.g. https://openreview.net/forum?id=HyhbYrGYe&amp;noteId=HyhbYrGYe). However, I have a use case, where I instead want to make the predictions of a Softmax layer more confident for another layer that's connected to the output from the Softmax layer (i.e. an auxiliary classification task using the predicted probability distribution).

For instance, I'd like to perform a differentiable operation I can apply to the output of a Softmax layer that will make my prediction go from [.80, .1, .1] to [.98, .01, .01].

One solution would be to just take the logits and compute another Softmax with a lower temperature, but that's quite computationally expensive as I have many classes. Is there a better way to do it?",6,0,False,self,,,,,
1000,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,1,67wpcj,datawhatnow.com,[P] SimHash for question deduplication,https://www.reddit.com/r/MachineLearning/comments/67wpcj/p_simhash_for_question_deduplication/,Weenkus,1493310167,,3,23,False,https://a.thumbs.redditmedia.com/WYhNdmKInQ4dtGutT7vp914sv2sp4INx9BXqHVnVS14.jpg,,,,,
1001,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,1,67wqzg,github.com,Awesome Machine Learning with Ruby,https://www.reddit.com/r/MachineLearning/comments/67wqzg/awesome_machine_learning_with_ruby/,small_arbox,1493310582,,0,1,False,default,,,,,
1002,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,2,67x3sc,github.com,[P] Let's fix MXNet docs! How you can join in and help,https://www.reddit.com/r/MachineLearning/comments/67x3sc/p_lets_fix_mxnet_docs_how_you_can_join_in_and_help/,phunter_lau,1493313764,,9,28,False,https://b.thumbs.redditmedia.com/bgSFPALLs9CIUnfjhXOIe-YibbOjppMzsFjocp2MCUw.jpg,,,,,
1003,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,4,67y05p,self.MachineLearning,Amazon EC2 F1 Instances (customisable FPGAs) - anyone tried for deep learning?,https://www.reddit.com/r/MachineLearning/comments/67y05p/amazon_ec2_f1_instances_customisable_fpgas_anyone/,andyandy16,1493321874,[removed],0,1,False,default,,,,,
1004,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,5,67yckn,self.MachineLearning,Backprop in convnet has my brain hurting,https://www.reddit.com/r/MachineLearning/comments/67yckn/backprop_in_convnet_has_my_brain_hurting/,the_turtleman,1493325007,[removed],0,1,False,default,,,,,
1005,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,5,67yffn,self.MachineLearning,Online chat rooms for discussing ML code/hacks/bugs?,https://www.reddit.com/r/MachineLearning/comments/67yffn/online_chat_rooms_for_discussing_ml_codehacksbugs/,mnipm,1493325741,[removed],0,1,False,default,,,,,
1006,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,6,67yjvv,driftwheeler.com,Melondream: Erotica Clustering by Neural Network,https://www.reddit.com/r/MachineLearning/comments/67yjvv/melondream_erotica_clustering_by_neural_network/,driftwheeler,1493326874,,1,1,True,default,,,,,
1007,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,6,67yp6a,self.MachineLearning,Network analysis and machine learning,https://www.reddit.com/r/MachineLearning/comments/67yp6a/network_analysis_and_machine_learning/,thatsadsid,1493328269,[removed],0,1,False,default,,,,,
1008,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,7,67z84k,alexgkendall.com,[D] Have We Forgotten about Geometry in Computer Vision?,https://www.reddit.com/r/MachineLearning/comments/67z84k/d_have_we_forgotten_about_geometry_in_computer/,internet_ham,1493333594,,31,89,False,https://b.thumbs.redditmedia.com/Jb9-sJTHIAj3x2Hx868rlcCCJgItifQq5RpZnObGG9g.jpg,,,,,
1009,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,8,67zeai,youtube.com,[P] Diagnosing Machine Learning Models,https://www.reddit.com/r/MachineLearning/comments/67zeai/p_diagnosing_machine_learning_models/,Dim25,1493335454,,2,25,False,https://b.thumbs.redditmedia.com/1k5gTTOv1L0Hp8U4ighlCrOuGRC1avx6Qmbh9VaFasM.jpg,,,,,
1010,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,10,6800nm,self.MachineLearning,The pain about deep learning research,https://www.reddit.com/r/MachineLearning/comments/6800nm/the_pain_about_deep_learning_research/,mlthrownaway,1493342435,[removed],0,1,False,default,,,,,
1011,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,10,6803et,self.MachineLearning,[R] The pain about deep learning research,https://www.reddit.com/r/MachineLearning/comments/6803et/r_the_pain_about_deep_learning_research/,mlthrownaway,1493343280,[removed],0,0,False,default,,,,,
1012,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,12,680net,54.174.116.134,[P] Dataset builder for financial ML,https://www.reddit.com/r/MachineLearning/comments/680net/p_dataset_builder_for_financial_ml/,[deleted],1493349907,[deleted],4,20,False,default,,,,,
1013,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,14,6814fp,hsc.com,Role of Machine Learning in Accelerating Digital Transformation,https://www.reddit.com/r/MachineLearning/comments/6814fp/role_of_machine_learning_in_accelerating_digital/,shweta_hsc,1493357055,,0,1,False,default,,,,,
1014,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,17,681f4a,blog.agi.io,[N] Open Sourcing MNIST and NIST Preprocessing Code,https://www.reddit.com/r/MachineLearning/comments/681f4a/n_open_sourcing_mnist_and_nist_preprocessing_code/,nocortex,1493368662,,21,0,False,https://b.thumbs.redditmedia.com/nDUXreENodA-icb-tQz1jPrRu_9E-f6meMPwawQNZ2M.jpg,,,,,
1015,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,17,681f60,self.MachineLearning,What do you do after building a model? How do you deploy it? Any resources/tutorials/books?,https://www.reddit.com/r/MachineLearning/comments/681f60/what_do_you_do_after_building_a_model_how_do_you/,dnt404-1,1493368684,[removed],0,1,False,default,,,,,
1016,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,17,681gde,medium.com,Rethinking Design Tools in the Age of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/681gde/rethinking_design_tools_in_the_age_of_machine/,ManiBePoint,1493369263,,0,1,False,default,,,,,
1017,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,17,681gg7,self.MachineLearning,Understanding LSTM network architectures,https://www.reddit.com/r/MachineLearning/comments/681gg7/understanding_lstm_network_architectures/,chain20,1493369309,[removed],0,1,False,default,,,,,
1018,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,17,681hqn,self.MachineLearning,[D] Sequence to Sequence LSTM architectures,https://www.reddit.com/r/MachineLearning/comments/681hqn/d_sequence_to_sequence_lstm_architectures/,chain20,1493369949,"The LSTM example in Lasagne (and most examples online) take a sequence and produce a single output. The LSTM layer is unfolded for the entire sequence and fed to a Dense Layer:

    l_in = lasagne.layers.InputLayer(shape=(None, None, vocab_size))
    l_forward_1 = lasagne.layers.LSTMLayer(l_in, N_HIDDEN, grad_clipping=GRAD_CLIP, nonlinearity=lasagne.nonlinearities.tanh)
    l_forward_2 = lasagne.layers.LSTMLayer(l_forward_1, N_HIDDEN, grad_clipping=GRAD_CLIP, nonlinearity=lasagne.nonlinearities.tanh, only_return_final=True)
    l_out = lasagne.layers.DenseLayer(l_forward_2, num_units=vocab_size, W=lasagne.init.Normal(), nonlinearity=lasagne.nonlinearities.softmax)

I imagine it looks like this : [LSTM 1](http://imgur.com/fRKnDYR)

If you want to achieve this, cant you just take the output of the last LSTM since the ""recurrence"" should capture all the required information from the past? 

Also, many books and blogs that explain unfolded RNNs and LSTMs use a figure like this: [LSTM 2](http://imgur.com/7Qx9PXw)

What is the relation between these 2 architectures and why do we not see the second one more often?

I am under the impression that the second network is used for sequence to sequence learning. How do I implement this in Lasagne?",5,0,False,self,,,,,
1019,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,18,681mx9,github.com,Perceptron - a simple and presentable Artificial Neural Network builder,https://www.reddit.com/r/MachineLearning/comments/681mx9/perceptron_a_simple_and_presentable_artificial/,[deleted],1493372404,[deleted],0,1,False,default,,,,,
1020,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,19,681ti0,slideshare.net,Machine learning and data mining solutions,https://www.reddit.com/r/MachineLearning/comments/681ti0/machine_learning_and_data_mining_solutions/,digitalmarketingrobi,1493375468,,0,1,False,default,,,,,
1021,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,19,681tln,github.com,simple Artificial neural network builder for testing and comparing performance,https://www.reddit.com/r/MachineLearning/comments/681tln/simple_artificial_neural_network_builder_for/,[deleted],1493375516,[deleted],0,1,False,default,,,,,
1022,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,19,681vns,youtube.com,generate some images using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/681vns/generate_some_images_using_tensorflow/,[deleted],1493376473,[deleted],0,1,False,default,,,,,
1023,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,19,681wh9,youtube.com,generate some images using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/681wh9/generate_some_images_using_tensorflow/,[deleted],1493376837,[deleted],0,1,False,default,,,,,
1024,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,20,681y0c,youtube.com,[P] generate some images using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/681y0c/p_generate_some_images_using_tensorflow/,Menckenhil2wu,1493377468,,0,0,False,https://a.thumbs.redditmedia.com/hegD4PZBJJfUE3QRMaxB5m0Piq1pfVO5HHqY0h2QnE0.jpg,,,,,
1025,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,20,681z4x,blog.paralleldots.com,Emotion Detection Using Machine Learning - ParallelDots,https://www.reddit.com/r/MachineLearning/comments/681z4x/emotion_detection_using_machine_learning/,gargisharmapd,1493377938,,0,1,False,default,,,,,
1026,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,20,6821fk,self.MachineLearning,Algorithm for learning successful/unsuccessful paths of arbitrary length?,https://www.reddit.com/r/MachineLearning/comments/6821fk/algorithm_for_learning_successfulunsuccessful/,shakedzy,1493378867,[removed],0,1,False,default,,,,,
1027,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,20,68244e,self.MachineLearning,Stem cell data usage to grow software brain simulation,https://www.reddit.com/r/MachineLearning/comments/68244e/stem_cell_data_usage_to_grow_software_brain/,ProgrammingGodJordan,1493379844,[removed],0,1,False,default,,,,,
1028,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,21,682e5e,self.MachineLearning,Recognizing emotion from voice with 84%+ accuracy,https://www.reddit.com/r/MachineLearning/comments/682e5e/recognizing_emotion_from_voice_with_84_accuracy/,Datapure,1493383444,[removed],0,1,False,default,,,,,
1029,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,22,682mhx,blog.kaggle.com,"[P] Dstl Satellite Imagery Competition, 1st Place Winners Interview: Kyle Lee",https://www.reddit.com/r/MachineLearning/comments/682mhx/p_dstl_satellite_imagery_competition_1st_place/,pmigdal,1493386149,,10,21,False,https://a.thumbs.redditmedia.com/qA90uxbltqvCHdCw7cbLCOcaM5B0dgL5AIF7GYp8vP0.jpg,,,,,
1030,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,22,682qfi,blog.metaflow.fr,"[P] TensorFlow: A proposal of good practices for files, folders and models architecture",https://www.reddit.com/r/MachineLearning/comments/682qfi/p_tensorflow_a_proposal_of_good_practices_for/,morgangiraud,1493387330,,25,283,False,https://b.thumbs.redditmedia.com/8hpyKchxAzbFJ2HpZuqS-XSjX3_IquV_mWlZxZB6rKE.jpg,,,,,
1031,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,23,6831gu,self.MachineLearning,[D] Semantics of recall/precision,https://www.reddit.com/r/MachineLearning/comments/6831gu/d_semantics_of_recallprecision/,[deleted],1493390533,[deleted],0,0,False,default,,,,,
1032,MachineLearning,t5_2r3gv,2017-4-28,2017,4,28,23,6831sd,datasciencecentral.com,Which machine learning algorithm should I use?,https://www.reddit.com/r/MachineLearning/comments/6831sd/which_machine_learning_algorithm_should_i_use/,pmz,1493390627,,0,1,False,default,,,,,
1033,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,0,6836dh,medium.com,"No, Kaggle is unsuitable to study AI and ML. My reply to Ben Hamner",https://www.reddit.com/r/MachineLearning/comments/6836dh/no_kaggle_is_unsuitable_to_study_ai_and_ml_my/,mostafabenh,1493391848,,0,1,False,default,,,,,
1034,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,0,683di2,self.MachineLearning,"[Question] State of the art in ""black-box"" supervised learning with deep neural network?",https://www.reddit.com/r/MachineLearning/comments/683di2/question_state_of_the_art_in_blackbox_supervised/,stratorex,1493393751,[removed],0,1,False,default,,,,,
1035,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,1,683jle,arxiv.org,"[R] ""Forward and Reverse Gradient-Based Hyperparameter Optimization"", Franceschi et al 2017",https://www.reddit.com/r/MachineLearning/comments/683jle/r_forward_and_reverse_gradientbased/,gwern,1493395345,,1,7,False,default,,,,,
1036,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,1,683ujf,self.MachineLearning,general ai or singularity POC (proof of concept),https://www.reddit.com/r/MachineLearning/comments/683ujf/general_ai_or_singularity_poc_proof_of_concept/,[deleted],1493398244,[removed],0,2,False,default,,,,,
1037,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,3,684dr3,self.MachineLearning,[D] What's the latest in wake word/hot word detection?,https://www.reddit.com/r/MachineLearning/comments/684dr3/d_whats_the_latest_in_wake_wordhot_word_detection/,pixelrealm_aaron,1493403234,It seems that a lot of major companies are all doing personal assistants which can be voice activated. What kinds of approaches are these companies using? Is there any open source implementation that I can self train or play with? Thanks!,1,0,False,self,,,,,
1038,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,3,684eht,github.com,Perceptron - Artificial neural network builder,https://www.reddit.com/r/MachineLearning/comments/684eht/perceptron_artificial_neural_network_builder/,[deleted],1493403431,[deleted],0,1,False,default,,,,,
1039,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,3,684fc5,artificialbrain.xyz,Best Introduction to Machine Learning,https://www.reddit.com/r/MachineLearning/comments/684fc5/best_introduction_to_machine_learning/,Mussem17,1493403659,,0,1,False,default,,,,,
1040,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,4,684oth,self.MachineLearning,https://github.com/casparwylie/Perceptron - do you like the user interface?,https://www.reddit.com/r/MachineLearning/comments/684oth/httpsgithubcomcasparwylieperceptron_do_you_like/,[deleted],1493406143,[removed],0,1,False,default,,,,,
1041,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,6,685itx,self.MachineLearning,[D] Follow-up methods to TRPO+GAE ?,https://www.reddit.com/r/MachineLearning/comments/685itx/d_followup_methods_to_trpogae/,xingdongrobotics,1493414435,"A second-order policy gradient method, TRPO introduced in 2015, and later on integrated with Generalized Advantage Estimation which leads to better results.  Until now, is there any follow-up methods we can use in addition to that ? ",1,4,False,self,,,,,
1042,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,6,685jtj,self.MachineLearning,Automating audio processing jobs,https://www.reddit.com/r/MachineLearning/comments/685jtj/automating_audio_processing_jobs/,titpetric,1493414711,[removed],0,1,False,default,,,,,
1043,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,6,685m5a,github.com,[P] Machine Learning for Music Workshop,https://www.reddit.com/r/MachineLearning/comments/685m5a/p_machine_learning_for_music_workshop/,brannondorsey,1493415379,,1,9,False,https://b.thumbs.redditmedia.com/wVW7o1oDlB_gTJZ1QcCEGfAjQHDzJ5ealx0R_-kpAYE.jpg,,,,,
1044,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,9,686eiu,self.MachineLearning,"What is the State of the art in ""Image Captioning""?",https://www.reddit.com/r/MachineLearning/comments/686eiu/what_is_the_state_of_the_art_in_image_captioning/,[deleted],1493424455,[removed],0,1,False,default,,,,,
1045,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,11,68767v,youtube.com,A.I. is Progressing Faster Than You Think!,https://www.reddit.com/r/MachineLearning/comments/68767v/ai_is_progressing_faster_than_you_think/,Pyrotecx,1493434427,,0,1,False,default,,,,,
1046,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,12,687daj,self.MachineLearning,Using the GPU on MacBook Pro,https://www.reddit.com/r/MachineLearning/comments/687daj/using_the_gpu_on_macbook_pro/,noename1,1493437200,[removed],0,1,False,default,,,,,
1047,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,12,687dv0,nrec.ri.cmu.edu,[Project] NREC Person Detection Dataset,https://www.reddit.com/r/MachineLearning/comments/687dv0/project_nrec_person_detection_dataset/,BrokenGumdrop,1493437445,,1,26,False,https://b.thumbs.redditmedia.com/dnUV7zXh83pOwSkcdtNApf4ggzm_Ei_thYcYr96d0lI.jpg,,,,,
1048,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,13,687kj1,self.MachineLearning,Some questions about deep learning and graphics cards.,https://www.reddit.com/r/MachineLearning/comments/687kj1/some_questions_about_deep_learning_and_graphics/,[deleted],1493440252,[removed],0,1,False,default,,,,,
1049,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,17,688cm9,self.MachineLearning,[D] Off-Policy A3C reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/688cm9/d_offpolicy_a3c_reinforcement_learning/,Delthc,1493454513,"EDIT: Thanks guys, I think I do now understand. For anybody interested, the answer seems to be: 
The linked code is wrong from a theoretical perspective (they use Policy Gradient on a replay memory), but works in practice because the policy in the memory and the current policy are still similar for the rather simple problem that is solved (cartpole)

------------------------------------

Hello, I have a question and hope someone can help me understand:
What exactly does prevent the A3C algorithm from beeing used off-policy? 

For example, the Actor-Critic algorithm from rlcode ( https://github.com/rlcode/reinforcement-learning/blob/master/Code%202.%20Cartpole/5.%20Actor-Critic/Cartpole_ActorCritic.py ) is off-policy: 
It uses a replay-memory and trains on random batches of it, just like Q-Learning does. However, it does not use n-step-reward, it trains on ""Critic(Next_State) - Critic(State)""


Sure, on-policy would mean not to use any replay memory but only learning on the newest state-action-reward pairs once (that reflect the current policy).
But if that was the only difference, one could easily use A3C off-policy, right? So what exactly does prevent an off-policy variant of A3C and why is it always stated as strictly on-policy (with sophisticated extensions needed to make it off-policy, like ACER)?

Is it because of the n-step-rewards, that can only be computed correctly for following a given policy and will become ""obsolete"" or ""wrong"" if the policy has changed? 
This is the only explanation I could come up with, as n-step-rewards means to follow the current policy for n-steps and then calculating the reward of the past action in strict correlation with the current policy, hence its on-policy?!

So, is the only difference between a off-policy actor-critic algorithm and A3C the lack of a replay-memory and n-step-reward calculation??


Thanks in advance",30,16,False,self,,,,,
1050,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,17,688duu,youtube.com,How to Convert Text to Images - Intro to Deep Learning #16,https://www.reddit.com/r/MachineLearning/comments/688duu/how_to_convert_text_to_images_intro_to_deep/,ackstazya,1493455272,,0,1,False,default,,,,,
1051,MachineLearning,t5_2r3gv,2017-4-29,2017,4,29,22,6899ft,self.MachineLearning,Help me take a direction,https://www.reddit.com/r/MachineLearning/comments/6899ft/help_me_take_a_direction/,cseguy321,1493471476,[removed],0,1,False,default,,,,,
1052,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,0,689r9b,crickytics.com,[P] Predicting the outcome of Cricket Matches using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/689r9b/p_predicting_the_outcome_of_cricket_matches_using/,Faizann24,1493478094,,18,36,False,https://b.thumbs.redditmedia.com/IYsWToeVod3ylbmvHT96UWQnbguFWO-h3q66Hz4mYlg.jpg,,,,,
1053,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,1,68a2zq,self.MachineLearning,[D] Silly benchmarking discovery... Surface Pro 4 is surprisingly fast for deep learning... any ideas why?,https://www.reddit.com/r/MachineLearning/comments/68a2zq/d_silly_benchmarking_discovery_surface_pro_4_is/,JosephLChu,1493481843,"So, on a lark I decided a while back to install Theano and Keras on my Microsoft Surface Pro 4 with Windows 10.  Interestingly, it takes only about 170 seconds to train an epoch of my port of Char-RNN on the CPU.  In comparison, most laptop and desktop CPUs I've worked with take upwards of 1000+ seconds to do the same, and the fastest I've ever benchmarked was about 40 seconds with a computer with an Nvidia Titan X GPU.

So, any ideas as to why this is the case?

Edit:  So apparently the poor results of the 1000+ seconds per epoch computers was due to a bug in the Theano 0.9.0 release that has been fixed already in the latest bleeding edge version.  So, I guess... nevermind?",15,0,False,self,,,,,
1054,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,1,68a36w,kaggle.com,[Project] Predicting Winners of UFC Fights from previous fight record. Any input/critique is appreciated,https://www.reddit.com/r/MachineLearning/comments/68a36w/project_predicting_winners_of_ufc_fights_from/,rhead42,1493481901,,8,5,False,default,,,,,
1055,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,2,68ai83,github.com,BerryNet - Deep learning gateway on Raspberry Pi,https://www.reddit.com/r/MachineLearning/comments/68ai83/berrynet_deep_learning_gateway_on_raspberry_pi/,figurelover,1493486501,,0,1,False,default,,,,,
1056,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,2,68akhu,eli.thegreenplace.net,Softmax derivation and Jacobian,https://www.reddit.com/r/MachineLearning/comments/68akhu/softmax_derivation_and_jacobian/,pete0273,1493487223,,0,1,False,default,,,,,
1057,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,2,68an44,github.com,[P] DeepLab-Resnet (semantic segmentation) in pytorch,https://www.reddit.com/r/MachineLearning/comments/68an44/p_deeplabresnet_semantic_segmentation_in_pytorch/,isht7,1493488022,,0,9,False,https://b.thumbs.redditmedia.com/PzYPS4t3EwIJJYDMViWc4VLcR8-b9xFvN9USqjiIMFs.jpg,,,,,
1058,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,3,68aqvo,blog.insightdatascience.com,Separating Overlapping Chromosomes with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/68aqvo/separating_overlapping_chromosomes_with_deep/,mwakanosya,1493489167,,0,1,False,default,,,,,
1059,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,3,68b0je,self.MachineLearning,[D] Idea: Program to pull youtube links from this sub and add them to my watch later playlist.,https://www.reddit.com/r/MachineLearning/comments/68b0je/d_idea_program_to_pull_youtube_links_from_this/,[deleted],1493492099,[deleted],4,0,False,default,,,,,
1060,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,4,68b2nl,self.MachineLearning,SuperBowl Tweet (sentiment) analysis,https://www.reddit.com/r/MachineLearning/comments/68b2nl/superbowl_tweet_sentiment_analysis/,Matheuslut,1493492735,[removed],0,1,False,default,,,,,
1061,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,6,68byvs,artificialbrain.xyz,Architecting Predictive Algorithms for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/68byvs/architecting_predictive_algorithms_for_machine/,Mussem17,1493503067,,0,1,False,default,,,,,
1062,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,7,68c88v,youtube.com,[R] Toward Efficient Deep Neural Network Deployment: Deep Compression and EIE (2016),https://www.reddit.com/r/MachineLearning/comments/68c88v/r_toward_efficient_deep_neural_network_deployment/,peeyek,1493506252,,10,71,False,https://b.thumbs.redditmedia.com/BJY-Gxyiie8i3Jk46npVHOpmKIKJCIXOAMAlGPnB5EE.jpg,,,,,
1063,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,9,68crcy,aioptify.com,"Top 16 Machine Learning, Data Mining, and NLP Books",https://www.reddit.com/r/MachineLearning/comments/68crcy/top_16_machine_learning_data_mining_and_nlp_books/,kjahan,1493512838,,0,1,False,default,,,,,
1064,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,11,68dc1i,cnbc.com,Heres how one of Googles top scientists thinks people should prepare for machine learning,https://www.reddit.com/r/MachineLearning/comments/68dc1i/heres_how_one_of_googles_top_scientists_thinks/,[deleted],1493520717,[deleted],1,1,False,default,,,,,
1065,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,15,68e1oj,unanth.com,Must Read free e-Books on Machine Learning,https://www.reddit.com/r/MachineLearning/comments/68e1oj/must_read_free_ebooks_on_machine_learning/,kshitij_unanth,1493532047,,0,1,False,default,,,,,
1066,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,15,68e6ij,github.com,Awesome automatic speech recognition papers roadmap,https://www.reddit.com/r/MachineLearning/comments/68e6ij/awesome_automatic_speech_recognition_papers/,[deleted],1493534508,[deleted],0,1,False,default,,,,,
1067,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,16,68ed9w,self.MachineLearning,"[D]What is the State of the art in ""Image Captioning""?",https://www.reddit.com/r/MachineLearning/comments/68ed9w/dwhat_is_the_state_of_the_art_in_image_captioning/,underfitting,1493537896,,4,5,False,self,,,,,
1068,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,19,68et4c,youtube.com,CS-50 Small Green Onion Pepper Leek Chopping Slicing Shredding Machine,https://www.reddit.com/r/MachineLearning/comments/68et4c/cs50_small_green_onion_pepper_leek_chopping/,Elaine2008,1493547636,,0,1,False,default,,,,,
1069,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,19,68euv3,techcrunch.com,"Someone scraped 40,000 Tinder selfies to make a facial dataset for AI experiments",https://www.reddit.com/r/MachineLearning/comments/68euv3/someone_scraped_40000_tinder_selfies_to_make_a/,Maccle415,1493548660,,0,1,False,default,,,,,
1070,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,19,68evng,i.redd.it,Insight DCU-UPC School on Deep Learning 2017 http://bit.ly/InsightDL2017,https://www.reddit.com/r/MachineLearning/comments/68evng/insight_dcuupc_school_on_deep_learning_2017/,xavigiro,1493549125,,1,1,False,default,,,,,
1071,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,20,68f0d3,self.MachineLearning,Why LSTM fails while feedforward network is ok?,https://www.reddit.com/r/MachineLearning/comments/68f0d3/why_lstm_fails_while_feedforward_network_is_ok/,[deleted],1493551664,[removed],0,1,False,default,,,,,
1072,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,21,68f60z,github.com,[P]Automatic Speech Recognition implemented in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/68f60z/pautomatic_speech_recognition_implemented_in/,zzw922cn,1493554330,,9,99,False,https://b.thumbs.redditmedia.com/otMOUD1Gc0lw23KwY0JPvNnhNI-YQELyZj3sjXWkwvU.jpg,,,,,
1073,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,21,68f6yj,youtube.com,Automatic Catfish Tilapia Mullet Fish Fillet Filleting Cutting Machine,https://www.reddit.com/r/MachineLearning/comments/68f6yj/automatic_catfish_tilapia_mullet_fish_fillet/,Elaine2008,1493554770,,0,1,False,default,,,,,
1074,MachineLearning,t5_2r3gv,2017-4-30,2017,4,30,22,68fidr,self.MachineLearning,What your favourite movies that feature some element of AI?,https://www.reddit.com/r/MachineLearning/comments/68fidr/what_your_favourite_movies_that_feature_some/,[deleted],1493559834,[removed],0,1,False,default,,,,,
