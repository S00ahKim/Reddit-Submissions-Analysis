,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2014-8-1,2014,8,1,11,2cas3t,"To Distribute, or Not to Distribute",https://www.reddit.com/r/MachineLearning/comments/2cas3t/to_distribute_or_not_to_distribute/,pacmanisfun,1406859540,,0,6
1,2014-8-1,2014,8,1,15,2cbbsw,Some Newbie Questions on NeuroNetworks,https://www.reddit.com/r/MachineLearning/comments/2cbbsw/some_newbie_questions_on_neuronetworks/,aLittleDrunkenGoat,1406874018,"I'm new to NeuroNetworks. I'm trying to implement a neuronetwork like the one described in the first part of these lecture notes: http://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf, but I'm stumped on a few points:

* The notes say that the bias unit value is +1, and the affine function for computing the activation of nodes on the hidden layer seems to imply that there is no weight associated with the connection between the bias unit and the unit it connects to (is that right?). BUT the notes also say that bias units should be initialized to  some small number. So is it +1 or some small random number?

* Page 8 shows how to compute the partial derivative of b^i . It says that the partial derivative is the delta of node i in the current layer +1, but there could be many different values depending on the number of nodes in of l+1. How can you compute the partial derivative of b^i on layer l given n number of nodes on l+1?",7,2
2,2014-8-1,2014,8,1,16,2cbhiz,ISSUU - Excavator Ripper Attachments by Machines4u,https://www.reddit.com/r/MachineLearning/comments/2cbhiz/issuu_excavator_ripper_attachments_by_machines4u/,jessicperson,1406879990,,0,1
3,2014-8-2,2014,8,2,2,2cclyr,Working professional about to join a MS in CS program. Need course advice.,https://www.reddit.com/r/MachineLearning/comments/2cclyr/working_professional_about_to_join_a_ms_in_cs/,iammayankg,1406912514,"My interests lie in AI (machine learning and graph theory mostly). 

I will be joining a MS CS program specializing in Machine learning.

Currently I am considering to take the following courses :

* Machine Learning
* Algorithms
* Distributed Systems
* Graph theory

I skipped _Intro to AI_ because I already took a similar course as an undergraduate and again on edX which was provided by UC-Berkeley.

[This](http://www.cs.rutgers.edu/graduate/courses/) is the list of offered courses.

Can reddit suggest me a few interesting courses to take and also the expected difficulty level so that I make the most out of it?
",5,2
4,2014-8-2,2014,8,2,2,2ccp03,"Yelp extends academic dataset 1M+ reviews from 5 cities worldwide. Data includes businesses, users, social graph, tips, checkins and more. Dataset Challenge Round 4 starts today!",https://www.reddit.com/r/MachineLearning/comments/2ccp03/yelp_extends_academic_dataset_1m_reviews_from_5/,Zephyr314,1406914205,,5,47
5,2014-8-2,2014,8,2,5,2cda8o,Looking for class of solutions or algorithms to a type of problem involving multivariate performance prediction,https://www.reddit.com/r/MachineLearning/comments/2cda8o/looking_for_class_of_solutions_or_algorithms_to_a/,[deleted],1406925971,"Hi all,

I'm looking to be pointed in the right direction in exploring a class of algorithms that can help me solve a particular problem.

The problem involves a set of input pictures, each with a set of properties, some boolean, some within a numerical range or percentile.

A subset of these pictures are selected and displayed in the ""wild"".  Over time they generate engagement from people checking these pictures out.  So each of them has an ""engagement score"" that changes over time.

My goal is to predict, given new input pictures, their engagement score from only the set of properties each picture originally comes with.  My thoughts on how to do this is to identify a) a subset of these properties that are mostly independent and have intuitive influence on the engagement score, and b) devise some sort of regression or other to create a weighted, multivariate objective function that can be used to predict engagement scores of new pictures.

Then I'd like to sift these newly predicted high engagement scored pictures into the wild as well and confirm their performance, and evolve the algorithm over time.

Would I be on the right track with this methodology, and can anyone direct me to papers, articles or concepts that may help?",0,1
6,2014-8-2,2014,8,2,7,2cdhnv,Twitter analysis machine learning (ish?),https://www.reddit.com/r/MachineLearning/comments/2cdhnv/twitter_analysis_machine_learning_ish/,Arktic,1406930404,"So, myself and some friends have decided to spend our spare time working on a start-up idea. A part of it depends on sentiment analysis of data (Mainly tweets). During our investigations we noticed that all the sentiment analysis apis currently out there are pretty poor. I am a front end developer, so machine learning is out of my grasp, but I'm convinced there there must be a better way. 

My questions is.... If you were to implement a solution that could work out if people were social talking positively or negativity about a subject, whilst also identifying trends, what approach would you take/ what advice could you give?

Pretty big and open question, but any thoughts would be awesome!",6,3
7,2014-8-2,2014,8,2,8,2cdrm9,Anyone use C#??,https://www.reddit.com/r/MachineLearning/comments/2cdrm9/anyone_use_c/,watersign,1406936782,"Ive seen some data analyst / scienctist profiles on Linkedin, and many modellers are using it in addition to Matlab. 

what's good / bad about it? ",8,2
8,2014-8-2,2014,8,2,23,2cfbka,Improving the way neural networks learn,https://www.reddit.com/r/MachineLearning/comments/2cfbka/improving_the_way_neural_networks_learn/,based2,1406989934,,21,43
9,2014-8-3,2014,8,3,7,2cgi0n,"Benchmark of convnets places Theano on top. Mine question, FFT convolutions, FFT have something to do with Fast Fourier transform?",https://www.reddit.com/r/MachineLearning/comments/2cgi0n/benchmark_of_convnets_places_theano_on_top_mine/,test3545,1407019830,"And in offchance if it indeed the case, FFT is a sort of approximation compared to doing real convolutions, correct?

EDIT: I was talking about this benchmarking, https://github.com/soumith/convnet-benchmarks",11,1
10,2014-8-3,2014,8,3,9,2cgrg0,Closed Form Missing Value Imputation Question,https://www.reddit.com/r/MachineLearning/comments/2cgrg0/closed_form_missing_value_imputation_question/,diyweatherman,1407026692,"Sorry if this is a trivial question, I haven't had any applicable formal education, but I've been looking into how to do missing value imputation, and I am surprised that most methods seem to use iterative methods that involve the whole data set each iteration.
I was expecting the imputation of missing values to have a closed form solution for the linear model methods such as PCA.

I'm also not so much interested in imputing missing values of a fixed data set, instead I keep getting new online samples with some missing values, and would like to fill in the missing values (usually about 1% to 5% missing) while their real values haven't arrived yet. My dataset so far contains about 8 million samples of 1000 values (30GB), and all values have a mean of zero and standard deviation of one, and are highly correlated with at least a handful of other values.


Before I had read anything about imputation I assumed I could first build a covariance matrix estimate with my dataset (I'm OK with assuming the covariances are not changed by any missing data), and that after that I wouldn't need the data anymore, except for maybe a random sample of it that fits in memory to tune some hyper-parameters like the number of principal components to use in the case of PCA, or the noise and regularization for a marginalized denoising autoencoder.


I also expected that the calculation of missing values was generally done using a closed form solution as a function of the known values and the weights of the linear reconstruction model, and possibly a regularization term as well.


I was writing some code for handling the large amount of data to estimate the covariance matrix, and calculating a reconstruction matrix, but then I started reading to find the formula to do the imputation in closed form... but I couldn't find anything on that, just iterative methods.


Am I missing something here? Is this a bad or impossible way to approach the problem?


I would really like to know how to calculate the missing values from the known values and a weight matrix W   (W = P*P^T , where P is a matrix of the first few principal components).

I think I would need to find the missing values of A that minimizes something like


  (A * W - A)^2 +  lambda * Amissing ^2


where lambda is the regularization term, A is a vector of input values, and Amissing are only the originally missing values.


I suspect it's something like the differences between the reconstructed values and the input values, projected back to the missing values, a bit like back-propagation, and then multiplied by the inverse of some matrix. But I can't quite figure out the exact solution. 


If anyone could help or suggest a better method, I would greatly appreciate it.


Thank you!


edit:  
I found this paper that seems related http://eigenvector.com/Docs/Wise_IFAC_91.pdf",1,7
11,2014-8-4,2014,8,4,0,2ci9hh,Predict amazon rating from other review attributes,https://www.reddit.com/r/MachineLearning/comments/2ci9hh/predict_amazon_rating_from_other_review_attributes/,purpleladydragons,1407079725,"Hey guys, I'm working through [metacademy's roadmap for machine learning](http://www.metacademy.org/roadmaps/cjrd/level-up-your-ml). The recommended project after the second book is to work with a dataset of about 500,000 reviews and try to guess a given review's rating from its other attributes. I'm struggling with the size of the dataset, so instead of wasting time on large and possibly inappropriate computations, I figured I'd ask here - what three different ML techniques would you use? Here's an example review:

    product/productId: B001E4KFG0
    review/userId: A3SGXH7AUHU8GW
    review/profileName: delmartian
    review/helpfulness: 1/1
    review/score: 5.0
    review/time: 1303862400
    review/summary: Good Quality Dog Food
    review/text: I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.

I figured I'd use a naive bayes classifier on the summary (or the text, but that took too long for me). Another idea was to use the frequent terms as features and then do k-nearest neighbors. My current main struggle is just dealing with the size of the dataset. Trying to turn the summaries into a bag of words took an extremely long time for what looks like a pet project idea. 

So, how should I deal with the largeness and which basic techniques should I be using? 

Sorry if this question is a little too ""do my homework for me"", but I hoped that since it was an independent project without any public solution that it'd be okay. 
",4,8
12,2014-8-4,2014,8,4,4,2civp0,Learning from the best,https://www.reddit.com/r/MachineLearning/comments/2civp0/learning_from_the_best/,tcc8,1407094824,,2,61
13,2014-8-4,2014,8,4,6,2cj439,Linear Discriminant Analysis bit by bit,https://www.reddit.com/r/MachineLearning/comments/2cj439/linear_discriminant_analysis_bit_by_bit/,rasbt,1407100350,,2,14
14,2014-8-4,2014,8,4,10,2cjpra,Has anyone ever implemented NFQCA reinforcement learning?,https://www.reddit.com/r/MachineLearning/comments/2cjpra/has_anyone_ever_implemented_nfqca_reinforcement/,eubarch,1407114735,"Hi there,

  I'm trying to implement NFQCA as described in [Reinforcement Learning in Feedback Control](http://rd.springer.com/article/10.1007%2Fs10994-011-5235-x#page-1) by Hafner and Riedmiller.  If you don't have access to Springer, NFQCA stands for Neurally Fitted Q-Learning with Continuous Actions, and it's an adaptation of the actor-critic architecture that uses a neural network for both the actor and critic (totaling two networks).  Some lecture slides that describe it are [here](http://www6.in.tum.de/pub/Main/TeachingWs2009MachineLearning/Slides_07.pdf).  Slide 11 gives an overview of the technique.  



   In a nutshell, you have a feed-forward neural network (FFNN) that serves as the policy Pi(x), where x is a state vector.  The output of Pi(x) is *u*, an action.  Another FFNN serves as the critic, or Q function Q(x,u), and it produces a value *v*.  The output of Pi is part of the input of Q.  The state vector x is an input to both.  

  From the paper, 

    In iteration step k of the NFQCA algorithm
    we assume that the recent policy _k represents the greedy evaluation of the Q-function:
    _k (x)  argmin_u (Q_k (x,u)). With this assumption we can formulate the Q-update without
    a minimization step over all actions as Q-update(x, u) = c(x, u) + Q_k (x, _k (x))


...Where c(x, u) is a special cost function that smoothly approaches 0 from a constant *C* as the desired set-point (defined as some desired state) is reached, and x' is the action at time t+1.  The update for Q is regular backpropagation (the authors use RProp), but the update for Pi is a little different-- You simply carry the backpropagation from Q back through the linked input/output nodes, calculating a delta for Q's input layer as if it were hidden, and using this information to continue the backpropagation algorithm through Pi. 


That seemed like a really neat trick, and I wanted to try it.  I have a simple cart-pole simulator set up and I'm using batch RMSProp (very similar to RProp) to update my Pi and Q networks.  Now that I have my learner all set up, I'm running into some trouble and I don't think it's a simple programming error.  First of all, doesn't the Q update rule look sort of odd for actor-critic?  Why are we summing costs instead of rewards?  In my algorithm, if learning start with the pole facing downward (furthest away from the reward state), then the cost for one action is 1/epoch_size (my value for *C*).  Q spits out some arbitrary, untrained value for the duration of the epoch, and the target values used to update the Q network all end up as more-or-less the same arbitrary value plus 1/epoch_size.  This results in the Pi network being encouraged to apply force in some direction, but iterating for another epoch never changes the situation-- as the cart slowly accelerates, the pole stays un-inverted and the Q/Pi networks get the same update over and over again, encouraging Pi to slowly apply more force in one direction or another.  The Q network's value estimations are pushed to 1.0 + (1/epoch_size), since each epoch encourages Q's output value to increase.  Something is wrong here.  There's no mechanism for exploration as with discrete-action Q-learning.  When (near) maximum cost for an entire epoch is reached, what about this algorithm is supposed to make behavior change?  Even resetting the simulation (but not the networks) on occasion and setting the pole to a random angle doesn't seem to change this.  Is something missing from this paper, or am I interpreting the update rule incorrectly?




",0,4
15,2014-8-4,2014,8,4,12,2cjzx3,Reading suggestions to improve my feature engineering skills?,https://www.reddit.com/r/MachineLearning/comments/2cjzx3/reading_suggestions_to_improve_my_feature/,gordahn,1407121583,"Hello, /r/machinelearning!

I'm at a point in my continuing education of machine learning and data science where I feel comfortable with the mathematics and properties behind most models, and I feel competent in understanding when to choose certain models and how to transform and pre-process data so as to take advantage of the model's properties.

While I've been told this from the beginning, I recently had the Aha! realization that good features are really what separates good models from great models.

So my question to you all is, what books or papers should I read in order to get better at hand crafting features? I understand that this is sort of where the science meets the art, and that feature engineering is naturally pretty domain specific. But surely there are general intuitions that I could learn that could help me to build good features for domains I do understand?",3,18
16,2014-8-4,2014,8,4,18,2ckp23,Ink dispensing system,https://www.reddit.com/r/MachineLearning/comments/2ckp23/ink_dispensing_system/,colorexpert4,1407143903,,0,1
17,2014-8-4,2014,8,4,21,2cl10c,How Microsoft is building a machine learning future,https://www.reddit.com/r/MachineLearning/comments/2cl10c/how_microsoft_is_building_a_machine_learning/,serenesan,1407156486,,0,0
18,2014-8-4,2014,8,4,23,2clb2c,Midlife methods,https://www.reddit.com/r/MachineLearning/comments/2clb2c/midlife_methods/,[deleted],1407163527,"I would like to find a new career path and would love to use machine learning systems to help me make a few decisions. 

Should I create a corpus containing 10 years of emails and personal documents and compare it to potential positions? What systems or methods would you use?

Initially I was thinking about a sentiment/polarity analysis to determine what I'm the most happy doing then comparing the top results to positions/careers.  

I'm sure there are much better ways to go about this, does anyone have insight?

If you know of a specific text you think I should review please let me know, I'm happy to research I just don't know where to start. 

Thanks all! 


Edits:

I intend to look for the most positive sentiments in my corpus and match it against position descriptions. The thinking being that what I'm the happiest talking about would be what I would enjoy doing full time.
I do apologize for being vague, it's not a form of laziness it's a lack of experience.",3,3
19,2014-8-5,2014,8,5,4,2cm3s6,Nice applet for intuitive understanding of convolution,https://www.reddit.com/r/MachineLearning/comments/2cm3s6/nice_applet_for_intuitive_understanding_of/,helshowk,1407179043,,8,3
20,2014-8-5,2014,8,5,4,2cm6w5,Beginner looking for datasets with results,https://www.reddit.com/r/MachineLearning/comments/2cm6w5/beginner_looking_for_datasets_with_results/,noclaf,1407180627,"I admit, strange title but I'm not yet sure how to word it. I am a programming who has recently started reading about machine learning. In order for this stuff to stick in my mind, I'd like to write my own code and run it on some real data. However, I'd love some sample data which others have used in their analysis so I can compare the results I get against others' results.

I understand that my results won't match others exactly, but if I understand the algorithm and code it correctly, and I clean up my data correctly, my results should at least be _similar_ to what others have found.

Are there any such data sets which also come with predictions, correlations, classifications or regression lines which others have found?",7,2
21,2014-8-5,2014,8,5,5,2cmgzp,Research in digital preservation and machine learning,https://www.reddit.com/r/MachineLearning/comments/2cmgzp/research_in_digital_preservation_and_machine/,piscoster,1407185867,"Hello guys,

I had a talk with my prof that day about digital preservation. It seems to be one of the big topics for the next years and I am extremely interested to write about a problem which goes with this topic. At the moment I am missing some interesting ideas, which connect to big data or machine learning. Therefore my question:

What are for your the interesting problems in digital preservation in connection to machine learning?

Would appreciate ideas/papers/keywords!
",3,0
22,2014-8-5,2014,8,5,10,2cn8ki,Neglected machine learning ideas,https://www.reddit.com/r/MachineLearning/comments/2cn8ki/neglected_machine_learning_ideas/,yudlejoza,1407201448,,4,14
23,2014-8-5,2014,8,5,14,2cnwi9,From Generic to Specific Deep Representations for Visual Recognition,https://www.reddit.com/r/MachineLearning/comments/2cnwi9/from_generic_to_specific_deep_representations_for/,T_hank,1407217500,,1,3
24,2014-8-5,2014,8,5,16,2co4r2,Solutions to kaggle past challenges,https://www.reddit.com/r/MachineLearning/comments/2co4r2/solutions_to_kaggle_past_challenges/,vcjha,1407225169,,0,25
25,2014-8-5,2014,8,5,21,2cojpk,Topological Anomaly Detection with Python,https://www.reddit.com/r/MachineLearning/comments/2cojpk/topological_anomaly_detection_with_python/,shaggorama,1407240616,,0,13
26,2014-8-5,2014,8,5,21,2col3l,Trommel - New or Used Trommel Screens for Sale in Australia,https://www.reddit.com/r/MachineLearning/comments/2col3l/trommel_new_or_used_trommel_screens_for_sale_in/,jessicperson,1407241747,,0,1
27,2014-8-5,2014,8,5,21,2comsd,Parametrizing and interpreting OPTICSxi Clustering,https://www.reddit.com/r/MachineLearning/comments/2comsd/parametrizing_and_interpreting_opticsxi_clustering/,doublebyte1,1407243040,,0,1
28,2014-8-6,2014,8,6,0,2cozew,Recommending music on Spotify with deep learning,https://www.reddit.com/r/MachineLearning/comments/2cozew/recommending_music_on_spotify_with_deep_learning/,benanne,1407251120,,23,114
29,2014-8-6,2014,8,6,4,2cpqjt,KCBO  A Bayesian Data Analysis Toolkit,https://www.reddit.com/r/MachineLearning/comments/2cpqjt/kcbo_a_bayesian_data_analysis_toolkit/,cavedave,1407265607,,2,8
30,2014-8-6,2014,8,6,4,2cpums,Neural Network using MATLAB - Newbie,https://www.reddit.com/r/MachineLearning/comments/2cpums/neural_network_using_matlab_newbie/,sidk,1407267898,"Okay so Im trying to create a GANN using matlabs Neural Network toolbox.

It kinda looks like this - 
http://i.stack.imgur.com/t2wmJ.png
As it seems to me, it is simply a feedforward network with additional connections between input and output layers.

The question is HOW do I add those connections?The MATLAB interpretation of Neural networks i weird to me anyway and I simply cannot figure this out.
I am using the 'network' function in MATLAB.
Some help would be really appreciated.",7,1
31,2014-8-6,2014,8,6,12,2cr3sv,Can anyone give me some pointers for a project I want to start?,https://www.reddit.com/r/MachineLearning/comments/2cr3sv/can_anyone_give_me_some_pointers_for_a_project_i/,[deleted],1407294571,"I have a raspberry pi, and I want to make a thing in my room sort of like Siri, that I will be able to talk to and it will pull things up on a screen. I will use some free speech recognition software, but what I don't understand is how to go about making it ""understand"" what I said.  How do things like Siri do this? There are lots of different ways to ask Siri to set an alarm. How should I do this?",5,0
32,2014-8-6,2014,8,6,20,2cs24b,Sensible ML setup for estimating landmark positions in time series?,https://www.reddit.com/r/MachineLearning/comments/2cs24b/sensible_ml_setup_for_estimating_landmark/,disentangle,1407325441,"I would like to estimate the exact position of certain ""landmarks"" in a low dimensional time series. Each landmark is characterized by a specific type of pattern in the data. I already know the type of each landmark and their approximate locations; a region of 40 frames around those estimates should contain the landmark with sufficient contextual information.

Being new to machine learning I'm not sure what might be a sensible approach for a problem like this. For instance if something like this could be done with a neural net (?), what would the inputs/outputs and training cases look like? Would you predict a likelihood of the landmark being at any of the 40 input frames (i.e. have 40 outputs)? If so, would you present each training sample multiple times with different 40 frame ""windows""? Or, would you maybe predict the likelihood of the landmark being at say the center of the region presented to the network (i.e. single output), and use a sliding window to search for the most likely position?
",3,2
33,2014-8-6,2014,8,6,21,2cs3lo,website for collective annotations of scientific papers.,https://www.reddit.com/r/MachineLearning/comments/2cs3lo/website_for_collective_annotations_of_scientific/,JanHula,1407326777,"Hi everyone,
Because of the frustration I have when trying to comprehend new papers, I came up with an idea of collective annotations of ML papers. Every paper would have its own section on the web, and people would be able to annotate words, sentences or images. There would be some review system for good notes, so the paper would not be bloated too much. Users would then be able to expand the annotations. The most favored, would appear first, as in stackexchange. It's common practice, that someone is asking for an explanation of some paper, so the information is scattered over the web. This way, the information would be all in one place. And users could ask questions simply inside the paper. 
So my question is, how useful you think it would be? I would be most fortunate, if there already exist web like this, which the community could use for free...thanks for your feedback.",22,7
34,2014-8-6,2014,8,6,21,2cs5rg,Predicting world cup matches to avoid cooking.,https://www.reddit.com/r/MachineLearning/comments/2cs5rg/predicting_world_cup_matches_to_avoid_cooking/,copybin,1407328547,,3,23
35,2014-8-7,2014,8,7,0,2csn59,how to measure the transform ability of a query on Internet Advertising,https://www.reddit.com/r/MachineLearning/comments/2csn59/how_to_measure_the_transform_ability_of_a_query/,ningyu,1407339624,"hi all, I have a task which aims to measure the transform ablity of a keyword , the transform ablity can be understood as the probability of a query on the search engine brings an order to the customers.For example, I searched ""apple"" on the search engine then I go the website and buy a notebook, then ""apple"" bring a transaction to the apple company and the query ""apple"" has a strong ability to bring a transaction. (Maybe this example is not good but it could explain the idea)

Now I have the query log and the click log of advertisement on the search engine , how can I use these data to analyze the transform ablity of a query ? I think maybe some clarification algorithm could give answer but I'm not sure the result though.

Could you please give me some hints? Any feedback will be appreciated!",0,1
36,2014-8-7,2014,8,7,10,2cue0v,Forked version of stringkernels R package (testing needed!),https://www.reddit.com/r/MachineLearning/comments/2cue0v/forked_version_of_stringkernels_r_package_testing/,galapag0,1407375434,,2,5
37,2014-8-7,2014,8,7,11,2cuhzq,Seeking intuitive explanation of target propagation,https://www.reddit.com/r/MachineLearning/comments/2cuhzq/seeking_intuitive_explanation_of_target/,ndronen,1407378001,Can anyone succinctly explain the notion of target propagation that Yoshua Bengio advocates in [How Autoencoders Could Provide Credit Assignment in Deep Networks via Target Propagation](http://arxiv.org/abs/1407.7906)?,3,5
38,2014-8-7,2014,8,7,13,2cuvl0,Which type of algorithm to employ?,https://www.reddit.com/r/MachineLearning/comments/2cuvl0/which_type_of_algorithm_to_employ/,noneso,1407387498,"I am a developer with a pretty good knowledge of entry level machine learning algorithms. I am struggling to find a good fit for my current project.

We use what could be considered a content management system (CMS). A user could find documents either by searching, using guided navigation (drilldown menus/facets) or both. The main usage pattern is a user would enter a freeform query and then drill down from there.

We have data for when a user clicks on a document from a search result, with the proper breadcrumb selected, and even when an action occurred on the document screen such as edit or publish. What we do not have is if a document was displayed in the results and no further action was taken.

I am looking to develop a smarter system to pre-determine which drill down actions a user might want. Given a search query, which drill down actions will lead to either a click or preferably further action (edit/publish).

sample fake data
===========
Query | Facet | Action
---------|----------|----------
""barack obama"" | - | click
""barack obama"" | News | publish
""barack obama"" | News&gt;Politics | click
""george bush"" | - | no action (we do not capture this data)
""george bush"" | News&gt;Politics | publish

At first glance, it seems like some this is a collaborative filtering (to use a more developer centric term) problem, but there is no relationship between users. The efficiency of the algorithm is not important since hopefully a predictive model will only be built periodically.

A **publish** action is worth more than a **click** action, but can be equal if the algorithm does not allow weights on the outcome.
",3,1
39,2014-8-7,2014,8,7,16,2cv58h,"Global Vectors for Word Representation (GloVe), 11% more accurate than word2vec",https://www.reddit.com/r/MachineLearning/comments/2cv58h/global_vectors_for_word_representation_glove_11/,downtownslim,1407395996,,8,30
40,2014-8-7,2014,8,7,17,2cv827,Higgs Boson Machine Learning Challenge,https://www.reddit.com/r/MachineLearning/comments/2cv827/higgs_boson_machine_learning_challenge/,Mr_LincolnHawk,1407399101,"Find out more about this kaggle challenge to indentify signal-like-events

http://nbviewer.ipython.org/gist/Noire7/38924712e84545d8d641",0,0
41,2014-8-7,2014,8,7,17,2cva6l,Furniture recognition with deep learning,https://www.reddit.com/r/MachineLearning/comments/2cva6l/furniture_recognition_with_deep_learning/,kar321,1407401463,"I am wondering if good results could be archieved in image recognition for furniture. You make a picture of a piece of furniture (eg a chair) and then this will be compared with a database of furniture images and it will show you the result that is most similar to it.
What accuracy could be expected here?
Google reverse image search is performing pretty bad at this task. However image classification APIs like clarifai are producing quite good results for general classification. Could similiar results be achieved  for classification between different types of chairs, tables,... if you trained the network on these data? I could imagine that it might be difficult as the differences between two chairs can be subtle.

I would just like to have some expert opinions before I spend a lot of time on a task which might not be possible to solve with our current techniques.",4,0
42,2014-8-7,2014,8,7,19,2cvefk,TechnoCalifornia: Introduction to Recommender Systems,https://www.reddit.com/r/MachineLearning/comments/2cvefk/technocalifornia_introduction_to_recommender/,gamachi,1407406396,,0,8
43,2014-8-7,2014,8,7,19,2cvewn,Lessons learned from a year of Kaggling,https://www.reddit.com/r/MachineLearning/comments/2cvewn/lessons_learned_from_a_year_of_kaggling/,tomaskazemekas,1407406934,,3,66
44,2014-8-7,2014,8,7,19,2cvg1g,Back in Black: Analyzing the loudness and tempo of the Rolling Stone top 500 songs,https://www.reddit.com/r/MachineLearning/comments/2cvg1g/back_in_black_analyzing_the_loudness_and_tempo_of/,apassant,1407408250,,0,1
45,2014-8-7,2014,8,7,20,2cvito,"Pivigo, KPMG Launch London Data Science Bootcamp",https://www.reddit.com/r/MachineLearning/comments/2cvito/pivigo_kpmg_launch_london_data_science_bootcamp/,huitseeker,1407411140,,0,0
46,2014-8-7,2014,8,7,22,2cvowj,"Machine Learning, meet Computer Vision - Machine Learning",https://www.reddit.com/r/MachineLearning/comments/2cvowj/machine_learning_meet_computer_vision_machine/,blueoceandiver,1407416575,,0,0
47,2014-8-7,2014,8,7,22,2cvqto,Edu-Video |Building a Production Machine Learning Infrastructure  Josh Wills /Dir. Data Scientist,https://www.reddit.com/r/MachineLearning/comments/2cvqto/eduvideo_building_a_production_machine_learning/,Friars1993,1407417993,,0,0
48,2014-8-7,2014,8,7,23,2cvurd,ML with Spark MLlib on Elastic MapReduce,https://www.reddit.com/r/MachineLearning/comments/2cvurd/ml_with_spark_mllib_on_elastic_mapreduce/,johnnywalleye,1407420658,,0,4
49,2014-8-8,2014,8,8,0,2cw2nk,Couple of questions from a beginners perspective.,https://www.reddit.com/r/MachineLearning/comments/2cw2nk/couple_of_questions_from_a_beginners_perspective/,DucksHaveLowAPM,1407425328,"Hi everyone, I've found many great resources here and now that I've learned a bit (and I'm still overwhelmed on how much there is to know) I have a couple of questions:

1. What is the process of improving accuracy of the model?
Like - I have a data set with n features, have chosen algorithm - I can't just blast the data through the algorithm and expect to have a perfect fit. How do you choose the weights for features or features themselves? Or any other ways of improving the learning process?

2. How to handle missing values? I took a look at kaggle's higgs boson competition and there is some good part of the data that has null values in one to x columns. I thought about dividing the data into segments with missing column a, b, c, ab, bc, ac, abc but first of all the number of segments is 2^x and I don't know if I don't break some statistical relations by doing so.

3. I've looked at job offerings (in Europe) and more than half of them require a PhD, is this normal?

Thank you all for any guidance. ",5,2
50,2014-8-8,2014,8,8,6,2cx4ca,Applying to top PhD programs with statistics background?,https://www.reddit.com/r/MachineLearning/comments/2cx4ca/applying_to_top_phd_programs_with_statistics/,100ozrok,1407445470,"Hi, I'm a rising senior majoring in Statistics/Bio statistics with minors in computer science and math. I'm at
a top 20 school (if you go by US News rankings). I'm looking to apply to CS grad programs for ML. I wanted 
to know if my lack of a CS major will be held against me. I transferred to my university as a junior (was
previously a stats-cs major at my old college) but wasn't able to declare a CS major due to transfer credit
issues. I decided to go for math and cs minors instead. At my current school I've been working with two professors:
one in statistics/ml and the other in database research since winter of my junior year. I also have a year's
worth of research experience from my old school (database prof for all of sophomore year). GPA at current
school has been a 4.0 so far, and 3.75 at old school.

In terms of CS coursework- I've took data structure, algorithms, analysis of algorithms, discrete math,
machine learning, info retrieval, and a systems/architecture course. Math courses beyond the ususual (calc,linear
algebra,basic prob/stats) include optimization, analysis/real analysis, stochastic processes, graph theory, numerical
methods, and numerical analysis.

I do think I've taken more math and stats classes than most vanilla CS majors. Would my background
be good enough for schools like UWashington, CMU, Berkeley? My school also offers a one year masters degree in CS, though without any funding. I could apply to some thesis based masters programs that provide RAship, but there
don't seem to be many.  ",6,0
51,2014-8-8,2014,8,8,12,2cy3ng,Machine Learning Goes Open Source,https://www.reddit.com/r/MachineLearning/comments/2cy3ng/machine_learning_goes_open_source/,predictionio,1407467548,,5,0
52,2014-8-8,2014,8,8,14,2cyg4e,Collective paper annotation - solution,https://www.reddit.com/r/MachineLearning/comments/2cyg4e/collective_paper_annotation_solution/,JanHula,1407476613,"I am posting it again, because I am afraid, that my previous post is no more being watched.

I have eventually figured out a pretty neat way to collectively annotate ML papers. Please go here: https://hypothes.is/alpha/# , install the extension or bookmarklet and look on the 7 steps, which are mentioned there. Then go here: http://arxiv.org/pdf/1207.0580v1.pdf and enable the extension in url bar. You should see my test annotation on the right side. If you create an account, you can comment my annotation or create your own. But don't forget to set the comment as public. I hope you would be as impressed as me.
It's still alpha, so for some pdf documents it doesn't work. Often the lengthy ones. But the developers told me, that this will be fixed very soon (Tomorrow).   You can look at this intro: http://youtu.be/QCkm0lL-6lc .  I would like to know your feedback, how we could organize this. I was thinking about creating the github page, with links of papers, which are being annotated. Plus some voting for papers to add. I would start very simple at first, with only a few papers, so people will not loose interest, because of no participation on some paper.",4,3
53,2014-8-8,2014,8,8,17,2cyr8z,Kt hp bn nc ma vi loi nc gii kht khc | My p ma Vit Thng,https://www.reddit.com/r/MachineLearning/comments/2cyr8z/kt_hp_bn_nc_ma_vi_loi_nc_gii_kht_khc/,quynhtran116,1407487992,,1,0
54,2014-8-8,2014,8,8,19,2cyx1y,Machine Learning for behaviour replication.,https://www.reddit.com/r/MachineLearning/comments/2cyx1y/machine_learning_for_behaviour_replication/,WERE_CAT,1407494911,"I was working on the pricing of complex american options when I noticed that the exercise is often (very) subobptimal. (If you are not familiar with american options: these are options that can be used on multiple dates, so you have to choose optimally without knowing the future.)

 It seems that the clients are more sensitive to past growth or drop in rates than to their value at the moment, wich is a non optimal behaviour. I am looking for a way to modelise the suboptimal behaviour and I tought about Machine learning. But I can't find any reference on suboptimal options exercice. Do you have any broader exemple of Machine learning applied to the replication of human non optimal behaviour ? Do you have any tought on that  ?
",0,0
55,2014-8-8,2014,8,8,19,2cyxis,"IBM new neuromorphic chip: neural nets with 256 million parameters, 28nm tech, 5.4 billion transistors",https://www.reddit.com/r/MachineLearning/comments/2cyxis/ibm_new_neuromorphic_chip_neural_nets_with_256/,test3545,1407495413,,37,49
56,2014-8-8,2014,8,8,22,2cz7c8,Supervised Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/2cz7c8/supervised_learning_algorithms/,Edugarmer,1407504288,,0,1
57,2014-8-8,2014,8,8,23,2czdp2,Implementation of Developmental Learning MOOC - Starting October 2014.,https://www.reddit.com/r/MachineLearning/comments/2czdp2/implementation_of_developmental_learning_mooc/,alexgmcm,1407508405,,5,3
58,2014-8-8,2014,8,8,23,2czekz,Using scikit-learn Pipelines and FeatureUnions,https://www.reddit.com/r/MachineLearning/comments/2czekz/using_scikitlearn_pipelines_and_featureunions/,eloisius,1407508919,,0,13
59,2014-8-9,2014,8,9,2,2czt7i,Machine Learning Theory: An Introductory Primer,https://www.reddit.com/r/MachineLearning/comments/2czt7i/machine_learning_theory_an_introductory_primer/,hs613,1407517253,,5,56
60,2014-8-9,2014,8,9,4,2d0ael,"As a CS master's student with solid ML &amp; data science foundation, what is the best way to become a ""data scientist"" or ML researcher? [xpost r/datascience]",https://www.reddit.com/r/MachineLearning/comments/2d0ael/as_a_cs_masters_student_with_solid_ml_data/,exploding_octopus,1407525798,,8,4
61,2014-8-10,2014,8,10,6,2d3la9,Open-Source Recommendation API,https://www.reddit.com/r/MachineLearning/comments/2d3la9/opensource_recommendation_api/,LForLambda,1407620706,,0,12
62,2014-8-10,2014,8,10,18,2d4y8z,how cross validation help to gain a better model?,https://www.reddit.com/r/MachineLearning/comments/2d4y8z/how_cross_validation_help_to_gain_a_better_model/,phoenixbai,1407663841,"if I understand it right, this is the process of cross validation.
take 5-fold cv for example,

1) split dataset into 5 parts.

2) train a model using training data composed of 4 parts and test on the one that is left.

3) repeat 2) for 5 times.

4) return 5 evaluation scores, one score per model.

if this is the whole process, then how can I get a better model by doing cv? or is there a way to combine 5 model into a better one?

although it is said that cv is for minimizing the overfitting problem, but my question is how, how does it do it in implementation?",12,0
63,2014-8-10,2014,8,10,20,2d51cu,Skype Group,https://www.reddit.com/r/MachineLearning/comments/2d51cu/skype_group/,no_porner,1407668400,,2,0
64,2014-8-11,2014,8,11,0,2d5io0,Resources for learning about ensemble learning?,https://www.reddit.com/r/MachineLearning/comments/2d5io0/resources_for_learning_about_ensemble_learning/,rovingr,1407685508,I'd like to learn more about ensemble methods. What resources do you recommend? I'd prefer something with some hands-on examples in R or Python. ,10,11
65,2014-8-11,2014,8,11,16,2d7ryx,Loi xe nc ma no ph hp nht cho kinh doanh | My p ma Vit Thng,https://www.reddit.com/r/MachineLearning/comments/2d7ryx/loi_xe_nc_ma_no_ph_hp_nht_cho_kinh_doanh/,quynhtran116,1407742159,,0,0
66,2014-8-11,2014,8,11,19,2d81dw,So you wanna try Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/2d81dw/so_you_wanna_try_deep_learning/,snippyhollow,1407752132,,6,97
67,2014-8-11,2014,8,11,20,2d868l,Pretraining deep nets out of fasion?,https://www.reddit.com/r/MachineLearning/comments/2d868l/pretraining_deep_nets_out_of_fasion/,liosnel,1407757397,"I feel that recently, pretraining deep neural networks is not a common practice anymore. Is this a wrong observation?

Is it because dropout provides the needed regularization and rectified linear units are easy to train and initialize? 

Or is it because everyone thinks thier dataset is big enough?

Even with dropout + ReLUs + big dataset, why woudn't pretraining improve results?",8,9
68,2014-8-11,2014,8,11,23,2d8kci,The first completely reddit-based MOOC (x-posted in /r/robotics),https://www.reddit.com/r/MachineLearning/comments/2d8kci/the_first_completely_redditbased_mooc_xposted_in/,DrJosh,1407768044,,0,2
69,2014-8-12,2014,8,12,2,2d90rb,Machine Learning Thesis,https://www.reddit.com/r/MachineLearning/comments/2d90rb/machine_learning_thesis/,OverTheLump,1407777241,,6,0
70,2014-8-12,2014,8,12,2,2d950g,categorizing labels using k-means clustering for a SVM model,https://www.reddit.com/r/MachineLearning/comments/2d950g/categorizing_labels_using_kmeans_clustering_for_a/,bkamapantula,1407779512,"Hi,

I have data from two types (classes) of networks: net1, net2. Each network has 100 data instances. Each instance has twenty features and one output label.

My aims are two-fold: 

* build a classification model and 
* rank the features using fisher test and AUC

The labels for the data are floating numbers: 47.23, 67.5 etc. It can range from 0.0 to 100.0. If I use the labels as is, the prediction accuracy is, predictively, too low. I want to create bins to categorize these labels for a given range using k-means clustering algorithm. The number of labels hence will be the number of clusters I mention for the k-means algorithm. Once I build the model using k-fold cross validation, I will compare the performance by using two different kernels to start with: linear and RBF.

I want to repeat the steps 1 and 2 for three cases: 

* data from only net1,
* data from only net2 and 
* data from net1 and net2 (I will use +ve and -ve suffixes to separate the data from the two classes)

and observe which features rank high. Feature ranking using Linear SVM [1] lists 4 methods for ranking that include fisher test and AUC.

ML isn't my area of expertise. Hence, I would like to hear from the reddit ML community if this is the correct approach. I would love to hear suggestions and comments.


I started out with LibSVM but I didn't find it flexible to change the c and gamma parameters while using cross validation. I'm now using scikit-learn package in Python.


Thanks a lot!


[1] Feature Ranking Using Linear SVM - http://core.kmi.open.ac.uk/download/pdf/16008.pdf#page=61",0,1
71,2014-8-12,2014,8,12,10,2dambr,Phng php gi gn my p ma siu sch n nh | My p ma Vit Thng,https://www.reddit.com/r/MachineLearning/comments/2dambr/phng_php_gi_gn_my_p_ma_siu_sch_n_nh/,quynhtran116,1407807841,,0,0
72,2014-8-12,2014,8,12,11,2daoo8,nh ngha bng ti trong sn xut v i sng,https://www.reddit.com/r/MachineLearning/comments/2daoo8/nh_ngha_bng_ti_trong_sn_xut_v_i_sng/,quynhtran116,1407809287,,0,0
73,2014-8-12,2014,8,12,20,2dbqli,Basic introduction to Theano - making an Autoencoder,https://www.reddit.com/r/MachineLearning/comments/2dbqli/basic_introduction_to_theano_making_an_autoencoder/,dylanbyte,1407842197,"I recently decided to teach myself about theano. 

I thought that it might be useful for people trying to do the same to read about my experience with it: 
http://triangleinequality.wordpress.com/2014/08/12/theano-autoencoders-and-mnist/

There are many excellent tutorials already online, but sometimes I find it useful to hear from a beginner. ",20,43
74,2014-8-13,2014,8,13,0,2dcatk,.NET Rocks podcast on Machine Learning with Seth Juarez,https://www.reddit.com/r/MachineLearning/comments/2dcatk/net_rocks_podcast_on_machine_learning_with_seth/,Primalpat,1407856854,,1,0
75,2014-8-13,2014,8,13,1,2dchc7,Motivating applications for weakly supervised learning,https://www.reddit.com/r/MachineLearning/comments/2dchc7/motivating_applications_for_weakly_supervised/,soviet-matematik,1407860437,"Hi all,

Currently I am in process of writing my PhD proposal. I plan to work on weakly supervised methods for a big data. So far I extensively studied [semantic image segmentation problem](http://www.inf-cv.uni-jena.de/en/semantic_segmentation.html). Typically, for this problem only little amount of fully-annotated images are available and most of images have only weak supervision such as object bounding boxes.

I am curious whether anybody can suggest more applications for weakly supervised methods.",3,0
76,2014-8-13,2014,8,13,1,2dchxg,Need an introduction to RBMs,https://www.reddit.com/r/MachineLearning/comments/2dchxg/need_an_introduction_to_rbms/,Felix-Neko,1407860755,"Many times I've heard about Restricted Boltzmann Machines. Cannot you advice me something to read about them?

I'm also interested: how are they commonly **used** and what are their best-known **implementations?**",8,0
77,2014-8-13,2014,8,13,2,2dcnw7,Feature Learning for Binary Data,https://www.reddit.com/r/MachineLearning/comments/2dcnw7/feature_learning_for_binary_data/,goblin_got_game,1407863918,"I'm trying to do feature learning / dimensionality reduction on a large, sparse binary dataset.  I tried RBMs and then Autoencoders but was dissapointed to find their behaviors roughly equivalent.  I thought, since AEs are not restricted to a binary hidden representation, they might have more representational power.  Not the case.  

I started looking at [Logistic PCA](http://cseweb.ucsd.edu/~saul/papers/logpca_aistats03.pdf) and latent, probabilistic models like [this one](http://www.cs.helsinki.fi/u/ebingham/publications/paleo.pdf).  Does anyone have pointers to other techniques?  I assume entropy-based techniques could also be useful?",6,2
78,2014-8-13,2014,8,13,18,2df8so,A Random Forest question...,https://www.reddit.com/r/MachineLearning/comments/2df8so/a_random_forest_question/,daithibowzy,1407922574,"Let's a RF classifier contains 50 trees and it has to make a binary decision. If 25 of the trees vote 'YES' and the other 25 vote 'NO', how does the random forest decide on an overall prediction if the voting is tied?",16,6
79,2014-8-13,2014,8,13,18,2df9q7,Toronto Face Dataset,https://www.reddit.com/r/MachineLearning/comments/2df9q7/toronto_face_dataset/,spidey-fan,1407923595,"I came across a couple of papers [1,2] where the authors experimented on the Toronto Face Database, which contains a large number of labelled and unlabelled images of faces with identity and expression labels. I can't seem to find the download links to this database anywhere. Does anyone know how to get access to it?

[1] [Multi-Task Learning of Facial Landmarks and Expression] (http://www.uoguelph.ca/~gwtaylor/publications/gwtaylor_crv2014.pdf)

[2] [Disentangling factors of variation for facial expression recognition] (http://www-etud.iro.umontreal.ca/~rifaisal/material/rifai_eccv_2012.pdf)",1,2
80,2014-8-13,2014,8,13,20,2dfeva,Expansion of Liebherr Mining Equipment in Virginia,https://www.reddit.com/r/MachineLearning/comments/2dfeva/expansion_of_liebherr_mining_equipment_in_virginia/,steveharriss,1407929025,,0,1
81,2014-8-13,2014,8,13,21,2dficf,"The future of content consumption, through the eyes of Yahoo Labs &amp;mdash; Tech News and Analysis",https://www.reddit.com/r/MachineLearning/comments/2dficf/the_future_of_content_consumption_through_the/,whitecurl,1407932215,,0,3
82,2014-8-13,2014,8,13,21,2dfkwj,Neuroscientist-designer couple bring the power of vision to devices,https://www.reddit.com/r/MachineLearning/comments/2dfkwj/neuroscientistdesigner_couple_bring_the_power_of/,gentsopa,1407934202,,0,0
83,2014-8-13,2014,8,13,22,2dfn0c,Does a network graph of large subreddits already exist?,https://www.reddit.com/r/MachineLearning/comments/2dfn0c/does_a_network_graph_of_large_subreddits_already/,goddammitbutters,1407935714,"I'd be interested in a network graph like [this](http://upload.wikimedia.org/wikipedia/commons/5/5b/Wikipedia_multilingual_network_graph_July_2013.svg) that shows the connectedness between subreddits.

If it doesn't exist, would it be possible to form an alliance and make one?

We'd have to go through users, scrape the subreddits they post to, and treat those as ""connected"". I'd be curious to see which two hobbies unexpectedly appear together often.",2,15
84,2014-8-13,2014,8,13,22,2dfo11,Machinery Rollr,https://www.reddit.com/r/MachineLearning/comments/2dfo11/machinery_rollr/,steveharriss,1407936374,,0,1
85,2014-8-14,2014,8,14,3,2dgn7r,Smart Feature Selection with scikit-learn and BigMLs API | The Official Blog of BigML.com,https://www.reddit.com/r/MachineLearning/comments/2dgn7r/smart_feature_selection_with_scikitlearn_and/,[deleted],1407955522,,0,1
86,2014-8-14,2014,8,14,9,2dhopb,Redesigning online calendars: Why doesnt my calendar know me?,https://www.reddit.com/r/MachineLearning/comments/2dhopb/redesigning_online_calendars_why_doesnt_my/,dgreenfield_gnip,1407975678,,2,1
87,2014-8-14,2014,8,14,9,2dhryw,Best intro someone wanting to learn deep learning for side projects?,https://www.reddit.com/r/MachineLearning/comments/2dhryw/best_intro_someone_wanting_to_learn_deep_learning/,matlab484,1407977740,"I am taking the coursera class on machine learning right now, and I know there is one with hinton for neural networks, but does anyone know of one which goes through neural networks with tons of code examples? When I can see code, it helps me a lot, though I know the math and theory behind it is important as well. I know there is also libraries like theano which are used, does anyone know of any beginner code tutorials that are good for this? Thanks!",4,11
88,2014-8-14,2014,8,14,10,2dhsqq,Machine Learning the Hard Way,https://www.reddit.com/r/MachineLearning/comments/2dhsqq/machine_learning_the_hard_way/,machinecheating,1407978203,,7,69
89,2014-8-14,2014,8,14,14,2dies8,Learn Machine Learning Together,https://www.reddit.com/r/MachineLearning/comments/2dies8/learn_machine_learning_together/,Gravicle,1407992414,"I am a recent Mathematics graduate. I am an iOS and web developer and extremely interested in Machine Learning and neural nets. Mostly, I enjoy the thrill of learning something so exciting and challenging. On the other hand, I do have a few ideas which I wanna prototype.

So, here's the thing. Does anybody wanna learn it together? We can exchange notes, discuss various things and just collaboratively chip away!

EDIT: CLOSED
If you are just seeing this, I am sorry but I just sent out the last batch of invites for slack. We are at capacity now and are, unfortunately, limited by group dynamics. To work effectively, we need to stay within constraints where people can at least remember each other.

Still, if you are experienced in ML, deep learning, neural nets, etc. we need you and have a few spots left. Please PM me and let me know.",34,4
90,2014-8-14,2014,8,14,21,2dj8ei,Boolean time series algorithm how to choose,https://www.reddit.com/r/MachineLearning/comments/2dj8ei/boolean_time_series_algorithm_how_to_choose/,onlineFF,1408020669,"Consider a Boolean time sequence, less sample data &lt; 2000, but is still growing. To obtain robust prediction method can use what method?",5,1
91,2014-8-14,2014,8,14,22,2dj9iu,Scaling up data frames,https://www.reddit.com/r/MachineLearning/comments/2dj9iu/scaling_up_data_frames/,ResearchAce,1408021492,,0,2
92,2014-8-14,2014,8,14,22,2djbf9,Very Rare Event Classification Problem - Any thoughts?,https://www.reddit.com/r/MachineLearning/comments/2djbf9/very_rare_event_classification_problem_any/,officialbensing,1408022772,"I am working on a model with 400,000 samples where only 4,000 are classified as the event I'm looking to predict (approximately 1 in 400 or 0.25%). Currently, I'm struggling to implement a successful model, however I found some success using logistic regression by setting the class weights inversely proportional to class frequencies in the training set. If you're familiar with sklearn, I am using LogisticRegression(class_weight='auto'). The model does accurately predict approximately 60% of the rare events, which is great, but the number of false positives is enormous. How should I think about reducing the number of false positives?

Can someone provide some guidance as to rare event binary classification problems?",8,3
93,2014-8-14,2014,8,14,23,2djem5,Theoretical resources/books?,https://www.reddit.com/r/MachineLearning/comments/2djem5/theoretical_resourcesbooks/,CreativePunch,1408024811,"Hi all,

I have been into machine learning for a while now. Being a programmer first I feel I have a good foundational knowledge of the practical side of machine learning. I know the tools and methods well. 

However I feel that there is a big part of knowledge missing which is the theoretical/mathemathical side to machine learning.

Having always been eager to keep teaching myself I figured I'd delve deeper into the matter. 

I have a background in CS and college level math/stat knowledge (been a while since I fully used that knowledge though).

I was wondering if you guys had any good theoretical books, or more preferable, free resources, that I could get to learn the mathemathics behind machine learning.

My main interest goes out to neural networks but other resources are more than welcome! Right now I get how they work, and how some other methods work such as SVM, logistic regression,... However I feel that even though I KNOW how they work, I do not yet fully UNDERSTAND.

I know the difference between supervised/unsupervised learning, I have participated in some kaggle challenges, succesfully using sklearn and other libraries to train and finetune commonly used models.

What I do need: beginner-intermediate mathemathical books/resources on machine learning/neural networks

What I don't need: practical books that teach about using a ML library like sklearn, torch, ...

In other words, I am currently viewing machine learning very much from the programming/practical side of the spectrum, but I would like to get more into the theoretical/mathemathical side.

If the uses programming exercises or the likes, that's not a problem, as long as the main focus is on the theory/mathemathics and the reasons for the theory/math.

I hope that's clear enough and that you guys can help, thanks!",6,22
94,2014-8-15,2014,8,15,1,2djy1o,"TA for AI class in University. Please suggest interesting exercises, readings, videos or concepts to generate interest!",https://www.reddit.com/r/MachineLearning/comments/2djy1o/ta_for_ai_class_in_university_please_suggest/,gardinal,1408035303,"I am the teaching assistant of Artificial Intelligence course which is being introduced for the first time in my Uni. 

I have worked on Robocup 2D Soccer for a year. There are basically two projects from which students have to decide : Robocup 2D Soccer and Angry Birds AI. They are worth 80% of the grade.

We are two weeks into the course right now and the lectures till now have been majorly philosophical. I can sense the interest being lost. The last topic which was taught was the Turing Test.

Are there any videos, articles, small programming exercises, TED talks or any material which I could use to generate interest in students and get them excited. The 80% project is going to be very tough and lengthy but I want the remaining 20% to be something which is really fun and able to generate interest and get them excited. 

Can you suggest any thing interesting which people being introduced to AI should know or learn. Something which doesn't take a lot of time (a lecture maybe). Anything?

Also, the students are from 4th and 3rd year of college and pursuing a degree in ICT and have a very good programming level.",13,7
95,2014-8-15,2014,8,15,3,2dk9gm,A Convolutional Neural Network for Modelling Sentences,https://www.reddit.com/r/MachineLearning/comments/2dk9gm/a_convolutional_neural_network_for_modelling/,galapag0,1408040965,,8,19
96,2014-8-15,2014,8,15,5,2dkoq2,Dataset for text clustering,https://www.reddit.com/r/MachineLearning/comments/2dkoq2/dataset_for_text_clustering/,neeratyoy,1408049069,"Is there any free repository for textual data (English) for eventual text clustering ? I intend to perform the standard procedures of stop-word eliminations, stemming, etc. first.   ",4,3
97,2014-8-15,2014,8,15,10,2dlibu,Viv: The Global Brain,https://www.reddit.com/r/MachineLearning/comments/2dlibu/viv_the_global_brain/,captcompile,1408067574,,5,0
98,2014-8-15,2014,8,15,11,2dllb9,Guesswork - Verticalized machine learning service to predict customer intent,https://www.reddit.com/r/MachineLearning/comments/2dllb9/guesswork_verticalized_machine_learning_service/,manidoraisamy,1408069512,,0,1
99,2014-8-15,2014,8,15,20,2dmi9c,Clustering algorithm for news articles,https://www.reddit.com/r/MachineLearning/comments/2dmi9c/clustering_algorithm_for_news_articles/,ju6ju8Oo,1408101065,"are there any specific clustering / classification algorithms for grouping news articles in niche topics?
I want to group articles from different writers so that I do not need to read similar articles from multiple sources.

And is encog a good choice?

Update: Should I look into similarity/duplication instead? The task should be something similar to Google news aggregation. But I want to make something for my own RSS subscriptions.",8,11
100,2014-8-15,2014,8,15,20,2dmksu,Streamline your cross-validation and classification workflow - scikit-learn's Pipeline in action,https://www.reddit.com/r/MachineLearning/comments/2dmksu/streamline_your_crossvalidation_and/,rasbt,1408103794,,0,13
101,2014-8-16,2014,8,16,0,2dn188,PyStruct: Structured Learning in Python,https://www.reddit.com/r/MachineLearning/comments/2dn188/pystruct_structured_learning_in_python/,galapag0,1408115705,,0,19
102,2014-8-16,2014,8,16,0,2dn4vm,Your Very Own Personalised Image Search Engine using python.,https://www.reddit.com/r/MachineLearning/comments/2dn4vm/your_very_own_personalised_image_search_engine/,RedItJot,1408117756,,0,2
103,2014-8-16,2014,8,16,2,2dnecp,Facebooks Quest to Build an Artificial Brain Depends on This Guy.,https://www.reddit.com/r/MachineLearning/comments/2dnecp/facebooks_quest_to_build_an_artificial_brain/,qkdhfjdjdhd,1408123016,,0,1
104,2014-8-16,2014,8,16,2,2dnfd7,"Introducing QuickML: A machine learning library for Java, including random forests and a hyper-parameter optimizer, seeking contributors",https://www.reddit.com/r/MachineLearning/comments/2dnfd7/introducing_quickml_a_machine_learning_library/,[deleted],1408123545,,10,6
105,2014-8-16,2014,8,16,4,2dnuub,Neural Networks vs Multivariate Regression,https://www.reddit.com/r/MachineLearning/comments/2dnuub/neural_networks_vs_multivariate_regression/,indiasfinest,1408131965,"Can someone help me understand when you'd want to use neural networks vs multivariate regressions? I know there is some obvious reasoning: multivariate regression will give you a formula where NNs are entirely ""blackbox"". But can NNs uncover patterns that mutivariate cannot? My hunch is yes, but I can't conceptualize why.  

I'm a novice data scientist and have Googled quite a bit on this question, but can never wrap my head around the answer. I'm hoping some of you can point me the right direction. ",3,1
106,2014-8-16,2014,8,16,8,2doi7e,What should I know before taking on word2vec?,https://www.reddit.com/r/MachineLearning/comments/2doi7e/what_should_i_know_before_taking_on_word2vec/,onewugtwowugs,1408146091,"I made my bachelor's thesis on distributional semantic models, more specifically a common weighted count-based model. I have heard a lot of hype about Mikolov's word2vec model, and started reading up on it. But despite much effort into decrypting his papers on the topic, I still feel like I don't know how the model actually works. I believe it could be because I haven't studied deep learning models before or its word embeddings, but wanted to verify this with you first, and ask for help to pick out some topics as prerequisite to word2vec. 

Thanks",19,17
107,2014-8-16,2014,8,16,12,2dp2x3,Metacademy - A resource for learning ML,https://www.reddit.com/r/MachineLearning/comments/2dp2x3/metacademy_a_resource_for_learning_ml/,olaf_nij,1408161388,"[Metacademy](http://www.metacademy.org/) is a great resource which compiles lesson plans on popular machine learning topics.

Note: I am not affiliated with Metacademy. I just think the site would be helpful for beginners based on the common questions posted here.",14,48
108,2014-8-16,2014,8,16,17,2dpk1o,Tin ch ca xe nc ma trong i sng,https://www.reddit.com/r/MachineLearning/comments/2dpk1o/tin_ch_ca_xe_nc_ma_trong_i_sng/,quynhtran116,1408178329,,0,1
109,2014-8-17,2014,8,17,0,2dq77s,Vowpal Wabbit for Fast Learning - Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2dq77s/vowpal_wabbit_for_fast_learning_machine_learning/,mttd,1408203814,,0,12
110,2014-8-17,2014,8,17,4,2dqt52,Re-sampling unbalanced datasets.,https://www.reddit.com/r/MachineLearning/comments/2dqt52/resampling_unbalanced_datasets/,A_Schwarzenschnitzel,1408219000,,12,19
111,2014-8-17,2014,8,17,7,2dr4bk,This Wednesday: Free webcast about Data Science at the Command Line [x-post /r/datascience],https://www.reddit.com/r/MachineLearning/comments/2dr4bk/this_wednesday_free_webcast_about_data_science_at/,eroenj,1408226565,,2,0
112,2014-8-17,2014,8,17,9,2dri59,Neural Net for Regression,https://www.reddit.com/r/MachineLearning/comments/2dri59/neural_net_for_regression/,Unum_Lupus,1408236476,"I've used neural nets several times for classification problems, but I haven't heard of them being used for regression. Is it possible, and if so how would you implement it? Would you just have hidden layers as normal and then a final output layer with a single unit and no non-linearity applied?",5,1
113,2014-8-17,2014,8,17,18,2dsfqi,Amateur machine learning,https://www.reddit.com/r/MachineLearning/comments/2dsfqi/amateur_machine_learning/,shekib82,1408268378,"I work in software development. Have been for 10 years. But I have now started understanding machine learning after taking a coursera course. I would don't think I can apply it to my line of work. So I am looking for some amateur projects to do on my spare time.
Do you know any open source large scale machine learning programming projects I can contribute to?",5,4
114,2014-8-17,2014,8,17,20,2dsk7l,NuPIC's Geospatial Encoder - Sparse Distributed Representations from GPS Data,https://www.reddit.com/r/MachineLearning/comments/2dsk7l/nupics_geospatial_encoder_sparse_distributed/,fergbyrne,1408274887,,0,20
115,2014-8-17,2014,8,17,22,2dss2i,(open) linked data in machine learning,https://www.reddit.com/r/MachineLearning/comments/2dss2i/open_linked_data_in_machine_learning/,piscoster,1408283611,"Hello guys,

I am extremely interested in the concept from Lee, linked data. However, I haven`t seen much research about it in machine learning.  Besides that I would like to contribute to this field in my free time and I am looking for research questions.

Therefore, my question is:

Do you know any kind of interesting research related to linked data and machine learning?

I really would appreciate your hints about papers/research articles?

Best regards!
",2,2
116,2014-8-18,2014,8,18,0,2dsycv,Is there a term for model parameters that aren't tuning parameters?,https://www.reddit.com/r/MachineLearning/comments/2dsycv/is_there_a_term_for_model_parameters_that_arent/,Kodiologist,1408288848,"We often recognize a distinction between tuning parameters and ""normal"" model parameters. An example where this is clear is ridge regression, where the ridge penalty is a tuning parameter and the coefficients of regression are normal parameters. A less obvious example is *k*-nearest-neighbors, where *k* is a tuning parameter and the identities of the *k* nearest neighbors for a given test case are normal parameters.

The key practical difference between tuning parameters and normal parameters is that one usually uses a fitting algorithm (e.g., least squares) to choose the values of the normal parameters that minimize training error, whereas for the tuning parameters, the training-error-minimizing value is trivial (like 0, in the case of ridge regression) and one instead must use a higher-order procedure (like cross-validation) if one wants to use training data to choose the parameter's value.

The question is, what do you call normal parameters, if anything?
",4,0
117,2014-8-18,2014,8,18,0,2dt0dy,Train an artificial neural network with a constraint solver,https://www.reddit.com/r/MachineLearning/comments/2dt0dy/train_an_artificial_neural_network_with_a/,p-col,1408290276,,1,1
118,2014-8-18,2014,8,18,1,2dt5m8,K-nearest neighbor question,https://www.reddit.com/r/MachineLearning/comments/2dt5m8/knearest_neighbor_question/,watersign,1408293957,"I'm trying to predict how much insurance an employee will potentially buy based on employees who are already covered, using only the age and salary. On a previous data set, I found that the length of employment had the biggest predictive impact. I am using the k-NN algorithm in SPSS Modeler and using the default settings (3-5 clusters). I have the salary and age for both covered and uncovered employees and am using the salary and age of the covered to predict the potential amount of coverage that will be purchased for the uncovered group.  The problem I am having is that the way the data is distributed, it is skewed toward the lower end of the pay scale and there are thousands of people who are more or less making the same salary. 




In another model I  created using a different data set, I had the tenure of employment which provided much better results and the predictions looked more accurate as opposed to the results I am getting now, such as predicting a 19 year old who makes $25000 a year will buy an insurance policy that will cover their income 4x (100K). In the other data, I took the predicted amounts tthat were less than the emplyoees salary and tagged them accordingly as I feel these people are unlikely to buy insurance because of who they're 'closet' too, and wanted to use the predicted amounts that were equal or greater than to target.





Am I going about this the right way? or should I be using a different algorithm? ",7,3
119,2014-8-18,2014,8,18,1,2dt6p7,Svm only returns one type of category on prediction?,https://www.reddit.com/r/MachineLearning/comments/2dt6p7/svm_only_returns_one_type_of_category_on/,matlab484,1408294727,"I am working on a bag of words, svm classifcation pipeline, and have two categories, the first with 6000 images and the second with 70. The test set is 30% of my data, and the training is 70%. When I try predicting with my test set, the svm believes everything is part of one category. My histograms contain 1000 bins. Am I doing something wrong with how I am approaching the problem? Thanks!",6,3
120,2014-8-18,2014,8,18,3,2dtccg,Sparse autoencoder from ufldl,https://www.reddit.com/r/MachineLearning/comments/2dtccg/sparse_autoencoder_from_ufldl/,rishok,1408298437,is there any analysis done on the Sparse autoencoder from ufldl e.g on the mnist task,2,0
121,2014-8-18,2014,8,18,6,2dtu4z,Question: Trying to use linear programming as an alternative to machine learning,https://www.reddit.com/r/MachineLearning/comments/2dtu4z/question_trying_to_use_linear_programming_as_an/,[deleted],1408309813,"I'm not quite sure if this is the right subreddit, but I'm curious how linear programming on a specific problem would compare to machine learning solutions I've already implemented. 

I've got the following dataset:

         Features         Algorithms
       ------------ ----------------------
    P |            |                      |
    r |            |                      |
    o |            |                      |
    b |            |                      |
    l |            |                      |
    e |            |                      |
    m |            |                      |
    s |            |                      |


There are two matrices, the feature matrix (N x M) and the algorithms matrix (N x K). N is the amount of problems, M the amount of features and K the amount of algorithms. The feature matrix contains features that can be extracted from mathematical problems. The algorithms matrix contains information for a lot of different algorithms (K). Each column in this matrix contains the information for a single algorithm. This information is how long it takes the algorithm to solve the problem (or -1 if it doesn't). So instead of only having a single label column there are multiple. 

The goal is, given a maximum amount of time, to find out which algorithms are best suited for solving the problem. This means that it is a combination of classification and regression. The algorithms have to be chosen (prediction) and how long they should run (regression). The maximum amount of time is used because multiple algorithms can be run within this timespan and these have to be chosen and the time has to be distributed over them.

There are different kinds of solutions, for example figuring out which algorithms solve the most problems and taking the mean time and just using this. Or just picking random algorithms and dividing the the maximum amount of time over those.

Another option is using KNN and using rows from the algorithm matrix as labels. This way it's only a classification problem.

Combining classification and regression methods is also possible. For classification all values can be set to 0 (no solve) or 1 (solve) and then random forest classifiers can be trained over each algorithm (column). This way we can use these forests to predict whether a certain algorithm should be used for a certain problem. We still need the time then, for this we can train a regressor for each column (removing any unsolvable problems). These regressors can then be used to predict the amount of time for the strategies that the classifier has chosen. 

All the above solutions already work and are more as an example of what's possible and to hopefully give a better understanding of the structure of the data.

**At the moment I'm interested in how this problem can be represented and solved using linear programming.** I've been looking into linear programming by just reading up on it and trying out several simple problems, but I can't really seem to wrap my head around it, so I'm wondering if anyone here has any suggestions or can nudge me into the right direction.",0,1
122,2014-8-18,2014,8,18,6,2dtv7d,Question: Trying to use linear programming as an alternative to machine learning on a specific dataset,https://www.reddit.com/r/MachineLearning/comments/2dtv7d/question_trying_to_use_linear_programming_as_an/,Xylon-,1408310507,"I've got the following dataset:

         Features         Algorithms
       ------------ ----------------------
    P |            |                      |
    r |            |                      |
    o |            |                      |
    b |            |                      |
    l |            |                      |
    e |            |                      |
    m |            |                      |
    s |            |                      |


There are two matrices, the feature matrix (N x M) and the algorithms matrix (N x K). N is the amount of problems, M the amount of features and K the amount of algorithms. The feature matrix contains features that can be extracted from mathematical problems. The algorithms matrix contains information for a lot of different algorithms (K). Each column in this matrix contains the information for a single algorithm. This information is how long it takes the algorithm to solve the problem (or -1 if it doesn't). So instead of only having a single label column there are multiple.

The goal is, given a maximum amount of time, to find out which algorithms are best suited for solving the problem. This means that it is a combination of classification and regression. The algorithms have to be chosen (prediction) and how long they should run (regression). The maximum amount of time is used because multiple algorithms can be run within this timespan and these have to be chosen and the time has to be distributed over them.

There are different kinds of solutions, for example figuring out which algorithms solve the most problems and taking the mean time and just using this. Or just picking random algorithms and dividing the the maximum amount of time over those.

Another option is using KNN and using rows from the algorithm matrix as labels. This way it's only a classification problem.

Combining classification and regression methods is also possible. For classification all values can be set to 0 (no solve) or 1 (solve) and then random forest classifiers can be trained over each algorithm (column). This way we can use these forests to predict whether a certain algorithm should be used for a certain problem. We still need the time then, for this we can train a regressor for each column (removing any unsolvable problems). These regressors can then be used to predict the amount of time for the strategies that the classifier has chosen.

All the above solutions already work and are more as an example of what's possible and to hopefully give a better understanding of the structure of the data.

**At the moment I'm interested in how this problem can be represented and solved using linear programming.** I've been looking into linear programming by just reading up on it and trying out several simple problems, but I can't really seem to wrap my head around it, so I'm wondering if anyone here has any suggestions.
",9,9
123,2014-8-18,2014,8,18,11,2dunxu,Vit Thng  n v cung cp my p ma tin cy uy tn | My p ma Vit Thng,https://www.reddit.com/r/MachineLearning/comments/2dunxu/vit_thng_n_v_cung_cp_my_p_ma_tin_cy_uy/,quynhtran116,1408329924,,1,0
124,2014-8-18,2014,8,18,12,2dut3z,ERL - Evolved Reinforcement Learner,https://www.reddit.com/r/MachineLearning/comments/2dut3z/erl_evolved_reinforcement_learner/,CireNeikual,1408333481,"Hello!

I have been working on and off on a larger machine learning project for the past two months, and I thought I should share it here to get some ideas/criticism. 

It's called ERL, which stands for Evolved Reinforcement Learner.

It was conceived in our AGI discussion group on Slack. The idea is to have a large ""brain sandbox"", some space where vast quantities of reinforcement learning algorithms exist. One can then search through this algorithm-space with something like a genetic algorithm.

ERL tries to remain as unrestrictive on the possible learning algorithms that can present themselves as possible, while remaining computationally feasible. In order to speed things up, it runs on the GPU using OpenCL.

ERL consists of a field of nodes (not called neurons since they can function entirely differently from the neurons we know), each with connections to several of its neighbors. Each node has a dynamical system, encoded into genes using a compositional pattern producing network, that governs the node's output(s) (there can be several outputs per node). Each connection also has a dynamical system, which governs its output(s). On top of the connections, nodes can also spread a ""gas"" (or several gases) to other nodes as an alternative form of node communication.

The dynamical systems (compositional pattern producing networks) are run through an OpenCL kernel language rule compiler for maximum performance and readability.

Inputs are clusters of nodes which receive additional external inputs that go through an encoder dynamical system. Similarly, outputs are clusters whose outputs are averaged and passed through a decoder.

Furthermore, the field is divided into regions using yet another compositional pattern producing network. This gives each node a ""type ID"" that allows it to function in unique ways.

Together, these components form a generic node-network that can learn many different kinds of learning rules, but with the restriction that these learning rules must be mostly local (they use information available at the connection/node level).

In order to evolve a general reinforcement learning agent (that's the goal of this project, although theoretically it can do all types of learning), each genotype is evaluated on a set of experiments. These experiments have their resulting fitness values scaled and summed before being passed to the evolutionary algorithm.

Over time (several generations), I have noticed a steady increase in fitness on the experiments. So the concept is at least not entirely without merit.

It is quite processing intensive, so far I haven't really trained it past around 60 generations. But with longer training times, and improvements to the genotype representation and evolutionary algorithm, performance of the genes should improve drastically (I hope).

With this I attempted to do something entirely novel. It is quite possible that someone has thought of this concept before, but I haven't found any evidence of an implementation so far.

This software is free and open source. Zlib license.
It is still early, but it functions. Here it is on GitHub: [https://github.com/222464/ERL](https://github.com/222464/ERL)

The README's description of the project is somewhat outdated (I wrote it before actually coding anything, that's why it is in future tense), but I will update it soon with a more detailed explanation of what is going on.

Now, I would love to hear criticisms or ideas for improvement. Or maybe some computing time. Or maybe even a code contribution! ;)

Here is a video of ERL doing pole balancing. The video happened after 16 generations (I got too impatient to evolve it for longer :P). This is about 45 minutes of evolution time if I had to guess. The stuff on the right side shows the first output of each node in the field.

SEIZURE WARNING! The neural field tends to flicker...

[https://www.youtube.com/watch?v=uwhtyG1PPag&amp;feature=youtu.be](https://www.youtube.com/watch?v=uwhtyG1PPag&amp;feature=youtu.be)

TL;DR: Evolving learning algorithms from scratch.",2,16
125,2014-8-18,2014,8,18,14,2dv1zv,Participate in a pattern recognition study (2 minutes to help connect machine learning and psychology),https://www.reddit.com/r/MachineLearning/comments/2dv1zv/participate_in_a_pattern_recognition_study_2/,appliedphilosophy,1408340436,,1,2
126,2014-8-18,2014,8,18,22,2dvsug,Machine Learning to Production,https://www.reddit.com/r/MachineLearning/comments/2dvsug/machine_learning_to_production/,Stareons,1408368629,"I've completed a masters in CS focusing on machine learning.  I've learned lots about algorithms at a theoretical level and implementing them in Java/Weka and in Python/Scikit-learn.

What I didn't learn and am slightly stumped on is moving ML to production.

That is to say I can get good results on data and someone wants to use my application to make daily predictions.  How do you move ML applications to production so users can feed in their new input and receive predictions preferably with minimal input from myself.

(I understand this is a big and vague question - but it's a new area for me).",9,11
127,2014-8-19,2014,8,19,2,2dwik0,"For Big-Data Scientists, Janitor Work Is Key Hurdle to Insights",https://www.reddit.com/r/MachineLearning/comments/2dwik0/for_bigdata_scientists_janitor_work_is_key_hurdle/,carmichael561,1408383753,,7,44
128,2014-8-19,2014,8,19,2,2dwipy,Interview with COPSS Award winner Martin Wainright,https://www.reddit.com/r/MachineLearning/comments/2dwipy/interview_with_copss_award_winner_martin_wainright/,carmichael561,1408383840,,0,6
129,2014-8-19,2014,8,19,5,2dx0uc,Geospatial Tracking With NuPIC,https://www.reddit.com/r/MachineLearning/comments/2dx0uc/geospatial_tracking_with_nupic/,numenta,1408393657,,2,0
130,2014-8-19,2014,8,19,9,2dxo0o,Dynamic neural fields and Cognitive Neuromorphic architectures,https://www.reddit.com/r/MachineLearning/comments/2dxo0o/dynamic_neural_fields_and_cognitive_neuromorphic/,conic_relief,1408406880,,0,1
131,2014-8-19,2014,8,19,11,2dy1le,"2014 ImageNet results out, 6.7% top-5 classification error (2013 was 11%)",https://www.reddit.com/r/MachineLearning/comments/2dy1le/2014_imagenet_results_out_67_top5_classification/,downtownslim,1408415528,,17,26
132,2014-8-19,2014,8,19,12,2dy9is,"IPython notebook Theano tutorial, from basic usage to a simple neural net",https://www.reddit.com/r/MachineLearning/comments/2dy9is/ipython_notebook_theano_tutorial_from_basic_usage/,abracaradbra,1408420550,,0,27
133,2014-8-19,2014,8,19,15,2dylm5,Best java library for learning/understanding ML concepts?,https://www.reddit.com/r/MachineLearning/comments/2dylm5/best_java_library_for_learningunderstanding_ml/,icutyouwithmyknife,1408429874,,2,1
134,2014-8-20,2014,8,20,1,2dzsrk,[Feature Engineering question] How would you convert a point in time to a position in a cycle?,https://www.reddit.com/r/MachineLearning/comments/2dzsrk/feature_engineering_question_how_would_you/,saosebastiao,1408465085,"There are a lot of cycles in time series, with common cycles being Hour of Day, Minute of Hour, Day of Week, Week of Year, Month of Year, etc. Sometimes my intuition tells me that the relative position within the cycle is more relevant than the point in time. 

For example, at an e-commerce site, predicting order volume may require knowing the volume at a given time of day. However, training on Hour of Day seems like a bit of a copout. If there are true cycles, then historical data about hour 23 should also lend weight to the prediction for hours 00 as well as 22. 

I've been thinking about this and so far my best thoughts involve sin transformations, but I'm wondering if there are any other methods out there for solving this problem. ",7,5
135,2014-8-20,2014,8,20,3,2e0a0x,So I made a logistic regression animation. Enjoy!,https://www.reddit.com/r/MachineLearning/comments/2e0a0x/so_i_made_a_logistic_regression_animation_enjoy/,TLDRu,1408473708,,66,96
136,2014-8-20,2014,8,20,3,2e0a74,Deep learning research,https://www.reddit.com/r/MachineLearning/comments/2e0a74/deep_learning_research/,no_porner,1408473799,"I am looking for ideas for a research project on deep learning inspired by some recent CVPR papers. 
Please guide me.

",1,0
137,2014-8-20,2014,8,20,5,2e0o0m,Automatic Parameter Tuning for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2e0o0m/automatic_parameter_tuning_for_machine_learning/,jpzk,1408481140,,9,7
138,2014-8-20,2014,8,20,5,2e0og4,What are hot academic topics in machine learning right now?,https://www.reddit.com/r/MachineLearning/comments/2e0og4/what_are_hot_academic_topics_in_machine_learning/,Regentag,1408481348,"Hello guys,

besides deep learning, what are currently the hot academic/business problems in machine learning right now. 

I appreciate your answer!
",8,4
139,2014-8-20,2014,8,20,7,2e0w7y,Feature Extraction from Web pages,https://www.reddit.com/r/MachineLearning/comments/2e0w7y/feature_extraction_from_web_pages/,annamnara,1408485625,I am working on Web KB data set using some machine learning classification  Technique. SO I need the feature representation for these web pages. Is there any direct feature represented dataset available or any standard tools that will feature extraction by providing all web pages.,1,0
140,2014-8-20,2014,8,20,17,2e2bx8,How to handle cyclic data features and graph data?,https://www.reddit.com/r/MachineLearning/comments/2e2bx8/how_to_handle_cyclic_data_features_and_graph_data/,tomatosource,1408522153,"So for a school assignment we are looking to get a regression model for a data set that includes cyclic data (hours of the day), among other features, and should output cyclic data (lat/long coords). I am wondering how to handle the wrap around, e.g. 11pm and 1am are very close, but 23/01 are far away, can tools like scikit handle this automatically? Is there some way I can transform the input?

And secondly- graph data, do I just treat each node in the graph as a feature and have a boolean value (connected/not connected) for each item?

Thanks for any help :) 

Please let me know if this in the wrong spot too!
",2,1
141,2014-8-20,2014,8,20,18,2e2gv1,Predicting the next node to explore in a tree,https://www.reddit.com/r/MachineLearning/comments/2e2gv1/predicting_the_next_node_to_explore_in_a_tree/,Crashthatch,1408528047,"**The Problem**

I have a tree-graph which is to be explored from the root, with a goal node hidden somewhere in the tree. Each node and edge has several features (the tree specific ones like depth, and parent, but also some other data- categorical or numerical features which are discovered once that node is explored). I need to write an algorithm for exploring this tree, with the aim of finding the goal node in as few steps as possible.

At each step, the algorithm has 2 decisions to make:

* 1) Which already-explored node should we start from?

* 2) Which edge from that node should be explored next (some edge properties such as type are known before exploring down it).

That edge &amp; the node at the end are then explored, and the algorithm loops.

Some of the properties on the nodes&amp;edges are related to finding the goal node. Examples of valid rules might be: 

* When feature A == 100, then the goal node is a child of that node. In that case, it makes sense to focus exploration on children of that node. 

* When B == 'category1' then exploring down the edge of type X is frequently where the goal is.

* If you came down an edge of type X to get to this node, and this node has B &gt; 50, then explore from here down an edge of type Y.

I'm looking for a way to discover these rules, and so build an algorithm that can explore to find the goal quickly by looking at the signs (features on nodes) along the way.

I have a bunch of trees for which I have found the goal by brute-force exploration, and am hoping to use them as training data to determine what features might be important and learn rules this exploration algorithm should follow.


**Possible approaches**

I have done some machine learning and participated in Kaggle competitions before, but always where the training data was clear, independent rows of data with a clearly defined label and error metric. I really don't know the best approach to take to get my tree into that form, or even if that's what I should be doing? A* / Djikstra seem like they might have a use here, but they all require a single ""distance"" measure, which I don't have. Perhaps I should attempt to learn a regressor which maps from the features on a node to some kind of distance metric? Or just train a model to produce a binary ""should explore"" prediction (using what features)?

Has anyone tackled anything like this before? Any suggestions on what to try? Good resources for machine learning rules &amp; exploration paths? Ways of converting trees to rows which I can learn from? Better places than reddit to ask this question :P ?

Thanks.",3,4
142,2014-8-20,2014,8,20,21,2e2q0u,"A Novel, Simple Interpretation of Nesterov's Accelerated Method as a Combination of Gradient and Mirror Descent [PDF]",https://www.reddit.com/r/MachineLearning/comments/2e2q0u/a_novel_simple_interpretation_of_nesterovs/,urish,1408537322,,0,2
143,2014-8-20,2014,8,20,21,2e2qbp,Machine learning deals with coputer science and artificial intelligence to read data etc.,https://www.reddit.com/r/MachineLearning/comments/2e2qbp/machine_learning_deals_with_coputer_science_and/,goclark,1408537579,,0,0
144,2014-8-20,2014,8,20,21,2e2sbu,Ensemble of Exemplar-SVMs for Object Detection and Beyond [2011],https://www.reddit.com/r/MachineLearning/comments/2e2sbu/ensemble_of_exemplarsvms_for_object_detection_and/,galapag0,1408539258,,0,2
145,2014-8-20,2014,8,20,22,2e2u7u,"[MOOC/Coursera] Mining Massive Datasets by Jure Leskovec, Anand Rajaraman, and Jeff Ullman",https://www.reddit.com/r/MachineLearning/comments/2e2u7u/mooccoursera_mining_massive_datasets_by_jure/,chalupapa,1408540675,,13,77
146,2014-8-20,2014,8,20,23,2e32l8,Surrogate Loss Functions?,https://www.reddit.com/r/MachineLearning/comments/2e32l8/surrogate_loss_functions/,GratefulTony,1408546037,"Was wondering if anyone had any practical experience with using surrogate loss functions for classification? For instance: a problem that needs high percision, but requires low recall might be best optimized under a asymmetrical loss function-- There is some literature on the topic like:

http://www.isa.uni-stuttgart.de/Steinwart/Publikationen/2007/Steinwart07a.pdf

Anyone have anecdotes?",0,3
147,2014-8-21,2014,8,21,0,2e34hv,"How do you pronounce ""C4.5"": ""C four point five"" or ""C four five""?",https://www.reddit.com/r/MachineLearning/comments/2e34hv/how_do_you_pronounce_c45_c_four_point_five_or_c/,[deleted],1408547133,,1,0
148,2014-8-21,2014,8,21,1,2e3eok,2d / 3d convolution in CNN clarification,https://www.reddit.com/r/MachineLearning/comments/2e3eok/2d_3d_convolution_in_cnn_clarification/,chestervonwinchester,1408552766,"As I understand it currently, if there are multiple maps in the previous layer, a convolutional layer performs a discrete 3d convolution over the previous maps (or possibly a subset) to form new feature map. Is this interpretation correct? If so, does this also apply when ""previous layer"" is the input layer with multiple maps (say color channels or stereo)?

I am trying to resolve a discrepancy in architecture descriptions in [this paper](http://www.ais.uni-bonn.de/papers/icann2010_maxpool.pdf). Fig. 1 shows 64 maps in C3 and P4 layers while the description in section 4.2 describes 32 maps in these layers. I am trying to figure out if this is a typo or if it is my misunderstanding.

Any help? Thanks!
",5,1
149,2014-8-21,2014,8,21,3,2e3uob,Using Gradient Boosted Trees to Predict Bike Sharing Demand,https://www.reddit.com/r/MachineLearning/comments/2e3uob/using_gradient_boosted_trees_to_predict_bike/,pacmanisfun,1408560988,,0,3
150,2014-8-21,2014,8,21,4,2e3vcs,Supervised Learning - a workflow chart,https://www.reddit.com/r/MachineLearning/comments/2e3vcs/supervised_learning_a_workflow_chart/,rasbt,1408561342,,13,50
151,2014-8-21,2014,8,21,4,2e40bs,What machine learning models are typically used for credit risk?,https://www.reddit.com/r/MachineLearning/comments/2e40bs/what_machine_learning_models_are_typically_used/,miiuuu,1408563972,"I have an interview for a data scientist job in a company specialized in payday loans. I know my team (risk team) uses machine learning a lot. I was curious about what data they might use and what algorithms.

Data: I assume they get the credit score of the borrower from a credit bureau. The age and number of dependents might help too. What else?

Algorithm: It's binary classification, so logistic regression is a good candidate. What else?

Note: I'm not sure where to post this. I thought I would get more suggestions here than in r/finance, I don't mind if they are not used in real life as long as they make some sense.",7,2
152,2014-8-21,2014,8,21,16,2e5spe,Use Diffbot as a Portfolio Harvester,https://www.reddit.com/r/MachineLearning/comments/2e5spe/use_diffbot_as_a_portfolio_harvester/,suphper,1408605487,,0,1
153,2014-8-21,2014,8,21,18,2e5zng,Graders - The Latest Catalog,https://www.reddit.com/r/MachineLearning/comments/2e5zng/graders_the_latest_catalog/,jessicperson,1408613240,,0,1
154,2014-8-21,2014,8,21,23,2e6lg0,Ensembling for already strong models?,https://www.reddit.com/r/MachineLearning/comments/2e6lg0/ensembling_for_already_strong_models/,my_face_is_up_here,1408631741,"Sorry if this is a stupid question; I've only recently learned about ensembling.

It seems like most of the ensemble methods involve utilizing many weaker models that are quick to train, and combining them to form a very good model in the end. Would the same algorithms apply to more complex models and models of different types? For example, if I have an SVM model, a logistic regression model, a neural network, and a kNN classifier, can I combine them all using Bagging or AdaBoost? If not, how would I combine them? Is a simple arithmetic mean enough?",5,6
155,2014-8-22,2014,8,22,1,2e6y3w,3x faster convolutions in Theano,https://www.reddit.com/r/MachineLearning/comments/2e6y3w/3x_faster_convolutions_in_theano/,galapag0,1408638862,,2,17
156,2014-8-22,2014,8,22,4,2e7j2o,Machine learning - the link between cost function and gradient descent; iterating,https://www.reddit.com/r/MachineLearning/comments/2e7j2o/machine_learning_the_link_between_cost_function/,orangerusty,1408649775,"Hi.
I am taking Prof. Ng's ML class. This is specifically the ex1 exercise.
I go through all the videos, quizzes, and take notes. When it comes to programming exercises, I try to build small model on Excel to confirm I am doing it right.

I can get the cost function on Excel but I can't get the batch gradient descent on Excel to match with the Octave's output. 

Example:
Let's say I have a (5 x 2) training set consisting of:

x = [ 8, 9 , 6 , 6, 7]
y = [ 3, 7, 7, 9, 6]

I can't do a 5x2 vector on this page but just picture a 5x2 vector with x and y:

8 3, 9 7, 6 7, 6 9, 7 6   with x and y respectively.

with theta0 = 0, theta1 = 0.
m= 5

I can get the cost function by:

1) [(theta0*X) - y]^2
  -
  - if i do that for rows 2 through 5 and sum all the 5 rows, I get 9 + 49 + 49 +81 +36 =  224.

2) Then I do 224* [1/(2*m)], which is 22.4

The cost function is 22.40.






Ok, now I have the cost function, to get the batch gradient descent for linear regression, it's:

theta(j): = theta(j) - alpha*(1/m)* sum of [theta0*x(i) - y(i)]*x(i)(j)

Where theta0 and theta1 is simultaneously updated. 

The class has set of 97 training set examples to iterate 1500x. All I want to do is iterate 5x over the training set of 5 on excel. If my 5x iteration result on excel matches the 5x on the octave (the language we are using in the class), then I know I am doing it right. 

Can anyone show me how to just iterate 5x on excel given the 5 x 2 training set above? As you can see, I don't understand and can't implement this simultaneous update of theta and iteration on excel. The class exercise has an iteration of 1500 and I can't confirm if that number is true or not. If i can't confirm it, I don't know when I am wrong or right.

Also, if you can explain to me in plain language the relationship between the cost function and the gradient descent. minimizing cost function to get an accurate hypothesis is an idea i intuitively understand, but where does the cost function fit in the gradient descent equation?

Any help would be appreciated. This is a huge hurdle for me and is preventing me from making progress in class. I just need to be able to do a small model on excel to know each step by step process. 















",6,1
157,2014-8-22,2014,8,22,5,2e7rsm,Machine Learning and Art: Seeing what Experts Sometimes Don't See,https://www.reddit.com/r/MachineLearning/comments/2e7rsm/machine_learning_and_art_seeing_what_experts/,LegacyAngel,1408654328,,0,18
158,2014-8-22,2014,8,22,8,2e8797,Gradient Descent without a derivative,https://www.reddit.com/r/MachineLearning/comments/2e8797/gradient_descent_without_a_derivative/,rudyl313,1408663205,"Lets say I have an unknown 1D function f(x) that I want to find the minimum of. I can evaluate f(x) at any x, but I can't find the derivative of f(x) at any x. 

Is it still possible to find the minimum of f(x) assuming it is convex? What procedure would you use? I was thinking you could approximate the derivative using [f(x2) - f(x1)] / [x2 - x1], where x1 and x2 were two consecutive points you sampled. Otherwise, I was just going to use a grid search (but I'm not sure what bounds to use).

What if f(x) is not 1D (i.e. x is a vector)?",20,5
159,2014-8-22,2014,8,22,11,2e8ne0,Thit b bo trm l g?  C th bn hiu sai,https://www.reddit.com/r/MachineLearning/comments/2e8ne0/thit_b_bo_trm_l_g_c_th_bn_hiu_sai/,rubytid,1408673604,,0,1
160,2014-8-22,2014,8,22,11,2e8ok8,Lp t h thng bo trm  B 1 li 10,https://www.reddit.com/r/MachineLearning/comments/2e8ok8/lp_t_h_thng_bo_trm_b_1_li_10/,rubytid,1408674356,,0,1
161,2014-8-22,2014,8,22,16,2e9bzq,The Most Popular Excavator Attachments | The Most Popular,https://www.reddit.com/r/MachineLearning/comments/2e9bzq/the_most_popular_excavator_attachments_the_most/,jessicperson,1408692635,,0,1
162,2014-8-22,2014,8,22,16,2e9cob,Mood for Music: Emotion Recognition on Acoustic Features,https://www.reddit.com/r/MachineLearning/comments/2e9cob/mood_for_music_emotion_recognition_on_acoustic/,esurior,1408693378,,0,5
163,2014-8-22,2014,8,22,18,2e9i8p,Using word2vec for different NLP tasks,https://www.reddit.com/r/MachineLearning/comments/2e9i8p/using_word2vec_for_different_nlp_tasks/,mczaar,1408699524,"I've came by word2vec algorithm which seemed to me as an efficient way to do good word vector representation. So I made my own implementation of this algorithm and trained it on some training set. Model that I've trained works as it should.

My question now is: did anyone came along an article (or discussion) that covers the use of word2vec implementation in tasks like NER or POS tagging. For example, I have NER tagger implemented with the use of CRF (I use hand crafted features for word representation). Is there any good way to use word2vec implementation combined with CRF suite. Or is there better ways for NER with word2vec word representation.",9,12
164,2014-8-22,2014,8,22,23,2ea2wv,Finance major looking for advice on AI degree.,https://www.reddit.com/r/MachineLearning/comments/2ea2wv/finance_major_looking_for_advice_on_ai_degree/,kurjagger,1408717638,,8,1
165,2014-8-23,2014,8,23,0,2eaayq,"x-post from /r/compsci: Book recommendation: Coding the Matrix, Linear Algebra through Computer Science Applications by Philip N. Klein",https://www.reddit.com/r/MachineLearning/comments/2eaayq/xpost_from_rcompsci_book_recommendation_coding/,skytomorrownow,1408722379,"Linear Algebra is a my first mathematical love. I never get tired of it for some reason. As such, I've collected quite a few LA texts, and I now have a new favorite! Here are some of the reasons I really enjoy this text:

*Coding the Matrix* is a computational approach to LA and starts with the assumption of a finite domain, thus, it is able to focus on a lot of practical computational examples, and skip the complications of infinite domains.

Adding to the above notion, the book focuses on portraying vectors as functions on finite domains which is a wonderful way to present them as it makes connecting them to practical applications very direct. 

Everything is in Python. I don't make this claim because I'm a Python fan (I am, but not a daily user or fanboy). I point this out because Python is used in ML and compsci, and therefore will be at least familiar to many readers. In addition, even those who love other languages would agree that Python has great mathematical tools, a large community, is free, is great for 'sketching' things quickly with tools like IPython notebooks. In addition, and this isn't Python-specific, the author has us think of vectors as functions on finite domains, and as such, there is heavy use of representing vectors as sparse dictionaries, which languages like Python do quite well.

The text spends a lot of time on signals, sparsity, compression, and other popular compsci topics. [edit for this subreddit: there are a ton of examples which ML enthusiasts will recognize throughout the book.] The author seems to have an endless supply of simple, practical examples which are sometimes just sprinkled in the main text, or presented as labs or asides.

There are a lot of great popular culture references to *The Matrix*, other Movies, and tons of xkcd comics which are always very related to the topic in the text, but keep the volume from being oppressive.

Anyway, if you like linear algebra topics, and lots of great compsci applications thereof, I highly recommend this book. Enjoy compsciers!",5,15
166,2014-8-23,2014,8,23,1,2eacr1,How is personalization factored with global neural network like what is used by Google?,https://www.reddit.com/r/MachineLearning/comments/2eacr1/how_is_personalization_factored_with_global/,bartturner,1408723413,"I am fascinated by machine learning and especially what Google has done with search.   I understand the learning aspect where Google teaches their neural networks with global queries.   

What I don't understand is how much is personalized and how personalization works.   A simple example might be the spelling of a word.   Say I live in the US and spell check changes my input of fbre to fiber (US spelling).   But what I don't understand is if this would be changed to fibre (UK Spelling) if I am in the UK?

Above is a relatively simple example but what I am more curious about are more complicated examples such as my wife has no interest in Comp Sci but has strong interest in horticulture .   If we are both logged in and never previously searched on a term that is common for horticulture and Comp Sci would my results be different than hers?

How would this be done in relatively simple terms?   Would you create the global neural network and then do additional training with my previous searches and other personalized information and give this training higher weights?   How does this approach scale?

Really appreciate any help.   Thanks in advance!",5,1
167,2014-8-23,2014,8,23,3,2eaw6n,Topic Modelling + Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2eaw6n/topic_modelling_deep_learning/,spidey-fan,1408733968,"I was reading up on topic based sentiment analysis / aspect based sentiment analysis, which deals with assigning sentiment to only particular topics or aspects of a document. Since deep learning has been recently used for sentiment classification, I was wondering if any work has been done on combining deep learning and topic detection for aspect/topic based sentiment analysis.",4,2
168,2014-8-23,2014,8,23,5,2eb4ro,Machine Learning Course Project Ideas,https://www.reddit.com/r/MachineLearning/comments/2eb4ro/machine_learning_course_project_ideas/,spidey-fan,1408738823,"I am a graduate student who has just started working in computer vision and deep learning. I need to choose a project for a machine learning course this semester, and am simply overwhelmed by the amount of literature and ideas available. What would be a good topic/idea for a one semester long project, preferably related to deep learning in vision?",2,1
169,2014-8-23,2014,8,23,15,2eckrp,Using two high recall classifiers,https://www.reddit.com/r/MachineLearning/comments/2eckrp/using_two_high_recall_classifiers/,[deleted],1408776696,"Hi

I am currently working on a classification problem, and using the cross validation results I can see that I have two classifiers, both of which have high recall but for different classes.

Classifier 1

Confusion Matrix :

      A             B

A  24,591       873

B  1,850         3686


Classifier 2

Confusion Matrix :

      A             B

A  21,983       3,481

B  587            4949

You can see that Classifier 1 has high recall on class A and Classifier 2 on class B.

How to get a final estimate that incorporated the advantages of both?
",3,6
170,2014-8-23,2014,8,23,23,2ed8q5,"Video: Signal and Image Classification, Stephane Mallat. (Deep Wavelet Scattering Networks)",https://www.reddit.com/r/MachineLearning/comments/2ed8q5/video_signal_and_image_classification_stephane/,compsens,1408804907,,2,21
171,2014-8-24,2014,8,24,1,2edf11,How much can Metaheuristics be used in place of backpropogation ?,https://www.reddit.com/r/MachineLearning/comments/2edf11/how_much_can_metaheuristics_be_used_in_place_of/,muktabh,1408809606,"I just started reading about genetic algorithms. So the question might be totally not making sense.
I saw a paper which said Genetic Algorithms can be used in DBN like systems as http://dl.acm.org/citation.cfm?id=2602287 (and almost with equivalent results). Are they faster/slower, better/worst to write as parallel ? There seems to be used very less online resources when I try to search about ""Autoencoders Genetic Algorithms"". Am I reading in the wrong direction ? ",3,1
172,2014-8-24,2014,8,24,2,2edmbc,Suggested Naming of Key Components of Hierarchical Temporal Memory,https://www.reddit.com/r/MachineLearning/comments/2edmbc/suggested_naming_of_key_components_of/,fergbyrne,1408814397,,0,0
173,2014-8-24,2014,8,24,6,2ee89k,Related subreddit : /r/datacleaning,https://www.reddit.com/r/MachineLearning/comments/2ee89k/related_subreddit_rdatacleaning/,datachili,1408828958,"We have recently created /r/datacleaning, dedicated to the wonderful field of data cleaning. This is a hugely important topic for any ml scientist, and often involves using the very same ml algorithms to detect and repair data errors that are used for data analysis. Data cleaning research is a very rich and technical field that is innately tied to ml research and statistics.

We would be much obliged if you took some time to check us out and subscribe to /r/datacleaning. Thanks!",1,8
174,2014-8-24,2014,8,24,7,2eeej7,"Machine Learning, good resources to start with?",https://www.reddit.com/r/MachineLearning/comments/2eeej7/machine_learning_good_resources_to_start_with/,mic8345,1408833411,"Hi everyone! In my spare time I enjoy programming and learning about Computer Science in general. I recently came across the fascinating topic of machine learning and thought that perhaps I could integrate my knowledge of R and Python with ML and have some fun building simple projects.

I read a little on the topic and it seems that I have (at least part of) the minimum knowledge required such as linear algebra, statistics and so on.

As a beginner, I would love to hear from people more knowledgeable than me and be advised on what resources I should dive myself into for an introduction on ML. Note however that, since I am doing this as a sort of hobby, I do not need a rigorous, heavily detailed documentation such as you'd need in case you were studying at university. Some advice also on python modules would be much appreciated. Today I downloaded and installed scikit-learn but I still have not had time to check it out. Is it good for machine learning?

My short-term plan is to write a simple sentiment analysis program and then improving it with new acquired concepts.",7,2
175,2014-8-24,2014,8,24,8,2eejah,Deep Learning: An MIT Press book in preparation,https://www.reddit.com/r/MachineLearning/comments/2eejah/deep_learning_an_mit_press_book_in_preparation/,richardabrich,1408836825,,24,79
176,2014-8-24,2014,8,24,9,2eemjl,Any experience with the Forest Fires dataset on UCI?,https://www.reddit.com/r/MachineLearning/comments/2eemjl/any_experience_with_the_forest_fires_dataset_on/,exploding_octopus,1408839197,"I find that (thus far) I've hack a knack for mining data, attribute selection, when to discretize, forming a solid intuition on which algorithm works best for what, but I am stumped by the forestfires.csv dataset on the UCI repository. Using real mining techniques (as opposed to forcing some guesswork by the model) I can't crack a correlation coefficient in the high teens on Weka. 

Been at this for a very long time. Anyone have any input or advice on how to tackle this thing?",2,2
177,2014-8-24,2014,8,24,12,2ef3lt,On Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2ef3lt/on_machine_learning/,RockDiesel,1408852450,,1,5
178,2014-8-24,2014,8,24,21,2efv6x,Designer Handbag Authentication Application,https://www.reddit.com/r/MachineLearning/comments/2efv6x/designer_handbag_authentication_application/,[deleted],1408884053,"Many counterfeit handbags are sold every day online that go unnoticed due to a lack of knowledge or insufficient obtainable evidence of the important details that are consistent with an authentic handbag. I have studied and analyzed handbags and other goods of specific brands only to realize that it is possible to authentic a bag to a certain degree. Some fakes are just too good. 

Therefore I was hoping to develop an app that could authenticate a handbag by looking at numerous important details. These details would be [font](http://www.google.com/imgres?imgurl=http%3A%2F%2Fspotfakehandbags.com%2Flouis-vuitton-made-in-spain-artsy-lo-strait.jpg&amp;imgrefurl=http%3A%2F%2Fspotfakehandbags.com%2Flouis-vuitton-label-font-stamp-spot-fake.html&amp;h=360&amp;w=480&amp;tbnid=EdJhTJEqTaatEM%3A&amp;zoom=1&amp;docid=M5D6NMNAgAuL7M&amp;ei=l9f5U8zUFIvMsQTJs4H4Aw&amp;tbm=isch&amp;client=ms-android-hms-tmobile-us&amp;ved=0CC0QMygNMA0&amp;iact=rc&amp;uact=3&amp;page=3&amp;start=12&amp;ndsp=9), [date stamps]( http://www.google.com/imgres?imgurl=http%3A%2F%2Fspotfakehandbags.com%2Ffake-louis-vuitton-date-code.jpg&amp;imgrefurl=http%3A%2F%2Fspotfakehandbags.com%2Fcounterfeit-louis-vuitton-wallet.html&amp;h=240&amp;w=360&amp;tbnid=0MfXAgiaiT2HYM%3A&amp;zoom=1&amp;docid=0qkHtmN8IuCVgM&amp;ei=PNj5U528MeTIsATAmoDQBg&amp;tbm=isch&amp;client=ms-android-hms-tmobile-us&amp;ved=0CCAQMygAMAA&amp;iact=rc&amp;uact=3&amp;page=1&amp;start=0&amp;ndsp=7), [stitching]( https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcRqxhAmv4aFlLguUISlkhm0m0gcjsrAQM6YQVVayj_TA6N4EQeMZA), etc.
 Would it be better to compare each image that a user might input to a database of authentic images? Or would an analysis of each image suffice?
One way that the app might work would be similar to the method one might use to deposit a check with their phone. You would choose which brand you want to authenticate and then be directed to your phone's camera prompt which would have a blocked image constraint in order to get the right shot. IE: a stitching shot would be a thin constraint so you wouldn't have to crop the photo. Similar to a check deposit, photos would be accepted or rejected based on the quality, sufficient angle, etc. After all sufficient evidence has been submitted, then output a binary response authentic or not authentic. 
I would appreciate any assistance with this. Thanks.",0,0
179,2014-8-24,2014,8,24,22,2efwrr,Artificial Dataset for Machine Learning with Python and Numpy / Theano,https://www.reddit.com/r/MachineLearning/comments/2efwrr/artificial_dataset_for_machine_learning_with/,CreativePunch,1408885896,,9,23
180,2014-8-25,2014,8,25,11,2ehrud,sklearn - is DecisionTreeRegressor able to use criterion other than defined 'mse'?,https://www.reddit.com/r/MachineLearning/comments/2ehrud/sklearn_is_decisiontreeregressor_able_to_use/,phoenixbai,1408932043,"is DecisionTreeRegressor able to use criterion other than default 'mse'? I want to use different criterion to do the split, but failed to find any example suggests that it is possible.

so, I am hoping that anyone here could help confirm it.

also, if you have tried it before, could you describe your general thoughts about its acurracy etc?

thanks",10,0
181,2014-8-25,2014,8,25,11,2ehvpt,ANTI VIBRATION PADS FOR HONING APPLICATIONS,https://www.reddit.com/r/MachineLearning/comments/2ehvpt/anti_vibration_pads_for_honing_applications/,Dynemech,1408934694,,3,0
182,2014-8-25,2014,8,25,14,2eiau5,"Stupid question, but is learning while drunk like training a neural net with dropout?",https://www.reddit.com/r/MachineLearning/comments/2eiau5/stupid_question_but_is_learning_while_drunk_like/,M_Bus,1408946394,"Is there any way that using dropout to train a neural network could be considered analogous to a process that either occurs naturally, or could be made to occur through some kind of intervention, in an actual brain?

It seems unlikely to me, despite my limited knowledge of neurology, but it's a question I've always wanted to ask.",14,0
183,2014-8-25,2014,8,25,15,2eid8s,Machine Learning Mindmaps,https://www.reddit.com/r/MachineLearning/comments/2eid8s/machine_learning_mindmaps/,doublebyte1,1408948761,,3,19
184,2014-8-25,2014,8,25,16,2eiev3,Skid Steer Attachments - PDF,https://www.reddit.com/r/MachineLearning/comments/2eiev3/skid_steer_attachments_pdf/,jessicperson,1408950568,,0,1
185,2014-8-25,2014,8,25,17,2eihyp,Tm v chn mua ng loi my p ma tt nht | My p ma Vit Thng,https://www.reddit.com/r/MachineLearning/comments/2eihyp/tm_v_chn_mua_ng_loi_my_p_ma_tt_nht_my/,quynhtran116,1408954173,,0,1
186,2014-8-25,2014,8,25,18,2eiknp,Introduction To Rope Luffing Knuckle Boom Crane - Intro Into Blog,https://www.reddit.com/r/MachineLearning/comments/2eiknp/introduction_to_rope_luffing_knuckle_boom_crane/,jessicperson,1408957587,,0,1
187,2014-8-25,2014,8,25,19,2eiq47,Optimal program generation. [X-Post from /r/singularity],https://www.reddit.com/r/MachineLearning/comments/2eiq47/optimal_program_generation_xpost_from_rsingularity/,bubaonaruba,1408964156,"I have played in the past with evolutionary generation of programs. Something similar to this: http://www.primaryobjects.com/CMS/Article149.aspx but using [Unlimited Register Machines](https://proofwiki.org/wiki/Definition:Unlimited_Register_Machine).

But as described in the 2nd article: http://www.primaryobjects.com/CMS/Article150.aspx
changing the language a little can have a huge impact on convergence rate. Meaning: it is easier to generate some programs in a slightly different language.

So the idea is to go 1 more level meta.

For a given class of programs, find the fastest converging primitive language for evolutionary program generation.

Of course the globally best solution is just a 'language' that implements solutions to the input problems as 'primitive instructions'.

But if we limit our search space to easy operations supported natively by hardware, or even slightly extended with very basic instructions, for every class of problems, there must exist an optimally convergent set of instructions. Why not find it?

Do you happen to know some articles/research in this field? Or maybe would you like to participate in such a hobby project?",3,1
188,2014-8-25,2014,8,25,20,2eirdl,Using NCD and Binary Tree Clustering to Debug AI Behaviour,https://www.reddit.com/r/MachineLearning/comments/2eirdl/using_ncd_and_binary_tree_clustering_to_debug_ai/,moconnor,1408965479,,4,13
189,2014-8-25,2014,8,25,21,2eiwds,"Video: Panel Discussion ""Is Deep Learning the Final Frontier and the End of Signal Processing ?"" [xpost /r/CompressiveSensing ]",https://www.reddit.com/r/MachineLearning/comments/2eiwds/video_panel_discussion_is_deep_learning_the_final/,compsens,1408970180,,7,0
190,2014-8-25,2014,8,25,22,2ej0am,"Predictive modeling, supervised machine learning, and pattern classification - the big picture",https://www.reddit.com/r/MachineLearning/comments/2ej0am/predictive_modeling_supervised_machine_learning/,rasbt,1408973206,,0,35
191,2014-8-26,2014,8,26,2,2ejpw8,The Plan to Build a Massive Online Brain for All The Worlds Robots,https://www.reddit.com/r/MachineLearning/comments/2ejpw8/the_plan_to_build_a_massive_online_brain_for_all/,rejuvyesh,1408988404,,4,12
192,2014-8-26,2014,8,26,3,2ejvh1,Which course to start with?,https://www.reddit.com/r/MachineLearning/comments/2ejvh1/which_course_to_start_with/,re44,1408991284,"I'm looking to either take the Learning from Data course offered by Caltech, or the ML course by Andrew Ng. I have decent math background (linear algebra, elementary prob/stats, and calc upto Calc III). It seems that the Caltech course is more rigorous, but also provides a better sense of intuition regarding ML. Any thoughts?",6,5
193,2014-8-26,2014,8,26,5,2ek6t5,vibration control solutions for press brakes,https://www.reddit.com/r/MachineLearning/comments/2ek6t5/vibration_control_solutions_for_press_brakes/,Dynemech,1408997455,,0,0
194,2014-8-26,2014,8,26,6,2ekd5o,[Meta] Journal Reading Circle,https://www.reddit.com/r/MachineLearning/comments/2ekd5o/meta_journal_reading_circle/,leonoel,1409000905,"I think I saw this idea being pitched before, but if not, I think is a good idea. I'm currently the mod of the ML group in G+, and I think we could gather some synergies between the two communities. ",16,15
195,2014-8-26,2014,8,26,8,2ekp68,Scaling up deep learning.,https://www.reddit.com/r/MachineLearning/comments/2ekp68/scaling_up_deep_learning/,qkdhfjdjdhd,1409007804,,2,3
196,2014-8-26,2014,8,26,9,2ekvv3,Personalised recommendations using Spark,https://www.reddit.com/r/MachineLearning/comments/2ekvv3/personalised_recommendations_using_spark/,AlesisNovik,1409011825,,0,11
197,2014-8-26,2014,8,26,13,2elikj,Is there a good neural network library that works well with genetic programming for the purposes of artificial life?,https://www.reddit.com/r/MachineLearning/comments/2elikj/is_there_a_good_neural_network_library_that_works/,UserPassEmail,1409025909,I don't really care what language it is in. Python would be nice.,5,0
198,2014-8-26,2014,8,26,15,2eluoq,The Ideal Cone Crushers - The Ideal,https://www.reddit.com/r/MachineLearning/comments/2eluoq/the_ideal_cone_crushers_the_ideal/,jessicperson,1409036140,,0,1
199,2014-8-26,2014,8,26,16,2elv5j,DeLorean: Microsoft paper on using predictive modelling to improve game streaming experience,https://www.reddit.com/r/MachineLearning/comments/2elv5j/delorean_microsoft_paper_on_using_predictive/,Barbas,1409036625,,0,9
200,2014-8-26,2014,8,26,17,2em084,EL5 - What are autoencoders used for?,https://www.reddit.com/r/MachineLearning/comments/2em084/el5_what_are_autoencoders_used_for/,chchan,1409042361,"I kind of got how autoencoders work. It is an single layer feed forward ANN where an loss function is optimized and where the input and output should be the same (unless you add noise to it like a denoising autoencoder). 

But what is it usually used for other than compression? I just want to know what else can I do with them.",7,14
201,2014-8-26,2014,8,26,21,2emce9,"Imagga takes the pain out of keyword tagging, intros tagging API",https://www.reddit.com/r/MachineLearning/comments/2emce9/imagga_takes_the_pain_out_of_keyword_tagging/,chrisimagga,1409055573,,0,0
202,2014-8-27,2014,8,27,1,2emzf5,Using a Neural Network for Sample Reduction?,https://www.reddit.com/r/MachineLearning/comments/2emzf5/using_a_neural_network_for_sample_reduction/,CreativePunch,1409069753,"Hi all,

As I was working with k-NN, a notoriously costly algorithm, I was wondering if it was possible to use a Neural Network with either some form of batch learning or pre-training to reduce sample size.

Something I had in mind, don't know exactly if it'd work:

Take a dataset of 10K samples with 30 input variables and 5 classes. Each class is represented by 2K samples in the dataset.

A Neural network trains to converge those 2K values per-class to 500 values in its final layer per class (leaving you with 2500 samples instead of 10 000), which are representative of all the training data. You would then store these final layers in sort of a lookup table.

Your test data will go through the same neural network, and you will then take the k-NN of the final layer, compared to the values you previously stored in the lookup table.

Alternatively I could pre-process the data and take the mean of each of 4 values which are closest to each other which would also reduce the data to 500 samples per class, but I feel this would probably be very destructive towards the data, and so perhaps a neural network could learn better intermediate representations.

Has there been any research on anything like this? Does anyone have any ideas?

This is purely theoretical, it would of course be great if the final accuracy is better than a standard k-NN, however right now I am mostly interested in a solution to the problem or any ideas which I have not thought of yet.",9,1
203,2014-8-27,2014,8,27,3,2enf1q,Ontology,https://www.reddit.com/r/MachineLearning/comments/2enf1q/ontology/,neeratyoy,1409077944,I'm trying to group words based on their roots from a given Ontology and it's heterarchy so as to reduce dimensions for eventual text-clustering. Is there any freely available ontology ? ,4,0
204,2014-8-27,2014,8,27,5,2env5f,Q&amp;A on Data Science with Peter Norvig,https://www.reddit.com/r/MachineLearning/comments/2env5f/qa_on_data_science_with_peter_norvig/,firefox8312,1409086366,,0,18
205,2014-8-27,2014,8,27,8,2eoc7q,Sentence segmentation without periods,https://www.reddit.com/r/MachineLearning/comments/2eoc7q/sentence_segmentation_without_periods/,arrowoftime,1409096182,"Does anyone know about any tools / libraries / algs for sentence segmentation that works on flat lists of words, ie ""hello how are you today what did you eat for breakfast"" that do not contain punctuation. I found NLTK has a [sentence tokenizer](http://www.nltk.org/api/nltk.tokenize.html), but its seems to be trained on punctuated strings only.",3,3
206,2014-8-27,2014,8,27,9,2eoet1,What are machine learning jobs like?,https://www.reddit.com/r/MachineLearning/comments/2eoet1/what_are_machine_learning_jobs_like/,[deleted],1409097702,"I'm in the 9th grade, and I've been thinking about what I want to do when I grow up. I want to do something involving computers, and I think machine learning is really interesting. What are jobs like? What do you do all day? Are there different ""areas"" or do you do everything? ",19,9
207,2014-8-27,2014,8,27,13,2ep372,"Statistics: Losing Ground to CS, Losing Image Among Students. ML field and lack of rigor?",https://www.reddit.com/r/MachineLearning/comments/2ep372/statistics_losing_ground_to_cs_losing_image_among/,Eruditass,1409113263,,26,13
208,2014-8-27,2014,8,27,14,2ep8p7,Machine Learning Pioneer Michael I. Jordan will be doing an AMA in /r/MachineLearning on September 10 10AM PST,https://www.reddit.com/r/MachineLearning/comments/2ep8p7/machine_learning_pioneer_michael_i_jordan_will_be/,olaf_nij,1409117543,"I'm happy to announce UC Berkeley Professor Michael I Jordan will be visiting /r/MachineLearning on September 10 10AM PST for an AMA.

In keeping with tradition, a thread will be created before the official AMA time for those who won't be able to attend.",11,131
209,2014-8-27,2014,8,27,15,2epd83,Komatsu Hybrid Excavator - The Ideal Machine To Maximize Your Productivity - The Ideal,https://www.reddit.com/r/MachineLearning/comments/2epd83/komatsu_hybrid_excavator_the_ideal_machine_to/,jessicperson,1409121798,,0,1
210,2014-8-27,2014,8,27,21,2epxuk,Young guy in need of big data advice,https://www.reddit.com/r/MachineLearning/comments/2epxuk/young_guy_in_need_of_big_data_advice/,shaagi96,1409143326,"Hey everyone,
I'm 18 and I'm about to start my International Bachelor's of Business Administration at university. As far as I know, it's basically a business degree which makes you pick up a language with your studies. I chose to learn mandarin Chinese. 
Anyways, I just learned about big data and machine learning recently and am interested in it. 
I want to be able to work for a big data firm as a summer intern in the next few years. In order to do this, what do you recommend I do? Is there any certification I can get (that's reasonably priced) that will make me employable by these data firms?

Also, I joined Teradata corporation's university network and they have a certification if their own which members can get 50% off of the exam price (the rest is free) but the certification is for teradata corporation. Its not a certification in big data itself.

In conclusion, how can I get myself some real world work experience in the field of big data, machine learning and data science?",1,0
211,2014-8-27,2014,8,27,22,2eq09t,Recent comments by Yoshua Bengio on the state of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2eq09t/recent_comments_by_yoshua_bengio_on_the_state_of/,egrefen,1409145177,,30,52
212,2014-8-27,2014,8,27,23,2eq7zu,Edu-Videos | 100 Most Popular Machine Learning Talks at VideoLectures.Net,https://www.reddit.com/r/MachineLearning/comments/2eq7zu/eduvideos_100_most_popular_machine_learning_talks/,Friars1993,1409150188,,1,5
213,2014-8-27,2014,8,27,23,2eq89h,Machine Learning and Hadoop- How One of the Most Widely Used Big Data Technologies Has Evolved,https://www.reddit.com/r/MachineLearning/comments/2eq89h/machine_learning_and_hadoop_how_one_of_the_most/,[deleted],1409150340,,0,1
214,2014-8-28,2014,8,28,2,2eqqo9,KDD 2014 Tutorials (slide links),https://www.reddit.com/r/MachineLearning/comments/2eqqo9/kdd_2014_tutorials_slide_links/,xamdam,1409160531,,0,17
215,2014-8-28,2014,8,28,2,2eqtin,Machine learning and soccer: Predicting the world cup games with play by play data,https://www.reddit.com/r/MachineLearning/comments/2eqtin/machine_learning_and_soccer_predicting_the_world/,fhoffa,1409162016,,0,0
216,2014-8-28,2014,8,28,3,2er03x,Any good tutorials for Recursive Autoencoders ?,https://www.reddit.com/r/MachineLearning/comments/2er03x/any_good_tutorials_for_recursive_autoencoders/,muktabh,1409165523,"Please suggest any good tutorials about unsupervised/semi supervised recursive autoencoders. I got some good tutorials on recursive neural networks for NLP, but could not find any beginner level tutorial for RAe. ",4,5
217,2014-8-28,2014,8,28,4,2er6kv,Classification of machine learning by computational complexity,https://www.reddit.com/r/MachineLearning/comments/2er6kv/classification_of_machine_learning_by/,chupvl,1409168976,"Is there any classification or ontology of machine learning algorithms by computational complexity? interested in supervised classification tasks mainly, but any other unsupervised methods will be also interesting to see.",4,5
218,2014-8-28,2014,8,28,10,2es5pl,What are the best tools for creating automated summaries of news stories?,https://www.reddit.com/r/MachineLearning/comments/2es5pl/what_are_the_best_tools_for_creating_automated/,rpfeyn,1409189346,,4,3
219,2014-8-28,2014,8,28,15,2essx6,is there a better way to detect the background color of an image?,https://www.reddit.com/r/MachineLearning/comments/2essx6/is_there_a_better_way_to_detect_the_background/,phoenixbai,1409205936,"I want to separate the background color from the main object color of an image.
First, I did kmeans on the pixels of an image and divide the colors into different groups. Calculated their corresponding proportions as well.

And for most images, the background color is either the first or second color that has the highest proportion. But can`t tell which is which. 

so I am looking for a way to know which one is a background color. does anyone have any good idea?

p.s. for now, I am calculating the frequency of colors appear at the borders of an image, and taking one with the highest frequency as the background color. but doesn`t seem reliable, so please  help.

thanks

thanks",11,2
220,2014-8-28,2014,8,28,19,2et89f,Does anyone have a clue on when videos of the talks from ICML Beijing 2014 will be released?,https://www.reddit.com/r/MachineLearning/comments/2et89f/does_anyone_have_a_clue_on_when_videos_of_the/,tod315,1409222640,,5,14
221,2014-8-28,2014,8,28,22,2etkyv,Good Machine Learning Conferences for someone new to the field?,https://www.reddit.com/r/MachineLearning/comments/2etkyv/good_machine_learning_conferences_for_someone_new/,nobodysbusiness,1409233330,"My employer is giving me the opportunity to attend a technical conference on machine learning, and I'm having trouble trying to pick which one to attend. I'm still a machine learning neophyte, and so I'd like to attend a conference with some content that is fairly approachable.

For example, the tutorials at the recent [ICML conference](http://icml.cc/2014/) seem like they would have been a good start for someone such as myself. Here's how they're described in the [call for tutorials](http://icml.cc/2014/index/article/23.htm):
&gt; The ideal tutorial should attract a wide audience, and should be broad enough to provide a gentle introduction to the chosen research area...

Are there any other conferences that you might recommend for a relative newbie? Are there any conferences that I should definitely *avoid*?

Thanks!",15,19
222,2014-8-29,2014,8,29,0,2etvnb,Looking to the Future of Data Science [NYTimes article on KDD],https://www.reddit.com/r/MachineLearning/comments/2etvnb/looking_to_the_future_of_data_science_nytimes/,carmichael561,1409239645,,1,0
223,2014-8-29,2014,8,29,1,2eu2ln,Question on Support Vector Regression,https://www.reddit.com/r/MachineLearning/comments/2eu2ln/question_on_support_vector_regression/,akshayv,1409243580,"Hello, 
I am new here and I was wondering if you guys could help me out.

I would like to know what you think is the most efficient way to solve the Lagrangian equation while solving for Support Vector Regression. ",1,0
224,2014-8-29,2014,8,29,9,2evgr6,Question re: time series matching/alignment,https://www.reddit.com/r/MachineLearning/comments/2evgr6/question_re_time_series_matchingalignment/,docere,1409271576,"For any time series researchers out there: When testing the accuracy of a time series subsequence matching algorithm in locating the temporal location of a particular subsequence, is there a specific name for this kind of test? I've looked through a few papers but couldn't find a clear answer.",7,6
225,2014-8-29,2014,8,29,13,2ew26o,"Looking for a review of ""Optimization for Machine Learning"" - worth a buy?",https://www.reddit.com/r/MachineLearning/comments/2ew26o/looking_for_a_review_of_optimization_for_machine/,[deleted],1409285344,,13,11
226,2014-8-29,2014,8,29,15,2ewcl9,"Does anyone knows Julia, the programming language",https://www.reddit.com/r/MachineLearning/comments/2ewcl9/does_anyone_knows_julia_the_programming_language/,largelymfs,1409294556,Does anyone knows about the programming language Julia?Is is easy to use GPU?,3,0
227,2014-8-29,2014,8,29,16,2ewe3u,The Unique Grove Cranes - Jim Beam Racing,https://www.reddit.com/r/MachineLearning/comments/2ewe3u/the_unique_grove_cranes_jim_beam_racing/,jessicperson,1409296170,,0,1
228,2014-8-29,2014,8,29,20,2ewszg,Multi-Index Locality Sensitive Hashing for Fun and Profit,https://www.reddit.com/r/MachineLearning/comments/2ewszg/multiindex_locality_sensitive_hashing_for_fun_and/,Barbas,1409313020,,1,5
229,2014-8-29,2014,8,29,21,2ewx6q,Ruslan Salakhutdinov's tutorial on Deep Learning from KDD '14.,https://www.reddit.com/r/MachineLearning/comments/2ewx6q/ruslan_salakhutdinovs_tutorial_on_deep_learning/,vikkamath,1409316701,,6,63
230,2014-8-29,2014,8,29,23,2ex7uh,Computer Eyesight Gets a Lot More Accurate,https://www.reddit.com/r/MachineLearning/comments/2ex7uh/computer_eyesight_gets_a_lot_more_accurate/,cavedave,1409323892,,0,2
231,2014-8-30,2014,8,30,14,2ezgbw,"Biomass Briquetting Press Machine, Plant Manufacturer, Supplier in India",https://www.reddit.com/r/MachineLearning/comments/2ezgbw/biomass_briquetting_press_machine_plant/,biomasss,1409376251,,0,1
232,2014-8-30,2014,8,30,21,2f02r1,Real-Time Face Pose Estimation,https://www.reddit.com/r/MachineLearning/comments/2f02r1/realtime_face_pose_estimation/,davis685,1409403318,,2,30
233,2014-8-31,2014,8,31,0,2f0gq2,How to perform Exploratory data analysis in Python (using Pandas)?,https://www.reddit.com/r/MachineLearning/comments/2f0gq2/how_to_perform_exploratory_data_analysis_in/,kunalj101,1409414227,,0,1
234,2014-8-31,2014,8,31,3,2f0sa9,Intriguing properties of neural networks,https://www.reddit.com/r/MachineLearning/comments/2f0sa9/intriguing_properties_of_neural_networks/,mathijs_appbrain,1409422078,,1,4
235,2014-8-31,2014,8,31,3,2f0vn2,Meet the NuPIC Community,https://www.reddit.com/r/MachineLearning/comments/2f0vn2/meet_the_nupic_community/,numenta,1409424338,,2,0
236,2014-8-31,2014,8,31,17,2f2ixh,Question: I want to try a personal project (CAD) but I don't know if it's too difficult,https://www.reddit.com/r/MachineLearning/comments/2f2ixh/question_i_want_to_try_a_personal_project_cad_but/,[deleted],1409472023,"Background: I have not taken any class in ML in school but I've taken several MOOCs related to it. I know that's not enough (it feels like I'm still on training wheels) but I'm interested in doing a personal project.


My uncle's a doctor specializing in radiology and he's had a lot of patients (and scans). I want to try to write a program that will determine if a patient had a stroke based on their scan (or maybe has a tumor?). I think one of my problems will be transferring data and image compression and that's just data gathering. I'm thinking of using neural networks and I don't know if it will work. Is this too complicated/undoable for a beginner? Thanks for any input


Edit: do you have any articles on ANN/SOM and DICOM image formats? All the articles I see are subscription-only",4,0
237,2014-8-31,2014,8,31,20,2f2qia,Working on Driving Assistance system. Where should I look for challenging opportunities.,https://www.reddit.com/r/MachineLearning/comments/2f2qia/working_on_driving_assistance_system_where_should/,finics,1409483094,"I am working in an MNC in India on ADAS. But as we know, lack of resources its difficult to carry out research work. I would also be looking into industrial research. ALso it seems there is a need for PhD to learn various aspects. But I am doubtful would it help to put some time for it? Or should I try n learn and go for Industrial job? 

Also would like suggetion for any other areas of ML to look for, like I found Genomics applications very interesting. But I dont have idea how can I do work for it. ",1,0
