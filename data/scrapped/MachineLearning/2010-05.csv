,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2010-5-1,2010,5,1,23,byqfo,Zulu - Automata learning from membership queries (Machine Learning competition),https://www.reddit.com/r/MachineLearning/comments/byqfo/zulu_automata_learning_from_membership_queries/,cpdomina,1272723685,,1,6
1,2010-5-3,2010,5,3,16,bzb6d,John Langford discusses connections between online learning and the state of the financial system,https://www.reddit.com/r/MachineLearning/comments/bzb6d/john_langford_discusses_connections_between/,urish,1272872197,,0,15
2,2010-5-6,2010,5,6,0,c0emy,The Fundamental Limits of Privacy For Social Networks ,https://www.reddit.com/r/MachineLearning/comments/c0emy/the_fundamental_limits_of_privacy_for_social/,cavedave,1273074130,,0,7
3,2010-5-6,2010,5,6,2,c0g5c,"What is R? Intermediate and Advanced 
R. [Videos]",https://www.reddit.com/r/MachineLearning/comments/c0g5c/what_is_r_intermediate_and_advanced_r_videos/,kunjaan,1273081718,,0,9
4,2010-5-8,2010,5,8,3,c16ay,Stanford video lectures on ML and NLP (in Silverlight! Why do they do that?),https://www.reddit.com/r/MachineLearning/comments/c16ay/stanford_video_lectures_on_ml_and_nlp_in/,[deleted],1273257566,[deleted],0,1
5,2010-5-8,2010,5,8,4,c17ax,Stanford Video Lectures on NLP,https://www.reddit.com/r/MachineLearning/comments/c17ax/stanford_video_lectures_on_nlp/,last_useful_man,1273262029,,1,6
6,2010-5-10,2010,5,10,23,c252i,Text Classification for Sentiment Analysis with a Naive Bayes Classifier,https://www.reddit.com/r/MachineLearning/comments/c252i/text_classification_for_sentiment_analysis_with_a/,japerk,1273502123,,2,16
7,2010-5-11,2010,5,11,0,c261q,World Cup 2010 Football Forecast Competition,https://www.reddit.com/r/MachineLearning/comments/c261q/world_cup_2010_football_forecast_competition/,cavedave,1273506507,,0,4
8,2010-5-11,2010,5,11,17,c2hpj,A new series about companies that rely on machine learning techniques,https://www.reddit.com/r/MachineLearning/comments/c2hpj/a_new_series_about_companies_that_rely_on_machine/,databuff,1273566106,,4,25
9,2010-5-11,2010,5,11,23,c2m14,"Data mining with WEKA, Part 2: Classification and clustering",https://www.reddit.com/r/MachineLearning/comments/c2m14/data_mining_with_weka_part_2_classification_and/,[deleted],1273588161,,3,22
10,2010-5-12,2010,5,12,2,c2owr,"Rank Aggregation in ""The Right Tool""",https://www.reddit.com/r/MachineLearning/comments/c2owr/rank_aggregation_in_the_right_tool/,DRMacIver,1273599268,,1,10
11,2010-5-12,2010,5,12,18,c30r1,"Do you have some interesting links, RSS feeds you can share? (ML, AI or anything interesting)",https://www.reddit.com/r/MachineLearning/comments/c30r1/do_you_have_some_interesting_links_rss_feeds_you/,resiros,1273656638,The two I read are kurzweilai.net RSS feed and [Sciencedaily](http://www.sciencedaily.com/news/computers_math/) feed,1,1
12,2010-5-13,2010,5,13,3,c380s,"""Item Comparison"" vs ""Ranking"" in Collaborative Filtering",https://www.reddit.com/r/MachineLearning/comments/c380s/item_comparison_vs_ranking_in_collaborative/,gabgoh,1273688691,"Could anyone point me to a link which does some kind of semi-theoretical or theoretical analysis of ""Item Comparison"" filtering (e.g where the user is asked to compare two items, such as pictures and choose which one he/she prefers e.g [friendlyrank](http://friendlyrank.com/okstupid.html)) and ""Ranking"" (obvious). What is the former even called? Is one better than the other, and why? Discussion is welcome",3,10
13,2010-5-16,2010,5,16,20,c4qck,"Data Dumps of ""The Right Tool"" now available - 60,000 answers and counting",https://www.reddit.com/r/MachineLearning/comments/c4qck/data_dumps_of_the_right_tool_now_available_60000/,[deleted],1274007606,[deleted],0,1
14,2010-5-16,2010,5,16,20,c4qg7,"What to do with 60,000 answers about programming languages?",https://www.reddit.com/r/MachineLearning/comments/c4qg7/what_to_do_with_60000_answers_about_programming/,DRMacIver,1274008629,,2,13
15,2010-5-17,2010,5,17,18,c51zx,"AskML: How to determine the most confident 
instances?",https://www.reddit.com/r/MachineLearning/comments/c51zx/askml_how_to_determine_the_most_confident/,personanongrata,1274087399,"As most of you know, confidence value for a model can be calculated with several techniques. For instance if you have an ensemble of decision tree classifiers, then you can find the confidence value by majority voting. 

Now, I have an ensemble of decision trees, i want to do sampling on the classified instances for active learning. But majority voting (in active learning this is called QBC) doesn't yield good results (actually it worsens). I want to try a different technique, probably smt like density based approaches will do OK. 

My main question is: 

Is it reasonable to think that the most confident classified example are the ones that are closest to the centroid of the cluster constituted by the classifier? If yes what is the mathematical reasoning behind that? If you have other suggestions please don't hesitate to share your ideas here.",2,0
16,2010-5-17,2010,5,17,19,c52l7,Machinery sales now goes online,https://www.reddit.com/r/MachineLearning/comments/c52l7/machinery_sales_now_goes_online/,devjohn1,1274090907,,0,1
17,2010-5-17,2010,5,17,23,c55wo,Text Classification for Sentiment Analysis  Precision and Recall,https://www.reddit.com/r/MachineLearning/comments/c55wo/text_classification_for_sentiment_analysis/,japerk,1274108046,,0,7
18,2010-5-18,2010,5,18,8,c5cja,Ask ML: I'm building a new desktop.  Recommendations?,https://www.reddit.com/r/MachineLearning/comments/c5cja/ask_ml_im_building_a_new_desktop_recommendations/,Troybatroy,1274138828,"$1000 soft limit

My current desktop has fewer cores than my laptop, 1 and 2 respectively, so I'm overdue for an upgrade.

I don't need a new monitor or any of that stuff.  Other than doing my ML research I would be doing a little bit of home audio recording and tv watching on it... and of course redditting :)

I've got 3 Convential PCI cards that I need from my current setup (ATI Radeon HD 3650, M-Audio Delta 66, and a Haupaugge TV card).  Oh and I'd be dual booting Linux and Windows 7, i.e. already have a license.

Motherboard, chip set recommendations please.

4 core or 6?

I'm contemplating a smallish SSD to complement my current HDD.

I use R, so 16G RAM seems appropriate.",3,0
19,2010-5-20,2010,5,20,7,c62ym,Google Prediction API - Google Code,https://www.reddit.com/r/MachineLearning/comments/c62ym/google_prediction_api_google_code/,[deleted],1274306776,,6,45
20,2010-5-24,2010,5,24,22,c7jgg,Evaluating Stopwords and Bigram Collocations for Text Classification,https://www.reddit.com/r/MachineLearning/comments/c7jgg/evaluating_stopwords_and_bigram_collocations_for/,japerk,1274708939,,0,9
21,2010-5-28,2010,5,28,19,c907j,"Autonomous quadrocopter flies through windows, straight into our hearts (video) -- Engadget",https://www.reddit.com/r/MachineLearning/comments/c907j/autonomous_quadrocopter_flies_through_windows/,mikef22,1275043947,,6,48
22,2010-5-30,2010,5,30,4,c9g6i,Come share some tips with us in /r/numerical (and help me grow it!).,https://www.reddit.com/r/MachineLearning/comments/c9g6i/come_share_some_tips_with_us_in_rnumerical_and/,dearsomething,1275162702,,0,11
23,2010-5-31,2010,5,31,11,c9rg7,Deep Learning in the popular media,https://www.reddit.com/r/MachineLearning/comments/c9rg7/deep_learning_in_the_popular_media/,gdahl,1275271585,"[This](http://www.wired.com/dangerroom/2010/05/darpa-code-teaching-itself-what-the-world-looks-like/) article is better than many I've seen, but still it makes me bemoan the state of science journalism.  I would avoid the comments if you want to avoid [this](http://xkcd.com/386/) situation.",1,3
24,2010-5-31,2010,5,31,23,c9wur,Optimizing Discounts with Data Mining,https://www.reddit.com/r/MachineLearning/comments/c9wur/optimizing_discounts_with_data_mining/,cavedave,1275316565,,1,0
