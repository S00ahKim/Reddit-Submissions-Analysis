,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,deeplearning,t5_2t5eh,2019-7-1,2019,7,1,11,c7mohh,self.deeplearning,What are some NN models that can use auxiliary info during training for image segmentation?,https://www.reddit.com/r/deeplearning/comments/c7mohh/what_are_some_nn_models_that_can_use_auxiliary/,Worth_Bet,1561946500,"For example imagine a poorly shot image of a river (blue) that shows a gap, and the supplementary information are detailed flow directions (green arrows) which help showing the river's true shape (no gap in reality). To **get the river shape**, most image segmentation models I see such as U-Net only uses RGB channels. **Are there any neural network models that can use this kind of auxiliary information along with RGB channels during training** for the image segmentation task?

https://i.redd.it/ap6mosg8nl731.png",2,3,False,self,,,,,
1,deeplearning,t5_2t5eh,2019-7-1,2019,7,1,11,c7mtmz,pmccaffrey.io,Learning deep learning in 3 months,https://www.reddit.com/r/deeplearning/comments/c7mtmz/learning_deep_learning_in_3_months/,musedivision,1561947350,,0,1,False,default,,,,,
2,deeplearning,t5_2t5eh,2019-7-1,2019,7,1,14,c7ollj,self.deeplearning,Difference between Autoencoder Representation and Model Embeddings,https://www.reddit.com/r/deeplearning/comments/c7ollj/difference_between_autoencoder_representation_and/,PyWarrior,1561958731,"Representation 1: While we train an Undercomplete Autoencoder on a data(let's say imagenet), we get a smaller dimension representation by the Hidden Layers.

Representation 2: When we train a multiclass classifier like VGGNet(let's say on imagenet), we also get a representation before the final pooling layers.

&amp;#x200B;

What is the main difference between the two representations of that training data?  
What are the cases when representation 1 will be better than representation 2 and vice-versa?",7,5,False,self,,,,,
3,deeplearning,t5_2t5eh,2019-7-1,2019,7,1,15,c7p2f1,self.deeplearning,suggestions for best approach for scene text detection,https://www.reddit.com/r/deeplearning/comments/c7p2f1/suggestions_for_best_approach_for_scene_text/,vjycoc,1561962093,"I am trying to extract numbers painted on vessels so that we could track them. I tried CTPN which is giving good results but it is very slow, tried pretrained yolov3 text detection but it is highly inaccurate with these handwritten/painted text i also tried it with custom dataset but it is not detecting any text in the image. vessels are in open area, please suggest better models and approaches related to scene text detection.",3,1,False,self,,,,,
4,deeplearning,t5_2t5eh,2019-7-1,2019,7,1,15,c7p9kg,link.medium.com,Begin creating Deep Learning models. A list of things I wish I knew a year ago (xpost /r/learnmachinelearning),https://www.reddit.com/r/deeplearning/comments/c7p9kg/begin_creating_deep_learning_models_a_list_of/,s_cond,1561963582,,1,32,False,default,,,,,
5,deeplearning,t5_2t5eh,2019-7-1,2019,7,1,16,c7pmbi,self.deeplearning,Suggestions for learning and practicing Linear Algebraic Calculus,https://www.reddit.com/r/deeplearning/comments/c7pmbi/suggestions_for_learning_and_practicing_linear/,fluideborah,1561966238,"Hi everyone! I come from a non-CS/Math background. I have been in the field of Deep Learning for over a year now, but I have worked mostly on implementations. I had taken a course in Deep Learning a while back and am currently doing my Master's Thesis in a specific Deep Learning application. 

&amp;#x200B;

Through my experience so far, I've realized there are fundamental limitations to doing good research unless you are comfortable with the underlying math and calculus that governs Deep Learning and a lot of other Machine Learning algorithms. Plus I personally feel quite unsatisfied with my work knowing that it's not very theoretically rigorous. I know it doesn't happen overnight but that's pretty much why I am asking this question. What is a good way to study and practice intermediate to advanced linear algebra and linear algebraic calculus that's used in Deep Learning + Machine Learning?  


I'd be very excited to know if there are good openly available practice materials + courses out there through which I can work my way upwards step-by-step. Thank you!",9,5,False,self,,,,,
6,deeplearning,t5_2t5eh,2019-7-1,2019,7,1,18,c7qk6n,self.deeplearning,Extract image patches from NETCDF files,https://www.reddit.com/r/deeplearning/comments/c7qk6n/extract_image_patches_from_netcdf_files/,m9404,1561974017,"I have a huge dataset of NETCDF files, each NETCDF file contains an image and its mask as a numpy multidimensional array. The mask contains flags, the size of the images is (17307 x 6344).

  
What is the best way to extract patches to train a model from these images, such as every patch must contain pixels corresponding to a specific flag (lets say flag\_value =2) in the mask, the patches should be square-sized.",0,1,False,self,,,,,
7,deeplearning,t5_2t5eh,2019-7-1,2019,7,1,21,c7ruu9,intellectyx.com,Big Data Analytics in Government: How the Public Sector Leverages Data Insights,https://www.reddit.com/r/deeplearning/comments/c7ruu9/big_data_analytics_in_government_how_the_public/,raj11113,1561983432,,0,3,False,default,,,,,
8,deeplearning,t5_2t5eh,2019-7-1,2019,7,1,23,c7t3or,self.deeplearning,Why does reducing Stride reduce the accuracy of an Object Detection Model?,https://www.reddit.com/r/deeplearning/comments/c7t3or/why_does_reducing_stride_reduce_the_accuracy_of/,ShotInTheEd,1561990556,"Apologies if this question has been answered before already - I am new to this sub!

&amp;#x200B;

I have been playing around with hyperparameters to try to create the most accurate object detection model I can using TensorFlow's faster\_rcnn\_inception\_resnet\_v2\_atrous\_coco pre-trained model. The model can be found under this git repository:  [https://github.com/tensorflow/models/blob/master/research/object\_detection/g3doc/detection\_model\_zoo.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) 

&amp;#x200B;

One of the adjustments I made was to decrease the height\_stride and width\_stride from 8 (default) to 4 under first\_stage\_anchor\_generator in the config file. My expectation was that this would improve the accuracy of the model at the expense of taking longer for inference times but it actually resulted in the model performing really poorly. What happened was precision was very high but recall was extremely low. Does anyone have any insight into why this could be?

&amp;#x200B;

Also, any suggestions on how best to tweak the hyperparameters to maximise the accuracy of a model (disregarding the inference time that is required) would be amazing. For example, I have increased the first\_stage\_max\_proposals which has noticeably increased the accuracy of the model.

&amp;#x200B;

Any help would be really appreciated!",2,0,False,self,,,,,
9,deeplearning,t5_2t5eh,2019-7-1,2019,7,1,23,c7thwf,self.deeplearning,5 Must read books for Data Scientists,https://www.reddit.com/r/deeplearning/comments/c7thwf/5_must_read_books_for_data_scientists/,HannahHumphreys,1561992651,[removed],0,1,False,self,,,,,
10,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,0,c7tw5e,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c7tw5e/data_science_career_track_prep_course/,HannahHumphreys,1561994597,[removed],0,1,False,self,,,,,
11,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,0,c7u9ra,self.deeplearning,Simpler RNN architecture,https://www.reddit.com/r/deeplearning/comments/c7u9ra/simpler_rnn_architecture/,axeonthra,1561996159,"Hello,

I would like to know if anyone has tried using simpler transformation function for the state in [Elman network](https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-20). 

I am thinking of something similar along the lines of:  


**h**\[n\] = 0.9 **h**\[n-1\] + 0.1 f(A**x**\[n\]+**b**)      // h - state, x input, state is hit with fixed scalar instead of matrix

**y**\[n\] = g(C **h**\[n\] + **e**)

&amp;#x200B;

All the RNN folks seem to jump into complex state manipulations directly. I could not find any literature for something simpler.

&amp;#x200B;

Best Regards

\~",0,1,False,self,,,,,
12,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,1,c7uke7,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c7uke7/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1561997016,[removed],0,1,False,self,,,,,
13,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,2,c7wbpg,self.deeplearning,Artificial Intelligence for Business,https://www.reddit.com/r/deeplearning/comments/c7wbpg/artificial_intelligence_for_business/,HannahHumphreys,1562002117,[removed],0,1,False,self,,,,,
14,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,10,c82vgc,twitter.com,Bunch of Web Dev &amp; Deep Learning books are now discounted,https://www.reddit.com/r/deeplearning/comments/c82vgc/bunch_of_web_dev_deep_learning_books_are_now/,JesseStromberg8,1562030109,,0,1,False,default,,,,,
15,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,10,c834x0,self.deeplearning,Bunch of Web-Development books are discounted (including Deep Learning ones),https://www.reddit.com/r/deeplearning/comments/c834x0/bunch_of_webdevelopment_books_are_discounted/,HildaDavidson,1562031654,"It's all in one bundle and it has about 15 different books all on web development while some of them being on Deep Learning strictly. I think it's a pretty thing to own since you can read it and even share it with your friends.

&amp;#x200B;

Check it here:",2,1,False,self,,,,,
16,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,11,c83sys,self.deeplearning,FFT based CNN,https://www.reddit.com/r/deeplearning/comments/c83sys/fft_based_cnn/,Hariharan__SJ,1562035607,"Can we use the Fft of an image in a CNN? So that instead of Convolution we'll be multiplying the image with the kernel.
Did some googling and I found that this works better for large kernels and not the small ones, still dunno why? Can someone explain this pls",2,15,False,self,,,,,
17,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,13,c84xww,humblebundle.com,Humble Book Bundle: Open Source Bookshelf by Bleeding Edge Press,https://www.reddit.com/r/deeplearning/comments/c84xww/humble_book_bundle_open_source_bookshelf_by/,Steam_Games,1562042823,,0,4,False,default,,,,,
18,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,15,c85pfq,self.deeplearning,Competition to improve the medical field!,https://www.reddit.com/r/deeplearning/comments/c85pfq/competition_to_improve_the_medical_field/,LateNightDeveloper,1562048274,"Kaggle is a host of thousands of datasets with an active community, made for developing new technology. It is mostly used for developing Machine Learning and Deep Learning software.

They recently sent me an email of this competition: [Recursion Cellular Image Classification *1] (https://www.kaggle.com/c/recursion-cellular-image-classification/) which I will be discussing in this post.

With the costs of developing new medication, and getting it out to patients as soon as possible, it is no surprise that most patients would rather go without it. This competition contains experimental noise from real biological signals, which developers could use to train their applications in a chance to win $13,000.

The idea is to greatly decrease the costs for treatments and ensure that it goes faster out to patients.

One kernal which exploded in a day is [Nanashis Quick Visualization + EDA *2] (https://www.kaggle.com/jesucristo/quick-visualization-eda/notebook)

Id defenitily recommend checking it out!

Link *1:https://www.kaggle.com/c/recursion-cellular-image-classification/

Link *2:https://www.kaggle.com/jesucristo/quick-visualization-eda/notebook

",0,13,False,self,,,,,
19,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,16,c867v4,self.deeplearning,Coolest Papers of CVPR 2019,https://www.reddit.com/r/deeplearning/comments/c867v4/coolest_papers_of_cvpr_2019/,PyWarrior,1562052077,What are some of the Coolest papers of CVPR 2019?,2,35,False,self,,,,,
20,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,16,c86eit,self.deeplearning,TensorFlow 2.0. Main Commands and Operations (compare with TF 1.X),https://www.reddit.com/r/deeplearning/comments/c86eit/tensorflow_20_main_commands_and_operations/,vb100_,1562053527," **TensorFlow 2.0. Main Commands and Operations (compare with TF 1.X)**   
[https://youtu.be/R6BAMldZ1Y4](https://youtu.be/R6BAMldZ1Y4?fbclid=IwAR1DFPU7zoiDD7Nj25ElD3OKS-8XT7nTUdfaQrwxE7QJGYM-GLBg_C7AKIY)

*Processing img cvu4bl2khu731...*",0,5,False,self,,,,,
21,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,18,c86zey,self.deeplearning,How many records are enough to train landmark detection model?,https://www.reddit.com/r/deeplearning/comments/c86zey/how_many_records_are_enough_to_train_landmark/,nikogamulin,1562058445,"Hi,

&amp;#x200B;

I have a small dataset (approx 120 images) of pupils and am trying to build the model to predict the points (x and y coordinates). Does anyone have any relevant experience in order to provide an estimate of how many images should be annotated to train the model?",2,2,False,self,,,,,
22,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,18,c871vd,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c871vd/data_science_career_track_prep_course/,HannahHumphreys,1562058983,[removed],0,1,False,self,,,,,
23,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,18,c87bwt,self.deeplearning,Machine Learning Bootcamp: Become a ML Engineer in 6 months. Job Guaranteed.,https://www.reddit.com/r/deeplearning/comments/c87bwt/machine_learning_bootcamp_become_a_ml_engineer_in/,HannahHumphreys,1562061221,[removed],0,1,False,self,,,,,
24,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,19,c87qui,self.deeplearning,[R] https://arxiv.org/abs/1811.07519 Higher-order Neural Networks for Action Recognition,https://www.reddit.com/r/deeplearning/comments/c87qui/r_httpsarxivorgabs181107519_higherorder_neural/,KaiiHu,1562064295,"I am delighted to announce that I have submitted our recent work to arXiv. Any feedback would be highly appreciated. [https://arxiv.org/abs/1811.07519](https://arxiv.org/abs/1811.07519)

In this paper, we proposed a new architecture: the *higher-order* operation. The term ""*higher order*"" comes from *higher order* functions. A higher order function is a function that takes a function as an argument, or returns a function. Similarly, the outputs of the *higher-order* operation are not feature maps, but a bank of filters for extracting features. Then the network use the filters to extract features.

The intuition comes from the complexity of action recognition. It is much harder to recognize an action in a video than objects in still images. An effective architecture should not only recognize the appearance of target objects associated with the action, but also understand how they relate to other objects in the scene, in both space and time.

&amp;#x200B;

*Processing img nrjlr6er7v731...*

In the figure, we have 4 categories of actions: a) pull something from left to right, b) push something from right to left, c) push something from left to right and d) pull something from right to left. Only understanding the appearance info is not enough since we have only the hand and the object ""something"" in all four actions. It is also insufficient with temporal information. Figure b is the reverse of figure a ""pull something from left to right"", but figure b is not simply the opposite: ""pull something from right to left"". It is important to understand the object-in-context pattern to classify the actions.

As scenes become more complicated and the number of objects whose relations need to be tracked increases, the complexity of the learning task faced by the architecture increases rapidly. The vanilla convolutions use fixed filters to recognize *every* object-in-context pattern required to recognize one category of action, potentially leading to a blow up of the number parameters required for effective recognition of the actions.

In such settings, we do not want to have a huge number of filters to cover all possible object-in-context patterns. It is best if the model can propose/derive a filter given a certain context ---- different filters for different contexts. The model does not need to store all the filters, but needs to learn how to propose a filter. 

We hypothesize that how to propose/derive a filter for a certain context is learnable and design the ""*higher order*"" operation. More explicitly, let \[;\\bm{X};\] and \[;\\bm{Y};\] represent the input and output respectively. Let \[;\\bm{y}\_p;\] and \[;\\bm{x}\_p;\] represent a specific location of \[;\\bm{Y};\] and the set of locations on \[;\\bm{X};\] where \[;\\bm{y}\_p;\] is computed, respectively.",0,1,False,self,,,,,
25,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,22,c89cgl,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c89cgl/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1562074764,[removed],0,1,False,self,,,,,
26,deeplearning,t5_2t5eh,2019-7-2,2019,7,2,22,c89fnt,self.deeplearning,[Research] Human vs Machine Attention in Neural Networks,https://www.reddit.com/r/deeplearning/comments/c89fnt/research_human_vs_machine_attention_in_neural/,cdossman,1562075293,"[https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-human-vs-machine-attention-in-neural-networks-69a8b59e577f](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-human-vs-machine-attention-in-neural-networks-69a8b59e577f) 

Abstract:  Recent years have witnessed a surge in the popularity of attention mechanisms encoded within deep neural networks. Inspired by the selective attention in the visual cortex, artificial attention is designed to focus a neural network on the most task-relevant input signal. Many works claim that the attention mechanism offers an extra dimension of interpretability by explaining where the neural networks look. However, recent studies demonstrate that artificial attention maps do not always coincide with common intuition. In view of these conflicting evidences, here we make a systematic study on using artificial attention and human attention in neural network design.",0,1,False,self,,,,,
27,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,1,c8az2k,intellectyx.com,The Role of AI and Machine Learning in Data Quality,https://www.reddit.com/r/deeplearning/comments/c8az2k/the_role_of_ai_and_machine_learning_in_data/,rohit1221qq,1562083227,,0,1,False,default,,,,,
28,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,3,c8d4kz,self.deeplearning,My GAN creates random weird texture,https://www.reddit.com/r/deeplearning/comments/c8d4kz/my_gan_creates_random_weird_texture/,whiteapplex,1562093516,"Hi, I'm trying to make a GAN from scratch, but the result isn't so great for now.

Here are the results: [https://imgur.com/a/zuPV8Yx](https://imgur.com/a/zuPV8Yx) and the repartition for probabilities of belonging to the set of generated images.

Does anyone understand why ? :/

The generator uses upsample+convolution starting from a random matrix,  the discriminator ends with a fully connected and maxout.",1,0,False,self,,,,,
29,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,3,c8d5zb,expoundai.wordpress.com,Back-propagation Demystified [Part 2]  Computational graphs in PyTorch and Static vs Dynamic graphs,https://www.reddit.com/r/deeplearning/comments/c8d5zb/backpropagation_demystified_part_2_computational/,msminhas93,1562093698,,0,18,False,default,,,,,
30,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,4,c8dfif,aws.amazon.com,Running PyTorch inference on MMS (MXNet Model ServeR),https://www.reddit.com/r/deeplearning/comments/c8dfif/running_pytorch_inference_on_mms_mxnet_model/,gautam5669,1562094888,,0,5,False,default,,,,,
31,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,5,c8ebi7,self.deeplearning,Recommendations for (pre-built) deep learning PC?,https://www.reddit.com/r/deeplearning/comments/c8ebi7/recommendations_for_prebuilt_deep_learning_pc/,NSFForceDistance,1562097995,"Hi /r/MachineLearning, 

&amp;#x200B;

I am looking to buy a more powerful pre-built machine for deep learning projects. I have searched previous posts on the sub for recommendations on this and the general consensus seems to be ""don't buy pre-built,"" but unfortunately grant funding restrictions don't allow me to buy parts separately and pre-built is my only option. I am looking for something that can handle large datasets of 3D images (typically 512 x 512 x 128-512 before any processing). I am leaning towards something with a 2080 Ti or two 2080's and enough CPU power to be able to handle pre-processing on each batch.

&amp;#x200B;

Does anyone have any experience or recommendations here? My price range is between $2000-$3000. Thanks :)",1,0,False,self,,,,,
32,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,14,c8jzhc,self.deeplearning,Advice for Beginner in Deep Learning?,https://www.reddit.com/r/deeplearning/comments/c8jzhc/advice_for_beginner_in_deep_learning/,bijeshmohan,1562130377,I've just enrolled in Deep Learning Specialization on Coursera and would like to take some advices from those who already completed the specialization successfully.,3,6,False,self,,,,,
33,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,14,c8k48z,self.deeplearning,"Joke thought experiment: How hard would it be to make a ""DeepD*ckInYourMouth""?",https://www.reddit.com/r/deeplearning/comments/c8k48z/joke_thought_experiment_how_hard_would_it_be_to/,Last_Username_Alive,1562131301,"I'm not going to develop it cuz i'm sure it would be used for evil (bullying, harassment, abuse etc)  


But i thought about it as a joke for your whatsapp guy buddies: just take any of their pictures and put a dick in their mouth, that would be hilarious.  


So how hard would it be?  


Would it even be possible to take DeepFace and train it with faces with dicks in them and do it?",3,0,True,nsfw,,,,,
34,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,17,c8lhmc,self.deeplearning,[Free + Online] Workshop on Getting Started with Kaggle using fast.ai + a Beginner friendly Comp,https://www.reddit.com/r/deeplearning/comments/c8lhmc/free_online_workshop_on_getting_started_with/,init__27,1562141840,"Hi Everyone, 

I volunteer at a few meetups, I'm an active Kaggler. The #1 question I've recieved is how to get started on Kaggle. 

&amp;#x200B;

DSNet Community will be hosting  a Workshop (Online + In-Person in Bangalore), everyone is welcome to participate (For free, ofcourse)

&amp;#x200B;

The workshop is aimed to give you a taste of kaggle and how to use [fast.ai](https://fast.ai) for image competitions. Note this will be a very beginner friendly comp and the only pre-req is watching Lec 1-4 from [fast.ai](https://fast.ai).

&amp;#x200B;

\*Schedule: 4-6PM IST, Saturday 6th July for the workshop

Competition: Runs from 4PM IST until 8AM Monday IST\*

We will also try to award prices to the best performers

&amp;#x200B;

Zoom Link to join virtually: [https://zoom.us/j/804236055](https://zoom.us/j/804236055)

Sign up here for a reminder: [http://eepurl.com/ghcImr](http://eepurl.com/ghcImr)

&amp;#x200B;

My Kaggle Profile: [https://kaggle.com/init27](https://www.kaggle.com/init27)

Blog: [https://medium.com/@init\_27](https://medium.com/@init_27)",0,1,False,self,,,,,
35,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,17,c8lo0w,medium.com,DataScience Digest - Issue #18,https://www.reddit.com/r/deeplearning/comments/c8lo0w/datascience_digest_issue_18/,flyelephant,1562143432,,0,14,False,default,,,,,
36,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,21,c8nn2g,self.deeplearning,How to encrypt my model?,https://www.reddit.com/r/deeplearning/comments/c8nn2g/how_to_encrypt_my_model/,lacaai,1562157831,"Hello guys, I have a trained model (h5 file) which I would like to give to some customers. I want to encrypt it, and I also want to encrypt my model script. Is there any general way to do it ?  
I use keras with tensorflow backend.",2,5,False,self,,,,,
37,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,22,c8o4az,self.deeplearning,Predict Intermediate Frames Between Two Frames,https://www.reddit.com/r/deeplearning/comments/c8o4az/predict_intermediate_frames_between_two_frames/,SaumyaaShah2498,1562160658,"Hey, can someone suggest a deep learning approach to generate intermediate images between two input images? I've tried shifting pixels based on optical flow, but it didn't work out. I've also tried the following:

[https://github.com/sniklaus/pytorch-sepconv](https://github.com/sniklaus/pytorch-sepconv)

The result is also not very good. It'll be very helpful if someone could suggest a solution to this. Thank you.

P.S The input images are not extracted from a video. They are captured using a DSLR consecutively.",6,6,False,self,,,,,
38,deeplearning,t5_2t5eh,2019-7-3,2019,7,3,22,c8odjo,self.deeplearning,[Research] How to Achieve Better Accuracy for Target-speaker Automatic Speech Recognition (ASR),https://www.reddit.com/r/deeplearning/comments/c8odjo/research_how_to_achieve_better_accuracy_for/,cdossman,1562162109,"[https://medium.com/ai%C2%B3-theory-practice-business/how-to-achieve-better-accuracy-for-target-speaker-automatic-speech-recognition-asr-8f96448e3668](https://medium.com/ai%C2%B3-theory-practice-business/how-to-achieve-better-accuracy-for-target-speaker-automatic-speech-recognition-asr-8f96448e3668) 

**Abstract:**  In this paper, we propose a novel auxiliary loss function for target-speaker automatic speech recognition (ASR). Our method automatically extracts and transcribes target speakers utterances from a monaural mixture of multiple speakers speech given a short sample of the target speaker. The proposed auxiliary loss function attempts to additionally maximize interference speaker ASR accuracy during training. This will regularize the network to achieve a better representation for speaker separation, thus achieving better accuracy on the target-speaker ASR. We evaluated our proposed method using two-speaker mixed speech in various signal-to-interference-ratio conditions. We first built a strong target-speaker ASR baseline based on the state-of-the-art lattice-free maximum mutual information. This baseline achieved a word error rate (WER) of 18.06% on the test set while a normal ASR trained with clean data produced a completely corrupted result (WER of 84.71%). Then, our proposed loss further reduced the WER by 6.6% relative to this strong baseline, achieving a WER of 16.87%. In addition to the accuracy improvement, we also showed that the auxiliary output branch for the proposed loss can even be used for a secondary ASR for interference speakers speech.",0,3,False,self,,,,,
39,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,1,c8pyzu,i.redd.it,EfficientNet: Theory + Code,https://www.reddit.com/r/deeplearning/comments/c8pyzu/efficientnet_theory_code/,spmallick,1562170347,,2,0,False,image,,,,,
40,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,1,c8q6h0,self.deeplearning,"RTX 2060 vs RTX 2070 vs GTX1080Ti, which is better for deep learning?",https://www.reddit.com/r/deeplearning/comments/c8q6h0/rtx_2060_vs_rtx_2070_vs_gtx1080ti_which_is_better/,ar0752545,1562171383,,7,12,False,self,,,,,
41,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,3,c8rljr,medium.com,Baidu PaddlePaddle DL Framework &amp; Huawei Kirin SoC: A Formidable Partnership,https://www.reddit.com/r/deeplearning/comments/c8rljr/baidu_paddlepaddle_dl_framework_huawei_kirin_soc/,Yuqing7,1562178128,,0,5,False,default,,,,,
42,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,3,c8rosx,self.deeplearning,Power BI A-Z: Hands-On Power BI Training For Data Science!,https://www.reddit.com/r/deeplearning/comments/c8rosx/power_bi_az_handson_power_bi_training_for_data/,HannahHumphreys,1562178549,[removed],0,1,False,self,,,,,
43,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,6,c8u7j3,self.deeplearning,REQUEST: Female breast size dataset,https://www.reddit.com/r/deeplearning/comments/c8u7j3/request_female_breast_size_dataset/,kyonInsane,1562190825,"I am trying to start one of the greatest human project in deep learning. Not without a proper dataset. The request is following:

1. Front photo of female, dressed in any cloth
2. Full bust measurement 
3. Under bust measurement
Lots of them

Project aiming:
Train a net that is capable of speaking out Bra size and its measurements when provided with casual image.

I was amazed how female people including my wife is being troubled at selecting bras. Any help out there?

PS. don't let any bra company steal this idea from us!",4,0,False,self,,,,,
44,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,7,c8unsz,self.deeplearning,Two-Stream RNN/CNN for Action Recognition in 3D Videos,https://www.reddit.com/r/deeplearning/comments/c8unsz/twostream_rnncnn_for_action_recognition_in_3d/,babdulhakim2,1562193064,This a very good paper that for action recognition [https://arxiv.org/abs/1703.09783](https://arxiv.org/abs/1703.09783) I wonder if anyone has come across any reusable code that uses RNN and CNN for video classification,0,1,False,self,,,,,
45,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,11,c8wvpr,self.deeplearning,Any research about...,https://www.reddit.com/r/deeplearning/comments/c8wvpr/any_research_about/,lakshaytalkstocomput,1562206312,Is there any research about detecting a object in a frame of video and instead of detecting it from whole frame(next) it looks for in same region? What is it called if there is any research about it? Any help would be appreciated,1,0,False,self,,,,,
46,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,15,c8yyus,self.deeplearning,some question about text variant detection,https://www.reddit.com/r/deeplearning/comments/c8yyus/some_question_about_text_variant_detection/,harry771,1562220073," Dear friend of reddit,

I am a CS Student, I have a great interest in deep learning and NLP, that's why I took the cs224n along with other courses in Standford AI degree online. Among those courses, cs224n is my favorite, and I even pick Chatbot as my areaof interest. I apply all those skills I learn from cs224n to all kinds of NLP task I encountered, most of them work pretty well, however, a new problem I met in recent days got me into troubles.

For now, I am working on an NLP task on how to detect variant words. For example, we have samples like those, **yesssss,helloooo**, those are the simple ones. There are some complex samples like these,**126#45@120,1785 8943,abf23612.**These examples(numbers mix with other special symbols and space) I mention here are contact information(like phone numbers or facebook numbers ) some people left in a forum or reddit, so other people can follow them to other platforms. In this way, those who left the number can successfully attract people from this platform to some other platform((like app). Therefore, I need to build a model to identify these strings as contact information, one way to achieve this is using regular expressions to identify these strings, however, the variants of text are too many, we can't block all of them with regular expression. Another way I can think of is using the context as features to identify these contact information, and I reject this method as I go deep into the data. Most of the data I get come from web chatting(like chatting in facebook), the context is relatively short, which is not a good choice for feature engineering(I think).

So, this is the problem I encounter in my task, I wonder if you can give me some advice about how to solve this problem, some references or papers will do me the favor. I really appreciate if you can give me some advice about this problem. Thanks in advance.",3,2,False,self,,,,,
47,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,15,c8z04h,self.deeplearning,Noob question regarding data set size,https://www.reddit.com/r/deeplearning/comments/c8z04h/noob_question_regarding_data_set_size/,the_fourth_musk3teer,1562220303,"So I'm looking to train a RNN for sentiment analysis. I have a dataset of about 100 000, which is classified as good, neutral, or bad. 

However, the dataset for good and bad are about 10 000 respectively, while the neutral is the remaining 80 000. 

Do I need to have the same amount of data to train my network across all classifications?

I can further convert my dataset to a 5 star system (very bad, bad, neutral, good, very good) but I will face the same issue of not having the same dataset size for training

Thanks in advance for your time!",6,5,False,self,,,,,
48,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,21,c91rsr,self.deeplearning,ai development services|ai development company,https://www.reddit.com/r/deeplearning/comments/c91rsr/ai_development_servicesai_development_company/,clarke2106,1562241656,[removed],0,1,False,self,,,,,
49,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,23,c939s2,self.deeplearning,Machine Learning Bootcamp: Become a ML Engineer in 6 months. Job Guaranteed.,https://www.reddit.com/r/deeplearning/comments/c939s2/machine_learning_bootcamp_become_a_ml_engineer_in/,HannahHumphreys,1562250805,[removed],0,1,False,self,,,,,
50,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,23,c93exh,self.deeplearning,[Research] GANalyze: Toward Visual Definitions of Cognitive Image Properties,https://www.reddit.com/r/deeplearning/comments/c93exh/research_ganalyze_toward_visual_definitions_of/,cdossman,1562251616,"[https://medium.com/ai%C2%B3-theory-practice-business/ganalyze-toward-visual-definitions-of-cognitive-image-properties-d23b22486d6e](https://medium.com/ai%C2%B3-theory-practice-business/ganalyze-toward-visual-definitions-of-cognitive-image-properties-d23b22486d6e) 

Abstract:  We introduce a framework that uses Generative Adversarial Networks (GANs) to study cognitive properties like memorability, aesthetics, and emotional valence. These attributes are of interest because we do not have a concrete visual definition of what they entail. What does it look like for a dog to be more or less memorable? GANs allow us to generate a manifold of natural-looking images with fine-grained differences in their visual attributes. By navigating this manifold in directions that increase memorability, we can visualize what it looks like for a particular generated image to become more or less memorable. The resulting visual definitions"" surface image properties (like object size"") that may underlie memorability. Through behavioral experiments, we verify that our method indeed discovers image manipulations that causally affect human memory performance. We further demonstrate that the same framework can be used to analyze image aesthetics and emotional valence",0,9,False,self,,,,,
51,deeplearning,t5_2t5eh,2019-7-4,2019,7,4,23,c93gyt,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c93gyt/data_science_career_track_prep_course/,HannahHumphreys,1562251943,[removed],0,1,False,self,,,,,
52,deeplearning,t5_2t5eh,2019-7-5,2019,7,5,0,c93yao,self.deeplearning,CNN Implementation using Flutter,https://www.reddit.com/r/deeplearning/comments/c93yao/cnn_implementation_using_flutter/,zom8ie99,1562254517,How can I implement my CNN model (which is in hdf5 format) in android using Flutter? Is there any tutorial for this ?,4,0,False,self,,,,,
53,deeplearning,t5_2t5eh,2019-7-5,2019,7,5,0,c9422c,self.deeplearning,Worth waiting for RTX 2060 Super or just go with RTX 2060 from DL perspective?,https://www.reddit.com/r/deeplearning/comments/c9422c/worth_waiting_for_rtx_2060_super_or_just_go_with/,jklipn,1562255098,"Okay, so I just bought an RTX 2060 for $350 inclusive of taxes just before I read the announcement of Nvidia launching the Super cards.  Currently it is sitting unopened in front of me.  

I have been reading and studying ML/DL for the previous 9 months, first by taking Andrew Ng's course, then by studying CS231 notes at Stanford, and finally playing with a few models myself.  I made a speech recognition system for my relatively obscure mother tongue (which is not English), and image recognition system.  Along the way I have read all of the academic journal articles links in CS231 course and various well known blogs.  

Questions:
Given this background, is it worth the time to wait for RTX 2060 Super to start selling on 7/9?

Given this background, is it worth the extra money for RTX 2060 Super when the MSRP is $400, but with my sales tax it would be $431?  So at least $80 more expensive and possibly more close to $100 when taking into account  getting after market cards with good fans.",7,2,False,self,,,,,
54,deeplearning,t5_2t5eh,2019-7-5,2019,7,5,4,c96v4c,self.deeplearning,Created the fastest and most customizable NLP tokenizer in Python using a novel approach (not regex!),https://www.reddit.com/r/deeplearning/comments/c96v4c/created_the_fastest_and_most_customizable_nlp/,pvkooten,1562269761,[https://github.com/kootenpv/tok](https://github.com/kootenpv/tok),4,42,False,self,,,,,
55,deeplearning,t5_2t5eh,2019-7-5,2019,7,5,5,c97hgw,i.redd.it,Facebook just open-sourced their Deep Learning Recommendation Model (DLRM),https://www.reddit.com/r/deeplearning/comments/c97hgw/facebook_just_opensourced_their_deep_learning/,goncaloperes,1562273149,,3,17,False,image,,,,,
56,deeplearning,t5_2t5eh,2019-7-5,2019,7,5,6,c97piv,jackdry.com,David Silver's Reinforcement Learning Course [Summary],https://www.reddit.com/r/deeplearning/comments/c97piv/david_silvers_reinforcement_learning_course/,jdyr1729,1562274414,,0,1,False,default,,,,,
57,deeplearning,t5_2t5eh,2019-7-5,2019,7,5,6,c97uth,jackdry.com,5 Minute Summary of DeepMind's RL Course (Lecture 1),https://www.reddit.com/r/deeplearning/comments/c97uth/5_minute_summary_of_deepminds_rl_course_lecture_1/,jdyr1729,1562275242,,4,14,False,default,,,,,
58,deeplearning,t5_2t5eh,2019-7-5,2019,7,5,10,c9a0di,self.deeplearning,How can I review my Tensorflow knowledge?,https://www.reddit.com/r/deeplearning/comments/c9a0di/how_can_i_review_my_tensorflow_knowledge/,gitmonk,1562288893,"I learned to use Tensorflow a year and a half ago, just before I started my undergradute thesis. A lot has happened since then, and I kind of lost the practice (I was not that skilled to begin with). But anyway, what is the most fast and solid way I can review the basics and also learn more specific things like batch normalization and other advanced techniques? I thought about doing a project based learning, but I don't really know where to start. 

A little more context to see if you guys can point me out what to learn: my thesis is about 3D face reconstruction from 2D colored face images and I am currently working with the FRGC dataset.

I beg your pardon in advance if the post is not that clear, English is not my mothertongue.",2,3,False,self,,,,,
59,deeplearning,t5_2t5eh,2019-7-5,2019,7,5,14,c9c9y5,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c9c9y5/data_science_career_track_prep_course/,HannahHumphreys,1562305392,[removed],0,1,False,self,,,,,
60,deeplearning,t5_2t5eh,2019-7-5,2019,7,5,19,c9el13,self.deeplearning,Accuracy of the model,https://www.reddit.com/r/deeplearning/comments/c9el13/accuracy_of_the_model/,samisoomro24,1562323825,"Hello Everyone Hope you all are doing well. I working on a dataset consists of about 473 images that have 5 classes, some classes have more images and some have less images. I am classifying classes through pre-trained MobileNet model. My question is that how can I increase the accuracy of my model which is now about 30% I have tried data augmentation.",9,1,False,self,,,,,
61,deeplearning,t5_2t5eh,2019-7-5,2019,7,5,22,c9fwlp,self.deeplearning,[Research] Emotion Recognition Using Fusion of Audio and Video Features,https://www.reddit.com/r/deeplearning/comments/c9fwlp/research_emotion_recognition_using_fusion_of/,cdossman,1562332982,"[https://medium.com/ai%C2%B3-theory-practice-business/emotion-recognition-using-fusion-of-audio-and-video-features-3db8f46dce80](https://medium.com/ai%C2%B3-theory-practice-business/emotion-recognition-using-fusion-of-audio-and-video-features-3db8f46dce80) 

**Abstract:**  In this paper, we propose a fusion approach to continuous emotion recognition that combines visual and auditory modalities in their representation spaces to predict the arousal and valence levels. The proposed approach employs a pre-trained convolution neural network and transfer learning to extract features from video frames that capture the emotional content. For the auditory content, a minimalistic set of parameters such as prosodic, excitation, vocal tract, and spectral descriptors are used as features. The fusion of these two modalities is carried out at a feature level, before training a single support vector regressor (SVR) or at a prediction level, after training one SVR for each modality. The proposed approach also includes preprocessing and postprocessing techniques which contribute favorably to improving the concordance correlation coefficient (CCC). Experimental results for predicting spontaneous and natural emotions on the RECOLA dataset have shown that the proposed approach takes advantage of the complementary information of visual and auditory modalities and provides CCCs of 0.749 and 0.565 for arousal and valence, respectively.",1,16,False,self,,,,,
62,deeplearning,t5_2t5eh,2019-7-5,2019,7,5,23,c9geho,reddit.com,Sketch Notes of Deep Learning,https://www.reddit.com/r/deeplearning/comments/c9geho/sketch_notes_of_deep_learning/,mikasarei,1562335975,,0,1,False,default,,,,,
63,deeplearning,t5_2t5eh,2019-7-6,2019,7,6,3,c9j38x,self.deeplearning,Trying to measure RTX 2080 Ti usage during Deep Learning predictions,https://www.reddit.com/r/deeplearning/comments/c9j38x/trying_to_measure_rtx_2080_ti_usage_during_deep/,arnauda9,1562349768,"Hello everyone ! I am trying to measure the GPU memory usage and the time spent in the GPU during a prediction. I am having a look at NVML library and I do not understand what is the ""sample period"" and why it depends on the hardware.

[Screenshot of the NVML documentation](https://i.redd.it/tg9hh2eswi831.png)

Do you have any advice on what this means ?

Also, if you have a clear explanation on how to analyse memory and time usage, I would be glad to hear it.

Thanks it advance!",0,0,False,self,,,,,
64,deeplearning,t5_2t5eh,2019-7-6,2019,7,6,5,c9kz42,self.deeplearning,Any negative effects of applying 1x1 convolutional layers?,https://www.reddit.com/r/deeplearning/comments/c9kz42/any_negative_effects_of_applying_1x1/,Lucky_Gambler,1562359455,"This most likely is a dumb question, but has anyone here heard of or seen the implementation of 1x1 convolution layers (for specifically reducing computation cost) that actually significantly decreased the performance of a network in training? If so, could you post a link to the source code or paper or GitHub?",8,0,False,self,,,,,
65,deeplearning,t5_2t5eh,2019-7-6,2019,7,6,11,c9oc9n,self.deeplearning,Urgent Help needed. I 'actually' NEED to learn Deep Learning superficially in 3 DAYS. How do I do this?,https://www.reddit.com/r/deeplearning/comments/c9oc9n/urgent_help_needed_i_actually_need_to_learn_deep/,anotheraccount97,1562379405,"I got an internship through my university's 6 month industrial experience program where I was allowed to brag/overstate with fake Skills in order to get allotted a decent organization. I know Soft Dev (Java,DSA etc etc), Python somewhat. 

&amp;#x200B;

They've given me a deep learning profile on the basis of my mention of Tensorflow, Keras etc. Now the intern starts on Monday(3 days from now), so I'll need to learn it superficially so that my manager doesn't get the hint that I was lying. In the course of first week, I wish to learn as much as possible, and then with the ongoing internship of 6 months, I'll try to do my best to become an expert in the same. 

&amp;#x200B;

Please help me by stating exact resources, courses that I can binge through, and videos of workshops/bootcamps that I can go through this Sat/Sun/Mon to gain a presentable knowledge of the DL field, also some ML (I don't know ML too, extremely sorry for the disrespect to this beautiful field). Apologies and Thanks.",13,0,False,self,,,,,
66,deeplearning,t5_2t5eh,2019-7-6,2019,7,6,15,c9qiyx,blog.floydhub.com,How to plan and execute your ML and DL projects,https://www.reddit.com/r/deeplearning/comments/c9qiyx/how_to_plan_and_execute_your_ml_and_dl_projects/,pirate7777777,1562395084,,5,30,False,default,,,,,
67,deeplearning,t5_2t5eh,2019-7-6,2019,7,6,17,c9rbs8,self.deeplearning,How can you constrain the latent variable space of an Autoencoder to quantities that can be interpreted?,https://www.reddit.com/r/deeplearning/comments/c9rbs8/how_can_you_constrain_the_latent_variable_space/,fipeopp,1562401599,,4,4,False,self,,,,,
68,deeplearning,t5_2t5eh,2019-7-6,2019,7,6,17,c9rcqi,self.deeplearning,Which are creative ways to approach customer churn prediction (besides tree-based models or NNs)?,https://www.reddit.com/r/deeplearning/comments/c9rcqi/which_are_creative_ways_to_approach_customer/,fipeopp,1562401835,,0,1,False,self,,,,,
69,deeplearning,t5_2t5eh,2019-7-6,2019,7,6,20,c9sinx,self.deeplearning,RNN hidden state and weights shape,https://www.reddit.com/r/deeplearning/comments/c9sinx/rnn_hidden_state_and_weights_shape/,carnivorousdrew,1562411971,"I am having trouble building a RNN cell from scratch. Theoretically the output of the hidden ste function should be a vector of the same shape as the input, therefore the hidden state, hidden state's weight and input weight should be a different shape than the input, right?
What should their sizes be?",2,2,False,self,,,,,
70,deeplearning,t5_2t5eh,2019-7-6,2019,7,6,22,c9tfzm,self.deeplearning,Big Data,https://www.reddit.com/r/deeplearning/comments/c9tfzm/big_data/,HannahHumphreys,1562418725,[removed],0,1,False,self,,,,,
71,deeplearning,t5_2t5eh,2019-7-7,2019,7,7,3,c9x1o5,self.deeplearning,Keras loss functions: is there a way to get the indeces of the sample(s) being evaluated?,https://www.reddit.com/r/deeplearning/comments/c9x1o5/keras_loss_functions_is_there_a_way_to_get_the/,Dampware,1562438609,"Disclaimer: I'm relatively new to dl, so I'm very appreciative of any consideration you may give this. 

I have data that includes an image, label as well as some auxiliary tabular data for each sample.

The results I seek are a regression from the image only; in deployment, the associated auxiliary tabular data will not be present, so I don't wish to consider the tabular data in the nn or the regression results. However, I do wish to consider the auxiliary data in the loss function, to penalize the predictions. 

So I'm imagining something like this:
During training, as a prediction and loss is generated for each image / batch, I would use the prediction, the label and the auxiliary tabular data to alter the loss appropriately, before backprop.

To do this I'd need the indices of the samples being considered by the loss function to access the associated aux data. I haven't found a way to access those indices.

Any thoughts? Is this even feasible (using keras w tf) ?

Again, thanks for your time.",7,5,False,self,,,,,
72,deeplearning,t5_2t5eh,2019-7-7,2019,7,7,10,ca1moc,self.deeplearning,Convlutional implementation of sliding window Algorithm,https://www.reddit.com/r/deeplearning/comments/ca1moc/convlutional_implementation_of_sliding_window/,tahamagdy,1562464775,"I understand the convolutional implementation mechanism, My problem is that I don't know why the it is equivalent to the sequential sliding windows?!",2,2,False,self,,,,,
73,deeplearning,t5_2t5eh,2019-7-7,2019,7,7,17,ca4r34,self.deeplearning,looking for RTX 2080 Ti air blower coolers as separate component,https://www.reddit.com/r/deeplearning/comments/ca4r34/looking_for_rtx_2080_ti_air_blower_coolers_as/,gpuace,1562488982,"Does anybody know if one can buy RTX 2080 Ti air blower coolers seperatly? Are there companies out there or is there someone who has replaced the RTX 2080 Ti air blower cooler with a water cooler and has one or numerous to spare now? If yes, please send a message with your offer (with shipment to Germany).",3,5,False,self,,,,,
74,deeplearning,t5_2t5eh,2019-7-7,2019,7,7,18,ca4wb3,self.deeplearning,"Did you know that if you watch ""The Thing"" with the subtitles on you can read the sounds of diarreah?",https://www.reddit.com/r/deeplearning/comments/ca4wb3/did_you_know_that_if_you_watch_the_thing_with_the/,shitknifeactual,1562490331,,1,0,False,self,,,,,
75,deeplearning,t5_2t5eh,2019-7-7,2019,7,7,20,ca5xob,self.deeplearning,Big Data Analytics Projects with Apache Spark,https://www.reddit.com/r/deeplearning/comments/ca5xob/big_data_analytics_projects_with_apache_spark/,HannahHumphreys,1562499529,[removed],0,1,False,self,,,,,
76,deeplearning,t5_2t5eh,2019-7-8,2019,7,8,0,ca82ac,self.deeplearning,My first journal entry.,https://www.reddit.com/r/deeplearning/comments/ca82ac/my_first_journal_entry/,jager_2798,1562513531,"Recently my publication titled:  ""Diagnosis of melanoma from dermoscopic images using a deep depthwise separable residual convolutional network "", was accepted at IET Image Processing. We used the ISIC dataset to train our network. Publication link:  [http://ietdl.org/t/h1Rq7b](http://ietdl.org/t/h1Rq7b)",6,20,False,self,,,,,
77,deeplearning,t5_2t5eh,2019-7-8,2019,7,8,14,cagrjt,analyticsindiamag.com,Google Makes DL Model Deployment Easy With Deep Learning Cloud Containers,https://www.reddit.com/r/deeplearning/comments/cagrjt/google_makes_dl_model_deployment_easy_with_deep/,analyticsindiam,1562562091,,1,27,False,default,,,,,
78,deeplearning,t5_2t5eh,2019-7-8,2019,7,8,17,caiily,self.deeplearning,New AMD Navi GPUs for deep learning,https://www.reddit.com/r/deeplearning/comments/caiily/new_amd_navi_gpus_for_deep_learning/,drr21,1562575451,What do you think about the new AMD GPUs for deep learning. Will they be a good alternative to Nvidia?,12,15,False,self,,,,,
79,deeplearning,t5_2t5eh,2019-7-8,2019,7,8,17,cailvn,self.reinforcementlearning,[RL] Tensorflow.js and GridWorld - From Value Fuction to A3C,https://www.reddit.com/r/deeplearning/comments/cailvn/rl_tensorflowjs_and_gridworld_from_value_fuction/,greentecq,1562576224,,0,1,False,default,,,,,
80,deeplearning,t5_2t5eh,2019-7-8,2019,7,8,18,cairc6,self.deeplearning,Paper with experimental results on when transfer learning makes sense,https://www.reddit.com/r/deeplearning/comments/cairc6/paper_with_experimental_results_on_when_transfer/,pppeer,1562577373,"(also posted in r/MachineLearning)

We wrote a paper with test results on when it makes sense to use transfer learning. The paper was published at IDA a while ago, but I still see this question pop up regularly, and I am also interested in what has been published since on this topic, as proper benchmarking to answer this question still seems to be lacking.

In a nut shell the answer of course is 'when you don't have enough data', but we quantified this through experimentation by varying the number of instances per class, as well as the number of layers 'copied' and more.

The intuition behind the paper is described in this medium post, and you will also find a link to a preprint should you not have access to the conference paper. See [https://medium.com/@petervanderputten/teaching-and-old-dog-new-tricks-transfer-learning-in-deep-neural-networks-ca85992119ec](https://medium.com/@petervanderputten/teaching-and-old-dog-new-tricks-transfer-learning-in-deep-neural-networks-ca85992119ec)

Feedback welcome!",4,1,False,self,,,,,
81,deeplearning,t5_2t5eh,2019-7-8,2019,7,8,19,cajafn,self.deeplearning,"Does DNN really understand what a ""digits"" means?",https://www.reddit.com/r/deeplearning/comments/cajafn/does_dnn_really_understand_what_a_digits_means/,rockking_jy,1562581310,"I've trained on MNIST(I know it's a bit ancient) with a DNN that's achieve above 99%, but then I use it on my own digit dataset, it's just around 11%. I know the distribution of these two datasets are not the same. But we human beings can figure out the new images with digits.",15,3,False,self,,,,,
82,deeplearning,t5_2t5eh,2019-7-8,2019,7,8,20,cajvtr,analyticsindiamag.com,Deep Learning Can Now Find Galaxies That Are Million Of Lightyears Away,https://www.reddit.com/r/deeplearning/comments/cajvtr/deep_learning_can_now_find_galaxies_that_are/,analyticsindiam,1562585534,,0,6,False,default,,,,,
83,deeplearning,t5_2t5eh,2019-7-8,2019,7,8,20,cajwfq,self.deeplearning,Does anybody know where can i find a pre-trained text detection network?,https://www.reddit.com/r/deeplearning/comments/cajwfq/does_anybody_know_where_can_i_find_a_pretrained/,pcrca,1562585647,I'm working on a text detection/recognition task and i don't have the time or resources to train something from scratch so i'm looking for a ready-to-use network for text detection/recogniton,2,1,False,self,,,,,
84,deeplearning,t5_2t5eh,2019-7-8,2019,7,8,21,cakm3c,self.deeplearning,Deep Nude Algorithm,https://www.reddit.com/r/deeplearning/comments/cakm3c/deep_nude_algorithm/,frankshawn1992,1562590151,I found out that Deep Nude algorithm was deleted from github. Did anyone clone it? Can you please share it?,59,0,False,self,,,,,
85,deeplearning,t5_2t5eh,2019-7-8,2019,7,8,22,cal8nb,self.deeplearning,Bayesian Machine Learning in Python: A/B Testing,https://www.reddit.com/r/deeplearning/comments/cal8nb/bayesian_machine_learning_in_python_ab_testing/,HannahHumphreys,1562593655,[removed],0,1,False,self,,,,,
86,deeplearning,t5_2t5eh,2019-7-8,2019,7,8,23,caljhk,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/caljhk/data_science_career_track_prep_course/,HannahHumphreys,1562595181,[removed],0,1,False,self,,,,,
87,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,3,caoit2,nature.com,HyperFoods: Machine intelligent mapping of cancer-beating molecules in foods,https://www.reddit.com/r/deeplearning/comments/caoit2/hyperfoods_machine_intelligent_mapping_of/,srohit0,1562609051,,2,4,False,default,,,,,
88,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,6,carki1,self.deeplearning,Using Doc2Vec to classify movie reviews,https://www.reddit.com/r/deeplearning/comments/carki1/using_doc2vec_to_classify_movie_reviews/,jdyr1729,1562622928,"Hi,

I just wrote an article explaining how to use gensim's implementation of Paragraph Vector, Doc2Vec, to achieve a state-of-the-art-result on the IMDB movie review problem. 

Thought I'd share it here for anyone who is interested: https://jackdry.com/using-doc2vec-to-classify-movie-reviews 

Hope you find it helpful!

Jack",2,28,False,self,,,,,
89,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,9,catlct,youtube.com,This video goes over a breast cancer diagnosis model that uses neural networks (implemented in python),https://www.reddit.com/r/deeplearning/comments/catlct/this_video_goes_over_a_breast_cancer_diagnosis/,antaloaalonso,1562633254,,0,2,False,image,,,,,
90,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,9,catp63,worthdoingbadly.com,"Researcher tricks m3.euagendas.org, the Twitter analysis website, with adversarial inputs",https://www.reddit.com/r/deeplearning/comments/catp63/researcher_tricks_m3euagendasorg_the_twitter/,atomlib_com,1562633849,,0,1,False,default,,,,,
91,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,12,cav2hp,self.deeplearning,Simple question about siamese nets,https://www.reddit.com/r/deeplearning/comments/cav2hp/simple_question_about_siamese_nets/,hassanzadeh,1562641316,"Hello guys,

what do u call each of the arms in a siamese net?

THanks",0,2,False,self,,,,,
92,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,14,cawakw,/r/deeplearning/comments/cawakw/decoding_synthetic_character_into_real_human/,Decoding synthetic character into real human,https://www.reddit.com/r/deeplearning/comments/cawakw/decoding_synthetic_character_into_real_human/,rozgo,1562648622,,2,7,False,default,,,,,
93,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,17,cay4jz,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cay4jz/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1562661209,[removed],0,1,False,self,,,,,
94,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,17,cay6rf,self.deeplearning,Lie detection with EEG sensor,https://www.reddit.com/r/deeplearning/comments/cay6rf/lie_detection_with_eeg_sensor/,clean_pegasus,1562661666,Is it possible to find out if someone is telling the truth using deep learning and neural networks?,2,3,False,self,,,,,
95,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,18,cayd73,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cayd73/data_science_career_track_prep_course/,HannahHumphreys,1562663001,[removed],0,1,False,self,,,,,
96,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,18,caygml,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/caygml/data_science_career_track_prep_course/,HannahHumphreys,1562663711,[removed],0,1,False,self,,,,,
97,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,18,cayl4n,analyticsindiamag.com,Why Do Neural Networks Generalize So Effortlessly And Other Questions,https://www.reddit.com/r/deeplearning/comments/cayl4n/why_do_neural_networks_generalize_so_effortlessly/,analyticsindiam,1562664604,,0,6,False,default,,,,,
98,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,18,cayohj,self.deeplearning,Bokeh effect with semantic segmentation or instance segmentation.,https://www.reddit.com/r/deeplearning/comments/cayohj/bokeh_effect_with_semantic_segmentation_or/,clean_pegasus,1562665264,Does Google pixel phones use semantic segmentation or instance segmentation for Bokeh effect?,0,1,False,self,,,,,
99,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,18,cayqlf,youtube.com,Astounding deepfake of Jim Carrey in the Shining.,https://www.reddit.com/r/deeplearning/comments/cayqlf/astounding_deepfake_of_jim_carrey_in_the_shining/,OwlKneeArn,1562665672,,18,79,False,image,,,,,
100,deeplearning,t5_2t5eh,2019-7-9,2019,7,9,22,cb0nr6,blog.esciencecenter.nl,Blogpost - Turning a panda into a cat? Why adversarial examples are not scarybut are most likely useful,https://www.reddit.com/r/deeplearning/comments/cb0nr6/blogpost_turning_a_panda_into_a_cat_why/,sonjageorg,1562677723,,0,1,False,default,,,,,
101,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,0,cb21uz,youtube.com,Put down the deep learning: When not to use neural networks and what to do instead,https://www.reddit.com/r/deeplearning/comments/cb21uz/put_down_the_deep_learning_when_not_to_use_neural/,ConfidentMushroom,1562684710,,0,8,False,image,,,,,
102,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,0,cb268i,intellectyx.com,The Role of AI and Machine Learning in Data Quality,https://www.reddit.com/r/deeplearning/comments/cb268i/the_role_of_ai_and_machine_learning_in_data/,raj11113,1562685292,,0,1,False,default,,,,,
103,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,1,cb37i7,aiprobook.com,"[WIP book] Deep Learning for Programmers, new release 0.5.0",https://www.reddit.com/r/deeplearning/comments/cb37i7/wip_book_deep_learning_for_programmers_new/,dragandj,1562690059,,0,2,False,default,,,,,
104,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,2,cb43b1,self.deeplearning,Video Classification - LSTM and 3DConv,https://www.reddit.com/r/deeplearning/comments/cb43b1/video_classification_lstm_and_3dconv/,Beukgevaar,1562693994,"Currently I'm looking into the aspect of Video Classification using python and Keras/Tensorflow, but I'm encountering some errors.

&amp;#x200B;

Basic idea: Trying to identify certain movements from video, which are already split into train and test with subfolders per label with its extracted frames.

&amp;#x200B;

For now this is my code for the LSTM network:

`train_data_dir = './train'`

`validation_data_dir = './test'`

`nb_train_samples = 46822`

`nb_validation_samples = 8994`

`epochs = 10`

`batch_size = 16`

&amp;#x200B;

`input_shape = (img_width, img_height, 3)`

&amp;#x200B;

`#TimeDistributed CNN + LSTM`

`model = Sequential()` 

`model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2), padding='same', input_shape=(224, 135, 3))))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(Conv2D(32, (3,3), kernel_initializer=""he_normal"")))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))`

 

`model.add(TimeDistributed(Conv2D(64, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(Conv2D(64, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))`

 

`model.add(TimeDistributed(Conv2D(128, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(Conv2D(128, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))`

 

`model.add(TimeDistributed(Conv2D(256, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(Conv2D(256, (3,3), padding='same',)))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))`

 

`model.add(TimeDistributed(Conv2D(512, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(Conv2D(512, (3,3), padding='same')))`

`model.add(TimeDistributed(Activation('relu')))`

`model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))`

 

`model.add(TimeDistributed(Flatten()))`

&amp;#x200B;

`model.add(Dropout(0.5))`

`model.add(LSTM(256, return_sequences=False, dropout=0.5))`

`model.add(Dense(6))`

`model.add(Activation('softmax'))`  


`model.compile(loss ='categorical_crossentropy', optimizer ='rmsprop', metrics =['accuracy'])`  
`model.summary()`

&amp;#x200B;

`train_datagen = ImageDataGenerator(rescale = 1. / 255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)` 

`test_datagen = ImageDataGenerator(rescale = 1. / 255)`

`train_generator = train_datagen.flow_from_directory(train_data_dir, target_size =(img_width, img_height), batch_size = batch_size, class_mode ='categorical')` 

`validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size =(img_width, img_height), batch_size = batch_size, class_mode ='categorical')` 

`model.fit_generator(train_generator, steps_per_epoch = nb_train_samples // batch_size, epochs = epochs, validation_data = validation_generator, validation_steps = nb_validation_samples // batch_size)`

&amp;#x200B;

And for the 3D Convolutional Network:

......

`model = Sequential()` 

`model.add(Conv3D(32, (3,3,3), input_shape=(20, 224, 135, 3)))`

`model.add(Activation('relu'))`

`model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))`

`model.add(Conv3D(64, (3,3,3)))`

`model.add(Activation('relu'))`

`model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))`

`model.add(Conv3D(128, (3,3,3)))`

`model.add(Activation('relu'))`

`model.add(Conv3D(128, (3,3,3)))`

`model.add(Activation('relu'))`

`model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))`

`model.add(Conv3D(256, (2,2,2)))`

`model.add(Activation('relu'))`

`model.add(Conv3D(256, (2,2,2)))`

`model.add(Activation('relu'))`

`model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))`

 

`model.add(Flatten())`

`model.add(Dense(1024))`

`model.add(Dropout(0.5))`

`model.add(Dense(1024))`

`model.add(Dropout(0.5))`

`model.add(Dense(6, activation='softmax'))`

......

&amp;#x200B;

But for each of these code 1 get an error:

\- LSTM --&gt; *ValueError: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input\_shape or batch\_input\_shape in the first layer for automatic build.*

It seems like it is ignoring the model.compile line? Or am I missing something?

&amp;#x200B;

\- 3DConv --&gt; *ValueError: Error when checking input: expected conv3d\_1\_input to have 5 dimensions, but got array with shape (16, 224, 135, 3)*  
I have no idea how/where to add the extra dimension for the model.fit\_generator.

&amp;#x200B;

Hope there is someone who is able to assist me with the above.",0,1,False,self,,,,,
105,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,3,cb557v,self.deeplearning,Awesome AI research reviews: BEST OF CVPR 2019 on Computer Vision News of July (with codes!),https://www.reddit.com/r/deeplearning/comments/cb557v/awesome_ai_research_reviews_best_of_cvpr_2019_on/,Gletta,1562698634,"The July issue of Computer Vision News includes RSIP Vision's choices for BEST OF CVPR 2019.

Read 48 pages with exclusive articles on AI, computer vision and deep learning.

Exclusive interview with Andrew Fitzgibbon on page 20. Subscribe for free on page 48!

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019July/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-july-pdf/)

Enjoy!

&amp;#x200B;

https://i.redd.it/ebp5l24srb931.jpg",0,22,False,self,,,,,
106,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,5,cb6jkg,self.deeplearning,Custom loss function for occluded landmarks detection,https://www.reddit.com/r/deeplearning/comments/cb6jkg/custom_loss_function_for_occluded_landmarks/,nikogamulin,1562704876,"Hi,

I am building a model which is supposed to detect at most 6 different landmarks on the image. In some cases, some landmarks are occluded.

The output is an 18-dimensional vector. First 6 values are binary (0/1) and determine whether the landmark is visible or occluded. the remaining 12 values represent x and y coordinates for 6 landmarks. The x and y values for occluded landmarks are 0.

The output layer consists of 6 sigmoid and 12 linear units.

The loss function is defined as follows:

`def custom_loss(y_true, y_pred):`

`cLP_true, cRP_true, cCTL_true, cCTR_true, cCBR_true, cCBL_true, yLP_true, xLP_true, yRP_true, xRP_true, yCTL_true,`   
  `xCTL_true, yCTR_true, xCTR_true, yCBR_true, xCBR_true, yCBL_true, xCBL_true = tf.split(y_true, num_or_size_splits=18, axis=1)`

`cLP_pred, cRP_pred, cCTL_pred, cCTR_pred, cCBR_pred, cCBL_pred, yLP_pred, xLP_pred, yRP_pred, xRP_pred, yCTL_pred, xCTL_pred, yCTR_pred, xCTR_pred, yCBR_pred, xCBR_pred, yCBL_pred, xCBL_pred = tf.split(y_pred, num_or_size_splits=18, axis=1)`

`loss_regression = 0`

`loss_regression += cLP_true * ((yLP_pred - yLP_true)**2 + (xLP_pred - xLP_true)**2)`

`loss_regression += cRP_true * ((yRP_pred - yRP_true)**2 + (xRP_pred - xRP_true)**2)`

`loss_regression += cCTL_true * ((yCTL_pred - yCTL_true)**2 + (xCTL_pred - xCTL_true)**2)`

`loss_regression += cCTR_true * ((yCTR_pred - yCTR_true)**2 + (xCTR_pred - xCTR_true)**2)`

`loss_regression += cCBR_true * ((yCBR_pred - yCBR_true)**2 + (xCBR_pred - xCBR_true)**2)`

`loss_regression += cCBL_true * ((yCBL_true - yCBL_pred)**2 + (xCBL_pred - xCBL_true)**2)`



`loss_class = binaryCE([cLP_true, cRP_true, cCTL_true, cCTR_true, cCBR_true, cCBL_true], [cLP_pred, cRP_pred, cCTL_pred, cCTR_pred, cCBR_pred, cCBL_pred])`

   

`return loss_regression + 10 * loss_class`

&amp;#x200B;

I would appreciate any comment/suggestion for further improvement.",0,1,False,self,,,,,
107,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,6,cb6uz9,self.deeplearning,Image Data Augmentation for Deep Learning,https://www.reddit.com/r/deeplearning/comments/cb6uz9/image_data_augmentation_for_deep_learning/,HenryAILabs,1562706304,[https://www.youtube.com/watch?v=mljRx81K1gY](https://www.youtube.com/watch?v=mljRx81K1gY),0,2,False,self,,,,,
108,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,6,cb7fcn,self.deeplearning,"Few-shot, weakly or semi-supervised learning if only have 20 training images for segmentation?",https://www.reddit.com/r/deeplearning/comments/cb7fcn/fewshot_weakly_or_semisupervised_learning_if_only/,b3873656,1562708917,"I have a training set of 20 images of semiconductors that I need to perform segmentation for. I was thinking semantic or salient segmentation would work

I'm new to deep learning. From what i understand, semantic segmentation usually requires at least thousands of training images to get good results. But since I only have 20 images, I'm not sure what to do instead. Should I look into few-shot semantic segmentation methods? Or methods that do weakly/semi-supervised learning? What about domain adaptation/transfer learning? 

Or could I just use those 20 images to create like 100,000 images using augmentation, and then use semantic segmentation?

How should I approach this problem?",3,1,False,self,,,,,
109,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,11,cbaqdn,youtube.com,Artificial Intelligence: Become An Expert,https://www.reddit.com/r/deeplearning/comments/cbaqdn/artificial_intelligence_become_an_expert/,ashleymadison1750,1562725817,,0,0,False,default,,,,,
110,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,11,cbarwk,pubs.rsna.org,Management of Thyroid Nodules Seen on US Images: Deep Learning May Match Performance of Radiologists,https://www.reddit.com/r/deeplearning/comments/cbarwk/management_of_thyroid_nodules_seen_on_us_images/,ketsok,1562726059,,0,3,False,default,,,,,
111,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,12,cbbh8j,self.deeplearning,"How do you set up a DBN when the data is the shape of a space, or when the space into which the data is embedded is non Euclidean?",https://www.reddit.com/r/deeplearning/comments/cbbh8j/how_do_you_set_up_a_dbn_when_the_data_is_the/,IntrepidDust,1562729990,"How do you set up a DBN when the data is the shape of a space, such as with a relational database, or when the space into which the data is embedded is non Euclidean, such as on the surface of a sphere or inside a fractal, such as an organ or organism?",0,0,False,self,,,,,
112,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,14,cbcrlg,self.deeplearning,From Online Courses to Reading Papers,https://www.reddit.com/r/deeplearning/comments/cbcrlg/from_online_courses_to_reading_papers/,patronus816,1562737751,"Hi! I finished Andrew Ng's courses on Deep Learning except the RNN part which was the last module I think? I'm also looking into taking a Master's in Machine Learning and I want it to be computer vision focused. 

I was wondering if there was a bridge between the Ng Courses and individually reading the ""State of the art"" papers? I'm trying to get myself to read these papers as they might potentially lead me to a topic/problem I want to focus on for my Master's thanks!",4,5,False,self,,,,,
113,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,16,cbdv0w,self.deeplearning,Deepfake video detection. Is it possible?,https://www.reddit.com/r/deeplearning/comments/cbdv0w/deepfake_video_detection_is_it_possible/,testimoni,1562745451,"Hello,

&amp;#x200B;

I am new here and recently became aware of deepfake videos and it amazed me. I was just thinking if there is a way to determine a video containg deepfake content or not? For example, user upload a video to see if this video is deepfake or not. How to determine it programmatically?",12,11,False,self,,,,,
114,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,18,cbehnu,blog.tensorpad.com,Introduction to TensorWatch,https://www.reddit.com/r/deeplearning/comments/cbehnu/introduction_to_tensorwatch/,whitezl0,1562750460,,0,6,False,default,,,,,
115,deeplearning,t5_2t5eh,2019-7-10,2019,7,10,20,cbfpr4,analyticsindiamag.com,Someone Finally Done It: DeepFaked Jim Carrey Into The Shining,https://www.reddit.com/r/deeplearning/comments/cbfpr4/someone_finally_done_it_deepfaked_jim_carrey_into/,analyticsindiam,1562759272,,0,2,False,default,,,,,
116,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,0,cbi9ds,medium.com,Are Commercial Labs Stealing Academias AI Thunder?,https://www.reddit.com/r/deeplearning/comments/cbi9ds/are_commercial_labs_stealing_academias_ai_thunder/,Yuqing7,1562773145,,3,23,False,default,,,,,
117,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,0,cbiijy,i.redd.it,Can anyone apply DeepNude on this photo?,https://www.reddit.com/r/deeplearning/comments/cbiijy/can_anyone_apply_deepnude_on_this_photo/,frankshawn1992,1562774372,,11,0,False,image,,,,,
118,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,2,cbjbzx,self.deeplearning,SQL for Data Science,https://www.reddit.com/r/deeplearning/comments/cbjbzx/sql_for_data_science/,HannahHumphreys,1562778229,[removed],0,1,False,self,,,,,
119,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,2,cbjjm9,i.redd.it,Cleft Facial Lip and Palate Images,https://www.reddit.com/r/deeplearning/comments/cbjjm9/cleft_facial_lip_and_palate_images/,samisoomro24,1562779206,,0,2,False,image,,,,,
120,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,3,cbkbw7,self.deeplearning,How to transform stock data for LSTM-based neural network,https://www.reddit.com/r/deeplearning/comments/cbkbw7/how_to_transform_stock_data_for_lstmbased_neural/,jdyr1729,1562782825,"I am trying to classify stock returns using an LSTM-based neural network.

I would like to use closing price and volume as features (see below), but am unsure of whether I need to transform these (e.g., by differencing) before feeding them into the network?

If anybody has done this sort of thing before and could give me some advice, or could refer me to any papers, I'd be very grateful.

[Closing price and volume](https://i.redd.it/p7n7zun4qi931.png)

Thanks,

Jack",3,1,False,self,,,,,
121,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,12,cbqovr,self.deeplearning,Announcing a series of blogs on PyTorch C++ API (Libtorch),https://www.reddit.com/r/deeplearning/comments/cbqovr/announcing_a_series_of_blogs_on_pytorch_c_api/,Kushashwa,1562815750,"Hi everyone. 

I'm happy to announce a series of blogs on PyTorch C++ API. When I started using the C++ API, I had lots of problems and thanks to the community at [discuss.pytorch.com](https://discuss.pytorch.com) where I got most of the help. I decided to write blogs on using C++ API for the community. Here it comes! 

There have been 3 blogs as of now, and I would love to hear your comments and feedback on them.

 [https://krshrimali.github.io/Announcing-PyTorch-CPP-Series/](https://krshrimali.github.io/Announcing-PyTorch-CPP-Series/) 

&amp;#x200B;

[Announcing PyTorch C++ API Series! - krshrimali.github.io](https://i.redd.it/ez8mwe51gl931.png)

Thanks!",8,41,False,self,,,,,
122,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,15,cbsjcx,stackraft.com,"[HIRING] Machine Learning Engineer, FTE, Redwood City, CA, Salary : 140000 - 220000 USD",https://www.reddit.com/r/deeplearning/comments/cbsjcx/hiring_machine_learning_engineer_fte_redwood_city/,vmanasvi,1562828230,,0,0,False,default,,,,,
123,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,16,cbslo9,i.redd.it,Can anybody explain the formulation of the minmax game in GANs ?,https://www.reddit.com/r/deeplearning/comments/cbslo9/can_anybody_explain_the_formulation_of_the_minmax/,styx97,1562828696,,6,5,False,image,,,,,
124,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,19,cbtykw,intellectyx.com,How big data is transforming the real estate industry,https://www.reddit.com/r/deeplearning/comments/cbtykw/how_big_data_is_transforming_the_real_estate/,raj11113,1562839706,,0,1,False,default,,,,,
125,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,19,cbuceh,self.deeplearning,Weakly Supervised Object Detection In Practice,https://www.reddit.com/r/deeplearning/comments/cbuceh/weakly_supervised_object_detection_in_practice/,tahaemara,1562842600,"I published a new post on how to make a classification model performs both object classification and object localization in a single forward pass.

[http://emaraic.com/blog/weakly-supervised-detection](http://emaraic.com/blog/weakly-supervised-detection)",0,3,False,self,,,,,
126,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,21,cbv05j,self.deeplearning,cdQA  a software-suite for easy implementation of Question Answering systems,https://www.reddit.com/r/deeplearning/comments/cbv05j/cdqa_a_softwaresuite_for_easy_implementation_of/,crAAzyKKid,1562847059,"Hi,

&amp;#x200B;

With some colleagues I developed an end-to-end software suite for easy implementation and deployment of Question-Answering systems in Python. It uses a pipeline with classical Information Retrieval techniques and the Deep Learning model BERT.

[https://cdqa-suite.github.io/cdQA-website/](https://cdqa-suite.github.io/cdQA-website/)

[https://github.com/cdqa-suite/cdQA](https://github.com/cdqa-suite/cdQA)

&amp;#x200B;

We wrote an article in TDS explaining how to implement it easily: [https://towardsdatascience.com/how-to-create-your-own-question-answering-system-easily-with-python-2ef8abc8eb5](https://towardsdatascience.com/how-to-create-your-own-question-answering-system-easily-with-python-2ef8abc8eb5)

&amp;#x200B;

Don't hesitate to reach me out if you have questions, comments or ideas of improvement",1,4,False,self,,,,,
127,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,22,cbvkl8,self.deeplearning,Is discussion of deepnudes ban in this subreddit or not?,https://www.reddit.com/r/deeplearning/comments/cbvkl8/is_discussion_of_deepnudes_ban_in_this_subreddit/,apostle8787,1562850768,,0,6,False,self,,,,,
128,deeplearning,t5_2t5eh,2019-7-11,2019,7,11,23,cbw5fm,self.deeplearning,How to start with time series forecasting??,https://www.reddit.com/r/deeplearning/comments/cbw5fm/how_to_start_with_time_series_forecasting/,drag_97,1562854783,I have experience with CNN and NN but I want to make some projects on time series forecasting using LSTM . Any advice where should I start?,0,1,False,self,,,,,
129,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,0,cbwlra,self.deeplearning,The 5th Place Approach to the 2019 ACM Recsys Challenge by Team RosettaAI,https://www.reddit.com/r/deeplearning/comments/cbwlra/the_5th_place_approach_to_the_2019_acm_recsys/,steeveHuang,1562857382,"Just finished the writeup for our 5th place solution in the 2019 ACM RecSys Challenge! This blog post will talk about the datasets, the loss function, the Neural Networks architecture, and feature engineering. Hope you enjoy it :)

&amp;#x200B;

[https://blog.rosetta.ai/the-5th-place-approach-to-the-2019-acm-recsys-challenge-by-team-rosettaai-eb3c4e6178c4](https://blog.rosetta.ai/the-5th-place-approach-to-the-2019-acm-recsys-challenge-by-team-rosettaai-eb3c4e6178c4)",0,1,False,self,,,,,
130,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,1,cbxnky,self.deeplearning,NLP inference in floating point?,https://www.reddit.com/r/deeplearning/comments/cbxnky/nlp_inference_in_floating_point/,CArchGuy,1562862297,Are there any current NLP models that require floating point operations in inference rather than fixed point ? Thanks,0,1,False,self,,,,,
131,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,4,cbzqp2,self.deeplearning,AI To Save Snow Leopards,https://www.reddit.com/r/deeplearning/comments/cbzqp2/ai_to_save_snow_leopards/,lomiag,1562871826," I know Microsoft has been all over news with their AI that helps snow leopard preservation community. But I work for a small non-profit organization Kashmir World Foundation, and during my internship I created a program to detect snow leopard in the wild and classify them. So the preservation workers do not spend their valuable time sorting them. Just wanted to share it here.

![img](9s1luucr2q931)

![img](4s3cnotr2q931)",12,45,False,self,,,,,
132,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,7,cc2751,self.deeplearning,My general understanding to fully connect layer in the neural network.,https://www.reddit.com/r/deeplearning/comments/cc2751/my_general_understanding_to_fully_connect_layer/,jacky_guo,1562883392,"Hi, I have been doing import tensorflow for years. Last night, I was thinking about how the Linear layer works and it reminded me of the basic linear algebra. I want to share my thoughts and hope pytorcher and tensorflowers please leave some comments! 

&amp;#x200B;

From feedforward perspective: Applying Linear layer to tensors (vector) is literally doing space transformation, this transformation should better disentangle the original vector into a better space (projected onto the basis) for downstream tasks (eg:classification).

&amp;#x200B;

From optimization (backward) perspective: Learning a linear layer is finding the transformation basis, so the data in the original space can be better represented in another space (E.g.: output space with two dimensions in the binary classification case).

&amp;#x200B;

Is my understanding correct?",1,1,False,self,,,,,
133,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,8,cc2unk,self.deeplearning,GPU to run object detection and segmentation model (Under $250),https://www.reddit.com/r/deeplearning/comments/cc2unk/gpu_to_run_object_detection_and_segmentation/,fiorano10,1562886739,"We have a robot with a mini ITX PC and were trying to add a GPU to running our detection and segmentation models (pre-trained). Its enclosed in a sealed box so were looking for a low profile GPU. I found the 1050Ti and 1650 to be good contenders but couldnt find a low profile version for the 1650 under $250. The 1650 has more CUDA cores, and performs 30-50% better. Are there any other options under $250 which we should be looking at?",6,5,False,self,,,,,
134,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,8,cc3dbp,self.deeplearning,What type of NN would be best for auto punctuation?,https://www.reddit.com/r/deeplearning/comments/cc3dbp/what_type_of_nn_would_be_best_for_auto_punctuation/,TheDigitalRhino,1562889486,,0,1,False,self,,,,,
135,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,11,cc4y3w,self.deeplearning,Using deep learning to actually learn more efficiently,https://www.reddit.com/r/deeplearning/comments/cc4y3w/using_deep_learning_to_actually_learn_more/,backtoreality0101,1562898471,"Does anyone know of any example programs/code that has been used to help people be more efficient in how they learn or keep up with their respective literature? I work in academics and was wondering if there is a way to combine twitter databases from my field, with text books from the field and then high impact journal publications to create an algorithm that could then be used to learn better? Any ideas on this? Anyone working on something like this?",2,6,False,self,,,,,
136,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,15,cc76x3,towardsdatascience.com,Not just another GAN paper  SAGAN,https://www.reddit.com/r/deeplearning/comments/cc76x3/not_just_another_gan_paper_sagan/,Shemetz,1562912836,,2,6,False,default,,,,,
137,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,18,cc8foi,self.deeplearning,Deep Learning and Modern Natural Language Processing (NLP),https://www.reddit.com/r/deeplearning/comments/cc8foi/deep_learning_and_modern_natural_language/,Amber3825,1562922305, [https://morioh.com/p/c71ad53ac79d](https://morioh.com/p/c71ad53ac79d),1,10,False,self,,,,,
138,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,18,cc8ft6,self.deeplearning,Advanced Artificial Intelligence Projects with Python,https://www.reddit.com/r/deeplearning/comments/cc8ft6/advanced_artificial_intelligence_projects_with/,HannahHumphreys,1562922330,[removed],0,1,False,self,,,,,
139,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,19,cc8wx2,self.deeplearning,Are rtx 2070 max q laptops good for deep learning?,https://www.reddit.com/r/deeplearning/comments/cc8wx2/are_rtx_2070_max_q_laptops_good_for_deep_learning/,ar0752545,1562925778,,13,8,False,self,,,,,
140,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,19,cc8xnm,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cc8xnm/data_science_career_track_prep_course/,HannahHumphreys,1562925915,[removed],0,1,False,self,,,,,
141,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,20,cc9ikg,self.deeplearning,NVIDIA 1050Ti vs 1650,https://www.reddit.com/r/deeplearning/comments/cc9ikg/nvidia_1050ti_vs_1650/,ai_badger,1562930002,Which GPU is better for deep learning? Any compatibility issues with either of the the aforementioned GPUs with Tensorflow/PyTorch?,10,2,False,self,,,,,
142,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,22,ccaxae,self.deeplearning,Introduction to PyTorch,https://www.reddit.com/r/deeplearning/comments/ccaxae/introduction_to_pytorch/,MaryDBlackwell,1562938505, [https://medium.com/@LisaMariaz/introduction-to-pytorch-291c0ebd7090](https://medium.com/@LisaMariaz/introduction-to-pytorch-291c0ebd7090),0,6,False,self,,,,,
143,deeplearning,t5_2t5eh,2019-7-12,2019,7,12,22,ccaykn,self.deeplearning,[Research] How we do things with words: Analyzing text as social and cultural data,https://www.reddit.com/r/deeplearning/comments/ccaykn/research_how_we_do_things_with_words_analyzing/,cdossman,1562938702,"[https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-computational-text-analysis-analyzing-text-as-social-and-cultural-data-19139f65d484](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-computational-text-analysis-analyzing-text-as-social-and-cultural-data-19139f65d484) 

Abstract:  In this paper, we have consolidated our experiences, as scholars from very different disciplines, in analyzing text as social and cultural data and described how the research process often unfolds. Each of the steps in the process is time-consuming and labor-intensive. Each presents challenges. And especially when working across disciplines, the research often involves a fair amount of discussioneven negotiationabout what means of operationalization and approaches to analysis are appropriate and feasible. And yet, with a bit of perseverance and mutual understanding, conceptually sound and meaningful work results so that we can truly make use of the exciting opportunities rich textual data offers.",0,3,False,self,,,,,
144,deeplearning,t5_2t5eh,2019-7-13,2019,7,13,0,ccc7hy,medium.com,AI-Based Photo Restoration,https://www.reddit.com/r/deeplearning/comments/ccc7hy/aibased_photo_restoration/,pvl18,1562944828,,2,51,False,default,,,,,
145,deeplearning,t5_2t5eh,2019-7-13,2019,7,13,0,cccjm7,self.deeplearning,How to make an image based mode to work on videos?,https://www.reddit.com/r/deeplearning/comments/cccjm7/how_to_make_an_image_based_mode_to_work_on_videos/,AhmedZubairGCU,1562946431,I am looking to make [VITON](https://arxiv.org/pdf/1711.08447.pdf) to work on videos preferably in real time like snapchat filters. Can someone guide me how this can happen and what is the method so it can be done on other models as well. Thanks,0,2,False,self,,,,,
146,deeplearning,t5_2t5eh,2019-7-13,2019,7,13,0,cccmj2,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cccmj2/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1562946807,[removed],0,1,False,self,,,,,
147,deeplearning,t5_2t5eh,2019-7-13,2019,7,13,0,ccco99,self.deeplearning,Where to find cvpr research papers?,https://www.reddit.com/r/deeplearning/comments/ccco99/where_to_find_cvpr_research_papers/,AhmedZubairGCU,1562947051,I am looking to find research papers for cvpr-ntire 2019 image restoration and enhancement challenge. Also where to find ICCP 2019 research papers? Are these available online for free?,6,2,False,self,,,,,
148,deeplearning,t5_2t5eh,2019-7-13,2019,7,13,3,ccedg8,self.deeplearning,Lane segmentation,https://www.reddit.com/r/deeplearning/comments/ccedg8/lane_segmentation/,_synaps_,1562954799,"Does anyone know an accessible state of the art lane segmentation model with this quality of outcome:

https://youtu.be/l5xu1DI6pDk",0,1,False,self,,,,,
149,deeplearning,t5_2t5eh,2019-7-13,2019,7,13,11,ccjwix,self.deeplearning,How to make CNN kernels as diverse as possible,https://www.reddit.com/r/deeplearning/comments/ccjwix/how_to_make_cnn_kernels_as_diverse_as_possible/,hassanzadeh,1562983750,"Hello guys,

I have a CNN with a few filters and I would like to make these filters as distant as possible. What is the right way that I can add  a regularizer term or something similar to the cost so that makes the kernels as distinct as possible?

&amp;#x200B;

Thanks",0,3,False,self,,,,,
150,deeplearning,t5_2t5eh,2019-7-13,2019,7,13,12,cckls5,github.com,Examples and best practices for building recommendation systems by Microsoft,https://www.reddit.com/r/deeplearning/comments/cckls5/examples_and_best_practices_for_building/,ConfidentMushroom,1562988173,,0,4,False,default,,,,,
151,deeplearning,t5_2t5eh,2019-7-13,2019,7,13,23,ccpznt,self.deeplearning,First deep learning rig,https://www.reddit.com/r/deeplearning/comments/ccpznt/first_deep_learning_rig/,nilsiism,1563028476,"Hi Community,

&amp;#x200B;

I'm currently trying to build my first deep learning setup and I'd prefer to spend as little as possible for a decent workstation. I spent the last days reading tons of blog and forum posts, but am even more confused now. I'd really appreciate your help and hope this post isn't too redundant.

Situation:

I'm a PhD student working on mobile robotics. In the lab I use a Dell XPS laptop for all of my work due to the needed mobility. My current work doesn't need a more powerful setup, but the second part of my PhD will become way more DL heavy. Therefore, I'd like to build my own DL workstation at home and start tinkering around with things such that I'm not completely lost once I need to start working on the DL part.

I general I'd like to

\- Compete in Kaggle competitions

\- Prototype and train networks for object segmentation and motion prediction

\- Tinker around with a lot of open source networks available

I should mention that I could have access to a server with 4x 1080ti quite regularly that is little used by other people.

&amp;#x200B;

I put together 3 different setups that I'm considering to build

Setup 1:

[https://pcpartpicker.com/user/nilsiism/saved/#view=qKP8Mp](https://pcpartpicker.com/user/nilsiism/saved/#view=qKP8Mp)

&amp;#x200B;

Setup 2:

[https://pcpartpicker.com/user/nilsiism/saved/#view=6cZXvK](https://pcpartpicker.com/user/nilsiism/saved/#view=6cZXvK)

&amp;#x200B;

Setup 3:

[https://pcpartpicker.com/user/nilsiism/saved/#view=VMGhgs](https://pcpartpicker.com/user/nilsiism/saved/#view=VMGhgs)

&amp;#x200B;

\- I'd use the new 2070 super for setup 1 and 2. It's just that they aren't available at pcpartpicker yet.

\- I'd not run a dual boot but rather have the 1T m2 running Ubuntu 18.04 and the 500GB m2 + 500GB SSD running Windows 10 (I still have the 500GB SSD laying around here).

\- All setups would run with just 1x GPU. There might be a point in time where I would update the system with a 2nd GPU, but if I'll ever need more I'll most likely already work in a company that provides a workstation.

&amp;#x200B;

This are my concerns:

Setup 1: This would be my preferred workstation. I just feel it's the most bang/buck. I'm also considering to get the 9900k instead for the double threads as the price difference is only GBP70, but not sure if it's worth it.I'm just a bit scared how future prove this setup is. Apart from the Xeon and X-series intel GPUs non of the Intel CPUs support more than 16x pcie lanes. How much would the performance of a second GPU suffer (just to mention again, a second is the max I'll ever expect to add to any of this setups) compared to a setup supports +44 lanes?  According to this blog [https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/](https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/) it doesn't really matter, but I feel the rest of the internet is just talking lanes, lanes, lanes, ...

&amp;#x200B;

Setup 2: A more future prove setup for more less the same money would be to use an AMD CPU. However, I'll mainly use Ubuntu on this machine and lacking support kind of scares the crap out of me. In general I'd just really prefer an Intel CPU due to the bigger Ubuntu and DL support in general. I'd only consider this switch for the additional lanes and I don't really understand if I'll ever need them even if I add a second GPU.

&amp;#x200B;

Setup 3: Okay last but not least would be more of a high end setup. It would provide the most future prove workstation, while I could still stick with Intel. Also if I'd go with this CPU I'd also directly go for the bigger GPU. However I feel the bang/buck for this setup is ridiculously bad compared to the other two (I guess that's how it's with all high-end tech).

&amp;#x200B;

Any advice would be really appreciated. I guess my main current concern is: How many pcie lanes do I really need even if I run 2 GPUs.",13,3,False,self,,,,,
152,deeplearning,t5_2t5eh,2019-7-13,2019,7,13,23,ccq7li,self.deeplearning,Adding Attention in Keras/Seeking Team Member,https://www.reddit.com/r/deeplearning/comments/ccq7li/adding_attention_in_kerasseeking_team_member/,cvantass,1563029729,"Does anyone here know how to add attention to an LSTM model using Keras? I am for some reason struggling to find good/helpful documentation about this online. If anyone has any links that they know actually explain it correctly, that would be much appreciated. 

Alternatively, I am looking for one more team member who knows RNNs well to join my project (in the realm of creative AI) as we get ready to launch. If youre interested, you can message me for the details.",3,14,False,self,,,,,
153,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,0,ccqo7y,self.deeplearning,Log Loss for Best and Worst answer,https://www.reddit.com/r/deeplearning/comments/ccqo7y/log_loss_for_best_and_worst_answer/,AlexGuilBot,1563032277,"Say I have 5 categorical targets, one of those would be the best answer and one would be the worst. If the model doesn't choose the best, then I want to ensure at least that it doesn't choose the worst without worrying about which of the remaining 3 it chooses. 

Anyone has an idea how I should define my loss function? Some weighting I guess?",0,2,False,self,,,,,
154,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,1,ccre53,intellectyx.com,How to Use Big Data Analytics to Grow Your Marketing ROI,https://www.reddit.com/r/deeplearning/comments/ccre53/how_to_use_big_data_analytics_to_grow_your/,raj11113,1563036144,,0,1,False,default,,,,,
155,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,3,ccskk2,self.deeplearning,Using an LSTM-based model to predict EasyJet's stock returns (Keras tutorial),https://www.reddit.com/r/deeplearning/comments/ccskk2/using_an_lstmbased_model_to_predict_easyjets/,jdyr1729,1563042182,"Hi,

I've just written a tutorial explaining how to build an LSTM-based model that predicts the accuracy of EasyJet's stock returns with an accuracy of 55.2%. 

Thought I'd share it here for anyone who is interested:  [https://jackdry.com/using-an-lstm-based-model-to-predict-stock-returns](https://jackdry.com/using-an-lstm-based-model-to-predict-stock-returns) 

Hope you find it useful!

Jack",13,16,False,self,,,,,
156,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,11,ccxl0s,medium.com,How NLP Is Advancing Asset Management,https://www.reddit.com/r/deeplearning/comments/ccxl0s/how_nlp_is_advancing_asset_management/,Yuqing7,1563069897,,0,3,False,default,,,,,
157,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,12,ccy61n,self.deeplearning,"[Discussion] Validation loss vs Validation accuracy, what should be given more preference while monitoring network?",https://www.reddit.com/r/deeplearning/comments/ccy61n/discussion_validation_loss_vs_validation_accuracy/,SheerHunter,1563073559,"I always prefer validation loss/accuracy over training loss/accuracy as lots of people do.

Generally I prefer to monitor validation loss as well as validation accuracy when everything is going ideally (i.e. loss going down and accuracy going up).
But at times this metrics dosent behave as they should ideally and we have to choose either one of them. Then what should be all the factors that should be considered to take a decision.

I personally inclines towards validation loss more as compared to validation accuracy. If you have multi-class Classification problem which include at least one dominating class whose Classification is eady and the network is classifying it correctly all the time, then validation accuracy will may go up but in contrast network may not learn remaining class properly.",4,3,False,self,,,,,
158,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,13,ccyu30,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/ccyu30/data_science_career_track_prep_course/,HannahHumphreys,1563077882,[removed],0,1,False,self,,,,,
159,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,14,cczl34,self.deeplearning,Transfer learning with YOLOv3,https://www.reddit.com/r/deeplearning/comments/cczl34/transfer_learning_with_yolov3/,kphyx,1563083311,"Hey everyone,

I'm a newbie here so excuse me if my question sounds dumb. 

Is it possible to use transfer learning with YOLOv3 if it had been pre-trained on lets say coco dataset?

Basically, what i wanna do is add a new class to the existing set of classes instead of training the network on exclusively my dataset.",2,10,False,self,,,,,
160,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,20,cd21nt,self.deeplearning,Pytorch RL CPP with ALE,https://www.reddit.com/r/deeplearning/comments/cd21nt/pytorch_rl_cpp_with_ale/,Teenvan1995,1563104182,"Check out Pytorch-RL-CPP: a C++ (Libtorch) implementation of Deep Reinforcement Learning algorithms with C++ Arcade Learning Environment.

[Pytorch-RL-CPP](https://github.com/navneet-nmk/Pytorch-RL-CPP)",0,0,False,self,,,,,
161,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,20,cd27wb,youtube.com,Breast cancer diagnosis with neural networks (implemented in python),https://www.reddit.com/r/deeplearning/comments/cd27wb/breast_cancer_diagnosis_with_neural_networks/,antaloaalonso,1563105530,,2,39,False,image,,,,,
162,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,21,cd2gog,self.deeplearning,Data augmentation for 2D time series?,https://www.reddit.com/r/deeplearning/comments/cd2gog/data_augmentation_for_2d_time_series/,pk12_,1563107286,"I have time series which has two channels x and y. Can anyone please point me to data augmentation resources for such time series?

Thanks",0,0,False,self,,,,,
163,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,22,cd2zgy,link.medium.com,An Intuitive Explanation to Dropout,https://www.reddit.com/r/deeplearning/comments/cd2zgy/an_intuitive_explanation_to_dropout/,alimasri91,1563110711,,2,0,False,default,,,,,
164,deeplearning,t5_2t5eh,2019-7-14,2019,7,14,23,cd3q33,self.deeplearning,Mathematical Foundation For Machine Learning and AI,https://www.reddit.com/r/deeplearning/comments/cd3q33/mathematical_foundation_for_machine_learning_and/,HannahHumphreys,1563115202,[removed],0,1,False,self,,,,,
165,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,3,cd6kqx,i.redd.it,Object Detection of dirt piles,https://www.reddit.com/r/deeplearning/comments/cd6kqx/object_detection_of_dirt_piles/,akg2Deep,1563129984,,12,1,False,image,,,,,
166,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,4,cd763m,medium.com, Releasing first online 3D Point Cloud labeling tool in Supervisely,https://www.reddit.com/r/deeplearning/comments/cd763m/releasing_first_online_3d_point_cloud_labeling/,tdionis,1563132920,,1,3,False,default,,,,,
167,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,4,cd76om,self.deeplearning,Deep Learning Structure Guide for Beginners,https://www.reddit.com/r/deeplearning/comments/cd76om/deep_learning_structure_guide_for_beginners/,Magniminda,1563132998," 

### 1- What is deep learning?

&amp;#x200B;

*In* its simplest form, *deep learning*, also known as *deep machine learning* or *deep structured learning*, is a subset of machine learning and refers to neural networks that have the ability to learn the input datas increasingly abstract representations. These days, implementation of deep learning techniques can be found to a great extent, from self-driving cars to academic researches.

### 2- What sets deep learning apart?

&amp;#x200B;

*If* you follow prominent job portals, you can find that theres a significant number of **deep learning professionals** job positions almost all of which are paying really well. Now, you may wonder why do companies hire these professionals? Or, what can such a professional bring to them? Lets have a look.

#### 2.1- Quality and accuracy

&amp;#x200B;

*Every* company wants quality and sometimes work produced by human employees come inferior and with errors. This is particularly true for data processing repetitive tasks. However, a worker powered by deep learning is capable of developing new understandings and producing high-quality, accurate results.

With the help of deep learning, software robots can understand spoken language, recognize more images and data, and work more efficiently. These are the main reasons why companies across the globe are hiring deep learning professionals.

#### 2.2- Increased cost and time benefit

&amp;#x200B;

*In* its simple form, neural networks can be considered as trainable brains. These networks are provided with information and trained to do tasks, and theyll use that training together with new information and their own work experience when it comes to accomplishing those tasks.

Implementation of deep learning in business can save the company a significant amount of time and money. In addition, when time-consuming or repetitive tasks are done efficiently and quickly, employees are freed up to take care of creative tasks that actually need human involvement.",0,1,False,self,,,,,
168,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,5,cd7k93,self.deeplearning,"Is anyone able to access the ""Sequences, Time Series and Prediction"" deeplearning.ai course?",https://www.reddit.com/r/deeplearning/comments/cd7k93/is_anyone_able_to_access_the_sequences_time/,etmhpe,1563134889,"I am just trying to audit the course on Coursera - here is the link [https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction](https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction)

When I click ""Enroll for Free"" and click the ""Audit"" link in the popup nothing happens.  Usually it takes you to the course home after you click ""audit"".  This happening for anyone else?",1,2,False,self,,,,,
169,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,5,cd7o7l,github.com,Simple annotated word2vec using Tensorflow 2 [Feedback please!],https://www.reddit.com/r/deeplearning/comments/cd7o7l/simple_annotated_word2vec_using_tensorflow_2/,richardanaya,1563135429,,4,1,False,default,,,,,
170,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,6,cd8evd,self.deeplearning,Help Us Help Humanity,https://www.reddit.com/r/deeplearning/comments/cd8evd/help_us_help_humanity/,omnihaand,1563139123,"So, I'm the Manager of IT and Cloud Services for an AI startup. We're working on an OCR project to help the education system, but we're getting to the point where or models are too big to train on our dual 2080 Ti host. 

Unfortunately, RTX Titans and Cloud resources are beyond expensive. So, I'm wondering if there are any recommendations for funding or resources that I should look into?

Sorry I couldn't make this funny or nerdy enough T9 get more attention. But, feel free to giggle at our shoestring budget that left is modifying an electrical closet to house some of our hardware.

https://twitter.com/omnihaand/status/1150514745344237568?s=09

No, we don't have an UPS, yet... XD",2,1,False,self,,,,,
171,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,10,cdb70m,github.com,LogReLU: A New Activation Function Inspired By ReLU,https://www.reddit.com/r/deeplearning/comments/cdb70m/logrelu_a_new_activation_function_inspired_by_relu/,multisilicon,1563154542,,2,16,False,default,,,,,
172,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,13,cdd00e,self.deeplearning,Is a PhD in deep learning worth it?,https://www.reddit.com/r/deeplearning/comments/cdd00e/is_a_phd_in_deep_learning_worth_it/,james75yw,1563165642,"I am finishing up my Masters in Computer Science from a public university in the east coast. I worked mostly on VR and some computer graphics and computer vision during my Masters.

I want to get into deep learning as I find it more interesting as I started working on it very recently for a coding challenge. I have an opportunity to start a PhD at the computer engineering department at my school this fall. The lab that I would be joining have 7 students with most of them working on deep learning. The lab has a lot of titan X gpus, more importantly the school has an excellent super computer (top 10 most powerful among schools in USA). 

PhD is a big commitment and I am excited about it, also worried about it at the same time. Is it worth getting a PhD in deep learning? My focus area would be computer vision. I would really appreciate your thoughts on the worthiness of PhD.

I apologize in advance for any typos as I am typing this up on my phone while trying to sleep.",5,2,False,self,,,,,
173,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,16,cdeb5s,self.deeplearning,"HP Omen 15 dc 1009tx and ROG Scar Strix 3, which laptop is better for deep learning? (Portability is an issue right now, so I can't buy desktop)",https://www.reddit.com/r/deeplearning/comments/cdeb5s/hp_omen_15_dc_1009tx_and_rog_scar_strix_3_which/,ar0752545,1563174966,,1,1,False,self,,,,,
174,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,17,cdexia,blog.tensorpad.com,Using a Machine Learning Model in a Web Application Client,https://www.reddit.com/r/deeplearning/comments/cdexia/using_a_machine_learning_model_in_a_web/,whitezl0,1563179845,,0,0,False,default,,,,,
175,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,19,cdfua6,self.deeplearning,Windows or Linux?,https://www.reddit.com/r/deeplearning/comments/cdfua6/windows_or_linux/,NidoAnhsirk,1563186941,"I've just started with Machine learning and Artificial intelligence(Let's say deep learning) course. I have used Windows till this point of time, but would love to know if it's better to start learning with Linux. I've come across many articles and threads that suggest opting for a Linux environment and a few of them suggest sticking with windows as it doesn't make much difference these days(or in the near future). Can you tell me which one to go with, and also the reasons behind your choice?

&amp;#x200B;

P.S: I use an Alienware(12 GB RAM, Nvidia - 2GB VRAM, i7 processor). I'm planning to build my own PC within 6 months.",24,18,False,self,,,,,
176,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,22,cdhog0,habr.com,"AI-based photo restoration: defects removal, inpainting, colorization",https://www.reddit.com/r/deeplearning/comments/cdhog0/aibased_photo_restoration_defects_removal/,atomlib_com,1563198460,,1,9,False,default,,,,,
177,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,23,cdi897,self.deeplearning,How to speed-up deep learning research,https://www.reddit.com/r/deeplearning/comments/cdi897/how_to_speedup_deep_learning_research/,councilanderson2,1563201383,"I am working on enhancement tasks using deep generative neural networks. I only have access to one 10 GB GPU, and I really want to speed up my research. I want to experiment with using different architectures but every single trial takes at least 3 days. I have some ideas about comparing multiple models in parallel, by as reducing the model sizes, batch size or the input size. Once I find the best performing model, I can scale things up, though I don't know if this is a good idea. What are your opinions?",4,3,False,self,,,,,
178,deeplearning,t5_2t5eh,2019-7-15,2019,7,15,23,cdii1v,self.deeplearning,Is there a legitimate (FOSS) easy-to-run program (in cli or not) for personal GPU Benchmarking on Linux ?,https://www.reddit.com/r/deeplearning/comments/cdii1v/is_there_a_legitimate_foss_easytorun_program_in/,Atralb,1563202762,,1,1,False,self,,,,,
179,deeplearning,t5_2t5eh,2019-7-16,2019,7,16,2,cdk89r,self.deeplearning,Neural Attention Usage,https://www.reddit.com/r/deeplearning/comments/cdk89r/neural_attention_usage/,reverse61,1563210753,"Hi,

&amp;#x200B;

I'm currently investigating the possible uses of neural attention. I believe it's particularly used in LSTM's and basically text-related problems.

&amp;#x200B;

My thought is the following : If I have an image labeled with the number of objects of interest inside (a scalar, then), and I'd like to be able to demonstrate that the algorithm indeed focuses on these objects, I could use a neural attention at some point, and produce both the attention-map, and the result. This wouldn't yield any (I believe) performance gain, but would make the model more human-friendly.

&amp;#x200B;

I couldn't find any paper relative to this particular use of neural attention, but I believe it must have already been done ?

&amp;#x200B;

Do you guys have any thoughts on this ?

&amp;#x200B;

Thanks a lot !",1,1,False,self,,,,,
180,deeplearning,t5_2t5eh,2019-7-16,2019,7,16,6,cdnv4b,self.deeplearning,"Trying to share my ""projects"" and to find people to work on something with",https://www.reddit.com/r/deeplearning/comments/cdnv4b/trying_to_share_my_projects_and_to_find_people_to/,mishazakharovbmx,1563226649,"Hello! I wrote a few ""projects"" I want to share with you. There is my ml-library: [https://github.com/mishazakharov/ML-library](https://github.com/mishazakharov/ML-library), my dl-library: [https://github.com/mishazakharov/DL-library](https://github.com/mishazakharov/DL-library) and image-classifier: [https://github.com/mishazakharov/ImageClassificator](https://github.com/mishazakharov/ImageClassificator).

I am kind of new to everything. Been doing this for 3-4 months(Python, ml and dl. But I had all the maths needed in my pocket). So I do not claim for high efficiency and ""quality"" of abstractions and code. Posting here just to share my projects, may be someone would like them or give me some advices I definitely need, and also I am LOOKING FOR people to do some fun dl-ml-related projects in order to boost skills and gain knowledge! I feel like my code may look for some of you as a complete garbage, I am a complete newcomer, so take it easy on me, please! Any advice or opportunity is appreciated!!!",13,21,False,self,,,,,
181,deeplearning,t5_2t5eh,2019-7-16,2019,7,16,7,cdo8wb,github.com,DL in production: an open source project for deploying your models as JSON APIs on AWS,https://www.reddit.com/r/deeplearning/comments/cdo8wb/dl_in_production_an_open_source_project_for/,ospillinger,1563228509,,0,14,False,default,,,,,
182,deeplearning,t5_2t5eh,2019-7-16,2019,7,16,14,cdsuvd,self.deeplearning,My first article on TowardsDataScience,https://www.reddit.com/r/deeplearning/comments/cdsuvd/my_first_article_on_towardsdatascience/,jager_2798,1563255037,"Finally I got to contribute to the website I learnt deep learning from. My first article on TDS explaining residual learning: https://towardsdatascience.com/a-deeper-dive-into-residual-learning-d92e0aaa8b32

Feel free to give your feedback!",4,14,False,self,,,,,
183,deeplearning,t5_2t5eh,2019-7-16,2019,7,16,20,cdvz2t,doradolist.com,Machine Learning books suggested by top experts like Professor Bengio (U of Montreal) and Daphne Koller (Cofounder of Coursera),https://www.reddit.com/r/deeplearning/comments/cdvz2t/machine_learning_books_suggested_by_top_experts/,TJ1,1563277683,,2,41,False,default,,,,,
184,deeplearning,t5_2t5eh,2019-7-16,2019,7,16,21,cdw96x,arxiv.org,Prior Activation Distribution (PAD): A Versatile Representation to Utilize DNN Hidden Units,https://www.reddit.com/r/deeplearning/comments/cdw96x/prior_activation_distribution_pad_a_versatile/,AskLbm,1563279314,,0,1,False,default,,,,,
185,deeplearning,t5_2t5eh,2019-7-16,2019,7,16,21,cdwgu9,youtube.com,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educative",https://www.reddit.com/r/deeplearning/comments/cdwgu9/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1563280550,,0,2,False,image,,,,,
186,deeplearning,t5_2t5eh,2019-7-16,2019,7,16,21,cdwjjq,self.deeplearning,[Research] Prior Activation Distribution (PAD): A Versatile Representation to Utilize DNN Hidden Units,https://www.reddit.com/r/deeplearning/comments/cdwjjq/research_prior_activation_distribution_pad_a/,AskLbm,1563281006,"Link: [https://arxiv.org/pdf/1907.02711.pdf](https://arxiv.org/pdf/1907.02711.pdf)

&amp;#x200B;

In this paper, we introduce the concept of Prior Activation Distribution (PAD) as a versatile and general technique to capture the typical activation patterns of hidden layer units of a Deep Neural Network used for classification tasks. We show  that  the  combined  neural  activations  of  such  a  hidden  layer  have  class-specific distributional properties, and then define multiple statistical measures to compute how far a test samples activations deviate from such distributions. Using a variety of benchmark datasets (including MNIST, CIFAR10, Fashion-MNIST &amp; notMNIST), we show how such PAD-based measures can be used, independent of  any  training  technique,  to  (a)  derive  fine-grained  uncertainty  estimates  for inferences; (b) provide inferencing accuracy competitive with alternatives that require execution of the full pipeline, and (c) reliably isolate out-of-distribution test samples.",0,1,False,self,,,,,
187,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,1,cdyztq,blog.paperspace.com,Train ML Models on Free Cloud GPUs ,https://www.reddit.com/r/deeplearning/comments/cdyztq/train_ml_models_on_free_cloud_gpus/,MMFeaster,1563292978,,1,2,False,default,,,,,
188,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,1,cdzqe2,ahmedbesbes.com,Automate the diagnosis of Knee Injuries with Deep Learning part 1: an overview of the MRNet Dataset,https://www.reddit.com/r/deeplearning/comments/cdzqe2/automate_the_diagnosis_of_knee_injuries_with_deep/,ahmedbesbes,1563296269,,0,1,False,default,,,,,
189,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,6,ce2zcc,self.deeplearning,ELMo from scratch in PyTorch?,https://www.reddit.com/r/deeplearning/comments/ce2zcc/elmo_from_scratch_in_pytorch/,Peyaash,1563310855,"In one of my projects I need to train ELMo embeddings.
AllenNLP has an implementation of this but I thought I'll take this opportunity to implement it from scratch.

I always wanted to develop the skill to replicate the result of research papers and experiment with them. So I think implementing this from scratch will give me a kick start. Also, I'll be able to learn a lot about PyTorch.

I already read the paper of ELMo, along with Character-Aware Neural Language Models, Highway Networks, really cool papers!

I'm pretty sure you passed the stage where I am at right now. So it would be tremendously helpful if you could share your opinion, experience and suggestions.

TIA",1,1,False,self,,,,,
190,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,6,ce3bft,datastuff.tech,LSTM: How to Train a Neural Network to Write like Lovecraft,https://www.reddit.com/r/deeplearning/comments/ce3bft/lstm_how_to_train_a_neural_network_to_write_like/,strikingLoo,1563312398,,0,2,False,default,,,,,
191,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,7,ce3yad,self.deeplearning,My notes for deeplearing.ai and fast.ai courses,https://www.reddit.com/r/deeplearning/comments/ce3yad/my_notes_for_deeplearingai_and_fastai_courses/,youali,1563315364,"Hello guys,

During the past months I've gone through the deeplearing.ai specialization and fast.ai courses (the two deep learning courses and machine learning course), I've take some notes that I found myself I keep coming to them from time to time. So I though I'd share them and maybe someone will find them helpful, after taking sometime to polish them and correct spelling erros here they are:

- deeplearing.ai notes: https://github.com/y-ouali/fast.ai_notes

- fastai notes:  https://github.com/y-ouali/deeplearning.ai_notes",17,104,False,self,,,,,
192,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,7,ce406g,github.com,Implementation of a knee injury classifier from MRI exams using PyTorch and MRNet data,https://www.reddit.com/r/deeplearning/comments/ce406g/implementation_of_a_knee_injury_classifier_from/,ahmedbesbes,1563315605,,0,2,False,default,,,,,
193,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,9,ce5ayc,self.deeplearning,What are the state of the art strategies in lifelong learning?,https://www.reddit.com/r/deeplearning/comments/ce5ayc/what_are_the_state_of_the_art_strategies_in/,GabiruAttack,1563322233,,0,1,False,self,,,,,
194,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,10,ce621n,youtube.com,Recurrent Neural Networks: Algorithms and Applications,https://www.reddit.com/r/deeplearning/comments/ce621n/recurrent_neural_networks_algorithms_and/,DiscoverAI,1563326320,,0,2,False,default,,,,,
195,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,10,ce6coq,youtube.com,Convolutional Neural Networks: An Intuitive Approach,https://www.reddit.com/r/deeplearning/comments/ce6coq/convolutional_neural_networks_an_intuitive/,DiscoverAI,1563327970,,0,3,False,image,,,,,
196,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,13,ce7wwp,self.deeplearning,"AMA with *Francois Chollet*, the creator of *Keras*",https://www.reddit.com/r/deeplearning/comments/ce7wwp/ama_with_francois_chollet_the_creator_of_keras/,init__27,1563337087,"KaggleNoobs Community will be hosting an AMA with \*Francois Chollet\*, the creator of \*Keras\*  on 28th July, 2019 during 9 am - 10:30 am PT. 

&amp;#x200B;

To Join, use this slack invite: [https://kagglenoobs.herokuapp.com/ ](https://t.co/BVPAIBoVy7) 

OR 

Leave your questions here, I'll post them during the AMA and post the complete AMA here afterward.  Till then, Francois Chollet was kind enough to share many great pieces of advice in this interview: [https://t.co/SmkDODXlFY](https://t.co/SmkDODXlFY)",0,1,False,self,,,,,
197,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,13,ce7xff,self.deeplearning,"AMA with Francois Chollet, the creator of Keras",https://www.reddit.com/r/deeplearning/comments/ce7xff/ama_with_francois_chollet_the_creator_of_keras/,init__27,1563337169,[removed],0,1,False,self,,,,,
198,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,14,ce8hd8,self.deeplearning,Opinions on AMD GPU for deep learning?,https://www.reddit.com/r/deeplearning/comments/ce8hd8/opinions_on_amd_gpu_for_deep_learning/,CzoKc,1563340753,"AMD feels better value for money specs wise but sadly there are is not direct cuda support and libraries are not optimized to be run on AMD GPUs. 

Any thoughts on building a deep learning rig using exclusively AMD GPUs? 

I know is possible to do, but not sure if it will be of good value",5,1,False,self,,,,,
199,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,14,ce8sap,youtu.be,Crater Detection with MaskRCNN,https://www.reddit.com/r/deeplearning/comments/ce8sap/crater_detection_with_maskrcnn/,yrajsm,1563342794,,1,1,False,default,,,,,
200,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,15,ce97dc,self.deeplearning,Semantic segmetation in panoramic images,https://www.reddit.com/r/deeplearning/comments/ce97dc/semantic_segmetation_in_panoramic_images/,frankshawn1992,1563345700,"Hello,
Does anyone know a software for semantic segmentation in panoramic images (350 images)",0,1,False,self,,,,,
201,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,16,ce9heo,self.deeplearning,Imbalanced Dataset,https://www.reddit.com/r/deeplearning/comments/ce9heo/imbalanced_dataset/,samisoomro24,1563347650,"Hello Everyone

I am doing image classification using pretrained MobileNet Model and I have dataset about 473 Images which is much less but another problem I am facing that I don't have equal number of Images in each class what should I do please suggest. Thanks",3,3,False,self,,,,,
202,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,18,cear81,amethix.com,Neural networks that don't need to be trained,https://www.reddit.com/r/deeplearning/comments/cear81/neural_networks_that_dont_need_to_be_trained/,fgadaleta,1563357349,,0,10,False,default,,,,,
203,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,21,cebywm,self.deeplearning,Hi can someone suggest me project idea for object detection?,https://www.reddit.com/r/deeplearning/comments/cebywm/hi_can_someone_suggest_me_project_idea_for_object/,bit2bit2,1563365327,,4,1,False,self,,,,,
204,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,21,cece2t,self.deeplearning,Projects in Hadoop and Big Data - Learn by Building Apps,https://www.reddit.com/r/deeplearning/comments/cece2t/projects_in_hadoop_and_big_data_learn_by_building/,HannahHumphreys,1563367691,[removed],0,1,False,self,,,,,
205,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,22,cecusu,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cecusu/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1563370151,[removed],0,1,False,self,,,,,
206,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,23,cedlfp,self.deeplearning,[Research] Advancing Semi-supervised Learning with Unsupervised Data Augmentation,https://www.reddit.com/r/deeplearning/comments/cedlfp/research_advancing_semisupervised_learning_with/,cdossman,1563373803,"[https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-advancing-semi-supervised-learning-with-unsupervised-data-augmentation-uda-f0f3e0ff951f](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-advancing-semi-supervised-learning-with-unsupervised-data-augmentation-uda-f0f3e0ff951f) 

Abstract: In this work, we propose to apply data augmentation to unlabeled data in a semi-supervised learning setting. Our method, named Unsupervised Data Augmentation or UDA, encourages the model predictions to be consistent between an unlabeled example and an augmented unlabeled example. Unlike previous methods that use random noise such as Gaussian noise or dropout noise, UDA has a small twist in that it makes use of harder and more realistic noise generated by state-of-the-art data augmentation methods. This small twist leads to substantial improvements on six language tasks and three vision tasks even when the labeled set is extremely small.",0,2,False,self,,,,,
207,deeplearning,t5_2t5eh,2019-7-17,2019,7,17,23,cedtkp,self.MachineLearning,"[P] Conditional Density Estimation Python Package and Large Benchmark with Neural Networks (MDN, KMN, Normalizing Flow) and Non-/Semi-parametric estimators",https://www.reddit.com/r/deeplearning/comments/cedtkp/p_conditional_density_estimation_python_package/,whiletrue2,1563374871,,0,2,False,default,,,,,
208,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,5,ceie3p,self.deeplearning,"Lead Data Scientist: Want to become expert in Deep Learning, specifically NLP 1-2 years.",https://www.reddit.com/r/deeplearning/comments/ceie3p/lead_data_scientist_want_to_become_expert_in_deep/,damient9,1563395561,"Hey all!

I was wondering if some in the channel could provide their opinion. Since it may help with the answer I currently work as a Lead Data Scientist and have a Phd in Physics.

Our work does not usually fit within the realm of Deep Learning or neural nets in general. The only difference was some of our NLP work on browsing data. 

My goal in 2 years is to become an expert in Deep Learning. I know that is general. Areas of interest are NLP; perhaps more specifically deriving sentiment and meaning for a classification or action, and strategic. I think I may mean GAN based DL. Deep Learning centered around strategic performance such as winning in games of strategy. So creating an environment then having a algorithm discover the best way to perform based on some metric.  

By expert I mean top 5-10 % in the field. I know the areas of DL I gave are a little general but I imagine I will fine tune once I start through some recommendations. 

So with that goal what would be some advise in terms of catching up on the literature; what should I read? What order? Are their moocs or paid courses that are worth it? Should I follow a certain blog, website, content creator, or person? Really any advise you have. 

Any help is greatly appreciated and reach out if you need more specifications.",11,1,False,self,,,,,
209,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,5,ceifcw,self.deeplearning,Implementation of mini batch K-means to compute anchor boxes.,https://www.reddit.com/r/deeplearning/comments/ceifcw/implementation_of_mini_batch_kmeans_to_compute/,lameass_nerd,1563395713,"I have implemented mini batch K-means to compute anchor boxes for the task of object detection. Here is the link to my repository

[https://github.com/siddharthgawas/iou-kmeans](https://github.com/siddharthgawas/iou-kmeans)

Suggestions are welcome.",0,2,False,self,,,,,
210,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,7,cejxtp,self.deeplearning,"What's the ""error delta"" means in backpropagation? error delta equals Gradient derivative?",https://www.reddit.com/r/deeplearning/comments/cejxtp/whats_the_error_delta_means_in_backpropagation/,ytninja,1563402763,"I'm so confused what the ""error delta"" means in backpropagation network. 

When I hear the word ""error"", it means ""cost"". But it's not in backprop.

I'm reading Michael Nielson's book, he said , ""delta error means derivative of each neuron"".

Is error same as Gradient? so Derivative means error?

Michael Nielslon said ""partial derivative Cost function with respect to partial derivtive of each neuron is error delta""

so, ""Ratio"" is error? and we try to calculate derivative to zero?

I feel like ""error"" means ""cost""... but error is not cost? mmm???",2,2,False,self,,,,,
211,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,9,cel6a5,self.deeplearning,Professional Hacker For Hire!,https://www.reddit.com/r/deeplearning/comments/cel6a5/professional_hacker_for_hire/,k3n3dy15,1563409153,"I have a Direct/Recommended source of an hacker, Contact ROBB via robbm536@gmail.com His always ready to render his services, hire him and he won't disappoint you. He can help hack into any device, social networks including- Facebook, hangouts, I messages, Twitter account, snapshot, Instagram, whatsapp, we chat, text messages., smart phones cloning, tracking emails and also any other media messenger or sites,cridit cord and transfer Do you need specialized and experienced hacking into Educational Institutions, websites, GPS coordinates tracking, surveillance footage, Grades hocking, Clearing of Criminal Records, Clear Credit Card Debts, Drop Money Into Credit Cards, Smartphone Hacksetc. Contact
 robbm536@gmail.com",1,0,False,self,,,,,
212,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,10,celnq5,youtube.com,Implementing K-Means Clustering From Scratch: Simply Explained,https://www.reddit.com/r/deeplearning/comments/celnq5/implementing_kmeans_clustering_from_scratch/,DiscoverAI,1563411847,,4,27,False,default,,,,,
213,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,15,ceonmo,/r/deeplearning/comments/ceonmo/httpsahmedbesbescomautomatethediagnosisofkneeinjur/,https://ahmedbesbes.com/automate-the-diagnosis-of-knee-injuries-with-deep-learning-part-1-an-overview-of-the-mrnet-dataset.html,https://www.reddit.com/r/deeplearning/comments/ceonmo/httpsahmedbesbescomautomatethediagnosisofkneeinjur/,ahmedbesbes,1563430146,,1,1,False,default,,,,,
214,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,16,cep3xd,self.deeplearning,How could I approach this?,https://www.reddit.com/r/deeplearning/comments/cep3xd/how_could_i_approach_this/,taudins,1563433470,"My school's chem students were administered printed surveys with 20 ""items"" (not questions, exactly) structured as follows:

                  Chemistry is

1. Boring |_1_|_2_|_3_|_4_|_5_|_6_|_7_| Exciting

2. Easy     |_1_|_2_|_3_|_4_|_5_|_6_|_7_| Hard

...........

20. Work |_1_|_2_|_3_|_4_|_5_|_6_|_7_| Play

In which they were required to circle a value in this 1-7 scale.

The bars and underscores are actually on the survey. These will be scanned in, likely as PDFs.
We already have hundreds of these as they've been collected over the past couple of years...
Needless to say, this would be excruciating to input this data by hand, so I figured as a Stats undergrad who has an interest in finally learning how to use deep learning, there should be a way to apply it here, if that's even a feasible approach to begin with.

Most of the responses are circles, but having looked through a few physical batches myself, some have been marked with x's, slashes, and some have made scratches where they had changed their answer so, some rows will have 2 marks (the scratch out and the intended response).

We had first considered preprocessing by trimming the excess paper in R, and dividing the survey into strips-- a strip for each item row and training a network to recognize a mark, and it's label would be a value 1-7.

I've been considering just using the entire main portion of the survey, a cropping of just the entire list of 20 items, and training a network to output a list of 20 values (1-7), per survey in order, from the top down. Is this even possible?",5,1,False,self,,,,,
215,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,17,cepks3,science.sciencemag.org,Superhuman AI for multiplayer poker,https://www.reddit.com/r/deeplearning/comments/cepks3/superhuman_ai_for_multiplayer_poker/,lopespm,1563437027,,1,1,False,default,,,,,
216,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,18,ceq5lp,ai.googleblog.com,Google AI Blog: Predicting the Generalization Gap in Deep Neural Networks,https://www.reddit.com/r/deeplearning/comments/ceq5lp/google_ai_blog_predicting_the_generalization_gap/,selfdrivingcars360,1563441598,,1,1,False,default,,,,,
217,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,18,ceqgi3,self.deeplearning,"Help needed: copy mechanism, seq2seq",https://www.reddit.com/r/deeplearning/comments/ceqgi3/help_needed_copy_mechanism_seq2seq/,BalazsSzalontai,1563443878,"I thought my task to solve was simple, but after weeks of trying and searching on Google I couldn't get it working.

The task: a simple seq2seq model, where the input is a short text (some lines), and  the output is a 3-token-long text, which consist only of tokens from the input. In other words, I want to give it a text as an input, and it should give me back 3 tokens from that input as the output. 

The input text is pretty structured, since it's python source code, and the output should be three of the ""main"" variables. (meaning of ""main"" is not important here, since it's part of a bigger project)

I have found an open source github project called CopyNet, I think using that could be the solution, but I wasn't able to get that working either.

I now have a seq2seq model, where it learns from input-output pairs, but it's just guessing, and I can't see any logical predictions, even if I have it train for hours on a powerful GPU.

I have a basic understanding of seq2seq models, I am using keras and have used fast ai before. I feel really stucked, and I'd appreciate any kind of help, such as some example code where copy mechanism is used so that I can understand how it works.",4,1,False,self,,,,,
218,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,19,ceqz2v,self.deeplearning,Master's study options in the EU?,https://www.reddit.com/r/deeplearning/comments/ceqz2v/masters_study_options_in_the_eu/,Slow_Breakfast,1563447458,"Hi everyone,

I'm planning to start my Master's degree, and looking for options within the EU. I'm quite interested in deep learning - particularly the theoretical aspects of neural networks, rather than just pure applications.

I'm thinking along the lines of exploring new network architectures, looking at how neural networks process information, explainability, that sort of thing (I realise this is a pretty vague explanation of what I want to do, but honestly, as long as I'm doing more than just throwing data at networks to see what sticks, I'm happy). I'm quite excited by the kind of work done at MIT's CSAIL lab (e.g., [their recent work in finding sparse networks](https://openreview.net/forum?id=rJl-b3RcF7)), DeepMind collaborations (e.g. their [curiosity-driven learning paper](https://arxiv.org/abs/1808.04355)), Hinton's recent work on capsule networks and so forth.

Quite frankly, it would be enormously cheaper for me to study within the EU than in the US or the UK, but I have been struggling to find places within the EU where this sort of work is done.  The closest I've been able to find so far is Aalto University in Finland, which offers a Master's degree in machine learning (though not deep learning specifically, as far as I can tell). Does anyone know of any places?",23,13,False,self,,,,,
219,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,20,cer6pz,ainow.ai, | AI AINOW,https://www.reddit.com/r/deeplearning/comments/cer6pz/_ai_ainow/,kailashahirwar12,1563448841,,0,0,False,default,,,,,
220,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,20,ceraar,github.com,An eXtra Small transformer LM for single GPU training,https://www.reddit.com/r/deeplearning/comments/ceraar/an_extra_small_transformer_lm_for_single_gpu/,bytestorm95,1563449501,,0,2,False,default,,,,,
221,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,22,cesan8,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cesan8/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1563455462,[removed],0,1,False,self,,,,,
222,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,22,cesga1,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cesga1/data_science_career_track_prep_course/,HannahHumphreys,1563456290,[removed],0,1,False,self,,,,,
223,deeplearning,t5_2t5eh,2019-7-18,2019,7,18,23,cetjkk,self.deeplearning,CNN using RGB pre-trained weights on 4 channel input,https://www.reddit.com/r/deeplearning/comments/cetjkk/cnn_using_rgb_pretrained_weights_on_4_channel/,StrasJam,1563461839,"Is it possible to use a CNN's pre-trained weights on an image with 4 input bands (RGB+NIR) if the network was originally trained on RGB images?

&amp;#x200B;

Would I need to randomly initialize a set of weights for my 4th channel now?",6,3,False,self,,,,,
224,deeplearning,t5_2t5eh,2019-7-19,2019,7,19,0,ceua1w,self.deeplearning,Conversion of .pb model into .tflite model,https://www.reddit.com/r/deeplearning/comments/ceua1w/conversion_of_pb_model_into_tflite_model/,zom8ie99,1563465293,I have my model trained as .pb file. How can I convert my model into .tflite in **windows** ?,0,2,False,self,,,,,
225,deeplearning,t5_2t5eh,2019-7-19,2019,7,19,6,ceyhsc,self.deeplearning,I have downloaded a pretrained graph. I want to train it further with my own training set,https://www.reddit.com/r/deeplearning/comments/ceyhsc/i_have_downloaded_a_pretrained_graph_i_want_to/,learningeveryday111,1563485097,"* I am using faster rnn v2 solver. 
* I have cloned a captcha solver git. From there I have downloaded a trained graph which was trained on 1K captcha images. But it is not solving captchas for my own images. I have seen that it works for images similar to those in the training set. 
* I want to know if I can add further train the graph with my own train/test set. I have manually labelled 300 such images. 
* Do I have to edit the config file of the model? Or change the checkpoints? I have no clue
* I assume that my problem must have a systematic answer since it seems obvious that the makers of tensorflow would want to keep training their models with newer data. I lack the knowledge and the vocabulary to look up on the internet. 

Thank you so much ",4,0,False,self,,,,,
226,deeplearning,t5_2t5eh,2019-7-19,2019,7,19,8,cezn60,self.deeplearning,Pytorch reinforcement learning in C++,https://www.reddit.com/r/deeplearning/comments/cezn60/pytorch_reinforcement_learning_in_c/,Teenvan1995,1563490821,"Check out Pytorch-RL-CPP: a C++ (Libtorch) implementation of Deep Reinforcement Learning algorithms with C++ Arcade Learning Environment.

One of the motivations behind this project was that existing projects with c++ implementations were using hacks to get the gym to work and therefore incurring a significant overhead which kind of breaks the point of having a fast implementation. 

Some of the ideas I have is to have something like fastai but for reinforcement learning in c++. I know it's really ambitious so if anyone wants to help out, send a PR! 
Thanks!

[Pytorch-RL-CPP](https://github.com/navneet-nmk/Pytorch-RL-CPP)",2,21,False,self,,,,,
227,deeplearning,t5_2t5eh,2019-7-19,2019,7,19,9,cf0bvr,self.deeplearning,Deep Learning inference in floating-point,https://www.reddit.com/r/deeplearning/comments/cf0bvr/deep_learning_inference_in_floatingpoint/,CArchGuy,1563494579,Are there any current natural language processing (NLP) models that require floating-point computations during inference? or can all NLP models be quantized work with fixed-point computations?,0,3,False,self,,,,,
228,deeplearning,t5_2t5eh,2019-7-19,2019,7,19,12,cf2nu7,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cf2nu7/data_science_career_track_prep_course/,HannahHumphreys,1563508306,[removed],0,1,False,self,,,,,
229,deeplearning,t5_2t5eh,2019-7-19,2019,7,19,13,cf2t7g,blog.udacity.com,Announcing the DeepRacer Scholarship Challenge from AWS,https://www.reddit.com/r/deeplearning/comments/cf2t7g/announcing_the_deepracer_scholarship_challenge/,ConfidentMushroom,1563509238,,1,0,False,default,,,,,
230,deeplearning,t5_2t5eh,2019-7-19,2019,7,19,18,cf5le8,self.deeplearning,Gpu price/value performance,https://www.reddit.com/r/deeplearning/comments/cf5le8/gpu_pricevalue_performance/,imperfectum,1563529866,"I just got interested in deep learning. For now I use Google colab, but I decided to buy some gpu. I'd like to ask you what gpu should I get? In my country used rtx 2070 is a little cheaper than 2060super, and 2070super is 100$ cheaper than used 2080. Used 2070 is ~180$ cheaper than 2070super. Which gpu is best for the money? Is it better to give ~300$ more for used 2080 or go with 2070/2060super?",0,2,False,self,,,,,
231,deeplearning,t5_2t5eh,2019-7-19,2019,7,19,19,cf60gp,youtube.com,"For me, one of the main barriers to the world of deep learning was setting up all the tools. Here's a video that I hope will eliminate this barrier. Hope you guys found it helpful!",https://www.reddit.com/r/deeplearning/comments/cf60gp/for_me_one_of_the_main_barriers_to_the_world_of/,antaloaalonso,1563533072,,4,40,False,image,,,,,
232,deeplearning,t5_2t5eh,2019-7-19,2019,7,19,19,cf60vd,self.deeplearning,I want to compete in deep learning competitions like Kaggle. Is RTX 2070 super sufficient?,https://www.reddit.com/r/deeplearning/comments/cf60vd/i_want_to_compete_in_deep_learning_competitions/,ar0752545,1563533156,"My processor is Core I9 9900K
16 GB RAM
480 GB SSD",6,1,False,self,,,,,
233,deeplearning,t5_2t5eh,2019-7-19,2019,7,19,23,cf7yn3,self.deeplearning,[Research] Predicting the Generalization Gap in Deep Neural Networks,https://www.reddit.com/r/deeplearning/comments/cf7yn3/research_predicting_the_generalization_gap_in/,cdossman,1563545127,"[https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-predicting-the-generalization-gap-in-deep-neural-networks-60d5568deb5d](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-predicting-the-generalization-gap-in-deep-neural-networks-60d5568deb5d) 

Abstract: we propose the use of a *normalized margin* distribution across network layers as a predictor of the *generalization gap*. We empirically study the relationship between the margin distribution and generalization and show that, after proper normalization of the distances, some basic statistics of the margin distributions can accurately predict the generalization gap. We also make available all the models used as a dataset for studying generalization through the github repository.",0,1,False,self,,,,,
234,deeplearning,t5_2t5eh,2019-7-20,2019,7,20,1,cf9hg0,github.com,"AshPy: TensorFlow 2.0 library for distributed training, evaluation, model selection, and fast prototyping",https://www.reddit.com/r/deeplearning/comments/cf9hg0/ashpy_tensorflow_20_library_for_distributed/,pgaleone,1563552746,,0,2,False,default,,,,,
235,deeplearning,t5_2t5eh,2019-7-20,2019,7,20,1,cf9ro2,self.computervision,Brambox: Object detection statistics made easy,https://www.reddit.com/r/deeplearning/comments/cf9ro2/brambox_object_detection_statistics_made_easy/,OPLinux,1563554113,,1,1,False,default,,,,,
236,deeplearning,t5_2t5eh,2019-7-20,2019,7,20,3,cfbfny,self.deeplearning,Universal function approximator of bounded range function,https://www.reddit.com/r/deeplearning/comments/cfbfny/universal_function_approximator_of_bounded_range/,ranirlol,1563561865,"Hello,

I have a question concerning the universal function approximator property. In my case, the function I want to approximate has a range over \[0,infinity). My question is, if I were to use ReLU as the output function a feedforward neural network in order to match the range of the function, would the universal function approximator theorem still apply? From Hornik (1991), the output function is linear. Any papers that tackle this problem?

Note that within my set-up, I'm constrained to use ReLU as the output function. 

Thanks a lot.",0,0,False,self,,,,,
237,deeplearning,t5_2t5eh,2019-7-20,2019,7,20,4,cfbwwu,self.deeplearning,Simulated Hardware for Training Neuromorphic Networks,https://www.reddit.com/r/deeplearning/comments/cfbwwu/simulated_hardware_for_training_neuromorphic/,IcyBaba,1563564164,Does anyone have any useful simulation software of analog neural networks or a paper describing a good model for a multi-neuron hardware setup (so I can make a reasonable fidelity simulation)? Does anyone have access to the Intel Loihi research chip?,2,2,False,self,,,,,
238,deeplearning,t5_2t5eh,2019-7-20,2019,7,20,4,cfc7wr,self.deeplearning,Legacy tensorflow mastery,https://www.reddit.com/r/deeplearning/comments/cfc7wr/legacy_tensorflow_mastery/,lokeshsonii,1563565638,"Hi, I've been using tensorflow native Keras for almost everything I do but I want be an expert in legacy tensorflow instead of Keras. I feel that's where I'll get more control over the framework itself. I'm into computer vision as of now. Can someone recommend the latest book/link/videos to learn more about legacy tensorflow. Thanks!",1,3,False,self,,,,,
239,deeplearning,t5_2t5eh,2019-7-20,2019,7,20,6,cfd55e,self.deeplearning,Buy another 1080ti or upgrade to single 2080ti (FP16)?,https://www.reddit.com/r/deeplearning/comments/cfd55e/buy_another_1080ti_or_upgrade_to_single_2080ti/,arc144,1563570238,"Hi,  I currently have a single 1080ti, which I use for deep learning  projects and kaggle competitions. I intend to upgrade my rig but I'm not  sure if I should go for another 1080ti or sell my 1080ti and buy a  2080ti. The price for both is almost the same (actually I need to buy  another psu if I go with 2 gpus, so 2x1080ti is more expensive) .

- **2x1080ti**: 
    - **Pros**: can run 2 experiments in parallel, a bit faster and more  memory 
    - **Cons**: more power consumption, need to but another psu, can't  upgrade further

- **2080ti**: 
    - **Pros**: can  train on FP16 (roughly 70% faster than a single 1080ti and almost  doubles the memory), less power consumption, easier to sell later (imo),  can buy a second one later, no need to buy a better psu right now 
    - **Cons**:  less raw memory (11 vs 22), much lower performance than 2x1080ti on  FP32, need to sell my current 1080ti (2 different gpus would be bad I  believe)

Anyone went through a similar experience and can give some advices? Thanks",15,8,False,self,,,,,
240,deeplearning,t5_2t5eh,2019-7-20,2019,7,20,8,cfenwj,self.deeplearning,Optimizing parameters for CNN autoencoder based on training and validation loss,https://www.reddit.com/r/deeplearning/comments/cfenwj/optimizing_parameters_for_cnn_autoencoder_based/,BlackHawk1001,1563577750,"Hello everybody

&amp;#x200B;

I have designed an autoencoder with a encoder and decoder consiting of 2D convolutational layers (the input are 40'000 2D images). I train the autoencoder using adam optimizer. The autoencoders has the following hyperparameters which I would like to tune (in brackets are my default values):

&amp;#x200B;

 \- Number of layers in encoder and decoder (I start with 2 in decoder and encoder)

 \- Filter size for convolutional layers (I start with 32 and 64)

 \- Convolutional kernel size (I start with 3x3)

 \- Stride size (I start with 2x2)

 \- Dropout (I start with 0.25 after each layer)

 \- Learning rate (0.001)

 \- learning\_rate\_decay (0)

 \- Latent dimension (I start with 8)

 \- Number of units in the dense layer (layer before creating latent space, I start with 16)

 \- Batch size (I start with 128)

&amp;#x200B;

One possibility would be to use just grid or random search but this is very inefficient and takes a long time with so many hyperparameters. Instead, I would like to observe the training and validation loss (using tensorboard) and adjust the parameters accordingly. For example when observing the training and validation loss there could be overfitting or underfitting (or also an increase in loss etc.).

&amp;#x200B;

Are there some general rules or hints how the hyperparameters could be adjusted based on the observed losses or based on other criterions?",0,1,False,self,,,,,
241,deeplearning,t5_2t5eh,2019-7-20,2019,7,20,12,cfh45v,arxiv.org,OmniNet: A unified architecture for multi-modal multi-task learning,https://www.reddit.com/r/deeplearning/comments/cfh45v/omninet_a_unified_architecture_for_multimodal/,turing_1997,1563592588,,0,15,False,default,,,,,
242,deeplearning,t5_2t5eh,2019-7-20,2019,7,20,18,cfk3a3,self.deeplearning,Speed up your reading,https://www.reddit.com/r/deeplearning/comments/cfk3a3/speed_up_your_reading/,davenlin19,1563615985,"Do you want to speed up your online reading with highlighted, skimmed, scanned or summarized resources? Would you benefit from them? What if there is a service for these resources? Would you use this one to better skim, scan and understand your materials?",3,1,False,self,,,,,
243,deeplearning,t5_2t5eh,2019-7-21,2019,7,21,1,cfnkkc,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cfnkkc/data_science_career_track_prep_course/,HannahHumphreys,1563639425,[removed],0,1,False,self,,,,,
244,deeplearning,t5_2t5eh,2019-7-21,2019,7,21,1,cfnxib,self.deeplearning,is it possible to utilize nvlink for vram pooling using 2 rtx 2070 super gpus?,https://www.reddit.com/r/deeplearning/comments/cfnxib/is_it_possible_to_utilize_nvlink_for_vram_pooling/,Jsom93,1563641354,"Hello everyone one. I'm building a new pc and it will be used for gaming and deep learning. Now I'm trying to choose the best gpu for it (between 1 rtx 2080 ti and 2 rtx 2070 super).

The rtx 2080 ti comes with a 11gb vram. Whereas rtx 2070 super comes with a 8gb vram. And I've read in few places that pooling the vram using nvlink by default is not there but it is uo for developers to implement it. And there are some developers that utilized it for their games.

Now my question is: for keras and tensorflow using python, will the vrams be pooled/shared so I would have 16gb vram out of 2 rtx 2070 super or not?

Also, If it is not possible with nvlink and there is another way to achieve it please tell me. My main concern is having more than 11gb vram without buying quadro/tesla gpus",24,13,False,self,,,,,
245,deeplearning,t5_2t5eh,2019-7-21,2019,7,21,2,cfo7t1,self.deeplearning,Is Mac good choice for deep learning?,https://www.reddit.com/r/deeplearning/comments/cfo7t1/is_mac_good_choice_for_deep_learning/,testimoni,1563642869,I am new on this topic and would like to start with some practice. I have my MacBook pro. Do you think Mac is suitable for DL projects or i should go with Windows PC?,18,2,False,self,,,,,
246,deeplearning,t5_2t5eh,2019-7-21,2019,7,21,2,cfo839,self.deeplearning,Efficient Video Generation on Complex Datasets (Codes and paper in the post),https://www.reddit.com/r/deeplearning/comments/cfo839/efficient_video_generation_on_complex_datasets/,ai-lover,1563642909,"Paper: arxiv.org/abs/1907.06571

They used chainer implementation for t-gan : github.com/pfnet-research

DeepMind did it again - they created realistic videos by just watching a ton of youtube videos.",2,1,False,self,,,,,
247,deeplearning,t5_2t5eh,2019-7-21,2019,7,21,2,cfoqq2,blog.floydhub.com,Becoming One with the data,https://www.reddit.com/r/deeplearning/comments/cfoqq2/becoming_one_with_the_data/,pirate7777777,1563645529,,0,0,False,default,,,,,
248,deeplearning,t5_2t5eh,2019-7-21,2019,7,21,12,cfumnm,self.deeplearning,"How to make a deep fake model take into account global transformation(going far away, close etc?)",https://www.reddit.com/r/deeplearning/comments/cfumnm/how_to_make_a_deep_fake_model_take_into_account/,Isamu_Isozaki,1563679504,"# Background info

Hi. I recently got a request to build a deep fake model using [this video](https://www.youtube.com/watch?v=ETbKiHQ2tP0&amp;amp=&amp;feature=youtu.be). Thus, I separated the video into roughly 17000 frames using [this repository](https://github.com/datitran/face2face-demo) and managed to get better landmarks using [this face detection repository](https://github.com/cleardusk/3DDFA). The output picture is below

[The left is the landmarks and the right is the target image](https://i.redd.it/paa9m68dokb31.png)

After a few hours of training, I got an ok output like

&amp;#x200B;

[Output sample](https://i.redd.it/mhilpeakokb31.png)

To clarify, the goal of this project is to

1. Extract landmarks from the input image and to transform that into the blue blob on the left. (Already successful)
2. Transform the blue blob into a face. (semi-successful)

Thus after a couple of days more of training, I switched to running the deep fake.

*Processing img q83o69v4pkb31...*

*Processing img lyyu7gx4pkb31...*

*Processing img i17cw8v4pkb31...*

*Processing img 1ayolex4pkb31...*

Thus, the problems are mostly

1. The deep fake can't handle global transformation(moving far away and close to the camera)
2. The deep fake can't handle face rotation
3. The deep fake consistently causes noise

# Solutions with problems

For now, I will not include increasing data because since it's a deep fake, there is a requirement that the lighting and the location of the camera to be the same. And so I think it is quite strenuous for the user to correct say a 1-hour video of him moving around.

While I may be able to solve 3 with a denoising GAN but I think it is a bit hard for high res images, for 2 I have no idea. For 1, the three solutions I came up with were

1. Do global transformation(scaling, translating) on the input images before training.

Problem: The background will be inconsistent because I need to fill up the empty spaces with black(0 paddings) which is non-ideal. I thought of using pix2pix to fill up the black spots but usually, I see that done with rectangular cut-outs and not usually from most of the image is black. I think I'll try this approach first though.

2. Force input face size(using dlib) to be a specific size. (non-ideal)

3. Use GAN

 Problem: Hard to produce high res(from my limited experience) images and also hard to generate global transformation like being further away.

&amp;#x200B;

Anyway, those are my thoughts and I think it's fair to say that I'm pretty stuck. If anyone has any suggestions please tell me! Modern deep fakes tend to be quite impressive and I will really like for me to be able to make one like them!",4,10,False,self,,,,,
249,deeplearning,t5_2t5eh,2019-7-21,2019,7,21,17,cfwvt2,self.deeplearning,I want to build my own route navigation model like the one in Google maps. Need help!,https://www.reddit.com/r/deeplearning/comments/cfwvt2/i_want_to_build_my_own_route_navigation_model/,learningeveryday111,1563697574,"I have taken up a project at our Computer Science department where we find the most optimised route between two points, while taking traffic into account. The Google Maps API is not very helpful since it doesnt give us a lot of things to optimise (like giving preference to 8 lane highways etc). It only gives the route directly in a JSON output. 

Id love to know any tutorials, research or a book which teaches about this topic. Can someone help me out with the resources? We expect to complete this project over a year. 

Thank you!",23,19,False,self,,,,,
250,deeplearning,t5_2t5eh,2019-7-21,2019,7,21,20,cfy984,self.deeplearning,Python Data Products for Predictive Analytics,https://www.reddit.com/r/deeplearning/comments/cfy984/python_data_products_for_predictive_analytics/,HannahHumphreys,1563710322,[removed],0,1,False,self,,,,,
251,deeplearning,t5_2t5eh,2019-7-21,2019,7,21,21,cfylqx,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cfylqx/data_science_career_track_prep_course/,HannahHumphreys,1563713008,[removed],0,1,False,self,,,,,
252,deeplearning,t5_2t5eh,2019-7-22,2019,7,22,2,cg1kev,self.deeplearning,Help needed: ArcFace in Keras,https://www.reddit.com/r/deeplearning/comments/cg1kev/help_needed_arcface_in_keras/,deflaid,1563730114,"Hi,

I have a working face recognition pipeline in Keras utilizing ResNet50 as a base model. When I use provided code for ArcFace from github ([https://github.com/4uiiurz1/keras-arcface/blob/master/metrics.py](https://github.com/4uiiurz1/keras-arcface/blob/master/metrics.py), not my repo, original paper link provided below), my neural network refuse to learn anything unless a set the \`m\` hyperparameter to zero, i.e. it becomes plain old softmax dense layer. In m=0 setting I can get &gt;99% val acc on CASIA-WebFace subset. Any ideas why is it not working with m=0.35 or m=0.5? I'm really stuck with this for several days now. I though the problem might be too hard to train right away, so I pretrained my model with m=0, then freezed all base model layers and re-trained with m=0.35, but after \~20 epochs I'm converging to \~0.2 acc.

&amp;#x200B;

\[paper link\]

[https://arxiv.org/abs/1801.07698](https://arxiv.org/abs/1801.07698)

\[implementation details\]

I'm using the same base model as in the paper (ResNet50+BN+Dropout+FC+BN), 512-D embedding size, SGD with lr=0.1 with momentum=0.9 and lr schedule same as specified in paper. Data classes are upscaled, so the training data is well balanced. All images in train and dev set are transformed using similarity transformation using 5 facial landmarks provided in SphereFace official repo and resized to 112x96 RGB image.",11,3,False,self,,,,,
253,deeplearning,t5_2t5eh,2019-7-22,2019,7,22,3,cg27hv,self.deeplearning,Interview with World's First Triple Kaggle Grandmaster: Abhishek Thakur,https://www.reddit.com/r/deeplearning/comments/cg27hv/interview_with_worlds_first_triple_kaggle/,init__27,1563733381,"It's really an honor for me to kick-off The Chai Time Data Science Show with an interview with the Only Triple Grandmaster on Kaggle: 

&amp;#x200B;

Here are the links to the interview. You can find it both in audio and video (of the interview) format:

[Podcast](https://anchor.fm/chaitimedatascience/episodes/Kaggle-Triple-Grandmaster--Abhishek-Thakur-Interview-e4mjoi)

&amp;#x200B;

[Video](https://www.youtube.com/watch?v=vMtORPcjDn8&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=2)

&amp;#x200B;

I'll be releasing 1 episode every Thursday, Sunday. 

Hope you like it, If you have any ideas/comments/suggestions, I'd really love to hear them.",4,8,False,self,,,,,
254,deeplearning,t5_2t5eh,2019-7-22,2019,7,22,12,cg8apu,self.deeplearning,Cat Vs not cat model Evaluation.,https://www.reddit.com/r/deeplearning/comments/cg8apu/cat_vs_not_cat_model_evaluation/,Herosixty7,1563767748,"I was working on some problem investigating building cat image classifiers. Unfortunately, the classifier ,correctly, classifies Amanda Seyfried as non-cat picture :(

https://i.redd.it/uojn12ae2sb31.png",14,6,False,self,,,,,
255,deeplearning,t5_2t5eh,2019-7-22,2019,7,22,13,cg8gzz,self.deeplearning,A basic underrating of image embedding,https://www.reddit.com/r/deeplearning/comments/cg8gzz/a_basic_underrating_of_image_embedding/,shivam529,1563768824,"Ive read numerous Articles and sometime I feel I have it all figured out and sometimes I dont, I just wanna know if my basic understanding is right ?  Say i have any deep learning vanilla architecture to start with , barring the output layer, could I use the the last output layer as my image embedding in how much ever dimensions according to my need ?",8,5,False,self,,,,,
256,deeplearning,t5_2t5eh,2019-7-22,2019,7,22,15,cg9py7,analyticsindiamag.com,Facebook DLRM Is A Game Changer for Recommendation Models,https://www.reddit.com/r/deeplearning/comments/cg9py7/facebook_dlrm_is_a_game_changer_for/,analyticsindiam,1563777549,,0,30,False,default,,,,,
257,deeplearning,t5_2t5eh,2019-7-22,2019,7,22,17,cgah4h,rubikscode.net,Deep Convolutional Q-Learning with Python and TensorFlow 2.0,https://www.reddit.com/r/deeplearning/comments/cgah4h/deep_convolutional_qlearning_with_python_and/,pmz,1563783486,,0,1,False,default,,,,,
258,deeplearning,t5_2t5eh,2019-7-22,2019,7,22,21,cgckyy,blog.floydhub.com,Gated Recurrent Unit (GRU) With PyTorch,https://www.reddit.com/r/deeplearning/comments/cgckyy/gated_recurrent_unit_gru_with_pytorch/,pirate7777777,1563798516,,0,26,False,default,,,,,
259,deeplearning,t5_2t5eh,2019-7-22,2019,7,22,22,cgcy13,self.deeplearning,A problem with training DCGANs,https://www.reddit.com/r/deeplearning/comments/cgcy13/a_problem_with_training_dcgans/,AbdulhadyFeteiha,1563800657,"I'm trying to generate paintings from Edvard Munch (a Norwegian artist) paintings data set. However, the generator doesn't develop over time! it keeps generating noise.

I claim that this happens due to the very limited data set (210 paintings, all i found).

I use a standard DCGANs architecture with 64\*64\*3 input dimensions. I tried training the model for 190, 1000 epochs with no results.

Below are samples of the output after: 4,20, and 1000 epochs. I hope that you can direct me to the mistake i'm making.

[1000 epochs](https://i.redd.it/er3newm9sub31.png)

[20 epochs](https://i.redd.it/xcgmss47sub31.png)

&amp;#x200B;

[4 epochs](https://i.redd.it/tvdwfdo9sub31.png)

Any ideas?",1,2,False,self,,,,,
260,deeplearning,t5_2t5eh,2019-7-22,2019,7,22,23,cgdmgc,self.deeplearning,How can I apply deep learning for OCR,https://www.reddit.com/r/deeplearning/comments/cgdmgc/how_can_i_apply_deep_learning_for_ocr/,addcolourtourlife,1563804342,"I need to extract text from scanned documents , eliminating headers, footers, tables etc.. extracting a structured paragraphs 

While using tesseract, able to extract text but it has all the special characters , headers, footers .. etc..

Is there anyway to apply deeplearning to extract clean paragraphs so that I can use it for text analysis?",8,10,False,self,,,,,
261,deeplearning,t5_2t5eh,2019-7-22,2019,7,22,23,cgdtgm,self.deeplearning,Where can I find a database of hand or finger images?,https://www.reddit.com/r/deeplearning/comments/cgdtgm/where_can_i_find_a_database_of_hand_or_finger/,Gameatro,1563805331,I am looking for a database of just hand or finger images. I don't want finger veins or hand gestures. I am not able to find such a database. All I got from searching on the internet is finger veins and prints or hand gestures. I need just finger images for my deep learning model. Can I get a link to an unlabelled database of that?,0,2,False,self,,,,,
262,deeplearning,t5_2t5eh,2019-7-22,2019,7,22,23,cgdzxi,self.deeplearning,[Research] A large-scale Corpus of Talk Radio Transcripts,https://www.reddit.com/r/deeplearning/comments/cgdzxi/research_a_largescale_corpus_of_talk_radio/,cdossman,1563806212,"[https://medium.com/ai%C2%B3-theory-practice-business/2-8-billion-words-of-transcribed-speech-for-social-science-and-natural-language-processing-d9857cb74c03](https://medium.com/ai%C2%B3-theory-practice-business/2-8-billion-words-of-transcribed-speech-for-social-science-and-natural-language-processing-d9857cb74c03) 

Abstract:  We introduce RadioTalk, a corpus of speech recognition transcripts sampled from talk radio broadcasts in the United States between October of 2018 and March of 2019. The corpus is intended for use by researchers in the fields of natural language processing, conversational analysis, and the social sciences. The corpus encompasses approximately 2.8 billion words of automatically transcribed speech from 284,000 hours of radio, together with metadata about the speech, such as geographical location, speaker turn boundaries, gender, and radio program information. In this paper we summarize why and how we prepared the corpus, give some descriptive statistics on stations, shows and speakers, and carry out a few high-level analyses.",2,9,False,self,,,,,
263,deeplearning,t5_2t5eh,2019-7-23,2019,7,23,0,cgejdh,self.deeplearning,A Summary of How Google Deep Learning is Essential to Understand Value of AI ML in World,https://www.reddit.com/r/deeplearning/comments/cgejdh/a_summary_of_how_google_deep_learning_is/,SunilAhujaa,1563808835,"Google Deep Learning Course is a popular segment in the AI and Data Science community. Known for its timely updates and futuristic applications, Data Scientists find all the resources in Google library very relevant to their ongoing projects in Machine Learning. For more information please visit here [https://www.analytixlabs.co.in/blog/2019/07/14/summary-google-deep-learning-essential-understand-value-ai-ml-world/](https://www.analytixlabs.co.in/blog/2019/07/14/summary-google-deep-learning-essential-understand-value-ai-ml-world/)",0,0,False,self,,,,,
264,deeplearning,t5_2t5eh,2019-7-23,2019,7,23,0,cgelk0,self.deeplearning,Is DCGAN the right method for this?,https://www.reddit.com/r/deeplearning/comments/cgelk0/is_dcgan_the_right_method_for_this/,nexxai,1563809113,"I have about 25,000 different photos of a subject (all with the same resolution of 1280x1024), and what I'd like to do is feed these into some kind of deep learning algorithm, with the intent of having it generate new photos of similar, but not real, subjects.  It would be similar to https://github.com/pearsonkyle/Artificial-Art except rather than generating animated 128x128 mini-photo/videos, I would just want to generate static, full-size photos, one at a time.  

I've got a fairly basic knowledge of deep learning and I want to learn a lot more, but I just want to make sure I'm not spinning my wheels and looking in the wrong place.",4,2,False,self,,,,,
265,deeplearning,t5_2t5eh,2019-7-23,2019,7,23,1,cgf2sx,youtube.com,Bernie Sanders on Jews [ Larry David Deepfake ],https://www.reddit.com/r/deeplearning/comments/cgf2sx/bernie_sanders_on_jews_larry_david_deepfake/,deepfakeblue,1563811375,,0,1,False,image,,,,,
266,deeplearning,t5_2t5eh,2019-7-23,2019,7,23,1,cgfohj,self.deeplearning,Machine Learning and Big Data Analytics with AWS,https://www.reddit.com/r/deeplearning/comments/cgfohj/machine_learning_and_big_data_analytics_with_aws/,HannahHumphreys,1563814198,[removed],0,1,False,self,,,,,
267,deeplearning,t5_2t5eh,2019-7-23,2019,7,23,8,cgknz1,self.deeplearning,How to do hyperparameter tuning with Unet in Keras?,https://www.reddit.com/r/deeplearning/comments/cgknz1/how_to_do_hyperparameter_tuning_with_unet_in_keras/,74throwaway,1563837550,"This is what I've tried so far using code from https://github.com/zhixuhao/unet:

    from model import *
    from data import *
    
    from hyperopt import fmin, tpe, hp, STATUS_OK, Trials
    from sklearn.metrics import roc_auc_score
    import sys
    
    space = {
            'lr': hp.choice('lr', [1e-6,5e-5,1e-5,5e-4,1e-4,5e-3,1e-3]),
            'batchi': hp.choice('batchi',  [0,1]),
            'dropout1': hp.choice('dropout1', [.3,.4,.5,.6,.7]),
            'dropout2': hp.choice('dropout2',  [.3,.4,.5,.6,.7]),
            'steps_per_epoch': hp.choice('steps_per_epoch',  [5,10,20]),
            'epochs': hp.choice('epochs',  [1,2,3,4]),
            'down_activation': hp.choice('down_activation',['relu','elu']),
            'up_activation': hp.choice('up_activation',['relu','elu']),
            }
    
    def unet_batch_hyper(space,pretrained_weights = None):
        
        print(""UNET_hyperparameter test"")
    
        input_size = (256,256,1)
        inputs = Input(input_size)
        
        conv1 = Conv2D(64, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(inputs)
        if space['batchi']==1:
            conv1 = BatchNormalization()(conv1)
        conv1 = Conv2D(64, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv1)
        if space['batchi']==1:
            conv1 = BatchNormalization()(conv1)
        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
        conv2 = Conv2D(128, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(pool1)
        if space['batchi']==1:
            conv2 = BatchNormalization()(conv2)
        conv2 = Conv2D(128, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv2)
        if space['batchi']==1:
            conv2 = BatchNormalization()(conv2)
        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
        conv3 = Conv2D(256, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(pool2)
        if space['batchi']==1:
            conv3 = BatchNormalization()(conv3)
        conv3 = Conv2D(256, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv3)
        if space['batchi']==1:
            conv3 = BatchNormalization()(conv3)
        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
        conv4 = Conv2D(512, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(pool3)
        if space['batchi']==1:
            conv4 = BatchNormalization()(conv4)
        conv4 = Conv2D(512, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv4)
        if space['batchi']==1:
            conv4 = BatchNormalization()(conv4)
        drop4 = Dropout(0.5)(conv4)
        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)
    
        conv5 = Conv2D(1024, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(pool4)
        if space['batchi']==1:
            conv5 = BatchNormalization()(conv5)
        conv5 = Conv2D(1024, 3, activation = space['down_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv5)
        if space['batchi']==1:
            conv5 = BatchNormalization()(conv5)
        drop5 = Dropout(0.5)(conv5)
    
        up6 = Conv2D(512, 2, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
        merge6 = concatenate([drop4,up6], axis = 3)
        conv6 = Conv2D(512, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(merge6)
        conv6 = Conv2D(512, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv6)
    
        up7 = Conv2D(256, 2, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
        merge7 = concatenate([conv3,up7], axis = 3)
        conv7 = Conv2D(256, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(merge7)
        conv7 = Conv2D(256, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv7)
    
        up8 = Conv2D(128, 2, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
        merge8 = concatenate([conv2,up8], axis = 3)
        conv8 = Conv2D(128, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(merge8)
        conv8 = Conv2D(128, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv8)
    
        up9 = Conv2D(64, 2, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
        merge9 = concatenate([conv1,up9], axis = 3)
        conv9 = Conv2D(64, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(merge9)
        conv9 = Conv2D(64, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv9)
        conv9 = Conv2D(2, 3, activation = space['up_activation'], padding = 'same', kernel_initializer = 'he_normal')(conv9)
        conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)
    
        model = Model(input = inputs, output = conv10)
    
        model.compile(optimizer = Adam(lr = space['lr']), loss = 'binary_crossentropy', metrics = [mean_iou1])#'accuracy'])
        
    
        if(pretrained_weights):
            model.load_weights(pretrained_weights)
    
        lr = space['lr']
        filepath=""weights-LR_""+str(lr)+""-S_20-E_{epoch:02d}-L_{loss:.2f}-batchN.hdf5""
        model_checkpoint = ModelCheckpoint(filepath,monitor='loss',verbose=1, save_best_only=True)
    
        return {'loss': loss1, 'status': STATUS_OK, 'model': model}
    
    trials = Trials()
    best = fmin(unet_batch_hyper, space, algo=tpe.suggest, max_evals=50, trials=trials)
    print('best: ')
    print(best)

Where I wasn't sure what to include for `loss1`. I read some tutorials online about how to use `hyperopt` in Keras, but I couldn't find anything for Unets. What I found online usually included:

    score, acc = model.evaluate(X_val, Y_val, verbose=0)
    return {'loss': -acc, 'status': STATUS_OK, 'model': model}

so instead of `model.fit_generator`, should I instead try the below?

    model.fit(X_train, y_train,     steps_per_epoch=space['steps_per_epoch'],epochs=space['epochs'], verbose = 0,callbacks=[val_call])
    score, acc = model.evaluate(X_test, Y_test, verbose=0)
    return {'loss': -acc, 'status': STATUS_OK, 'model': model}

and thus have to modify `def unet_batch_hyper(space,pretrained_weights = None):` so that it becomes this?

    def unet_batch_hyper(space,X_train, y_train, X_test, Y_test, pretrained_weights = None):",0,1,False,self,,,,,
268,deeplearning,t5_2t5eh,2019-7-23,2019,7,23,19,cgqnmn,github.com,Efficient Semantic Text Retrieval with Google's Universal Sentence Encoder and AquilaDB,https://www.reddit.com/r/deeplearning/comments/cgqnmn/efficient_semantic_text_retrieval_with_googles/,iamjbn,1563876219,,8,26,False,default,,,,,
269,deeplearning,t5_2t5eh,2019-7-23,2019,7,23,19,cgqp3b,self.deeplearning,"Question regarding ""architecture provides the family of possible distributions to sample from""",https://www.reddit.com/r/deeplearning/comments/cgqp3b/question_regarding_architecture_provides_the/,sriharsha_0806,1563876498,"Hi, 

In the Deep learning textbook of Ian Goodfellow, from Differentiable Generator Networks of  Deep Generative Models Chapter. It is mentioned, ""Where the architecture provides the family of possible distributions to sample from and the parameters select a distribution from within that family"". I thought the family of distributions is formed while the Backpropagation algorithm is training the data. But as mentioned in the sentence above the architecture itself provides a family of distributions to select from.",0,1,False,self,,,,,
270,deeplearning,t5_2t5eh,2019-7-23,2019,7,23,19,cgqpde,self.deeplearning,What is ancestral sampling?,https://www.reddit.com/r/deeplearning/comments/cgqpde/what_is_ancestral_sampling/,sriharsha_0806,1563876545,can anybody explain what is ancestral sampling?,1,3,False,self,,,,,
271,deeplearning,t5_2t5eh,2019-7-24,2019,7,24,0,cgu45l,self.deeplearning,What technologies does Andrej Karpathy use at Tesla ?,https://www.reddit.com/r/deeplearning/comments/cgu45l/what_technologies_does_andrej_karpathy_use_at/,That_Actuator,1563896005,I am looking for which OS he uses and which Frameworks etc. are used for Autopilot development ?,4,5,False,self,,,,,
272,deeplearning,t5_2t5eh,2019-7-24,2019,7,24,4,cgwysp,self.deeplearning,Can someone provide me links of some well commented ML/DL paper implementations in Github?,https://www.reddit.com/r/deeplearning/comments/cgwysp/can_someone_provide_me_links_of_some_well/,Hot_Ices,1563908946,"I was planning to read some easy and interesting ML/DL papers along with its implementation. But most of the papers' implementation are not well commented along side the codes. If you know some well commented implementations , please share.",8,22,False,self,,,,,
273,deeplearning,t5_2t5eh,2019-7-24,2019,7,24,4,cgxgql,medium.com,"2019 Google Scholar Metrics Released, CVPR Cracks the Top Ten",https://www.reddit.com/r/deeplearning/comments/cgxgql/2019_google_scholar_metrics_released_cvpr_cracks/,Yuqing7,1563911246,,0,1,False,default,,,,,
274,deeplearning,t5_2t5eh,2019-7-24,2019,7,24,5,cgy0es,self.deeplearning,LSTM parameter selection for sequence classification,https://www.reddit.com/r/deeplearning/comments/cgy0es/lstm_parameter_selection_for_sequence/,pk12_,1563913774,"Is there a guidebook or papers which provide ball park parameters for number of hidden units and the number of LSTM nodes?

It seems people just use cross validation, no explainable intuition involved",2,11,False,self,,,,,
275,deeplearning,t5_2t5eh,2019-7-24,2019,7,24,17,ch5cre,github.com,Found on GitHub a blazingly fast implementation of Byte Pair Encoding (BPE) algorithm. Much faster than Google SentencePiece.,https://www.reddit.com/r/deeplearning/comments/ch5cre/found_on_github_a_blazingly_fast_implementation/,Yutkin,1563955953,,3,64,False,default,,,,,
276,deeplearning,t5_2t5eh,2019-7-24,2019,7,24,22,ch8ieh,self.deeplearning,[Research] How much real data do we actually need: Analyzing object detection performance using synthetic and real data,https://www.reddit.com/r/deeplearning/comments/ch8ieh/research_how_much_real_data_do_we_actually_need/,cdossman,1563976634,"Abstract:  In recent years, deep learning models have resulted in a huge amount of progress in various areas, including computer vision. By nature, the supervised training of deep models requires a large amount of data to be available. This ideal case is usually not tractable as the data annotation is a tremendously exhausting and costly task to perform. An alternative is to use synthetic data. In this paper, we take a comprehensive look into the effects of replacing real data with synthetic data. We further analyze the effects of having a limited amount of real data. We use multiple synthetic and real datasets along with a simulation tool to create large amounts of cheaply annotated synthetic data. We analyze the domain similarity of each of these datasets. We provide insights about designing a methodological procedure for training deep networks using these datasets 

 [https://medium.com/ai%C2%B3-theory-practice-business/how-much-real-data-do-we-actually-need-71c4e83bbd33](https://medium.com/ai%C2%B3-theory-practice-business/how-much-real-data-do-we-actually-need-71c4e83bbd33)",0,4,False,self,,,,,
277,deeplearning,t5_2t5eh,2019-7-24,2019,7,24,23,ch8oxe,self.deeplearning,Machine Learning Subreddits,https://www.reddit.com/r/deeplearning/comments/ch8oxe/machine_learning_subreddits/,antaloaalonso,1563977545,"I've noticed that on many of the ML subreddits, there is a wide variety of libraries and tools used. For the experienced programmer, this may be okay or even preferable. However, if you are like the majority of ML programmers, then this can be intimidating, confusing, and frustrating. For those of you that fall in this category, I would like to invite you to a subreddit ([r/MachineLearningKeras](https://www.reddit.com/r/MachineLearningKeras/)) that will be focused on machine learning with the Keras API. Keras is easy to use, and is a great way to implement various projects. I hope that you will join me in making such a community on Reddit.",1,8,False,self,,,,,
278,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,0,ch9hy6,self.deeplearning,Are cGANs used to solve image segmentation problem ?,https://www.reddit.com/r/deeplearning/comments/ch9hy6/are_cgans_used_to_solve_image_segmentation_problem/,ReinforcementBoi,1563981473,I have not seen work where people use pix2pix or pix2pixHD to solve image segmentation problems. Why do regression setups work better in segmentation problems ?,3,3,False,self,,,,,
279,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,0,ch9j23,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/ch9j23/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1563981616,[removed],0,1,False,self,,,,,
280,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,1,cha2pa,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cha2pa/data_science_career_track_prep_course/,HannahHumphreys,1563984161,[removed],0,1,False,self,,,,,
281,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,1,cha324,self.deeplearning,Deep Learning Book,https://www.reddit.com/r/deeplearning/comments/cha324/deep_learning_book/,HippeTeddyBear,1563984207,"I was reading the DL textbook from [here](https://www.deeplearningbook.org/contents/generative_models.html). I understand how the probability of individual elements of hidden layer h gets derived. However, I could not understand the equation (20.15), which derive the conditional distribution of hidden layer h over visible layer v. Here is a screenshot from the textbook 

[Screen Shot from the Textbook](https://i.redd.it/bzw9wb3cy9c31.png)

 I hope to get some explanation of how it is derived. Any help would be appreciated. Thank you very much!",2,9,False,self,,,,,
282,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,1,cha5tg,self.deeplearning,"Is backpropagation the ""normie stuff"" of machine learning",https://www.reddit.com/r/deeplearning/comments/cha5tg/is_backpropagation_the_normie_stuff_of_machine/,DepHea,1563984540,i hardly understand this shit,7,0,False,self,,,,,
283,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,1,chaf6v,self.deeplearning,Computer Vision,https://www.reddit.com/r/deeplearning/comments/chaf6v/computer_vision/,HannahHumphreys,1563985736,[removed],0,1,False,self,,,,,
284,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,4,chcyop,self.deeplearning,L2 norm to find loss in deep learning,https://www.reddit.com/r/deeplearning/comments/chcyop/l2_norm_to_find_loss_in_deep_learning/,shivam529,1563997515,"For finding error between an image and output of a network we use sum of squared error , but most articles then call it L2 norm of matrix substractions of these two images which is the same thing, could someone explain how is it the same thing ?",1,5,False,self,,,,,
285,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,6,che1kd,self.deeplearning,An Explanation of Self-Supervised Deep Learning,https://www.reddit.com/r/deeplearning/comments/che1kd/an_explanation_of_selfsupervised_deep_learning/,HenryAILabs,1564002536,[https://www.youtube.com/watch?v=lbKg3OSTsgA&amp;t=198s](https://www.youtube.com/watch?v=lbKg3OSTsgA&amp;t=198s),2,3,False,self,,,,,
286,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,13,chj66d,self.deeplearning,Using OCR to write new documents,https://www.reddit.com/r/deeplearning/comments/chj66d/using_ocr_to_write_new_documents/,TheBrokenArt,1564030373,"I apologize if this is the wrong place for this question as I am just beginning to get involved in the deep learning space.

I couldn't find any resources for what I was looking for specifically, so I figured I'd try asking here.

I'm looking to use OCR and deep learning to feed text files (pdfs, word, etc) on a certain topic to the program and have it predict (or write) new information on the topic, based on the files its received.

Is this something that can be done? If so, how plausible is it for someone new to deep learning (not python language) to get started on a project like this?

Thanks in advance!",2,4,False,self,,,,,
287,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,15,chjvhq,self.deeplearning,Neural style transfer,https://www.reddit.com/r/deeplearning/comments/chjvhq/neural_style_transfer/,shivam529,1564035146,How would you use more than one style image in case of neural transfer ?,4,2,False,self,,,,,
288,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,15,chjzpu,self.deeplearning,What is the status of Capsule Network R&amp;D?,https://www.reddit.com/r/deeplearning/comments/chjzpu/what_is_the_status_of_capsule_network_rd/,rahul_roy_youtuber,1564036008,"So, I've started studying about Capsule Network for my classification project and thought about giving it a shot above my CNN implementation. But i saw that it takes about 15 to 20 mins to complete only one epoch, whereas my CNN model takes hardly 15-20 seconds. (My laptop specs: 7th gen i7, GTX 1050Ti, 16GB DDR4 RAM). And I've also noticed that it's been a while since it was introduced but it seems not many people are implementing this. What is the reason? P.S.: I didn't complete my training of the capsule network, as it was taking a really long time on my computer and didn't want to invest my time if it was not much benefitial.",4,17,False,self,,,,,
289,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,16,chkfjp,self.deeplearning,Questions about Pc recommendations,https://www.reddit.com/r/deeplearning/comments/chkfjp/questions_about_pc_recommendations/,Kidneystoner04,1564039156,"Im currently a student of engineering and recently started researching deep learning more and was wondering if my laptop could do anything basic? It has a gpu with 6gb vram, 16gb of ram, and an intel 8700k Id love to hear any advice yall have.",3,2,False,self,,,,,
290,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,17,chksui,self.deeplearning,Newbie Deep-Learning Machine Help: AMD ROCm vs NVIDIA CUDA,https://www.reddit.com/r/deeplearning/comments/chksui/newbie_deeplearning_machine_help_amd_rocm_vs/,RisingShogun,1564041946,"Hi! Im starting to get involved with like, the literal beginning of deep learning. Im building a machine because this is the first time I can actually build something of that magnitude + I really want to build something. My main conflict is with the type of interface I want to use. Ill leave some of the specifications Im leaning towards to give a better picture:

OS: Ubuntu Server 18.04
CPU: Ryzen 7 2700X
SSD/HDD: 2TB/6TB
PSU: EVGA P2 750W

Also some additional background info:
Im going for a Computer Science major at my college (penn state gang gang), so MATLAB is going to be used a decent ton when the time comes (in the next couple years)

The main issue is the confusion on what interface I should be using. I did want to use AMD ROCm because Im lowkey an AMD fanboy but also I really dont mind learning a whole lot of the coding language. I do know that CUDA is practically used everywhere and that is like a big bonus. My main concern with either or is being able to run MATLAB in the future when that time comes, so Im trying to go through the process as thoroughly as possible. If anyone has any misconceptions to break down or any input on which direction I should go for (especially any sources for more research), that would be a life saver!

Thanks in advance for any input! :)",7,11,False,self,,,,,
291,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,20,chmijl,self.deeplearning,FITCKNN with large data sets?,https://www.reddit.com/r/deeplearning/comments/chmijl/fitcknn_with_large_data_sets/,Herosixty7,1564054564," Hello, I have some dataset with size of 39366\*9 table which I need to apply KNN regression. 

My problem arises when I use all the data set the MATLAB gives me an error message:

&amp;#x200B;

 

`Error using bsxfun`

`Requested 900000000x1 (6.7GB) array exceeds`

`maximum array size preference. Creation of arrays`

`greater than this limit may take a long time and`

`cause MATLAB to become unresponsive. See array`

`size limit or preference panel for more`

`information.`

`Error in comparison2 (line 81)`

`S1 =`

`fitcknn(array2table(X_norm),y,'NumNeighbors',K3,'Standardize',1`

&amp;#x200B;

 

I have searched this errror and found some solution suggesting using tall arays 

when I tried it this error appears

 

`Error using fitcknn (line 247)`

`FITCKNN does not support tall arrays.`

 My question is, is it possible to use fitcknn with all of this data or should I try something else? if possible how can I do that?",0,2,False,self,,,,,
292,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,20,chmja1,self.deeplearning,How to implement CAM for binary classification?,https://www.reddit.com/r/deeplearning/comments/chmja1/how_to_implement_cam_for_binary_classification/,ralek673,1564054705,"Hello!

I am currently working on a personal project reimplementing this paper: [https://arxiv.org/pdf/1712.06957.pdf](https://arxiv.org/pdf/1712.06957.pdf) on PyTorch.

I used a pretrained DenseNet-169 and getting better results than the paper. I need to implement CAM now to visualize results. I found a lot of implemented CAM for DenseNet for a multiclassifier problem, but it doesn't work when with my binary classifier. I also replaced ""the final fully connected layer with one that has a single output, after which we applied a sigmoid nonlinearity"" as mentioned in the paper. 

When I get the outputs from the model, it has only one output (one class): 0 if prob &lt; 0.5, else 1.

I found this: [https://github.com/metalbubble/CAM/blob/master/pytorch\_CAM.py](https://github.com/metalbubble/CAM/blob/master/pytorch_CAM.py) but can't make it work on my model.

It bugs on the line ""cam = weight\_softmax\[idx\].dot(feature\_conv.reshape((nc, h\*w)))"" saying that np.float doesn't have dot function.

I don't know if you guys have any idea.

Thanks a lot,

Ralek",0,2,False,self,,,,,
293,deeplearning,t5_2t5eh,2019-7-25,2019,7,25,22,chnujn,self.deeplearning,[Research] A Unified Deep Framework for Joint 3D Pose Estimation and Action Recognition from a Single RGB Camera,https://www.reddit.com/r/deeplearning/comments/chnujn/research_a_unified_deep_framework_for_joint_3d/,cdossman,1564062307," **Abstract:** We present a deep learning-based multitask framework for joint 3D human pose estimation and action recognition from RGB video sequences. Our approach proceeds along two stages. In the first, we run a real-time 2D pose detector to determine the precise pixel location of important keypoints of the body. A two-stream neural network is then designed and trained to map detected 2D keypoints into 3D poses. In the second, we deploy the Efficient Neural Architecture Search (ENAS) algorithm to find an optimal network architecture that is used for modeling the spatio-temporal evolution of the estimated 3D poses via an image-based intermediate representation and performing action recognition. Experiments on Human3.6M, MSR Action3D and SBU Kinect Interaction datasets verify the effectiveness of the proposed method on the targeted tasks. Moreover, we show that our method requires a low computational budget for training and inference. 

 [https://medium.com/ai%C2%B3-theory-practice-business/a-unified-deep-framework-for-joint-3d-pose-estimation-and-action-recognition-from-a-single-rgb-45179b6fe774](https://medium.com/ai%C2%B3-theory-practice-business/a-unified-deep-framework-for-joint-3d-pose-estimation-and-action-recognition-from-a-single-rgb-45179b6fe774)",0,4,False,self,,,,,
294,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,1,chpogj,self.deeplearning,Building on a low-res model,https://www.reddit.com/r/deeplearning/comments/chpogj/building_on_a_lowres_model/,ziapelta,1564070651,"I have trained a model on relatively low resolution images. I'd like to build on this work to process higher resolution images, which will probably involve widening a few layers and possibly adding a few layers. However, the overall model structure will remain the same. Is there a way to leverage the low resolution model weights to speed up training of the higher resolution model?",2,3,False,self,,,,,
295,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,1,chpu3w,self.deeplearning,Opinion about research project on ASL finger spelling and it's scope,https://www.reddit.com/r/deeplearning/comments/chpu3w/opinion_about_research_project_on_asl_finger/,Denominator_Zero,1564071361,"Hi,
So I have been working on and developed a model for ASL fimger spelling (not the words, just apphabets). I have an accuracy of 80-90% and can implement it real time. The major advantage is the image processing algorithm I use which allows me to localise the hand anywhere in the frame and so I don't need a ROI box. Also the second advantage is the higher accuracy. The model combines blocks from YOLO and inception networks

So I was wondering if this work is suitable for being published as I have no experience about it. I see many videos on Reddit and online hence I'm not sure. Also if it is, is there any upcoming conference where I can submit to

Thanks",1,2,False,self,,,,,
296,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,1,chqa7v,self.deeplearning,What is inverse transform sampling?,https://www.reddit.com/r/deeplearning/comments/chqa7v/what_is_inverse_transform_sampling/,sriharsha_0806,1564073465,,1,2,False,self,,,,,
297,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,2,chqmjm,self.deeplearning,Winning Gold Medal on a Kaggle Competition using just kernels: Interview with Ryan Chesler,https://www.reddit.com/r/deeplearning/comments/chqmjm/winning_gold_medal_on_a_kaggle_competition_using/,init__27,1564075035,"To everyone who asks the question if free cloud resources are good enough for Kaggle Competitions, in this Interview with Kaggle Master Ryan Chesler, about his Gold Winning Solution to the Jigsaw ""Unintended Bias in Toxicity Classification"" Kaggle Competition, Ryan mentions their team did almost all of the workflow on JUST Kaggle kernels!  

Video: [https://www.youtube.com/playlist?list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1](https://www.youtube.com/playlist?list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1)

&amp;#x200B;

Podcast: [https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Master--ML-Engineer-Ryan-Chesler--Chai-Time-Data-Science-e4ntbt/a-ajj3f5](https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Master--ML-Engineer-Ryan-Chesler--Chai-Time-Data-Science-e4ntbt/a-ajj3f5)",5,37,False,self,,,,,
298,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,2,chr3zx,self.deeplearning,There is a really cool tool called SEER,https://www.reddit.com/r/deeplearning/comments/chr3zx/there_is_a_really_cool_tool_called_seer/,ai-lover,1564077280,"It recently obtained real-time face-mirroring ability.  **SEER is created by Takayuki TodoLink:** http://www.takayukitodo.com/ 

&amp;#x200B;

![video](qw00eju7nhc31)",0,3,False,self,,,,,
299,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,3,chrwyb,self.deeplearning,Best architecture for pixel wise segmentation,https://www.reddit.com/r/deeplearning/comments/chrwyb/best_architecture_for_pixel_wise_segmentation/,shivam529,1564081020,"I want to detect the portion of image which contains tic-tac-toe in it, so Im labeling all my images with 1 and 0 based on my tic-tac-toe and non Tic-tac-toe ROI, I want to feed this into a network and detect the ROI, I came acrosss FCN,U-net and many architectures .. what would be the best architecture provided I have ~300 images to train ?",5,3,False,self,,,,,
300,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,4,chs97p,self.deeplearning,"Here is a little ""project"" i wrote in neural machine translation field.",https://www.reddit.com/r/deeplearning/comments/chs97p/here_is_a_little_project_i_wrote_in_neural/,mishazakharovbmx,1564082624,"Here is a little translation application that can translate from english to russian - [https://github.com/mishazakharov/NMT](https://github.com/mishazakharov/NMT)

Don't go super-hard on me. I am doing this ml-dl related stuff only for 4 months to be honest, so I am kind of nooby at everything. Also looking for guys that can help me with creating suuuupersimple GUI to ""finish"" a bunch of ""projects"" I have and for this one as well.(Really need you guys, contact with me if you are interested to participate). 

Doing this post just to get some feedbacks on a code i wrote and find ""necessary"" GUI people.",0,0,False,self,,,,,
301,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,4,chsfmy,self.deeplearning,"Frugal student thinking of building my own rig; I keep seeing that GTX1060 6gb has the most value, but how much of this is hype? I see it everywhere, and maybe I'm looking for any counter arguments.",https://www.reddit.com/r/deeplearning/comments/chsfmy/frugal_student_thinking_of_building_my_own_rig_i/,LANGARTANDCULTURE,1564083493,"Any recommendation for the other parts of the computer, barebone is fine, I don't need anything fancy, I just want the biggest bang for my not so many bucks.   


Thanks!",17,5,False,self,,,,,
302,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,5,cht2zr,self.deeplearning,Multi-Task Self-Supervised Learning: The future of Computer Vision?,https://www.reddit.com/r/deeplearning/comments/cht2zr/multitask_selfsupervised_learning_the_future_of/,HenryAILabs,1564086590,[https://youtu.be/ODG60cYK7aU](https://youtu.be/ODG60cYK7aU),0,6,False,self,,,,,
303,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,6,chtlqc,self.deeplearning,Environmental Projects,https://www.reddit.com/r/deeplearning/comments/chtlqc/environmental_projects/,cvantass,1564089049,Does anyone know of any interesting projects out there that are helping to address climate change or other environmental issues? Curious to learn more about what AI can do for the environment.,2,11,False,self,,,,,
304,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,9,chvlbh,self.deeplearning,Google Colab RAM increase,https://www.reddit.com/r/deeplearning/comments/chvlbh/google_colab_ram_increase/,nulleq,1564099483,"It looks like Colab is beginning to allocate users 24GB worth of RAM instead of the default of 12. Is anyone else seeing this? This morning I tried running my model, and a messaged popped up saying to ""reset runtime to get more ram"" after my session crashed [1]. There also seems to be new UI upgrades?

[1] https://imgur.com/a/n8bUNhu",7,32,False,self,,,,,
305,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,13,chya6a,freevideolectures.com,Cutting Edge Deep Learning for Coders online course video lectures by Prof. Jeremy Howard,https://www.reddit.com/r/deeplearning/comments/chya6a/cutting_edge_deep_learning_for_coders_online/,freevideolectures,1564115411,,0,1,False,default,,,,,
306,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,13,chye04,self.deeplearning,Are convnets translation invariant?,https://www.reddit.com/r/deeplearning/comments/chye04/are_convnets_translation_invariant/,kjarvind,1564116121,"If conv nets are considered to be translation invariant, how can they predict bonding boxes?",2,1,False,self,,,,,
307,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,17,ci04f6,self.deeplearning,Face recognition with small dataset - image augmentation,https://www.reddit.com/r/deeplearning/comments/ci04f6/face_recognition_with_small_dataset_image/,marok94,1564128807,"So I need to perform face recognition with 7 person, where I have around 20 images for each person in dataset.

For face recognition, I oriented myself on Adrian Rosenbrock [post](https://www.pyimagesearch.com/2018/09/24/opencv-face-recognition/). I added face alignment step because from experiments I found that alignment step greatly improves accuracy when there are more than 2 (or 3) personas in dataset. 

But to achieve even better accuracy I want to do offline image augmentation. Why offline? Because I use pretrained face detection model and pretrained face embedding model, so only model that I train is final classifer (SVM, RandomForest...). For augmentation I use great library [imgaug](https://github.com/aleju/imgaug). I'll apply rotation, adding noise, cropping... All augmenters have random component in them that randomly decides proportion of augmentation (by how many degrees perform rotation and in which side, what amount of noise to add...)  


What I would like to know is this? Is it preferable to apply each transformation separately (so I'll have n times bigger dataset, where n is number of augmenters) or all of them in sequence ( so I'll have 2x times bigger dataset, or if I apply n different sequences n times bigger dataset). I'm afraid that I some sort of bias if I have 20 normal images, 20 rotated images, 20 noised images...",0,1,False,self,,,,,
308,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,19,ci1er6,self.deeplearning,DeepSORT: Deep Learning to Track Custom Objects in a Video,https://www.reddit.com/r/deeplearning/comments/ci1er6/deepsort_deep_learning_to_track_custom_objects_in/,manneshiva,1564138704,"Object Detection has seen several recent developments and reached a wide audience but a very important and not widely known extension of the OD is its applications in Object Tracking.

Here is the blog about the theory and challenges in object tracking, how to use pre-trained object detection models to identify and count unique objects and track their trajectories over several frames using the #DeepSORT algorithm! - [https://nanonets.com/blog/object-tracking-deepsort/](https://nanonets.com/blog/object-tracking-deepsort/)

&amp;#x200B;

&amp;#x200B;

[Object tracking using deep learning](https://i.redd.it/fx5fa9jtpmc31.gif)",2,49,False,self,,,,,
309,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,21,ci1ziv,self.deeplearning,Blog post: The Evolution of Deeplab for Semantic Segmentation,https://www.reddit.com/r/deeplearning/comments/ci1ziv/blog_post_the_evolution_of_deeplab_for_semantic/,beerensahu,1564142537,"The semantic segmentation is the technique of segmenting image with understanding of image in pixel level. The Deeplab from Google is one of the SOTA method for semantic segmentation using deep learning. In this post I have discussed the evolution of Deeplab, beginning from the classical image segmentation techniques through Deep-learning methods to various versions of the Deeplab for semantic segmentation.

Link: [https://towardsdatascience.com/the-evolution-of-deeplab-for-semantic-segmentation-95082b025571](https://towardsdatascience.com/the-evolution-of-deeplab-for-semantic-segmentation-95082b025571)",0,2,False,self,,,,,
310,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,22,ci2n9k,github.com,"GitHub - gnes-ai/gnes: GNES is Generic Neural Elastic Search, a cloud-native semantic search system based on deep neural network.",https://www.reddit.com/r/deeplearning/comments/ci2n9k/github_gnesaignes_gnes_is_generic_neural_elastic/,h_xiao,1564146455,,0,4,False,default,,,,,
311,deeplearning,t5_2t5eh,2019-7-26,2019,7,26,23,ci3eu0,self.deeplearning,[Research] What does it mean to understand a neural network?,https://www.reddit.com/r/deeplearning/comments/ci3eu0/research_what_does_it_mean_to_understand_a_neural/,cdossman,1564150604,"ABSTRACT:  We can define a neural network that can learn to recognize objects in less than 100 lines of code. However, after training, it is characterized by millions of weights that contain the knowledge about many object types across visual scenes. Such networks are thus dramatically easier to understand in terms of the code that makes them than the resulting properties, such as tuning or connections. In analogy, we conjecture that rules for development and learning in brains may be far easier to understand than their resulting properties. The analogy suggests that neuroscience would benefit from a focus on learning and development. 

 [https://medium.com/ai%C2%B3-theory-practice-business/what-does-it-mean-to-understand-a-neural-network-31fec6b1a4fe](https://medium.com/ai%C2%B3-theory-practice-business/what-does-it-mean-to-understand-a-neural-network-31fec6b1a4fe)",0,1,False,self,,,,,
312,deeplearning,t5_2t5eh,2019-7-27,2019,7,27,1,ci507z,self.deeplearning,Is Inverse reinforcement learning the future of RL ?,https://www.reddit.com/r/deeplearning/comments/ci507z/is_inverse_reinforcement_learning_the_future_of_rl/,MohamedRashad,1564158291,For some time i was thinking that imitation + reinforcement learning will be the solution for the whole RL problem and when i started reading about IRL i found it the best fusion of the two because it learns the reward function from imitation and keeps the agent interacting with the world as normal but i wanted to hear your thoughts about this .... what do you think of IRL ?,0,7,False,self,,,,,
313,deeplearning,t5_2t5eh,2019-7-27,2019,7,27,16,cieqfk,self.deeplearning,Inception Score in GAN text to image synthesis,https://www.reddit.com/r/deeplearning/comments/cieqfk/inception_score_in_gan_text_to_image_synthesis/,Bishwa12,1564213324,This is the kernel that I have been following [https://www.kaggle.com/bishwa/text-to-image2](https://www.kaggle.com/bishwa/text-to-image2/edit) . My question is how do we calculate Inception Score ? Do we need to save the images generated by generator during training and calculate the inception score on those images ?,2,8,False,self,,,,,
314,deeplearning,t5_2t5eh,2019-7-27,2019,7,27,17,cif0hw,self.deeplearning,PyTorch Tutorial - Deep Learning Using PyTorch - Learn PyTorch from Basics to Advanced,https://www.reddit.com/r/deeplearning/comments/cif0hw/pytorch_tutorial_deep_learning_using_pytorch/,Corey890,1564215574,[removed],0,1,False,self,,,,,
315,deeplearning,t5_2t5eh,2019-7-27,2019,7,27,17,cif67m,self.deeplearning,Looking for a simple Deep learning program that predicts a value,https://www.reddit.com/r/deeplearning/comments/cif67m/looking_for_a_simple_deep_learning_program_that/,phadeb,1564216881,"Is there a simple deep learning program that can take as input a text file with 2 columns : time, value and generate as output a text file where it predicts values for the next 3 time periods ?

Input Sample :

    Time;Value
    1;100
    2;120
    3;90

Output sample

    Time;Value
    4;87
    5;111
    6;129

Trained forever until instructed to stop, showing loss value while training.

Bonus : Can continue training from a previous model

Loss value = how big the gap between the past value and the predicted value",2,1,False,self,,,,,
316,deeplearning,t5_2t5eh,2019-7-27,2019,7,27,19,cig5ub,github.com,"ACL2019 paper code ""Simple and Effective Text Matching with Richer Alignment Features""",https://www.reddit.com/r/deeplearning/comments/cig5ub/acl2019_paper_code_simple_and_effective_text/,rqyang,1564224973,,0,2,False,default,,,,,
317,deeplearning,t5_2t5eh,2019-7-28,2019,7,28,4,cilgab,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cilgab/data_science_career_track_prep_course/,HannahHumphreys,1564254054,[removed],0,1,False,self,,,,,
318,deeplearning,t5_2t5eh,2019-7-28,2019,7,28,4,ciloec,self.deeplearning,DL Project Advice,https://www.reddit.com/r/deeplearning/comments/ciloec/dl_project_advice/,tbonelor,1564255112,"Hi everyone! I am currently working on a deep learning project and I am at a point where I haven't made much progress in a while. Any advice or links to resources would be appreciated.

 So the idea is,  given video footage of a soccer player running up to take a penalty kick, I would want the AI to be able to predict which side of the goal the player is going to shoot, as the player is about to kick the ball (not including lower or upper 90s of the goal, only caring about left or ride side to simplify the problem). As far as the data is concerned, I am using video footage data from SoccerNet ( [https://soccer-net.org/](https://soccer-net.org/)  here is the link if anyone wants to check it out), and wrote a script to edit the games to save clips of the game a minute before the official time of the goal, to record the run-up and the shot. The script also makes a copy of that same clip but flipped on the x-axis to create an even distribution of left-footed and right-footed penalties.

That's as far as I've gotten. The best idea that I could come up with is breaking the model into 2 parts: the 1st would be a model that can attempt to generate a Kalman filter based on the movement of the player taking the penalty, and then feeding that trajectory to a neural network to learn to predict either left or right. 

Besides that guess, I have no clue how to approach this problem. To let you know about my experience, I have done a couple of machine learning projects, and took Andrew- Ngs Deep Learning Specialization, which kind of held your hand when working on the Jupiter notebook assignments. I am also not sure about how to label the data as well, or if I am just overcomplicating this project. 

&amp;#x200B;

Thanks in advance or any guidance!",12,20,False,self,,,,,
319,deeplearning,t5_2t5eh,2019-7-28,2019,7,28,6,cin0hm,medium.com,"Ideas for Deep Learning Systems in July 2019. Packages, Construction/Architecture, and Real Estate.",https://www.reddit.com/r/deeplearning/comments/cin0hm/ideas_for_deep_learning_systems_in_july_2019/,diffgram-anthony,1564261856,,0,2,False,default,,,,,
320,deeplearning,t5_2t5eh,2019-7-28,2019,7,28,11,ciqh1h,self.deeplearning,What's the hardest thing about training DL models?,https://www.reddit.com/r/deeplearning/comments/ciqh1h/whats_the_hardest_thing_about_training_dl_models/,benur7,1564281001,"Hey guys, what's the hardest thing about training deep learning models? I am trying to conduct market research to discover problems and pains. Any help will be greatly appreciated!",3,0,False,self,,,,,
321,deeplearning,t5_2t5eh,2019-7-28,2019,7,28,14,cirvsc,self.deeplearning,Transfer learning for tic tac toe segmentation,https://www.reddit.com/r/deeplearning/comments/cirvsc/transfer_learning_for_tic_tac_toe_segmentation/,shivam529,1564290150,"Ive seen cases where people have to segment cars and they use resent architecture for transfer learning and then go ahead with segmentation tasks with say U-net, this sounds plausible to me since the Resnet pretrained model is already good at detecting cars as it has been trained on it. 

Now my question is it, to detect my tic tac toe wouldnt it be wrong to detect it from a pretrained model since it has never been trained on tic tac toe? Or I could you some layer of Resnet which is good at finding vertical and horizontal lines which is what my tic tac toe grid would exist of? So say, 3rd or 4th layer which is good at detecting these lines and hence my tic tac toe and then go ahead with segmenting ? Would this be a transfer learning approach or have I got it wrong ?",2,7,False,self,,,,,
322,deeplearning,t5_2t5eh,2019-7-28,2019,7,28,14,cis95u,self.deeplearning,DL hardware advice,https://www.reddit.com/r/deeplearning/comments/cis95u/dl_hardware_advice/,AusBarbell,1564292806,"Hi All,
I've looking to get some advice on the hardware required for a CNN training saliency detection models using commonly used data sets such as ECSSD, DUT-OMROM, ect. 
My PC specs are as follows:
* CPU: i5 6600k @ 4.5GHz
* RAM: 16Gb DDR4 3000Mhz
* GPU: GTX 1080 TI 11Gb
My main concern is the CPU and RAM, will these be sufficient?",2,3,False,self,,,,,
323,deeplearning,t5_2t5eh,2019-7-28,2019,7,28,17,citmlv,self.deeplearning,"Relation Extraction from entities [NLP , LSTM, PyTorch]",https://www.reddit.com/r/deeplearning/comments/citmlv/relation_extraction_from_entities_nlp_lstm_pytorch/,ai_badger,1564303915,"Hi everyone!  

I am working on relation extraction from text data.  

Say, that I have a sentence made of 100 words. This sentence has 4 words as entities (identified through some NER algorithm). The 4 words/entities are - **A, B, C, D**. The relation between **(A, B)** is **X**. The relation between **C, D** is Y.   

So, the triplets are - **(A, X, B)** and **(C, Y, D)**. I don't understand how to formulate the input and output from the model.   


One option is to simply use a classifier like SVM or logistic regression who's input would be A and B. The output would be X. I will do this for all the sentences. But this obviously would not give me correct results because there is some context in the sentence that assigns the relationship between the 2 entities. So, we'll need something like RNN-LSTM to factor that into account. So, now, how would I feed input data to this model? Do I feed the whole sentence? What would the output look like to calculate loss?  

I am just very confused by this. Pls halp.",7,12,False,self,,,,,
324,deeplearning,t5_2t5eh,2019-7-28,2019,7,28,18,citzb6,self.deeplearning,how to set up an EC2 instance on AWS for training a model on tensorflow for personal use?,https://www.reddit.com/r/deeplearning/comments/citzb6/how_to_set_up_an_ec2_instance_on_aws_for_training/,PreviousGarlics,1564306886,"I have built a couple of scripts that solves a captcha using tensorflow's Object Identification API for a project at college. I have labelled 1K captchas for training(800) and testing(200). Since I am working on a macbook, I don't have a gpu (and thus CUDA).

To test the scripts and the predictions, I ran the program for 10 images+labels for testing and 10 images+labels for training. The training went on for 10 hrs for around 5K steps, only on CPU. Clearly I need some GPU functionality and my institute can compensate me for AWS's charges. I went through some websites for a tutorial on setting up a virtual machine etc but everything looks so complicated and I am not able to find anything that does what I would want to do:

1. I want to run the exact same scripts that I have on my laptop on an AWS instance which has a gpu(maybe p2.xlarge). I have the following files that are needed for training:  


* faster\_rcnn\_inception\_v2\_coco.config
* the label map ie labelmap.pbtxt
* test folder with all the images
* train folder with all the images
* test\_label.csv which has all the labels for each image in the test folder
* train\_label.csv which has all the labels for each image in the train folder
* record files ie. test.record, train.record

I want to create the frozen\_inferene\_graph.pb file and download it. I will then use this graph in another script that just solves the captchas.

I do know that I can create an EC2 instance such as p2.xlarge and maybe run a jupyter notebook on that server, but I don't know how do I move all these files there, run scripts and how to download the forzen\_inference\_graph.pb file.

I believe there must be a standard solution to this problem since it seems too trivial to not have been resolved in 2019. But I am not able to find a suitable or straightforward solution in the ocean of Google search results. Any help help would be deeply appreciated! Thanks!

([I had originally posted this on SuperUser Stack Exchange](https://superuser.com/questions/1464933/how-to-set-up-an-ec2-instance-on-aws-for-training-a-model-on-tensorflow-for-pers))",5,1,False,self,,,,,
325,deeplearning,t5_2t5eh,2019-7-28,2019,7,28,20,ciuxbb,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/ciuxbb/data_science_career_track_prep_course/,HannahHumphreys,1564314499,[removed],0,1,False,self,,,,,
326,deeplearning,t5_2t5eh,2019-7-28,2019,7,28,22,civu6r,youtube.com,Fine Tuning OpenAI's GPT-2 to Generate Jeopardy Questions,https://www.reddit.com/r/deeplearning/comments/civu6r/fine_tuning_openais_gpt2_to_generate_jeopardy/,Automato-YT,1564320669,,0,1,False,default,,,,,
327,deeplearning,t5_2t5eh,2019-7-28,2019,7,28,22,civx9c,emanuelpeg.blogspot.com,Deep Learning vs. Machine Learning: elegir el mejor enfoque,https://www.reddit.com/r/deeplearning/comments/civx9c/deep_learning_vs_machine_learning_elegir_el_mejor/,emanuelpeg,1564321184,,0,0,False,default,,,,,
328,deeplearning,t5_2t5eh,2019-7-29,2019,7,29,2,ciyrb1,self.deeplearning,"Getting Hired in ML, Building a Portfolio | Interview with the CEO of SharpestMinds (ycombinator W'18): Edouard Harris",https://www.reddit.com/r/deeplearning/comments/ciyrb1/getting_hired_in_ml_building_a_portfolio/,init__27,1564335457,"A chat about SharpestMinds, their ycombinator experience, and especially a great discussion about building a Machine Learning Portfolio and all things about getting hired that I enjoyed a lot.

&amp;#x200B;

Audio: [https://anchor.fm/chaitimedatascience/episodes/Interview-with-CEO-of-SharpestMinds--Edouard-Harris--Chai-Time-Data-Science-e4nti6](https://anchor.fm/chaitimedatascience/episodes/Interview-with-CEO-of-SharpestMinds--Edouard-Harris--Chai-Time-Data-Science-e4nti6)

&amp;#x200B;

Video: [https://www.youtube.com/watch?v=2-ejeSFCJJc&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=4](https://www.youtube.com/watch?v=2-ejeSFCJJc&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=4)",0,2,False,self,,,,,
329,deeplearning,t5_2t5eh,2019-7-29,2019,7,29,3,ciznct,blockdelta.io,What is Deep Tech? And How Relevant Will it Be?,https://www.reddit.com/r/deeplearning/comments/ciznct/what_is_deep_tech_and_how_relevant_will_it_be/,BlockDelta,1564339646,,0,0,False,default,,,,,
330,deeplearning,t5_2t5eh,2019-7-29,2019,7,29,6,cj1ff2,self.deeplearning,"Suggestions wanted on applying Deep Learning for graphics detection/ recognition from newspaper, magazine, etc.",https://www.reddit.com/r/deeplearning/comments/cj1ff2/suggestions_wanted_on_applying_deep_learning_for/,nirmanlongjam,1564347976,"I am starting a research project on graphics detection/recognition for text-graphics separation from document with complex layout e.g. newspaper, magazine, etc. using Deep Learning.

I am pretty new to Deep Learning. 

Can anyone give suggestions/ pointers to start with the project ?",5,11,False,self,,,,,
331,deeplearning,t5_2t5eh,2019-7-29,2019,7,29,15,cj7e3o,medium.com,AI and deep learning to tackle traffic congestion,https://www.reddit.com/r/deeplearning/comments/cj7e3o/ai_and_deep_learning_to_tackle_traffic_congestion/,Verma_RJ,1564381502,,0,1,False,default,,,,,
332,deeplearning,t5_2t5eh,2019-7-29,2019,7,29,17,cj8n0g,self.deeplearning,Sources on Bayesian Deep Learning?,https://www.reddit.com/r/deeplearning/comments/cj8n0g/sources_on_bayesian_deep_learning/,robwoof,1564390642,"Hi everyone. I'm currently trying to get a better picture of Bayesian Deep Learning. We looked at the topic only briefly this year, especially regarding [modelling uncertainty](https://papers.nips.cc/paper/7141-what-uncertainties-do-we-need-in-bayesian-deep-learning-for-computer-vision) in Computer Vision tasks.
Can you recommend any paper or manual about the basics of Bayesian Neural Nets? Something that covers the standards (if there are any) of Backprop by Bayes, and anything that is important for the topic. Papers on the application of Bayesian Deep Learning are also welcome, since I'd like to reproduce the results of at least one paper in learning about this.
Thank you!",6,28,False,self,,,,,
333,deeplearning,t5_2t5eh,2019-7-29,2019,7,29,20,cj9xmr,self.deeplearning,Deep Learning Research Group,https://www.reddit.com/r/deeplearning/comments/cj9xmr/deep_learning_research_group/,bikanation,1564399386,"I am looking for a Researching group focusing on deep learning (nlp with deep learning specially) to advance my researching skills because i am not achieving much researching alone. This is my github repo . I am really passionate about researching and continuing in the academic field but want to build strong research portifolio. Also if there is a group contributing to open source project would be great. ( I am not looking for any kinds of payments or money , i want to improve my skills not earn money from research and i can consider it as an unpaid internship)",0,0,False,self,,,,,
334,deeplearning,t5_2t5eh,2019-7-29,2019,7,29,21,cjav7k,self.deeplearning,Question: is batch classification of N images faster than classifying N images one at a time?,https://www.reddit.com/r/deeplearning/comments/cjav7k/question_is_batch_classification_of_n_images/,Niffler8009,1564404864,"Cant seem to find any info on this. Basically which is faster, classifying a batch of N images or classifying N single image batches?",8,1,False,self,,,,,
335,deeplearning,t5_2t5eh,2019-7-29,2019,7,29,22,cjb8zz,speech2face.github.io,Speech2Face: Infering a face behind a voice,https://www.reddit.com/r/deeplearning/comments/cjb8zz/speech2face_infering_a_face_behind_a_voice/,saintvinasse,1564406916,,0,0,False,default,,,,,
336,deeplearning,t5_2t5eh,2019-7-29,2019,7,29,23,cjc7z6,self.deeplearning,[Research] Google AI: Learning Better Simulation Methods for Partial Differential Equations,https://www.reddit.com/r/deeplearning/comments/cjc7z6/research_google_ai_learning_better_simulation/,cdossman,1564411705," The worlds fastest supercomputers were designed for modeling physical phenomena, yet they still are not fast enough to robustly predict the impacts of climate change to design controls for airplanes based on airflow or to accurately simulate a fusion reactor. All of these phenomena are modeled by partial differential equations (PDEs), the class of equations that describe everything smooth and continuous in the physical world, and the most common class of simulation problems in science and engineering. To solve these equations, we need faster simulations, but in recent years, Moores law has been slowing.  At the same time, weve seen huge breakthroughs in machine learning (ML) along with faster hardware optimized for it. What does this new paradigm offer for scientific computing?   [https://medium.com/ai%C2%B3-theory-practice-business/google-ai-learning-better-simulation-methods-for-partial-differential-equations-db67a74506d2](https://medium.com/ai%C2%B3-theory-practice-business/google-ai-learning-better-simulation-methods-for-partial-differential-equations-db67a74506d2)",2,9,False,self,,,,,
337,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,0,cjckfr,insights.sei.cmu.edu,The Promise of Deep Learning on Graphs,https://www.reddit.com/r/deeplearning/comments/cjckfr/the_promise_of_deep_learning_on_graphs/,BillyPricePgh,1564413232,,1,5,False,default,,,,,
338,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,0,cjcpvn,self.deeplearning,How to optimize hyperparameters in stacked model?,https://www.reddit.com/r/deeplearning/comments/cjcpvn/how_to_optimize_hyperparameters_in_stacked_model/,jdyr1729,1564413916,"Hi,

I was wondering whether somebody could explain how to optimize hyperparameters for the base learners and meta algorithm when stacking? In many tutorials they seem to be plucked out of thin air!

Thanks,

Jack",0,2,False,self,,,,,
339,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,1,cjdmsx,self.deeplearning,[Question] Multi-Label Tagging for Images. Why my approach should or shouldn't work.,https://www.reddit.com/r/deeplearning/comments/cjdmsx/question_multilabel_tagging_for_images_why_my/,macromayhem,1564417971,"Hi, I am trying to train a network (MobilenetV2+FC+2output units) for predicting whether an image contains particular tags or not. Tags being: Jacket, Jeans. The output loss is binary cross entropy for each tag. 

&amp;#x200B;

The sample space of possible tag assignments is {(Jeans\[Y\], Jacket\[Y\]:1000), (Jeans\[Y\], Jacket\[X\]:1000), (Jeans\[X\], Jacket\[Y\]:100), (Jeans\[X\], Jacket\[X\]:1000)} along with the number of sample images to train on. Let's say the training images are cropped and contain a person and are of the size 128x64. 

I tried to train it first as a 4 class classification problem. The F1 score is acceptable for all classes except the one with less samples.

&amp;#x200B;

I found out that the number of Jackets\[Y\], Jackets\[X\], Jeans\[Y\] and Jeans\[N\] are roughly the same. I switched the problem from classification to tagging where I modify the training to be independent of input size(hence, batch size fixed at 1). While training now I randomly input either complete image, just the jacket(or upperbody) or the Jeans(lower-body) to the tagging network. 

&amp;#x200B;

This network doesn't learn anything. I tried it with different learning rates but the loss doesn't improve after 1st epoch. 

I have a strong feeling that the network shouldn't work either but I am not able to lay a concrete reason as to why. Any suggestion/help would be appreciated.",0,1,False,self,,,,,
340,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,3,cjfmql,self.deeplearning,Using endcoded features instead of dataset to train GANs,https://www.reddit.com/r/deeplearning/comments/cjfmql/using_endcoded_features_instead_of_dataset_to/,clean_pegasus,1564426583,Is there are type of GAN that uses encoded features to train the data instead of the complete dataset?,0,1,False,self,,,,,
341,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,5,cjgtqy,self.deeplearning,Possible to use binary labeled images as training and grayscale images as test for Unet semantic segmentation?,https://www.reddit.com/r/deeplearning/comments/cjgtqy/possible_to_use_binary_labeled_images_as_training/,74throwaway,1564431721,"I'm attempting to perform semantic segmentation using Unet using code from here: https://github.com/zhixuhao/unet

I have a set of grayscale images and their labeled images as binary images. I was wondering if instead of using the grayscale images as the training and the binary labeled images as the test, if it was possible to do the reverse? That is, use the grayscale as test and binary as training. Is this possible and/or not a bad idea?

If it's not a bad idea, how should I go about it? 

I tried the code at: https://pastebin.com/xCaV57Bg, https://pastebin.com/19yxpBE8, https://pastebin.com/RLMFTnQ4

But when I tried it, I got the error saying:

    Error when checking input: expected input_1 to have shape (1024,1024,257) but got array with shape (1024,1024,1)

The error seems to occur at `model.fit_generator(myGene,steps_per_epoch=20,epochs=500,callbacks=[model_checkpoint])` in `run.py`. How can I fix this?",2,1,False,self,,,,,
342,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,6,cjhk5r,twitter.com,"[PSA] ""Deep Learning Cookbook"" on the Machine Learning book bundle ($1)",https://www.reddit.com/r/deeplearning/comments/cjhk5r/psa_deep_learning_cookbook_on_the_machine/,wazuddin,1564434925,,2,14,False,default,,,,,
343,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,13,cjmuf3,youtu.be,Solving the Armadillo Problem - A great short talk about Adversarial Learning,https://www.reddit.com/r/deeplearning/comments/cjmuf3/solving_the_armadillo_problem_a_great_short_talk/,YaelMt,1564462177,,3,20,False,default,,,,,
344,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,15,cjnn40,self.deeplearning,Multiview 3D reconstruction,https://www.reddit.com/r/deeplearning/comments/cjnn40/multiview_3d_reconstruction/,frankshawn1992,1564467235,"Hi,
Can anyone suggest paper or software which does 3D reconstruction (with texture) of an object from multiple images ?",3,7,False,self,,,,,
345,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,17,cjoxb6,onlineitguru.com,Deep Learning vs Neural Networks,https://www.reddit.com/r/deeplearning/comments/cjoxb6/deep_learning_vs_neural_networks/,OnlineITGuru1,1564476119,,0,1,False,default,,,,,
346,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,18,cjp5ut,self.deeplearning,How could i fuse multi-dimensional visual feature..?,https://www.reddit.com/r/deeplearning/comments/cjp5ut/how_could_i_fuse_multidimensional_visual_feature/,GW_KIM,1564477869,"Hi there, i am a student studying computer vision.

And i wonder how can i fuse multi-dimensional visual feature.

In object detection, regions(object may exists) show different bbox size; visual feature dimension.

and i want to fuse some feature(before classifer&amp;regressor) from other feature that may shows different dimension.

If the detector is Faster-RCNN, there is ROI-pooling to fix the dimension along all object in a image, but others not.

Is there anyone who give some hint to me about it?

THX :)",0,2,False,self,,,,,
347,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,21,cjqr4k,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cjqr4k/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1564488078,[removed],0,1,False,self,,,,,
348,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,21,cjqwu2,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cjqwu2/data_science_career_track_prep_course/,HannahHumphreys,1564488930,[removed],0,1,False,self,,,,,
349,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,22,cjrw2a,self.deeplearning,Image preprocessing before applying CNN architectures,https://www.reddit.com/r/deeplearning/comments/cjrw2a/image_preprocessing_before_applying_cnn/,sambalshikhar,1564493899,What are some preprocessing hacks that you have come across which provided better results and why do they work?,7,4,False,self,,,,,
350,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,23,cjsspl,self.deeplearning,[Research] Deep Learning for Short-Segment Speaker Recognition,https://www.reddit.com/r/deeplearning/comments/cjsspl/research_deep_learning_for_shortsegment_speaker/,cdossman,1564498166,"**Abstract:** Today's interactive devices such as smart-phone assistants and smart speakers often deal with short-duration speech segments. As a result, speaker recognition systems integrated into such devices will be much better suited with models capable of performing the recognition task with short-duration utterances. In this paper, a new deep neural network, UtterIdNet, capable of performing speaker recognition with short speech segments is proposed. Our proposed model utilizes a novel architecture that makes it suitable for short-segment speaker recognition through an efficiently increased use of information in short speech segments. UtterIdNet has been trained and tested on the VoxCeleb datasets, the latest benchmarks in speaker recognition. Evaluations for different segment durations show consistent and stable performance for short segments, with significant improvement over the previous models for segments of 2 seconds, 1 second, and especially sub-second durations (250 ms and 500 ms) 

 [https://arxiv.org/abs/1907.10420](https://arxiv.org/abs/1907.10420)",0,2,False,self,,,,,
351,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,23,cjsu88,self.deeplearning,Realtime Data Augmentation inefficiency seems insane to me,https://www.reddit.com/r/deeplearning/comments/cjsu88/realtime_data_augmentation_inefficiency_seems/,QuickTurtle9,1564498345,"I am currently learning to use Keras and asking myself why it is recommended to use the realtime data augmentation method (ImageDataGenerator class) ? I tried it with MNIST and a CNN with 540k params but it would take hours to train the model, the performance is so bad. Instead I created a static augmented dataset with 400k images for training plus 10k for validation:

```
number_val = 10000
gen = datagen.flow(train_images[:-number_val], train_labels[:-number_val], batch_size=1000)

train_images_augmented = train_images.tolist()[:-number_val]
train_labels_augmented = train_labels.tolist()[:-number_val]
number_batches = 350
i = 0

for images, labels in gen:
  for image in images:
    train_images_augmented.append(image)
  for label in labels:
    train_labels_augmented.append(label)
  i += 1
  if i &gt;= number_batches:
    break
```

With that it takes just 67 seconds to reach an accuracy of 99.54% on the test dataset.

Is it only used to ensure that 'completely' new records are used in each epoch? And if so, is it really such an advantage that the extreme inefficiency is worthwhile? Another reason I can imagine is that it does not make a big difference on extreme large datasets when you're relying on a generator anyway. But even then it would be massive losses that you would have to accept in every training. Maybe I miss something, then I'm happy about an explanation :-)",7,6,False,self,,,,,
352,deeplearning,t5_2t5eh,2019-7-30,2019,7,30,23,cjsx7l,medium.com,(Video) Millie Fit: Your On-Demand AI Trainer,https://www.reddit.com/r/deeplearning/comments/cjsx7l/video_millie_fit_your_ondemand_ai_trainer/,nahuak,1564498713,,0,4,False,default,,,,,
353,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,0,cjtpyp,self.deeplearning,Has anybody tried Weights and Biases (W&amp;B)?,https://www.reddit.com/r/deeplearning/comments/cjtpyp/has_anybody_tried_weights_and_biases_wb/,aeduG,1564502172,"[https://www.wandb.com/](https://www.wandb.com/)

It is a tool to monitor neural nets and plot outputs, error curves, histograms etc. It is very easy to understand, integrates well with PyTorch or TensorFlow, and it is free for academic use. I wonder why not more people are using it.",4,2,False,self,,,,,
354,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,3,cjvwsu,self.deeplearning,Classifying data from satellite images,https://www.reddit.com/r/deeplearning/comments/cjvwsu/classifying_data_from_satellite_images/,rushan3103,1564511344,How would you get a satellite image and classify the data into either forests or urban areas etc,2,1,False,self,,,,,
355,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,3,cjvwug,i.redd.it,I Placed 4th in my First AI Competition. Read my write up of my agent on Unity's ObstacleTower AI Challenge.,https://www.reddit.com/r/deeplearning/comments/cjvwug/i_placed_4th_in_my_first_ai_competition_read_my/,soho-joe,1564511349,,4,49,False,image,,,,,
356,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,6,cjy4xy,self.deeplearning,Data pollution's effect on deep learning,https://www.reddit.com/r/deeplearning/comments/cjy4xy/data_pollutions_effect_on_deep_learning/,OldCoderK,1564520955,"I'm trying to find a paper that discusses what happens when some training samples are not labeled correctly.

e.g. The image of a cat is labeled as a dog once in 5000 samples.

Any pointers?",0,1,False,self,,,,,
357,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,15,ck4oj3,self.learnprogramming,Learn Artificial Intelligence  5 Free Courses for Beginners,https://www.reddit.com/r/deeplearning/comments/ck4oj3/learn_artificial_intelligence_5_free_courses_for/,skj8,1564555154,,0,0,False,default,,,,,
358,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,16,ck53ld,self.deeplearning,How to feed video frames to 3D CNN?,https://www.reddit.com/r/deeplearning/comments/ck53ld/how_to_feed_video_frames_to_3d_cnn/,juggy94,1564557948,"I have designed a 3D CNN network, each of my videos have frames of size approx 600x400 and approx 200 such frames. So I can't feed an entire video in one go to the network. So I decided to feed 5 frames at a time,however I can't figure how to access/feed the data accordingly. Right now my data is stored in numpy array with dimensions 10,200,600,400,3 for a dataset of 10 videos. 

I am currently using keras but I don't think I can use simple model.fit, I might have to loop through the data somehow. Or should I try using tensorflow instead and use feed_dict in some way?",0,5,False,self,,,,,
359,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,18,ck65xj,self.deeplearning,Is it weird when a 14 year old publishes a paper ?,https://www.reddit.com/r/deeplearning/comments/ck65xj/is_it_weird_when_a_14_year_old_publishes_a_paper/,nowsden,1564565682,"Hi everyone, 

is it weird when a 14 year old wants to publish a paper ? I've been working on and with computers for 8 years or and I have been working on a lot of stuff in Machine Learning for 4 years now and wrote several models and algorithms. Now I am working on a Self Driving Car Simulator and I want to publish a paper on it. Is there anything wrong with it or can you recommend me something ? Or give me some tips",40,51,False,self,,,,,
360,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,19,ck6m11,self.deeplearning,Baidu unveils ERNIE 2.0 natural language framework in Chinese and English,https://www.reddit.com/r/deeplearning/comments/ck6m11/baidu_unveils_ernie_20_natural_language_framework/,worldwide__master,1564568751,,0,1,False,self,,,,,
361,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,19,ck6m5w,venturebeat.com,Baidu unveils ERNIE 2.0 natural language framework in Chinese and English,https://www.reddit.com/r/deeplearning/comments/ck6m5w/baidu_unveils_ernie_20_natural_language_framework/,worldwide__master,1564568776,,0,2,False,default,,,,,
362,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,20,ck7jhh,freevideolectures.com,Natural Language Processing with Deep Learning online course video lectures by Stanford,https://www.reddit.com/r/deeplearning/comments/ck7jhh/natural_language_processing_with_deep_learning/,freevideolectures,1564574394,,1,1,False,default,,,,,
363,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,21,ck7kcc,medium.com,3 Reasons why AI Assisted Labeling will destroy Manual labor market,https://www.reddit.com/r/deeplearning/comments/ck7kcc/3_reasons_why_ai_assisted_labeling_will_destroy/,tdionis,1564574533,,1,2,False,default,,,,,
364,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,21,ck7s4l,habr.com,Human pose estimation on images for iOS using CoreML,https://www.reddit.com/r/deeplearning/comments/ck7s4l/human_pose_estimation_on_images_for_ios_using/,atomlib_com,1564575736,,0,2,False,default,,,,,
365,deeplearning,t5_2t5eh,2019-7-31,2019,7,31,23,ck9hu3,gigadom.in,"Getting started with Tensorflow, Keras in Python and R",https://www.reddit.com/r/deeplearning/comments/ck9hu3/getting_started_with_tensorflow_keras_in_python/,tvganesh,1564584647,,0,1,False,default,,,,,
