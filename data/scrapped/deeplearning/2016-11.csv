,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2016-11-3,2016,11,3,8,5ataio,Introducing The Nexar Challenge: Deep-Driving into the Future,https://www.reddit.com/r/deeplearning/comments/5ataio/introducing_the_nexar_challenge_deepdriving_into/,ilankadar,1478128500,"Nexar is prepared to make the world's roads safer, and you can help. Introducing our first open challenge. Your participation could be vital to creating a collision-free world, and the chance to win great prizes never hurts. For details, click here:https://blog.getnexar.com/introducing-the-nexar-challenge-deep-driving-into-the-future-31e0ed9db4b7#.9j40j9w9o",1,2
1,2016-11-3,2016,11,3,23,5awusb,Online learning in Tensorflow?,https://www.reddit.com/r/deeplearning/comments/5awusb/online_learning_in_tensorflow/,yahyaheee,1478181635,"Hey, I was wondering if anyone had come across any online learning examples in Tensorflow? Thanks",0,5
2,2016-11-3,2016,11,3,23,5awz59,Deep Learning in Aerial Systems Using Jetson,https://www.reddit.com/r/deeplearning/comments/5awz59/deep_learning_in_aerial_systems_using_jetson/,harrism,1478182956,,0,2
3,2016-11-4,2016,11,4,4,5ayzv6,Is it possible to jump into DL with little ML knowledge or do I need to study ML algorithms first?,https://www.reddit.com/r/deeplearning/comments/5ayzv6/is_it_possible_to_jump_into_dl_with_little_ml/,[deleted],1478202975,[deleted],2,0
4,2016-11-4,2016,11,4,7,5azrvk,My New Blog About Deep Learning With Torch and My Thoughts About It,https://www.reddit.com/r/deeplearning/comments/5azrvk/my_new_blog_about_deep_learning_with_torch_and_my/,TenseTV,1478210731,,0,1
5,2016-11-6,2016,11,6,17,5bewns,NeuralStyler 2.0 released,https://www.reddit.com/r/deeplearning/comments/5bewns/neuralstyler_20_released/,simpleuserhere,1478421580,,2,6
6,2016-11-7,2016,11,7,9,5bj7ex,Deep Learning can Now Design Itself!,https://www.reddit.com/r/deeplearning/comments/5bj7ex/deep_learning_can_now_design_itself/,codeaudit,1478479399,,0,1
7,2016-11-7,2016,11,7,22,5bm7a0,Computer Vision News (November) + Best of ECCV,https://www.reddit.com/r/deeplearning/comments/5bm7a0/computer_vision_news_november_best_of_eccv/,Gletta,1478526280,"Computer Vision News of November (72 pages):
http://www.rsipvision.com/ComputerVisionNews-2016November/
It includes the regular sections, as well as special Best of ECCV and Best of MICCAI, with interviews with Jitendra Malik, Michael Black, Polina Golland and others. Most research papers reviewed build on deep learning.",0,2
8,2016-11-8,2016,11,8,5,5bogwj,Prisma-like NeuralStyler brings more creative control,https://www.reddit.com/r/deeplearning/comments/5bogwj/prismalike_neuralstyler_brings_more_creative/,simpleuserhere,1478549240,,0,0
9,2016-11-8,2016,11,8,7,5bpgnl,PCIe Bandwidth for Workstation,https://www.reddit.com/r/deeplearning/comments/5bpgnl/pcie_bandwidth_for_workstation/,Gio_Gats,1478558840,"Working on a build that's part workstation, part gaming rig, and part deep-learning research platform.  I'm trying to eliminate bottlenecks wherever possible to get the most out of my hardware.
I'm planning to put two GTX 1070s, a 10Gb/s networking card, and a NVMe SSD into the PCIe slots on a MSI X99A Gaming Pro Carbon with an Intel i7-6850K (40 PCIe lanes).  
The manual tells me I can get x8/x16/x8/x8 bandwidth out of those slots.  With those limitations, am I better off sticking with 1Gb/s networking and a SATAIII?  
I know I probably won't see much bottleneck while gaming, but what about running optimized deep learning libraries like TensorFlow?  ",2,0
10,2016-11-9,2016,11,9,20,5c0j9r,Neural Networks Overview CheatSheet,https://www.reddit.com/r/deeplearning/comments/5c0j9r/neural_networks_overview_cheatsheet/,devnull90,1478690536,,1,12
11,2016-11-10,2016,11,10,17,5c6uz1,Architecture of RoI Pooling Layer,https://www.reddit.com/r/deeplearning/comments/5c6uz1/architecture_of_roi_pooling_layer/,mishastik,1478767132,Could somebody please point to an explicit description of the architecture of the Region of Interest (RoI) Pooling Layer in the Region-based CNNs ?,3,1
12,2016-11-11,2016,11,11,10,5cbvmu,Using AI for encouraging the elderly to live independently,https://www.reddit.com/r/deeplearning/comments/5cbvmu/using_ai_for_encouraging_the_elderly_to_live/,fpolacov,1478829077,,1,1
13,2016-11-11,2016,11,11,18,5cdn1o,Deep Learning - Eine bersicht,https://www.reddit.com/r/deeplearning/comments/5cdn1o/deep_learning_eine_bersicht/,flezzfx,1478856148,,0,1
14,2016-11-11,2016,11,11,18,5cdpdu,Nervana's VP of Algorithms: Catalyzing Deep Learnings Impact in the Enterprise,https://www.reddit.com/r/deeplearning/comments/5cdpdu/nervanas_vp_of_algorithms_catalyzing_deep/,reworksophie,1478857485,,0,1
15,2016-11-12,2016,11,12,0,5cf24z,"Where would you place ""deep learning"" on the Gartner Hype Cycle?",https://www.reddit.com/r/deeplearning/comments/5cf24z/where_would_you_place_deep_learning_on_the/,[deleted],1478878483,[deleted],2,4
16,2016-11-12,2016,11,12,3,5cfzrg,Image Segmentation Using DIGITS 5,https://www.reddit.com/r/deeplearning/comments/5cfzrg/image_segmentation_using_digits_5/,harrism,1478888520,,0,3
17,2016-11-12,2016,11,12,13,5cixc8,How AI Careers Fit into the Data Landscape,https://www.reddit.com/r/deeplearning/comments/5cixc8/how_ai_careers_fit_into_the_data_landscape/,mwakanosya,1478925893,,0,4
18,2016-11-13,2016,11,13,1,5cl0h1,Using deep learning to remove glasses from faces,https://www.reddit.com/r/deeplearning/comments/5cl0h1/using_deep_learning_to_remove_glasses_from_faces/,mwakanosya,1478966781,,1,7
19,2016-11-13,2016,11,13,3,5clkh4,Deep Learning for Natural Language Processing  ICLR 2017 Discoveries,https://www.reddit.com/r/deeplearning/comments/5clkh4/deep_learning_for_natural_language_processing/,atveit,1478973888,,0,2
20,2016-11-13,2016,11,13,11,5cnt6a,Let's build a Discord community for AI research,https://www.reddit.com/r/deeplearning/comments/5cnt6a/lets_build_a_discord_community_for_ai_research/,SyntaxExpert,1479002670,,0,6
21,2016-11-14,2016,11,14,23,5cw3y5,Deep Learning cheat sheet?,https://www.reddit.com/r/deeplearning/comments/5cw3y5/deep_learning_cheat_sheet/,[deleted],1479132601,[deleted],1,7
22,2016-11-15,2016,11,15,1,5cwspu,"Video Interview with Oriol Vinyals, Research Scientist at Google DeepMind",https://www.reddit.com/r/deeplearning/comments/5cwspu/video_interview_with_oriol_vinyals_research/,reworksophie,1479140850,,0,1
23,2016-11-17,2016,11,17,0,5d9osd,Heuristics for neural network hyperparameter selection,https://www.reddit.com/r/deeplearning/comments/5d9osd/heuristics_for_neural_network_hyperparameter/,Lopelh,1479309331,,0,2
24,2016-11-17,2016,11,17,7,5dc22v,Paid Research Opportunity: Deep Learning or Machine Learning,https://www.reddit.com/r/deeplearning/comments/5dc22v/paid_research_opportunity_deep_learning_or/,[deleted],1479333931,[deleted],0,1
25,2016-11-17,2016,11,17,9,5dcoae,Can't get MNIST tensor flow tutorial working,https://www.reddit.com/r/deeplearning/comments/5dcoae/cant_get_mnist_tensor_flow_tutorial_working/,[deleted],1479340800,[deleted],0,1
26,2016-11-17,2016,11,17,16,5demrq,text classification and prediction of relatedness,https://www.reddit.com/r/deeplearning/comments/5demrq/text_classification_and_prediction_of_relatedness/,Catslinger,1479368542,"Hello, I have a hypothetical project in mind:

I'd like a personal fulltext &amp; metadata search engine that can compare the content of text files (pdf, txt, doc) and arrange them visually according to their similarity and relatedness. This arrangement would look at the semantic surface of texts without being able to draw conclusions on the nature of their correlation (e.g. causal, hierarchical).

Now for the machine learning part:

Users should be able to rank and specify these relationships between texts whether or not they are, in fact, related argumentationally, and content-wise.

And the software would draw conclusions from these user-generated rankings / specifications and would make its own future predictions.

Example: ""Text A and Text B do not only use similar terms and structure, but Text B is also younger than Text A and - although not referencing Text A - uses ideas that were introduced in Text A."" or ""Text C references Text A, but from the argument it develops, it looks like it is targeting Text B rather than Text A.""

How would one start setting something like this up? Are there any projects doing something similar?
",1,2
27,2016-11-19,2016,11,19,7,5dp8r3,Lessons Learned from Deploying Deep Learning at Scale,https://www.reddit.com/r/deeplearning/comments/5dp8r3/lessons_learned_from_deploying_deep_learning_at/,[deleted],1479507532,[deleted],0,0
28,2016-11-19,2016,11,19,14,5dr4lm,Deep Learning for layman,https://www.reddit.com/r/deeplearning/comments/5dr4lm/deep_learning_for_layman/,shakthydoss,1479534295,,0,1
29,2016-11-19,2016,11,19,20,5ds3u5,Julia for Deep Learning Presented by IBM and Julia Computing at SC16,https://www.reddit.com/r/deeplearning/comments/5ds3u5/julia_for_deep_learning_presented_by_ibm_and/,Nuno_EdgarFernandes,1479555716,,0,4
30,2016-11-20,2016,11,20,3,5dto09,Wow! A photonic neural network.,https://www.reddit.com/r/deeplearning/comments/5dto09/wow_a_photonic_neural_network/,DarthRhaego,1479578828,And thus Alexander Tait and co embark on yet another promising pavement to faster and intelligent computing.   ,0,0
31,2016-11-20,2016,11,20,7,5duvu5,Deep Reinforcement Learning with Averaged Target DQN (a variance reduction method for DRL),https://www.reddit.com/r/deeplearning/comments/5duvu5/deep_reinforcement_learning_with_averaged_target/,MisterO123,1479593816,,0,2
32,2016-11-21,2016,11,21,8,5e0stm,Top 5 most important things that happened in deep learning in 2016?,https://www.reddit.com/r/deeplearning/comments/5e0stm/top_5_most_important_things_that_happened_in_deep/,[deleted],1479683708,[deleted],2,6
33,2016-11-22,2016,11,22,8,5e789d,Why did Bengio not sell out like Hinton and LeCun?,https://www.reddit.com/r/deeplearning/comments/5e789d/why_did_bengio_not_sell_out_like_hinton_and_lecun/,[deleted],1479769609,[deleted],1,3
34,2016-11-22,2016,11,22,12,5e8kxg,Top 5 developments that happened in deep learning in 2016 or 2015?,https://www.reddit.com/r/deeplearning/comments/5e8kxg/top_5_developments_that_happened_in_deep_learning/,[deleted],1479785853,[deleted],1,0
35,2016-11-22,2016,11,22,14,5e94ic,[D] A question about GANs,https://www.reddit.com/r/deeplearning/comments/5e94ic/d_a_question_about_gans/,yield22,1479793488,Will there be any differences by swapping min_G max_D in the objective of GANs? Training wise and optimality wise.,3,1
36,2016-11-23,2016,11,23,20,5egu5x,"Limited time special offer on REWORK Deep Learning, Machine Intelligence &amp; AI events! Super savings on Early Bird/Startup/Student passes",https://www.reddit.com/r/deeplearning/comments/5egu5x/limited_time_special_offer_on_rework_deep/,reworksophie,1479900662,,0,1
37,2016-11-23,2016,11,23,22,5ehb1k,Deep Learning Demo with eSOMTK1 in Retail Outlet | nVIDIA Tegra K1 SOM,https://www.reddit.com/r/deeplearning/comments/5ehb1k/deep_learning_demo_with_esomtk1_in_retail_outlet/,econsystems,1479908161,,0,2
38,2016-11-25,2016,11,25,20,5et3xs,"My LSTM is predicting white noise, something is wrong.",https://www.reddit.com/r/deeplearning/comments/5et3xs/my_lstm_is_predicting_white_noise_something_is/,PhantomFav,1480072425,"I'm playing with this tutorial:

http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/#comment-372293

And it's working correctly, but if i use the fitted model on the flight data, i can use the same hyper parameters to predict white noise using this code:

#Data Generation:

dataset = numpy.random.randint(500, size=(200,1))
dataset = dataset.astype(float32)

#Data Prediction:

scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(dataset)
plt.plot(dataset,b,model.predict(dataset[:,:,numpy.newaxis]),r)

final result:
https://s17.postimg.org/oavua7uq7/download.png

what am i doing wrong?",1,2
39,2016-11-25,2016,11,25,23,5etq7d,[D] What can deep learning actually achieve in medicine?,https://www.reddit.com/r/deeplearning/comments/5etq7d/d_what_can_deep_learning_actually_achieve_in/,[deleted],1480083008,[deleted],2,4
40,2016-11-27,2016,11,27,1,5f0448,[D] Is Deep Learning Growing at an Exponential Rate?,https://www.reddit.com/r/deeplearning/comments/5f0448/d_is_deep_learning_growing_at_an_exponential_rate/,[deleted],1480176746,[deleted],3,0
41,2016-11-28,2016,11,28,9,5f8m4b,[D] Why don't more teams use deep learning in Kaggle?,https://www.reddit.com/r/deeplearning/comments/5f8m4b/d_why_dont_more_teams_use_deep_learning_in_kaggle/,[deleted],1480293250,[deleted],2,2
42,2016-11-29,2016,11,29,1,5fclsi,"[D] Have 10K AWS Promotional Credit, how much DL work can I do on the cloud?",https://www.reddit.com/r/deeplearning/comments/5fclsi/d_have_10k_aws_promotional_credit_how_much_dl/,[deleted],1480350979,[deleted],0,1
43,2016-11-29,2016,11,29,1,5fcnmf,"[D] Won $5000 AWS Promotional Credit from a hackathon, how much DL work can I do on the cloud?",https://www.reddit.com/r/deeplearning/comments/5fcnmf/d_won_5000_aws_promotional_credit_from_a/,[deleted],1480351487,[deleted],0,1
44,2016-11-29,2016,11,29,5,5fe2rb,How does sparse autoencoder apply to variable time-sequence data for feature extraction?,https://www.reddit.com/r/deeplearning/comments/5fe2rb/how_does_sparse_autoencoder_apply_to_variable/,starsmiling,1480365451,"I have a variable length of time-sequence data, say 6 dimensions. I would like to use sparse autoencoder for feature extraction. Specifically, I want to get high dimensional features. From the references it seems that people always use same-length data to feed into autoencoder. What if the data has variable length? Is it a must to convert/pad/cut variable length into the same-length in order to train autoencoder?

Any information is appreciated!",0,2
45,2016-11-29,2016,11,29,9,5ffdzi,Image Processing using Deep Neural Networks Virtual Conference,https://www.reddit.com/r/deeplearning/comments/5ffdzi/image_processing_using_deep_neural_networks/,kevin_img_processing,1480378858,"Hello!

Just wanted to pass along a free Deep Learning for Image Processing Virtual Conference being put on by Wolfram Research Wednesday 11/30/16 and Wednesday 12/7/16. It's in Mathematica, which has recently released a deep learning library. 

You can find more information here:
https://www.wolfram.com/training/special-event/wolfram-virtual-conference-series/

I'm x-posting this on /r/deeplearning /r/Mathematica and /r/machinelearning as those seem to be the pertinent subs, but as it's an open invitation virtual conference, feel free to pass it on to anyone who might be interested.

Feel free to post any questions you might have here and I'll do my best to answer them.",0,2
46,2016-11-29,2016,11,29,17,5fhl1z,Picking a DL framework,https://www.reddit.com/r/deeplearning/comments/5fhl1z/picking_a_dl_framework/,[deleted],1480408265,[deleted],0,2
47,2016-11-29,2016,11,29,21,5fiboq,Deep-Learning Algorithm That Can Peer Into The Future,https://www.reddit.com/r/deeplearning/comments/5fiboq/deeplearning_algorithm_that_can_peer_into_the/,massiveattack778,1480421872,,0,0
48,2016-11-30,2016,11,30,11,5fmxh8,Deep networks performance on classifying convex regular polygons.,https://www.reddit.com/r/deeplearning/comments/5fmxh8/deep_networks_performance_on_classifying_convex/,puplan,1480471731,"I'm trying to find papers or just performance data on classifying simple geometric shapes, e.g. the first six convex regular polygons. The input data is computer graphics generated, producing high contrast, clean images of convex regular polygons in various scales and orientations (rotation only). There is no limit, other than reasonable CPU time, on number of training images provided. Testing is also done on randomly generated CG images.

Regular polygons are just an example. You can add circles, ellipses, non-regular polygons, etc. Basically any simple geometric shape, which competent elementary school students easily classify with 100% accuracy.",0,1
49,2016-11-30,2016,11,30,17,5fohlp,Hardware choices: VRAM and PCIe bandwidth,https://www.reddit.com/r/deeplearning/comments/5fohlp/hardware_choices_vram_and_pcie_bandwidth/,newtonian_mechanics,1480493198,"I want to build a system for deep learning. Since I'm new to this area and a lot of this is empirical science, I do not have a good idea of the tradeoffs involved.

I'm on a budget of about $2k.

I have read Tim Dettmers' [blog posts](http://timdettmers.com/) to get a general idea of what I should be looking for, but I still have the following questions:

Amount of VRAM: How much will it limit me if I go for GTX 1080 (8GB) instead of Pascal Titan (12GB)? I can buy 2 1080s for the price of a Titan. If it doesn't limit me much in terms of what models I can run, I think 2 1080s might be a better choice because I'd be able to test hyperparameters in parallel.

PCIe bandwidth: Tim Dettmers says I should go for CPUs with 40 PCIe lanes. That would mean Intel LGA2011 socket. How much of a performance difference can I expect between running a GPU on 8x vs 16x PCIe 3.0? If there isn't much difference, I could go for LGA1151 CPUs (16 lanes) as I probably won't be running more than 2 GPUs.

Thank you!",4,2
