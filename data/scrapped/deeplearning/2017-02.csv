,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2017-2-1,2017,2,1,13,5rddha,Noob questions - DL recommendations,https://www.reddit.com/r/deeplearning/comments/5rddha/noob_questions_dl_recommendations/,noisyfart,1485922238,"Hey guys,

I'm new to Reddit and relatively new to the whole ML/DL field (although I've played with some genetic algorithms in the past), and I was wondering if you could guide me through the tons of info available in the net.

I want to learn about DL and whatnot and I thought of giving you some background. Long term, I'd like to implement an NN that's pretty visual: maybe it can detect the predominant colour(s) of an image, whether you see animals or objects (and which ones ideally), detect text, etc. Probably a long shot, but I want to write an app that is continuously using the camera and giving you some extra metadata (and maybe feeding stuff to your HoloLens or something like that).

I was browsing and there's so many options. Do you recommend offline or cloud-based solutions? If offline, which one? Keras on top of TensorFlow/Theano? Any other alternative? If it's only, do you recommend Google, CNTK, etc?

Thanks!",6,4
1,2017-2-1,2017,2,1,20,5rf1a6,NeuroEvolution on Autonomous Car Pathing,https://www.reddit.com/r/deeplearning/comments/5rf1a6/neuroevolution_on_autonomous_car_pathing/,Digital10,1485949872,,0,3
2,2017-2-3,2017,2,3,2,5roaw1,Increasing Performance using Multi-Layer LSTM,https://www.reddit.com/r/deeplearning/comments/5roaw1/increasing_performance_using_multilayer_lstm/,mjfnd,1486058219,,0,1
3,2017-2-4,2017,2,4,0,5rughp,"Learn TensorFlow and deep learning, without a Ph.D. by Google Cloud Team",https://www.reddit.com/r/deeplearning/comments/5rughp/learn_tensorflow_and_deep_learning_without_a_phd/,[deleted],1486135060,[deleted],0,1
4,2017-2-4,2017,2,4,14,5rz3px,"Deep Learning community with articles on intuition for concepts, research paper summaries and study groups",https://www.reddit.com/r/deeplearning/comments/5rz3px/deep_learning_community_with_articles_on/,keshav57,1486187775,,1,6
5,2017-2-5,2017,2,5,2,5s1yjk,Training a chatbot on non-conversational text?,https://www.reddit.com/r/deeplearning/comments/5s1yjk/training_a_chatbot_on_nonconversational_text/,USAFairyPrincess,1486230957,"Hey all, this is something I've been thinking a lot of lately but I haven't really been able to find anything on the web about it, and my understanding of ML is still too limited for me to really produce anything original at the moment. That being said, I've had this idea.

I've seen videos of people creating chatbots with TensorFlow and other ML libraries, but they always need a training dataset that is conversational dialogue, a back and forth between two people. What I'm wondering, is if it is currently possible for us to create a chatbot that was trained off non-conversational text, such as a monologue, and then emulate the speech patterns of the author. This has come to my mind because I am 18 years old and started keeping a journal on May 5, 2008, and have 9 years of my detailed thoughts and experiences written down, with almost all of it now typed into a digital document. I want to train a chatbot off my journal to create, essentially, a little virtual me.

Thoughts?",12,4
6,2017-2-6,2017,2,6,15,5scrzz,15 Deep Learning Tutorials,https://www.reddit.com/r/deeplearning/comments/5scrzz/15_deep_learning_tutorials/,psangrene,1486363756,,0,8
7,2017-2-6,2017,2,6,23,5sefnl,Singular-Vision blog by BJ Dooley-- Deep Learning in Finance: The Video,https://www.reddit.com/r/deeplearning/comments/5sefnl/singularvision_blog_by_bj_dooley_deep_learning_in/,bjdooley,1486390304,,0,1
8,2017-2-7,2017,2,7,0,5seyfn,Deep Q Learning with Keras and Gym,https://www.reddit.com/r/deeplearning/comments/5seyfn/deep_q_learning_with_keras_and_gym/,kwk236,1486396248,,0,3
9,2017-2-7,2017,2,7,2,5sfjh9,"SimGANs - A Game Changer in Unsupervised Learning, Self Driving Cars, and More  Intuition Machine",https://www.reddit.com/r/deeplearning/comments/5sfjh9/simgans_a_game_changer_in_unsupervised_learning/,wayaai,1486401989,,0,5
10,2017-2-7,2017,2,7,12,5sj5y8,On the intuition behind deep learning and GANs  towards a fundamental understanding,https://www.reddit.com/r/deeplearning/comments/5sj5y8/on_the_intuition_behind_deep_learning_and_gans/,wayaai,1486439517,,0,5
11,2017-2-7,2017,2,7,18,5sken8,Oxford Deep NLP 2017 course with videos and Practicals,https://www.reddit.com/r/deeplearning/comments/5sken8/oxford_deep_nlp_2017_course_with_videos_and/,Digital10,1486458774,,1,11
12,2017-2-7,2017,2,7,21,5sl2e0,"Deep Learning &amp; Parameter Tuning with MXnet, H2o Package in R",https://www.reddit.com/r/deeplearning/comments/5sl2e0/deep_learning_parameter_tuning_with_mxnet_h2o/,NarendhiranS,1486469767,,0,2
13,2017-2-8,2017,2,8,0,5sm3zp,"Announcing AI With The Best online conference with Yoshua, Geoffrey and Ian Goodfellow in April",https://www.reddit.com/r/deeplearning/comments/5sm3zp/announcing_ai_with_the_best_online_conference/,MariaWTB,1486482548,,4,1
14,2017-2-8,2017,2,8,3,5sn49q,Anonymizing documents with Word Vectors and O(n) models,https://www.reddit.com/r/deeplearning/comments/5sn49q/anonymizing_documents_with_word_vectors_and_on/,mwakanosya,1486492133,,0,2
15,2017-2-8,2017,2,8,14,5squ9d,10 Deep Learning Terms Explained in Simple English,https://www.reddit.com/r/deeplearning/comments/5squ9d/10_deep_learning_terms_explained_in_simple_english/,psangrene,1486531222,,0,16
16,2017-2-8,2017,2,8,20,5ss7i4,What is the Relation Between Internet of Things and Data Visualization?,https://www.reddit.com/r/deeplearning/comments/5ss7i4/what_is_the_relation_between_internet_of_things/,cagataydemir,1486553656,,0,0
17,2017-2-9,2017,2,9,11,5sxe6m,A Comprehensive Introduction to Word Vector Representations,https://www.reddit.com/r/deeplearning/comments/5sxe6m/a_comprehensive_introduction_to_word_vector/,baristaGeek,1486607966,,0,1
18,2017-2-9,2017,2,9,21,5szqgz,Understanding Agent Cooperation | DeepMind,https://www.reddit.com/r/deeplearning/comments/5szqgz/understanding_agent_cooperation_deepmind/,[deleted],1486643652,[deleted],0,2
19,2017-2-10,2017,2,10,2,5t1kty,Build a fast deep learning machine for under $1K (hackernews discussion),https://www.reddit.com/r/deeplearning/comments/5t1kty/build_a_fast_deep_learning_machine_for_under_1k/,eleitl,1486662829,,0,6
20,2017-2-10,2017,2,10,16,5t5zdp,"13 Free Self-Study Books on Mathematics, Machine Learning &amp; Deep Learning",https://www.reddit.com/r/deeplearning/comments/5t5zdp/13_free_selfstudy_books_on_mathematics_machine/,NarendhiranS,1486712064,,1,8
21,2017-2-10,2017,2,10,21,5t6wqx,Evolution of Location Intelligence Tools,https://www.reddit.com/r/deeplearning/comments/5t6wqx/evolution_of_location_intelligence_tools/,cagataydemir,1486728306,,0,1
22,2017-2-10,2017,2,10,22,5t7bqz,"Which kind of network parameters do I need for document (black/white, high contrast, sparse) classification?",https://www.reddit.com/r/deeplearning/comments/5t7bqz/which_kind_of_network_parameters_do_i_need_for/,eleitl,1486734263,"I'm thinking about using deep learning to be able to relatively rapidly classify pages of documents -- all black/white or greyscale but with rather hard contrasts -- on presence or absence of certain graphs (molecular structures). I have a nice data set to train for that.

Question: are e.g. deep convoluted networks at all suitable for such input? There are no nice smooth gradients, only black/white or otherwise solid color angular lines. Example: https://upload.wikimedia.org/wikipedia/commons/9/90/Mitragynine2DACS.svg

The structures like above are *typically* not filling the full page. There might be several of such present on a single page. They are typically much larger than text characters but reasonably stereotypical. They have recurring subfeatures. They are typically not hand-drawn, so have little variance in terms of jitter, though of course bad scans can add artifacts.

So how large should I make my input tile? 

Should I reduce the resolution of the input image, or will I be able to handle e.g. 300 ppi images as is?

How do I know how many intermediate layers are enough? 

By trial and error?

Thanks.




",0,3
23,2017-2-11,2017,2,11,0,5t7slh,How to use Webhose.io rated reviews for sentiment classification,https://www.reddit.com/r/deeplearning/comments/5t7slh/how_to_use_webhoseio_rated_reviews_for_sentiment/,rangeva,1486739630,,0,1
24,2017-2-11,2017,2,11,0,5t7um0,Deep Learning for NLP at Oxford with Deep Mind 2017,https://www.reddit.com/r/deeplearning/comments/5t7um0/deep_learning_for_nlp_at_oxford_with_deep_mind/,zafmahmood,1486740219,,0,4
25,2017-2-11,2017,2,11,5,5t9or5,Ubuntu Deep Learning AWS AMI,https://www.reddit.com/r/deeplearning/comments/5t9or5/ubuntu_deep_learning_aws_ami/,Data-Daddy,1486758295,,3,3
26,2017-2-11,2017,2,11,11,5tbljb,[X-post from /r/machinelearning] An Idea on Machine Ethics,https://www.reddit.com/r/deeplearning/comments/5tbljb/xpost_from_rmachinelearning_an_idea_on_machine/,chipbag01,1486779387,"Disclaimer: Im not an AI researcher, just someone interested in the field.

Ive had an idea about how to align intelligent AI programs goals with our human goals:

The problem is simple: Say you have some sort of software AI agent. The agent has a goal (or goals) mandated by its creator(s), and makes decisions on actions to take that would further the goal(s). Whether or not it can carry out those actions *immediately* or *directly* is irrelevant; for now, were focusing on the agents decisions, since its actions result from them. How do the creators capture the nuance and conditions of their goals, and communicate it to the agent effectively?

My idea: dont give the agent discrete goals at all, at least initially. Instead, give it a network of weighted values to *guide* its decisions.

An example implementation could be created as follows:
1. Download a copy of [Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Database_download#Where_do_I_get_it.3F), in its entirety.
2. Find an article on something you like, or value highly (in my case, [fun](https://en.wikipedia.org/wiki/Fun)).
3. Apply a numerical value to the article. The value should correspond, as best as you can make it, to the ethical value you actually apply to what is described in the article. For example, I could value fun at 9.5/10. This tells the agent that, when it makes decisions, it should try to promote/encourage/further/increase the thing with a high value. This works in reverse, too: a low value (e.g., 2/10) would tell the agent to prevent/discourage/stop/decrease/eliminate the thing at hand.

NOTE: The scale doesnt really matter here; it could go from -10 to 10, -1 to 1, 0 to 10, 0 to 1, whatever works best for your particular setup. Im using 0 
to 10 in my example because its familiar (e.g., movie ratings).

4. Repeat steps 2-3 for multiple articles about things you find important to rate for the AI. All of these values are your specified values, and they cannot/should not be changed by the agent, at ***least*** not without user permission.
5. Specify to the agent that you are, in fact, done inputting specified values.
6. The AI agent analyzes the language used in all the articles in the database, paying special attention to links to other articles and the context of those links. It then uses these to calculate generated values, which have the same function as specified values ***except that*** the agent can change them whenever the user changes one or more specified values. This is similar to how Googles [PageRank](https://en.wikipedia.org/wiki/PageRank#Description) system works, at the base level.

Is this a thing out there? I found [this on MIRIs website](https://intelligence.org/research-guide/#eight), and [this article has the same idea](http://www.recode.net/2016/4/13/11644890/ethics-and-artificial-intelligence-the-moral-compass-of-a-machine), but I dont know of any implementations of it. Other than that, Ive found nothing quite like it.

Thoughts?",3,2
27,2017-2-12,2017,2,12,2,5tgac6,Multiple Different Natural Language Processing Tasks in a Single Deep Model,https://www.reddit.com/r/deeplearning/comments/5tgac6/multiple_different_natural_language_processing/,rajarsheem,1486834987,,0,4
28,2017-2-12,2017,2,12,22,5tlhcq,"Autoencoders  Deep Learning bits #1 data compression, image reconstruction and segmentation (with examples!)",https://www.reddit.com/r/deeplearning/comments/5tlhcq/autoencoders_deep_learning_bits_1_data/,pmz,1486907142,,0,7
29,2017-2-13,2017,2,13,0,5tlypv,"Is a GTX 295 useful for deep learning, and not just a space heater?",https://www.reddit.com/r/deeplearning/comments/5tlypv/is_a_gtx_295_useful_for_deep_learning_and_not/,eleitl,1486913808,"Is a dual-GPU with below specs of any use for deep learning? Thanks.

GPU-Prozessor:        GeForce GTX 295 (GPU 1 von 2)  
Treiberversion:        342.01  
Direct3D-API-Version:    10  
CUDA-Kerne:        240  
Kerntakt:        576 MHz  
Shadertakt:        1242 MHz  
Speicher-Datenrate:    1998 MHz  
Speicherschnittstelle:    448-Bit  
Gesamter verfgbarer Grafikspeicher:    2682 MB  
Dedizierter Videospeicher:    896 MB GDDR3  
System-Videospeicher:    0 MB  
Freigegebener Systemspeicher:    1786 MB  
Video-BIOS-Version:    62.00.45.00.02  
IRQ:            18  
Bus:            PCI Express x16  
 
GPU-Prozessor:        GeForce GTX 295 (GPU 2 von 2)  
Treiberversion:        342.01  
Direct3D-API-Version:    10  
CUDA-Kerne:        240  
Kerntakt:        576 MHz  
Shadertakt:        1242 MHz  
Speicher-Datenrate:    1998 MHz  
Speicherschnittstelle:    448-Bit  
Gesamter verfgbarer Grafikspeicher:    2682 MB  
Dedizierter Videospeicher:    896 MB GDDR3  
System-Videospeicher:    0 MB  
Freigegebener Systemspeicher:    1786 MB  
Video-BIOS-Version:    62.00.45.00.01  
IRQ:            16  
Bus:            PCI Express x16  ",2,1
30,2017-2-13,2017,2,13,6,5togrm,How to extract cnn features from small patches?,https://www.reddit.com/r/deeplearning/comments/5togrm/how_to_extract_cnn_features_from_small_patches/,mojovski,1486935630,"Can anyone advice me about feasible methods on cnn feature extraction from small patches? I would like to use something pre trained such as VGG models, which however are optimized for 256x256 only. (python or c++). Thanks in advance to everyone!",1,2
31,2017-2-13,2017,2,13,14,5tr5z0,Deep Learning for NLP at Oxford 2017 - Lecture 2a - Word Level Semantics...,https://www.reddit.com/r/deeplearning/comments/5tr5z0/deep_learning_for_nlp_at_oxford_2017_lecture_2a/,zafmahmood,1486963456,,0,1
32,2017-2-13,2017,2,13,19,5ts4tg,The risks and dangers of deep-learned biomarkers,https://www.reddit.com/r/deeplearning/comments/5ts4tg/the_risks_and_dangers_of_deeplearned_biomarkers/,nikitaljohnson,1486980787,,0,0
33,2017-2-13,2017,2,13,19,5ts8rx,Computer Vision News of February 2017 (both magazine and PDF formats),https://www.reddit.com/r/deeplearning/comments/5ts8rx/computer_vision_news_of_february_2017_both/,Gletta,1486982916,"Dear all,
here is the new issue of Computer Vision News - 36 pages with great content (and with codes). Free subscription at page 36.
This is the magazine version (recommended): http://www.rsipvision.com/ComputerVisionNews-2017February/
This is the PDF version: http://www.rsipvision.com/computervisionnews-2017february-pdf/
Enjoy!",0,2
34,2017-2-14,2017,2,14,4,5tusek,Turn your laptop into a Deep Learning BEAST,https://www.reddit.com/r/deeplearning/comments/5tusek/turn_your_laptop_into_a_deep_learning_beast/,danimex,1487012730,,10,0
35,2017-2-14,2017,2,14,6,5tvki5,Neural net with set (unordered) output instead of array,https://www.reddit.com/r/deeplearning/comments/5tvki5/neural_net_with_set_unordered_output_instead_of/,asfarley,1487020237,"I'd like to create a neural network where the output is a variable-sized, discrete set. Each element of the set is an (x,y) coordinate. 

I don't want to treat this output as an array/list because an array implies that the ordering of elements within the set is signifiant. Instead, I want to train a network where the output is considered to be correct when it contains the right elements, regardless of ordering. 

Has anyone seen something like this before? 
",8,7
36,2017-2-15,2017,2,15,0,5u0vbn,Distributed Tensorflow + Inifiband + Spark all in one System by Yahoo,https://www.reddit.com/r/deeplearning/comments/5u0vbn/distributed_tensorflow_inifiband_spark_all_in_one/,jpdowlin,1487086767,,3,5
37,2017-2-15,2017,2,15,1,5u147d,Interview With Google's Conversation Design Lead Nandini Stocker for International Women in Science Day 2017!,https://www.reddit.com/r/deeplearning/comments/5u147d/interview_with_googles_conversation_design_lead/,reworksophie,1487089211,,0,1
38,2017-2-15,2017,2,15,9,5u4adn,"I am quite proficient in R Language. In order to get the full potential of deep learning, should I learn Phython ?",https://www.reddit.com/r/deeplearning/comments/5u4adn/i_am_quite_proficient_in_r_language_in_order_to/,josenilocm,1487119575,,3,1
39,2017-2-15,2017,2,15,16,5u60bv,"[Data] Spanner, the Google Database That Mastered Time, Is Now Open to Everyone",https://www.reddit.com/r/deeplearning/comments/5u60bv/data_spanner_the_google_database_that_mastered/,NarendhiranS,1487142471,,3,7
40,2017-2-15,2017,2,15,20,5u6wlq,"Interview with the director of the new General AI Challenge, launching today, $50k prize",https://www.reddit.com/r/deeplearning/comments/5u6wlq/interview_with_the_director_of_the_new_general_ai/,reworksophie,1487159270,,0,1
41,2017-2-16,2017,2,16,16,5udeh4,FPGAs Focal Point for Efficient Neural Network Inference,https://www.reddit.com/r/deeplearning/comments/5udeh4/fpgas_focal_point_for_efficient_neural_network/,pete0273,1487229533,,0,2
42,2017-2-17,2017,2,17,16,5ukxqa,Innovation with Real-Time Data and Insights,https://www.reddit.com/r/deeplearning/comments/5ukxqa/innovation_with_realtime_data_and_insights/,cagataydemir,1487317285,,0,1
43,2017-2-17,2017,2,17,19,5ulfia,The Importance of Predictive Analytics for Your Business,https://www.reddit.com/r/deeplearning/comments/5ulfia/the_importance_of_predictive_analytics_for_your/,cagataydemir,1487326855,,0,1
44,2017-2-17,2017,2,17,20,5ulnvq,Deep Learning: A Practitioner's Approach (book) for is on sale at the moment $28.56 (-43%),https://www.reddit.com/r/deeplearning/comments/5ulnvq/deep_learning_a_practitioners_approach_book_for/,vecmilgravis,1487331381,,1,3
45,2017-2-17,2017,2,17,21,5ultep,"[Question] Is there an Atlas of deep learning models, learning algorithms, initializations, etc.",https://www.reddit.com/r/deeplearning/comments/5ultep/question_is_there_an_atlas_of_deep_learning/,jiminiminimini,1487333866,"I mean a guide that explains the relationships between current state of the art DNN models, initialization functions for different layers, training methods, data preprocessing, different normalization approaches etc. organized by properties of your dataset, the kind of task you are trying to do (such as classification, generation, prediction, sequence to sequence conversion, etc.).

I feel like I should be able to navigate the existing state of the art before trying to reinvent the wheel and fail.",4,3
46,2017-2-17,2017,2,17,22,5um4mg,Deep Learning; What are the current research issues?,https://www.reddit.com/r/deeplearning/comments/5um4mg/deep_learning_what_are_the_current_research_issues/,ebaldac,1487338494,"I would like to start researching on deep learning (I am particularly interested on designing algorithms). I am know about linear algebra, optimization, and machine learning basics, but I don't know where to look for ideas (among the huge amount of papers on deep learning). So, what are the current problems in the deep learning community?",7,3
47,2017-2-18,2017,2,18,23,5usjzy,Ground-up &amp; hands-on deep learning tutorial  diagnosing skin cancer w/ dermatologist-level,https://www.reddit.com/r/deeplearning/comments/5usjzy/groundup_handson_deep_learning_tutorial/,wayaai,1487426706,,0,3
48,2017-2-19,2017,2,19,17,5uxfsd,Deep Learning for Self-Driving Cars : Lecture 5,https://www.reddit.com/r/deeplearning/comments/5uxfsd/deep_learning_for_selfdriving_cars_lecture_5/,Mussem17,1487493992,,2,2
49,2017-2-20,2017,2,20,8,5v1a8a,Can anyone please list labs working on robotic grasp problem in vision apart from Prof. Ashutosh Saxena's lab?,https://www.reddit.com/r/deeplearning/comments/5v1a8a/can_anyone_please_list_labs_working_on_robotic/,Talos19,1487548331,"Also, if you know any latest paper on grasp problem, please mention that as well. Thank you! ",4,1
50,2017-2-21,2017,2,21,19,5vash9,Using Machine Learning for Anomaly Detection,https://www.reddit.com/r/deeplearning/comments/5vash9/using_machine_learning_for_anomaly_detection/,cagataydemir,1487672428,,0,1
51,2017-2-22,2017,2,22,0,5vc0yp,How is Deep Learning Changing Data Science Paradigms?,https://www.reddit.com/r/deeplearning/comments/5vc0yp/how_is_deep_learning_changing_data_science/,__me_again__,1487690436,,0,1
52,2017-2-22,2017,2,22,3,5vd05e,tensorflow 1.0.0 with rstudio docker images up.,https://www.reddit.com/r/deeplearning/comments/5vd05e/tensorflow_100_with_rstudio_docker_images_up/,mrchypark,1487700167,,0,1
53,2017-2-22,2017,2,22,4,5vdhs8,GPUs Are Now Available for Google Compute Engine and Cloud Machine Learning,https://www.reddit.com/r/deeplearning/comments/5vdhs8/gpus_are_now_available_for_google_compute_engine/,eleitl,1487704753,,0,2
54,2017-2-22,2017,2,22,4,5vdr0h,Wide &amp; Deep Learning: Memorization + Generalization,https://www.reddit.com/r/deeplearning/comments/5vdr0h/wide_deep_learning_memorization_generalization/,Mussem17,1487707155,,0,0
55,2017-2-22,2017,2,22,14,5vgxks,"Can anyone enlist the list of essential properties of an object to understand complete structure of the object? E.g. - geometric aspects, depth, what else? It's better they are quantifiable.",https://www.reddit.com/r/deeplearning/comments/5vgxks/can_anyone_enlist_the_list_of_essential/,Talos19,1487741736,,2,0
56,2017-2-23,2017,2,23,1,5vjsb7,Opening the Black Box: Interpretable Deep Learning for Genomics,https://www.reddit.com/r/deeplearning/comments/5vjsb7/opening_the_black_box_interpretable_deep_learning/,reworksophie,1487782368,,0,1
57,2017-2-23,2017,2,23,5,5vl702,Why Medicine Needs Deep Learning,https://www.reddit.com/r/deeplearning/comments/5vl702/why_medicine_needs_deep_learning/,Mussem17,1487795555,,1,0
58,2017-2-23,2017,2,23,12,5vnw5c,Any suggestions on a 1U/2U chassis that would support 4 GPUs?,https://www.reddit.com/r/deeplearning/comments/5vnw5c/any_suggestions_on_a_1u2u_chassis_that_would/,Saxi,1487821053,"I was looking at super micro's stuff, but they are only complete systems with P100 and I'm not looking to spend $35K, I want to drop in 1060's or 1070's.

Most servers don't have the PSU cables for GPUs nor the space.",3,2
59,2017-2-23,2017,2,23,16,5vp4m9,Faster R-CNN,https://www.reddit.com/r/deeplearning/comments/5vp4m9/faster_rcnn/,gungorbasa,1487835149,"Hey guys, I was trying to understand Faster RCNN paper but I am stuck on Region Proposing Networks part? Can someone help me on that?",2,2
60,2017-2-24,2017,2,24,0,5vr1u0,Choose subject for Thesis project between Deep Fool algorithm and Data Stream Anomaly Detection.,https://www.reddit.com/r/deeplearning/comments/5vr1u0/choose_subject_for_thesis_project_between_deep/,billythekid-,1487864320,I am about choosing one of two these subject.My main purpose is to parallize the algorithm via cuda . Which one of the two topics is according to your opinion and your experience more in demand these days? Thanks in advance,1,1
61,2017-2-24,2017,2,24,6,5vt8tx,Any examples of 3D/time-distributed cnn/r-cnn in Tensorflow/Keras?,https://www.reddit.com/r/deeplearning/comments/5vt8tx/any_examples_of_3dtimedistributed_cnnrcnn_in/,cctap,1487885346,Does anyone know of any 3D cnn or time-distributed cnn examples in Keras for video data? I have not been able to find any. ,0,3
62,2017-2-24,2017,2,24,6,5vt9xc,DeepCoder: Learning to Write Programs,https://www.reddit.com/r/deeplearning/comments/5vt9xc/deepcoder_learning_to_write_programs/,DataScienceInc,1487885627,,0,1
63,2017-2-24,2017,2,24,11,5vutts,"Talk + Q&amp;A on Deep Q-learning, based on the project ""Deep Reinforcement Learning: Playing a Racing Game""",https://www.reddit.com/r/deeplearning/comments/5vutts/talk_qa_on_deep_qlearning_based_on_the_project/,lopespm,1487902291,,0,1
64,2017-2-24,2017,2,24,17,5vwgow,Face Recognition with Deep Learning - Do I look like Brad Pitt?,https://www.reddit.com/r/deeplearning/comments/5vwgow/face_recognition_with_deep_learning_do_i_look/,gavlaaaaaaaa,1487925910,,1,1
65,2017-2-24,2017,2,24,18,5vwjq4,Online Workshop - Deep Dream and neural style transfer - matching deep learning with art,https://www.reddit.com/r/deeplearning/comments/5vwjq4/online_workshop_deep_dream_and_neural_style/,annkov,1487927612,,0,5
66,2017-2-24,2017,2,24,20,5vwx2e,Exploring Machine Learning at OpenAI &amp;amp; Google With the Experts,https://www.reddit.com/r/deeplearning/comments/5vwx2e/exploring_machine_learning_at_openai_amp_google/,teamrework,1487934543,,0,2
67,2017-2-26,2017,2,26,4,5w5tho,Convolutional Neural Networks for Underwater Color Classification,https://www.reddit.com/r/deeplearning/comments/5w5tho/convolutional_neural_networks_for_underwater/,Arzela-Ascoli,1488051120,"I have a set of underwater scenes consisting of known objects. I'm trying to segment these objects, and have pixel-level segmentation labels, but it seems that convolutional neural networks seem to be designed for image-level classification. When at a distance, the objects become sufficiently close in color to the background water that they can be difficult to recognize to the human eye (but by looking at other color space planes, you can usually figure it out). Any advice as to how to proceed?

I've also considered just a regular neural net or some other classifier trained on the individual pixel values (possibly preprocessed to stretch the color planes), and passing in a few patch statistics (ie, maximum, min value in patch, range)",1,1
68,2017-2-26,2017,2,26,9,5w7hed,Batch normalization and weight/activity regularization pathology?,https://www.reddit.com/r/deeplearning/comments/5w7hed/batch_normalization_and_weightactivity/,kappago,1488070167,"Using an example:

FC1-&gt;ReLu-&gt;X
or 
X-&gt;ReLu-&gt;FC1
where FC1 has some sort of regularization on it, and X is some sort of layer that can scale by a constant, for example another FC layer, or simply a scaling layer. Also, X is not regularized.
It seems that FC1 can ""cheat"" by just scaling all of its weights down by a constant, and having X scale up proportionally, causing the effective regularization to become gradually less powerful over time. So the idea is that X should be regularized as well.

Batch norm consists of scaling to 1 std dev, then scaling up or down as desired using the gamma parameter. But the first step doesn't have regularization applied to it, only gamma does (at least in the implementations I've seen). 
So the BN-&gt;ReLu-&gt;FC1 case should be okay, but not FC1-&gt;ReLu-&gt;BN.

Is my reasoning correct? How big of a problem is this?
",0,3
69,2017-2-27,2017,2,27,1,5warcx,The State Of AI: A list of the human tasks artificial intelligence has mastered,https://www.reddit.com/r/deeplearning/comments/5warcx/the_state_of_ai_a_list_of_the_human_tasks/,nikitaljohnson,1488125314,,2,2
70,2017-2-27,2017,2,27,13,5wes2f,How to implement Long-term Recurrent Convolutional Networks in Keras??,https://www.reddit.com/r/deeplearning/comments/5wes2f/how_to_implement_longterm_recurrent_convolutional/,GengisDroundStone,1488170668,"I want to implement the Long-term Recurrent Convolutional Networks, with keras and theano backend according to this [paper](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper.pdf) . How do I feed the output of the CNN into the LSTM? I'm very new to this, so any kind of help will be appreciated. ",3,1
71,2017-2-27,2017,2,27,19,5wg1sk,"Interpretability: the Next Deep Learning Challenge (Interview with Charlie Tang, Research Scientist at Apple)",https://www.reddit.com/r/deeplearning/comments/5wg1sk/interpretability_the_next_deep_learning_challenge/,reworksophie,1488191526,,0,1
72,2017-2-27,2017,2,27,21,5wghrp,Can Mobile Apps Benefit from Deep Learning AI?,https://www.reddit.com/r/deeplearning/comments/5wghrp/can_mobile_apps_benefit_from_deep_learning_ai/,julianrobert,1488199161,,0,1
73,2017-2-28,2017,2,28,5,5wj2p0,Deep Learning Lectures at the University of Oxford by Nando de Freitas,https://www.reddit.com/r/deeplearning/comments/5wj2p0/deep_learning_lectures_at_the_university_of/,Mussem17,1488226435,,1,11
