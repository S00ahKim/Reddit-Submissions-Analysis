,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,deeplearning,t5_2t5eh,2018-4-1,2018,4,1,21,88qbyi,self.deeplearning,Pre-trained sparse weights for YOLOV2 and Baidu Deep speech 2,https://www.reddit.com/r/deeplearning/comments/88qbyi/pretrained_sparse_weights_for_yolov2_and_baidu/,mosheshahar,1522584160,"Hi,

I am looking to download pre-trained weight sets for networks trained for weight sparsity. Does anyone have a link or a source?

Thanks",0,5,False,self,,,,,
1,deeplearning,t5_2t5eh,2018-4-2,2018,4,2,2,88sd0t,youtube.com,Stabilizing Training of GANs Intuitive Introduction with Kevin Roth (ETH Zurich),https://www.reddit.com/r/deeplearning/comments/88sd0t/stabilizing_training_of_gans_intuitive/,alexmlamb,1522602985,,0,5,False,https://a.thumbs.redditmedia.com/Fn5ApbZYl4KaLB78hIZWyydqbfizBg7j8HpkiuTpIq4.jpg,,,,,
2,deeplearning,t5_2t5eh,2018-4-2,2018,4,2,5,88tujz,self.deeplearning,Implementation of a CNN application on FPGA (HELP),https://www.reddit.com/r/deeplearning/comments/88tujz/implementation_of_a_cnn_application_on_fpga_help/,spookyboogy22,1522615331,"Hello guys, I am actually working on a project of image recognition by a deep convolutional neural network using FPGA, reading all those research papers made me lost and I really don't know from where should I begin and of course I do know how a neural network and its training work but the difficult part for me is the implementation, could you guys give me some suggestions, link of a helpful paper, steps to follow ...etc ? thank you",1,2,False,self,,,,,
3,deeplearning,t5_2t5eh,2018-4-2,2018,4,2,10,88vwd3,towardsdatascience.com,Entity extraction using deep learning,https://www.reddit.com/r/deeplearning/comments/88vwd3/entity_extraction_using_deep_learning/,dkarunakaran,1522633957,,0,8,False,https://b.thumbs.redditmedia.com/srLbYZek9MC9fN5c_-Uu-aZjFNZIwOHwXsDhBJ0sH4Q.jpg,,,,,
4,deeplearning,t5_2t5eh,2018-4-2,2018,4,2,17,88xvhg,datameetsmedia.com,A course-by-course review of Andrew Ng's Deep Learning specialization,https://www.reddit.com/r/deeplearning/comments/88xvhg/a_coursebycourse_review_of_andrew_ngs_deep/,wasabihater,1522658342,,0,10,False,https://b.thumbs.redditmedia.com/BiehOJxJ0mltjx6B-BmYupmz01OC1ai9FSB8Jl0YfbI.jpg,,,,,
5,deeplearning,t5_2t5eh,2018-4-2,2018,4,2,19,88yc85,giorgiop.github.io,AI and digital forgery,https://www.reddit.com/r/deeplearning/comments/88yc85/ai_and_digital_forgery/,dayikkk,1522665149,,0,8,False,https://b.thumbs.redditmedia.com/55eMgndFHEDhSpAE5AyKFUpuO6-aTlTZ7zF9sGFjiGU.jpg,,,,,
6,deeplearning,t5_2t5eh,2018-4-2,2018,4,2,20,88yijz,kdnuggets.com,A Weird Introduction to Deep Learning,https://www.reddit.com/r/deeplearning/comments/88yijz/a_weird_introduction_to_deep_learning/,digitalson,1522667499,,0,3,False,default,,,,,
7,deeplearning,t5_2t5eh,2018-4-3,2018,4,3,4,893ryg,self.deeplearning,Document classification strategy,https://www.reddit.com/r/deeplearning/comments/893ryg/document_classification_strategy/,chepetronix,1522696794,"Hi all! I have to design a model that classifies and performs OCR over a large collection of scanned documents in image format. There are around 10 different types of documents and depending on each type of document, a different set of information needs to be extracted. 
So, my question is, what would be your approach? Should I try to classify them as images and then perform OCR? Or OCR first and then classify depending on the text? A sequential model for this maybe?

Any insight would be appreciated!
",1,2,False,self,,,,,
8,deeplearning,t5_2t5eh,2018-4-3,2018,4,3,8,8967fu,self.deeplearning,"Do I still need to learn Caffe, or can I get by with Tensorflow and Keras?",https://www.reddit.com/r/deeplearning/comments/8967fu/do_i_still_need_to_learn_caffe_or_can_i_get_by/,krishnab75,1522710675,"Hey Folks, I am new to the deep learning world, but my background is in statistics. I had a question about libraries. So I love DIGITS and have been able to get the demos working, etc. So that is good. But I am having any amount of frustration with getting Caffe models to run in DIGITs because of some protobuf errors, etc. (Yes, I have consulted lots of stackexchange, nvidia forum, and github posts on issue).

Note, the only reason I did any work with Caffe was because many of the demos for Nvidia DIGITS are done in Caffe. 

Anyhow, this effort got me thinking about whether I really needed to learn all of the environments? I think DIGITS supports Caffe, Torch, and Tensorflow now, but even without DIGITS there is no reason to learn every library out there. A lot of my applications focus on CNNs for Object Detection in images, as well as some applications on textual analysis, etc. 

So I was not sure if I really needed to go through all of the trouble of getting every library installed and working, if I really was not going to use them all. Perhaps this is a good application of Zipf's law :). Of course, the folks on the forums have more experience with these libraries than I do, so I would defer to their judgement. Are there any big problems or limitations that I will run into if I focus on just TF and Keras? If I had to pick an additional library beyond this, which one should I choose?",0,1,False,self,,,,,
9,deeplearning,t5_2t5eh,2018-4-3,2018,4,3,12,898pag,self.deeplearning,Diabetic Retinopathy Detection,https://www.reddit.com/r/deeplearning/comments/898pag/diabetic_retinopathy_detection/,stargrazie,1522725426,"Hi guys, I have been working on this project for a while now. 
I have performed minimal image pre-processing, just data augmentation using Image Datagenerator from keras. 
Augmented the data to roughly extra 15k images per class. Thus making my data set to be 90k.
I have a CV of 5k images evenly split amount all 5 classes. 
I am using xavier initialization for weights, L2 regularization for class weights. Adam optimizer with a learning rate of 0.05. 
My architecture is similar to vgg 16. It has roughly 16 million parameters.

Unfortunately my model only predicts one class i.e 0. 
What should I do ? 
Any advice would be appreciated.",0,1,False,self,,,,,
10,deeplearning,t5_2t5eh,2018-4-3,2018,4,3,12,898tux,self.deeplearning,Diabetic retinopathy detection project,https://www.reddit.com/r/deeplearning/comments/898tux/diabetic_retinopathy_detection_project/,stargrazie,1522726035,"I have been working on this project for a while now. Would appreciate some help. 
My model isn't learning anything and only predicts one single class. 
The architecture is similar to vgg 16. 
I have used data augmentation to balance classes and also used class weights to give extra weightage to class 4/5 images. 
I am using relu activation function. 
i am initializing my weights using Xavier initialization and regularizing them using L2 regularization. 

There's minimal image processing only data augmentation using Image Datagenerator. 

What else can I do ? 
",3,0,False,self,,,,,
11,deeplearning,t5_2t5eh,2018-4-3,2018,4,3,14,89a5z4,self.deeplearning,How does the keras TimeDistributed Wrapper work internally?,https://www.reddit.com/r/deeplearning/comments/89a5z4/how_does_the_keras_timedistributed_wrapper_work/,akanimax,1522733231,"I have read the documentation of the TimeDistributed wrapper of keras. The shape information associated with the operation is clear. What I would like to know is if the wrapper applies the same set of weights to all the timesteps, or spawns different weights for different timesteps. 
If, the former is true, how does backpropagation take place through these ops?
Thank you!",2,3,False,self,,,,,
12,deeplearning,t5_2t5eh,2018-4-3,2018,4,3,20,89cyok,exastax.com,How Big Data Analytics is Transforming the Travel Industry,https://www.reddit.com/r/deeplearning/comments/89cyok/how_big_data_analytics_is_transforming_the_travel/,y-emre,1522756749,,0,1,False,https://b.thumbs.redditmedia.com/drTxJ9goiZoBzPWVn6XzvRqhhBZod7VxUoDlk3FRd3Y.jpg,,,,,
13,deeplearning,t5_2t5eh,2018-4-3,2018,4,3,21,89ddn2,towardsdatascience.com,Paper repro: Deep Metalearning using MAML and Reptile,https://www.reddit.com/r/deeplearning/comments/89ddn2/paper_repro_deep_metalearning_using_maml_and/,digitalson,1522759711,,0,3,False,https://a.thumbs.redditmedia.com/vIMQL2c8JueErouuyMbQ1jsCD4ldvIxuSqzMJt1_-T4.jpg,,,,,
14,deeplearning,t5_2t5eh,2018-4-3,2018,4,3,23,89e8a2,i.redd.it,How I train my models,https://www.reddit.com/r/deeplearning/comments/89e8a2/how_i_train_my_models/,csyrup,1522765159,,7,67,False,https://b.thumbs.redditmedia.com/dRoQrxiPqB2FyPzz3y_dxirKiwuMj16els9NzkcYY9E.jpg,,,,,
15,deeplearning,t5_2t5eh,2018-4-3,2018,4,3,23,89efss,towardsdatascience.com,How to build a Neural Network with Keras,https://www.reddit.com/r/deeplearning/comments/89efss/how_to_build_a_neural_network_with_keras/,jackblun,1522766365,,0,3,False,https://b.thumbs.redditmedia.com/ncGKn9f5Xq-5lKXPqOSZMeQaXHcZTCkxd36bW9sg16I.jpg,,,,,
16,deeplearning,t5_2t5eh,2018-4-4,2018,4,4,6,89il7b,self.deeplearning,LSTM - loss goes down and then back up,https://www.reddit.com/r/deeplearning/comments/89il7b/lstm_loss_goes_down_and_then_back_up/,crowoy,1522789404,"Attempting to train an LSTM - the loss seems to decrease sharply over the first ~50 epochs and the gradually increases continuously for the next ~1000 epochs.

I've been informed regularisation is a possible solutions. I've tried 20% dropout, 20% recurrent dropout, and then 20% of both. All of these options increase the values seen for loss, and the same shape of the graph is seen as well.

I've also been told to try L1 and L2 regularisation. But the LSTM section on Keras (https://keras.io/layers/recurrent/) seems to have 4 different types of regularisers:

- recurrent regulariser
- kernel regulariser
- activity regulariser
-bias regulariser

I'm really unsure on which ones to go about starting with, and with what values. As my network takes a long time to train in each case, an exhaustive search method is not feasible.",1,1,False,self,,,,,
17,deeplearning,t5_2t5eh,2018-4-4,2018,4,4,16,89nbx4,mljobslist.com,"Hey, guys, I created ML Jobs List, what do you think?",https://www.reddit.com/r/deeplearning/comments/89nbx4/hey_guys_i_created_ml_jobs_list_what_do_you_think/,gauthamz,1522826227,,6,3,False,https://b.thumbs.redditmedia.com/OqwVRFsqOS_lWi3hiSeQp416tW3YitMA9FIlLsSY8NY.jpg,,,,,
18,deeplearning,t5_2t5eh,2018-4-4,2018,4,4,17,89nn8p,self.deeplearning,Could this be a viable career for me?,https://www.reddit.com/r/deeplearning/comments/89nn8p/could_this_be_a_viable_career_for_me/,LikeMike81,1522830047,"Hi there,
Right now I am a journalist in my mid 30s thinking about switching careers at some point. In university I got a minor degree in ""information processing"" which is basically computer science with programming as well as linguistics. I was also doing some pretty beginner so stuff. The only programming language I ever worked with is c++.

So I got basic understanding of programming and ai but would have to learn a lot of stuff by myself. My question: would that even be viable or would I be way too far behind people that actually got a full time and more specific education? Would companies even bother with my resume?

And where would I start? Which programming language to learn, which books to read - what to ""build"" to show people that I know what I am doing?",8,4,False,self,,,,,
19,deeplearning,t5_2t5eh,2018-4-4,2018,4,4,22,89pa3e,towardsdatascience.com,Deep Learning vs Classical Machine Learning,https://www.reddit.com/r/deeplearning/comments/89pa3e/deep_learning_vs_classical_machine_learning/,magneticono,1522847210,,1,2,False,https://b.thumbs.redditmedia.com/KNuE1eserpTGAEwDxsGlb6DlSIb59E7fQsJLORn_frg.jpg,,,,,
20,deeplearning,t5_2t5eh,2018-4-4,2018,4,4,23,89prc6,arxiv.org,A Robust Real-Time Automatic License Plate Recognition based on the YOLO Detector (comprehensible paper with public dataset),https://www.reddit.com/r/deeplearning/comments/89prc6/a_robust_realtime_automatic_license_plate/,ghostzin,1522850864,,0,10,False,default,,,,,
21,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,0,89qcxo,imgur.com,"Some questions about ""Deep Learning: An Introduction for Applied Mathematicians"" paper",https://www.reddit.com/r/deeplearning/comments/89qcxo/some_questions_about_deep_learning_an/,[deleted],1522855035,[deleted],1,1,False,default,,,,,
22,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,0,89qfyg,self.deeplearning,"Some questions about ""Deep Learning: An Introduction for Applied Mathematicians"" paper",https://www.reddit.com/r/deeplearning/comments/89qfyg/some_questions_about_deep_learning_an/,maybenexttime82,1522855675,"I've came across an interesting paper about Deep Learning (""Deep Learning: An Introduction for Applied Mathematicians""), which could be found on arXiv, but I've stuck at interpreting this part marked in yellow:

https://imgur.com/a/dm9R0

If F(x) is 2D vector then in what sense it is ""close to some vector [1,0]^T""? 

My thought: Maybe in context ""angle between two vectors aka dot product"". If [1,0]^T and [0,1]^T could be interpreted as unit vectors of x and y axis, respectively then we could give some ""rules"" which determine if vector F(x) should be in category A (""close to [1,0]^T""). For example we could say: ""If angle between F(x) vector and [1,0]^T is less than equal to zero or less than 45 degrees then F(x) is in category A."" (I presume we need more constraints other than ""angle between vectors"" but let it be for this case it only depends on angle). 

How to interpret F1(x)&gt;F2(x) if those are vectors? How do you ""compare vectors"" anyway?
",8,6,False,self,,,,,
23,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,5,89sws9,self.deeplearning,Fast-RCNN,https://www.reddit.com/r/deeplearning/comments/89sws9/fastrcnn/,asranand7,1522872003,"
""A Fast R-CNN network takes as input an entire image and a set of object proposals. The networks first processes the whole image with several convolutions(conv) and max pooling layer to produce a conv feature map.Then for each object proposal region of interest pooling layer extracts a fixed length feature vector from the feature map."" (paragraph from Fast R-CNN paper)

How do we find the object proposal region in the final conv feature map given the object proposal on the real image ???
",7,6,False,self,,,,,
24,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,10,89vnux,self.deeplearning,LSTM classification in time series data,https://www.reddit.com/r/deeplearning/comments/89vnux/lstm_classification_in_time_series_data/,xpbit1024,1522892420,"So I was wondering howd one go about classifying every point of a time series data. Like the data points themselves are time dependent, but I want to predict the class of every single data point using this time dependency. ",10,1,False,self,,,,,
25,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,11,89w5mz,self.deeplearning,Anyone take the deeplearning.ai course?,https://www.reddit.com/r/deeplearning/comments/89w5mz/anyone_take_the_deeplearningai_course/,MLJungle,1522896539,"Hi,

I'm currently auditing the deeplearning.ai course and was wondering if anyone   enrolled in the course could share the programming assignments (they're locked for me) in the form of the jupyternotebooks. I would be highly grateful.

",2,1,False,self,,,,,
26,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,12,89wd77,self.deeplearning,Looking for any documentation on creating my own dataset to feed into a TensorFlow model.,https://www.reddit.com/r/deeplearning/comments/89wd77/looking_for_any_documentation_on_creating_my_own/,avtges,1522898418,Im stuck. How do I create a dataset using images? I do not want to pull pixel values and generate a flat file from the images like MNIST. ,0,1,False,self,,,,,
27,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,12,89wguq,self.deeplearning,Looking for a Deep Learning course that's tailored towards Java users?,https://www.reddit.com/r/deeplearning/comments/89wguq/looking_for_a_deep_learning_course_thats_tailored/,drea2,1522899386,Any help? All I can find are courses tailored for python. ,5,0,False,self,,,,,
28,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,20,89ys4u,dzone.com,Top 8 Deep Learning Frameworks,https://www.reddit.com/r/deeplearning/comments/89ys4u/top_8_deep_learning_frameworks/,chris_shpak,1522926629,,2,1,False,https://b.thumbs.redditmedia.com/DmvoQ4Mo5PC8RttE_J3TDIcWXtm32_AKYrbxORbO-ug.jpg,,,,,
29,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,20,89yvic,kdnuggets.com,"Top 20 Deep Learning Papers, 2018 Edition",https://www.reddit.com/r/deeplearning/comments/89yvic/top_20_deep_learning_papers_2018_edition/,magneticono,1522927565,,2,17,False,default,,,,,
30,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,21,89z72q,self.deeplearning,Computer for deep learning,https://www.reddit.com/r/deeplearning/comments/89z72q/computer_for_deep_learning/,Stygian2a,1522930680,"Hi everybody!

I need to buy a computer for research in deep learningm and I have a budget of 3000/4000
Do you have any suggestions?

Thank you!",1,3,False,self,,,,,
31,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,21,89z7d4,kdnuggets.com,Implementing Deep Learning Methods and Feature Engineering for Text Data: The Continuous Bag of Words (CBOW),https://www.reddit.com/r/deeplearning/comments/89z7d4/implementing_deep_learning_methods_and_feature/,dearpetra,1522930752,,0,2,False,https://b.thumbs.redditmedia.com/rN8wE8AXlGMIn-L3cPv48B_fEHryFfB6QtfYQWmLegw.jpg,,,,,
32,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,22,89zslp,insidebigdata.com,How AI Can Create Conflict within Businesses  and What to Do About It,https://www.reddit.com/r/deeplearning/comments/89zslp/how_ai_can_create_conflict_within_businesses_and/,trumtra,1522935836,,0,1,False,https://b.thumbs.redditmedia.com/lKIK27Q1b0I5A920V8m7Rz7QjNNkj7OyGEdeBk7dnoY.jpg,,,,,
33,deeplearning,t5_2t5eh,2018-4-5,2018,4,5,23,89zy0c,self.deeplearning,Is this config good for deep learning?,https://www.reddit.com/r/deeplearning/comments/89zy0c/is_this_config_good_for_deep_learning/,Stygian2a,1522936973,"Hi everyone!

I want to build a computer for research in deep learning, and I thought I might go with this config : https://pcpartpicker.com/list/8VcXP3

Do you have any opinions on this build? I think everything is compatible. Any ideas on how I might upgrade it? I have maybe 1000 pounds to spend (in addition to the current build)

Thank you!",2,2,False,self,,,,,
34,deeplearning,t5_2t5eh,2018-4-6,2018,4,6,1,8a19n1,github.com,"DeepLearn - Implementation and reproducible code for deep learning papers on NLP(QA, sentence matching, attention, knowledge base completion), CV(transfer learning, multi-modal learning), Audio(scene recognition, tagging).",https://www.reddit.com/r/deeplearning/comments/8a19n1/deeplearn_implementation_and_reproducible_code/,bhatt_gaurav,1522946451,,0,6,False,https://a.thumbs.redditmedia.com/xoDW76k9hhh4mrynPvvE4PpnXjUdMIjh1EGSNj4g_c4.jpg,,,,,
35,deeplearning,t5_2t5eh,2018-4-6,2018,4,6,4,8a2kfk,youtube.com,Extension of Deep Photo Style Transfer to Videos,https://www.reddit.com/r/deeplearning/comments/8a2kfk/extension_of_deep_photo_style_transfer_to_videos/,randomchickibum,1522955404,,6,19,False,https://b.thumbs.redditmedia.com/ADmjT9LZ-v4InmTLARd4PsLyqM4sbo6HYCRXVV0CjPw.jpg,,,,,
36,deeplearning,t5_2t5eh,2018-4-6,2018,4,6,20,8a8krd,mlyearning.org,Prof Andrew Ng is writing a book about managing a ML project - sign up for free updates,https://www.reddit.com/r/deeplearning/comments/8a8krd/prof_andrew_ng_is_writing_a_book_about_managing_a/,ScotchMonk,1523012401,,11,31,False,https://b.thumbs.redditmedia.com/ox4Rx8Tje9A80HyRnePP3qZ5_UvOEepuy1_vToyxrcw.jpg,,,,,
37,deeplearning,t5_2t5eh,2018-4-6,2018,4,6,21,8a97io,self.deeplearning,How to predict labels from sequences?,https://www.reddit.com/r/deeplearning/comments/8a97io/how_to_predict_labels_from_sequences/,M0shka,1523018851,"Hi! I'm new to Deep Learning. I don't know if I'm allowed to ask this here, so I'm sorry if I'm breaking any rule. 

I have a dataset with 3 columns. 
Column 1 - ID number (0 to 2000)
Column 2 - sequence number (14 alphabets long) 
Column 3 - label (either 1 or 0) 

I'd like to predict the label given only the ID number. 

I was hoping someone would guide me on what method I could use. Or if you could link some existing projects or papers on something like this, I would really appreciate it! 

Thanks ",2,9,False,self,,,,,
38,deeplearning,t5_2t5eh,2018-4-6,2018,4,6,23,8a9v4h,self.deeplearning,Generating glove vectors with lstm (seq2seq)?,https://www.reddit.com/r/deeplearning/comments/8a9v4h/generating_glove_vectors_with_lstm_seq2seq/,myfirstproject,1523024312,"Hello!

I am currently involved in a project that aims to generate new word sequences from an word input sequence. Ideally I would like my model to output 50 dimensional vectors which we then assign the closest known 50D Glove vector. However, I haven't encountered anyone trying this approach (instead, most generative text models seem to use one hot encodings or word indices as targets)? Is there something I am missing that makes it difficult to use gloVe vectors as targets? Do you know of any paper that attempts to do this?

Thank you!


",2,3,False,self,,,,,
39,deeplearning,t5_2t5eh,2018-4-7,2018,4,7,0,8aanf4,self.deeplearning,Hiring NLP Deep Learning Position at Wells Fargo,https://www.reddit.com/r/deeplearning/comments/8aanf4/hiring_nlp_deep_learning_position_at_wells_fargo/,nsu0000,1523030111,"Hi,

I'm hiring two data scientists at Wells Fargo (jobs just posted) and I think a lot of people that follow this subreddit would make good candidates, particularly for the senior of the two positions.

I'm in a specialized NLP / Machine Learning group at Wells Fargo where we are looking to build out our capabilities with deep learning methods for text classification and other use cases. We work in Python (Tensorflow/Keras) and PySpark primarily, and tend to make heavy use of word embeddings. Past projects have included things like automatic complaint detection in customer communications using word embeddings and an ensemble of machine learning models, as well as a deep autoencoder to identify anomalous complaints.

If you are interested, you can look at the job descriptions at [WellsFargo.com/careers](https://www.wellsfargo.com/about/careers/) and search for job opening IDs 5398649 (for the senior position) or 5398760 (for a mid-level data scientist position). Both jobs are open for any U.S. location (including remote / work from home).

Ideal candidates would be strong Python/PySpark coders who have an NLP / ML background and big data experience. The best thing to do if you're interested is just to apply. But, if anyone wants to reach out to me directly with questions, LinkedIn is probably the best way. Thanks! [https://www.linkedin.com/in/nathan-susanj-35856824/](https://www.linkedin.com/in/nathan-susanj-35856824/)",0,7,False,self,,,,,
40,deeplearning,t5_2t5eh,2018-4-7,2018,4,7,3,8abtf0,theaigeek.com,AI Weekly 6 April 2018,https://www.reddit.com/r/deeplearning/comments/8abtf0/ai_weekly_6_april_2018/,TomekB,1523038690,,0,2,False,https://b.thumbs.redditmedia.com/wE3GFEdhVZshF7NUXj0axD6m5BdQXDlCgKx7SLrj-so.jpg,,,,,
41,deeplearning,t5_2t5eh,2018-4-8,2018,4,8,5,8akozs,github.com,Convolutional neural network for colorizing and up-scaling B&amp;W flowers images,https://www.reddit.com/r/deeplearning/comments/8akozs/convolutional_neural_network_for_colorizing_and/,Henshmi,1523131769,,0,4,False,default,,,,,
42,deeplearning,t5_2t5eh,2018-4-8,2018,4,8,7,8alj2a,medium.com,LSTM inference shoot-out: Intel Skylake vs NVIDIA V100,https://www.reddit.com/r/deeplearning/comments/8alj2a/lstm_inference_shootout_intel_skylake_vs_nvidia/,dayman56,1523138979,,1,3,False,default,,,,,
43,deeplearning,t5_2t5eh,2018-4-8,2018,4,8,7,8alnso,twitter.com,Intels Naveen Rao Confirms on twitter that Intel will show Nervana NNP benchmarks at AI event in May,https://www.reddit.com/r/deeplearning/comments/8alnso/intels_naveen_rao_confirms_on_twitter_that_intel/,dayman56,1523140190,,1,6,False,default,,,,,
44,deeplearning,t5_2t5eh,2018-4-8,2018,4,8,16,8aohl1,youtube.com,The Evolution of Convolution Neural Networks,https://www.reddit.com/r/deeplearning/comments/8aohl1/the_evolution_of_convolution_neural_networks/,ajhalthor,1523171939,,0,18,False,default,,,,,
45,deeplearning,t5_2t5eh,2018-4-9,2018,4,9,12,8avf8p,github.com,Rapid Prototyping NLP Deep Learning Systems,https://www.reddit.com/r/deeplearning/comments/8avf8p/rapid_prototyping_nlp_deep_learning_systems/,Deepblue129,1523243895,,0,4,False,https://b.thumbs.redditmedia.com/jaozUnYHzshK8vSRexfUsjhPJPdZOPufI1Dn3JptsNM.jpg,,,,,
46,deeplearning,t5_2t5eh,2018-4-9,2018,4,9,13,8avx5n,alibabacloud.com,Alibaba Cloud Announces Cooperation with NVIDIA GPU Cloud (NGC) at The Computing Conference  Shenzhen Summit,https://www.reddit.com/r/deeplearning/comments/8avx5n/alibaba_cloud_announces_cooperation_with_nvidia/,Michael_Pa,1523249212,,0,1,False,default,,,,,
47,deeplearning,t5_2t5eh,2018-4-9,2018,4,9,21,8axyy9,self.deeplearning,How would one go about amplifying features of an image,https://www.reddit.com/r/deeplearning/comments/8axyy9/how_would_one_go_about_amplifying_features_of_an/,pythomad,1523276275,"Hello,I am trying to make a model that is like an auto encoder but instead of a bottleneck it is simply bigger than the sample size so it learns to make the sample bigger in size without padding it so far I have tried Dense layers with mnist but so far I have had no luck does anyone know a paper about this subject ,thanks",1,2,False,self,,,,,
48,deeplearning,t5_2t5eh,2018-4-9,2018,4,9,23,8ayoyg,github.com,"Supporting rapid prototyping for research, I am LAUNCHING PyTorch-NLP, a deep learning NLP toolkit!",https://www.reddit.com/r/deeplearning/comments/8ayoyg/supporting_rapid_prototyping_for_research_i_am/,Deepblue129,1523283014,,4,9,False,https://b.thumbs.redditmedia.com/jaozUnYHzshK8vSRexfUsjhPJPdZOPufI1Dn3JptsNM.jpg,,,,,
49,deeplearning,t5_2t5eh,2018-4-10,2018,4,10,9,8b3kj7,github.com,Simple and Clean Keras Project Template Architecture,https://www.reddit.com/r/deeplearning/comments/8b3kj7/simple_and_clean_keras_project_template/,Ahmed_El_Hinidy,1523321329,,0,12,False,https://b.thumbs.redditmedia.com/0Nld_XkAajwafV_88t2tP-6vN23U4pBWx75Jao4iTkQ.jpg,,,,,
50,deeplearning,t5_2t5eh,2018-4-10,2018,4,10,15,8b5hli,self.deeplearning,Need help with training a GAN on CIFAR-10,https://www.reddit.com/r/deeplearning/comments/8b5hli/need_help_with_training_a_gan_on_cifar10/,akanimax,1523340723,"I have been trying to train a simple dc-gan for the cifar-10 dataset first before learning and experimenting with other gan architectures. But, I have had no luck yet. 
the code is here -&gt; https://github.com/ARANIKC/adversarial-learning

The problem that I am facing is that the discriminator gives up very soon due to which even though the generator outputs noise, the model converges. I have refered to the Radford et. al. paper of dc-gans and incorporated all the suggestions given in it. 

Still, the problem persists.

To all the GAN experts out there, and also those who have sucessfully trained a dc-gan on cifar-10 before, I call out to please help me. 

Thank you!",0,3,False,self,,,,,
51,deeplearning,t5_2t5eh,2018-4-10,2018,4,10,19,8b6oqb,self.deeplearning,Why do a lot of people try to explain some DL concepts on activation functions like tanh() or sigmoid() but not Relu?,https://www.reddit.com/r/deeplearning/comments/8b6oqb/why_do_a_lot_of_people_try_to_explain_some_dl/,flyed1,1523357395,"I read before that the Relu function (or its variants, ex: leaky Relu...etc) became the default activation function for training DL models. And no one is still using sigmoid or tanh.

In one of the deep learning courses of Andrew Ng. He explained the effect of frobenius norm (L2 regularization) on the tanh function, why not Relu although things is different in the Relu function (the shape of the function).

I'm not just talking about the L2 norm but a few other concepts too that i read or learn about. i know maybe it's easier but it is different, the shape of the function and its properties are different. And it's the most used activation function too so it'll be useful to explain the concepts on it.",1,2,False,self,,,,,
52,deeplearning,t5_2t5eh,2018-4-10,2018,4,10,20,8b6rq3,self.deeplearning,Google colab - OOM error,https://www.reddit.com/r/deeplearning/comments/8b6rq3/google_colab_oom_error/,maildivert,1523358426,"Has anyone got their model running on Colab's GPU ?

I know its free but I always get OOM error.",1,2,False,self,,,,,
53,deeplearning,t5_2t5eh,2018-4-10,2018,4,10,23,8b7wra,amid.fish,Lessons Learned Reproducing a Deep Reinforcement Learning Paper,https://www.reddit.com/r/deeplearning/comments/8b7wra/lessons_learned_reproducing_a_deep_reinforcement/,dearpetra,1523370053,,0,11,False,default,,,,,
54,deeplearning,t5_2t5eh,2018-4-11,2018,4,11,2,8b9hlq,github.com,[P] NuDream - Some changes were made in the original Deep Dream's code to get more control or change the outcome.,https://www.reddit.com/r/deeplearning/comments/8b9hlq/p_nudream_some_changes_were_made_in_the_original/,[deleted],1523381251,[deleted],0,1,False,default,,,,,
55,deeplearning,t5_2t5eh,2018-4-11,2018,4,11,4,8bae74,nnwj.de,Backpropagation - Neural Networks with Java,https://www.reddit.com/r/deeplearning/comments/8bae74/backpropagation_neural_networks_with_java/,joey_php,1523387392,,0,0,False,https://b.thumbs.redditmedia.com/q4HK0mkZ19oI8ZmurpVLJqeXwMCVqkshg75fh4sFCno.jpg,,,,,
56,deeplearning,t5_2t5eh,2018-4-11,2018,4,11,15,8bf1d2,code.facebook.com,AV1 beats x264 and libvpx-vp9 in practical use case,https://www.reddit.com/r/deeplearning/comments/8bf1d2/av1_beats_x264_and_libvpxvp9_in_practical_use_case/,semi23,1523428673,,1,1,False,https://b.thumbs.redditmedia.com/V02aLmcLLsV9KGmkOUTv8S7zfsCBhkbFpAv47ZmoAQE.jpg,,,,,
57,deeplearning,t5_2t5eh,2018-4-11,2018,4,11,18,8bfv13,justcoders.net,"Classify images using keras, This is my first trial of blogging about machine learning. Please if you have any feedback, it is highly appreciated.",https://www.reddit.com/r/deeplearning/comments/8bfv13/classify_images_using_keras_this_is_my_first/,AbdallahNasir,1523440429,,0,1,False,https://b.thumbs.redditmedia.com/NDKJd42_Q9vaReenVH08OEH4HUnV5-usYBuR1s_5VLE.jpg,,,,,
58,deeplearning,t5_2t5eh,2018-4-11,2018,4,11,19,8bg2dh,exastax.com,How Airlines are Using Big Data,https://www.reddit.com/r/deeplearning/comments/8bg2dh/how_airlines_are_using_big_data/,y-emre,1523443036,,2,1,False,https://b.thumbs.redditmedia.com/mK4UDFP0-yp8j7BGeLKQfziHjKBUXW6uwyvlwZlQ4pY.jpg,,,,,
59,deeplearning,t5_2t5eh,2018-4-11,2018,4,11,20,8bgcmt,kdnuggets.com,Implementing Deep Learning Methods and Feature Engineering for Text Data: The Skip-gram Model,https://www.reddit.com/r/deeplearning/comments/8bgcmt/implementing_deep_learning_methods_and_feature/,magneticono,1523446397,,0,4,False,default,,,,,
60,deeplearning,t5_2t5eh,2018-4-11,2018,4,11,20,8bgdo5,towardsdatascience.com,My Journey to Reinforcement Learning  Part 1.5: Simple Binary Image Transformation with Q-Learning,https://www.reddit.com/r/deeplearning/comments/8bgdo5/my_journey_to_reinforcement_learning_part_15/,polllyyy,1523446745,,0,11,False,https://b.thumbs.redditmedia.com/d6e8Tb4cEq5X-SfdsNzR4o6VN83xGp4kJGq39x37FWE.jpg,,,,,
61,deeplearning,t5_2t5eh,2018-4-11,2018,4,11,22,8bgx4a,self.deeplearning,What can we explain about the following Convolutional neural network layers in the link below?,https://www.reddit.com/r/deeplearning/comments/8bgx4a/what_can_we_explain_about_the_following/,amnon123,1523452113,"Here is the link for the image of relevant Convolutional neural network:
https://ibb.co/b0Ddbc",1,0,False,self,,,,,
62,deeplearning,t5_2t5eh,2018-4-11,2018,4,11,23,8bh9q1,self.deeplearning,What can we explain about the following Convolutional neural network layers in the link below?,https://www.reddit.com/r/deeplearning/comments/8bh9q1/what_can_we_explain_about_the_following/,amnon123,1523455224,How and what can be learned from the Convolutional neural network in the attached image?,0,0,False,self,,,,,
63,deeplearning,t5_2t5eh,2018-4-11,2018,4,11,23,8bhp08,github.com,Fast Blind Guidance System using Deep Learning,https://www.reddit.com/r/deeplearning/comments/8bhp08/fast_blind_guidance_system_using_deep_learning/,Mrshadow143,1523458615,,2,4,False,https://b.thumbs.redditmedia.com/c3OXb35Wo1PZNn05bG35rMDXwiOJfmAboJIeXfCONtQ.jpg,,,,,
64,deeplearning,t5_2t5eh,2018-4-12,2018,4,12,0,8bhudg,stacksocial.com,AI &amp; Deep Learning Bundle - Explore the Future's Most Exciting New Technologies in 7 e-Books &amp; 10 Hours of Course Content,https://www.reddit.com/r/deeplearning/comments/8bhudg/ai_deep_learning_bundle_explore_the_futures_most/,NVIDIA_CEO,1523459764,,0,0,False,https://a.thumbs.redditmedia.com/wnjpjrgzuWRPt7POe69VN4UkYUIqJoAe2teCELIJRk0.jpg,,,,,
65,deeplearning,t5_2t5eh,2018-4-12,2018,4,12,0,8bi0ot,laknath.com,Is this a toxic comment? - a set of experiments using sequence models and CNNs for a Kaggle competition,https://www.reddit.com/r/deeplearning/comments/8bi0ot/is_this_a_toxic_comment_a_set_of_experiments/,laknath,1523461107,,0,2,False,https://b.thumbs.redditmedia.com/KUZUtVE2dR8yZu6qtYKvZBIxCyj4XP78Wd02FTu9Y3k.jpg,,,,,
66,deeplearning,t5_2t5eh,2018-4-12,2018,4,12,2,8bir9z,self.deeplearning,What can we explain about the following Convolutional neural network layers in the link below?,https://www.reddit.com/r/deeplearning/comments/8bir9z/what_can_we_explain_about_the_following/,amnon123,1523466710,"Here is the link for the image of relevant Convolutional neural network:
https://ibb.co/b0Ddbc
What can we say and deduce about this neural network?  ",1,1,False,self,,,,,
67,deeplearning,t5_2t5eh,2018-4-12,2018,4,12,6,8bkp9d,self.deeplearning,From Industrial Revolution to AI Revolution,https://www.reddit.com/r/deeplearning/comments/8bkp9d/from_industrial_revolution_to_ai_revolution/,aqavi,1523481471,"From Industrial Revolution to AI Revolution #AI #ArtificialIntelligence #DeepLearning #MachineLearning #Industry40  
https://blog.wecognize.com/blog/2018/04/11/industrial-ai-revolution/",0,0,False,self,,,,,
68,deeplearning,t5_2t5eh,2018-4-12,2018,4,12,11,8bmqan,github.com,Image to Text converter OCR,https://www.reddit.com/r/deeplearning/comments/8bmqan/image_to_text_converter_ocr/,Mrshadow143,1523499168,,4,1,False,https://b.thumbs.redditmedia.com/UYoM1urYnYNgYi1b7NLm-MgYAHJOcXwNoAe2b_opgpw.jpg,,,,,
69,deeplearning,t5_2t5eh,2018-4-12,2018,4,12,11,8bmvfv,self.deeplearning,Computer Vision or NLP project ideas,https://www.reddit.com/r/deeplearning/comments/8bmvfv/computer_vision_or_nlp_project_ideas/,errminator,1523500535,"Hi everyone,

I'm looking for a project that could realistically be completed in 1 month (full time). Ideally I'd like to work on something with medical imaging or with NLP.

I'm relatively new to the field but will receive supervision and funding during this project if I can make it exciting/attractive to a potential supervisor, hence why I'm appealing to the community for ideas.

My ideas so far would be cancer detection (but maybe data isn't public and also it's been done before?) or some sort of educational chatbot that can teach and answer calculus questions and is capable of producing LaTeX output. What do you think of these?

As I said I'm really open to any computer vision or NLP suggestions (generative/classification etc). The key point is it should be realistic for someone who's only been learning the field for 6 months or so and should be possible to complete in 1 month full time.

Thanks. I really appreciate your thoughts and input :)",3,3,False,self,,,,,
70,deeplearning,t5_2t5eh,2018-4-12,2018,4,12,19,8bp8ja,self.deeplearning,CFP: CHASE DL-EDGE-IOT Workshop,https://www.reddit.com/r/deeplearning/comments/8bp8ja/cfp_chase_dledgeiot_workshop/,kunalbme,1523530343,"CHASE Workshop 2018
https://sites.google.com/view/chase-dl-edge-iot/home

DL-EDGE-IOT

Deep Learning and Edge Computing in IOT-centered Health Applications

Sep 26-Sep 28, 2018 - Washington, D.C., USA

In conjunction with IEEE/ACM CHASE 2018

Important Dates:
- Workshop Paper Submission: June 8, 2018
- Workshop Paper Acceptance: July 13, 2018
- Workshop Camera-Ready Paper: July 23, 2018
- Submission link:  https://edas.info/newPaper.php?c=24762

Interdisciplinary landscape of connected health research demands researchers from different areas such as deep learning, machine learning, internet of things (IoT), wearable sensing, distributed computing, embedded systems, big data, and medical devices to collaborate for accurate, efficient and reliable systems for a wide array of health applications. Recent advancements in deep learning and model compression of deep models on wearables have created unique opportunities for connected health. The new opportunities also have associated challenges that need to be addressed to achieve the goal of accuracy, efficiency, privacy, reliability and security. 

This workshop aims to bring together the collaboration between research groups in academia and industry. It compasses a wide array of techniques, methods, architectures and solutions in low-resource machine learning, model-compressed deep learning, secure, private and efficient fog computing for practical IoT use cases. The DL-EDGE-IOT workshop invite authors from both academia and industry to submit high quality papers containing original work.

DL-EDGE-IOT workshop includes (but not limited to) the following topics:

- Deep learning and low-resource machine learning for wearable IoT
- Machine learning for IoT signal processing on edge device
- Neural network model compression for wearables
- Information-theoretic signal learning on IoT devices
- Fog, edge and mist computing for DL in connected health
- Edge-based DL for wearable health solutions
- Novel emerging applications of IoT in biomedical signal processing on edge devices
- Fog computing for mobile-based location search; context-aware, information processing
- Scalability, privacy and usability aspects of DL-focused IoT
- Design, development and evaluation of fog architectures for data analysis, visualization and interoperability for connected health
- Big data storage in IoT and Edge Computing for healthcare applications
- Nano-CMOS and Post-CMOS based sensors, circuits, and controller
- Accelerators for IoT Health (e.g., neuromorphic and cognitive computing)
- End-to-End ML-driven privacy preserving and security approaches for IoT Health 
- Braininspired and neuromorphic components, circuits, and systems for Connected Health 
- Case studies of IoT Health (e.g., Predictive analytics and population health management, risk prediction and patient subtyping, behavioral coaching, social network analysis for IoT Health)

KEYNOTE: ""Intelligent ear-level devices for hearing enhancement and health monitoring leveraging edge and cloud computing""

Tao Zhang, PhD, Director of the Signal Processing Research, Starkey Hearing Technologies


",0,1,False,self,,,,,
71,deeplearning,t5_2t5eh,2018-4-12,2018,4,12,21,8bpn8t,kdnuggets.com,Getting Started with PyTorch Part 1: Understanding How Automatic Differentiation Works,https://www.reddit.com/r/deeplearning/comments/8bpn8t/getting_started_with_pytorch_part_1_understanding/,magneticono,1523534965,,1,17,False,default,,,,,
72,deeplearning,t5_2t5eh,2018-4-12,2018,4,12,21,8bpq6d,medium.freecodecamp.org,Building an image caption generator with Deep Learning in Tensorflow,https://www.reddit.com/r/deeplearning/comments/8bpq6d/building_an_image_caption_generator_with_deep/,trumtra,1523535831,,0,1,False,https://b.thumbs.redditmedia.com/F5VCQTuYa-z4G79HxP06wA0WjAktkYtLrVRRLKzuM2I.jpg,,,,,
73,deeplearning,t5_2t5eh,2018-4-13,2018,4,13,16,8bxgcb,spectrum.ieee.org,Facebook AI Director Yann LeCun on His Quest to Unleash Deep Learning and Make Machines Smarter,https://www.reddit.com/r/deeplearning/comments/8bxgcb/facebook_ai_director_yann_lecun_on_his_quest_to/,tahaemara,1523605621,,0,10,False,https://b.thumbs.redditmedia.com/H09C6mJOGgmUY3I-olKNu1l7SXbxAhg14BozROxKuCg.jpg,,,,,
74,deeplearning,t5_2t5eh,2018-4-13,2018,4,13,21,8byns2,towardsdatascience.com,How Attractive Are You in the Eyes of Deep Neural Network?,https://www.reddit.com/r/deeplearning/comments/8byns2/how_attractive_are_you_in_the_eyes_of_deep_neural/,polllyyy,1523621453,,4,7,False,https://b.thumbs.redditmedia.com/F4txrXhjLGNuELqJksHJnMTBvKOGfb-OLpwidKkqxVo.jpg,,,,,
75,deeplearning,t5_2t5eh,2018-4-13,2018,4,13,23,8bzjne,blog.qure.ai,What We Learned Deploying Deep Learning at Scale for Radiology Images,https://www.reddit.com/r/deeplearning/comments/8bzjne/what_we_learned_deploying_deep_learning_at_scale/,rahulBatmanDravid,1523629502,,4,31,False,https://b.thumbs.redditmedia.com/X928_eRB9-DrKrZxiitghs38x8zeklPYiutChTC_gTU.jpg,,,,,
76,deeplearning,t5_2t5eh,2018-4-13,2018,4,13,23,8bzsse,self.deeplearning,How do I assemble a training dataset of images?,https://www.reddit.com/r/deeplearning/comments/8bzsse/how_do_i_assemble_a_training_dataset_of_images/,avtges,1523631561,"I want to build my own dataset with images I download from the internet, to train my ML project in TensorFlow I have searched google, searched stack overflow, looked at other datasets on Kaggle and all over. 

I am just not able (smart enough) to put the pieces together. Does anyone have any experience doing this?

The app compares images to guess whether, for example, it's looking at a dog or a cat. ",0,2,False,self,,,,,
77,deeplearning,t5_2t5eh,2018-4-14,2018,4,14,3,8c1dg9,theaigeek.com,AI Weekly 13 April 2018,https://www.reddit.com/r/deeplearning/comments/8c1dg9/ai_weekly_13_april_2018/,TomekB,1523643665,,0,2,False,default,,,,,
78,deeplearning,t5_2t5eh,2018-4-14,2018,4,14,12,8c552d,self.deeplearning,Good techniques for forecasting revenue over various timeframes,https://www.reddit.com/r/deeplearning/comments/8c552d/good_techniques_for_forecasting_revenue_over/,interstellarhighway,1523678065,"I am working on a problem where the goal is to develop a predictive model for predicting taxi revenue. My data is a subset from a publicly available dataset of taxi details from the city of Chicago. Basically the dataset contains details such as cab ID, start and destination locations, total price of the ride and such. I am looking to write a predictive model that can train on this data, and be able to predict how taxi revenue for a 'typical' taxi (median) would be like in the future: hourly, daily, weekly, etc. (which I will be testing against the data from 2017, training on the data before that). Because the data also contains Taxi ID, my idea is to concatenate the details for each taxi together based on hour/day/week etc., and then use those medians as training data.

I was hoping to get some suggestions as to what would some good techniques to look into for a problem like this. From my research there seem to be a lot of techniques (ARIMA, decision trees, LSTM etc.) aimed at this kind of problems but I am not completely sure if I should consider it as a time series forecasting or a classical regression problem. Would LSTMs be a good choice? And if I want to predict for different timeframes (hour/day/week), do I have to train separately for each?",6,5,False,self,,,,,
79,deeplearning,t5_2t5eh,2018-4-14,2018,4,14,17,8c6d52,self.deeplearning,Get to know what makes it Deep Learning,https://www.reddit.com/r/deeplearning/comments/8c6d52/get_to_know_what_makes_it_deep_learning/,anuj1207,1523695366,,0,0,False,self,,,,,
80,deeplearning,t5_2t5eh,2018-4-15,2018,4,15,14,8cd9g4,analyticsinsight.net,Hot Deep Learning Applications to Watch,https://www.reddit.com/r/deeplearning/comments/8cd9g4/hot_deep_learning_applications_to_watch/,analyticsinsight,1523770255,,0,4,False,https://b.thumbs.redditmedia.com/ccGkqN-N69MYaM2H6cKN-04ifB6morrd1ggkGo0-tJA.jpg,,,,,
81,deeplearning,t5_2t5eh,2018-4-15,2018,4,15,16,8cdr77,self.deeplearning,Using pretrained network,https://www.reddit.com/r/deeplearning/comments/8cdr77/using_pretrained_network/,errminator,1523777858,"What does it mean to do this? For example, I have read about people taking VGG16 or AlexNet and applying them to other CNN image classification problems. My question is how does this work as presumably VGG16 and AlexNet were trained on some particular dataset so how can we suddenly expect them to classify totally new images?

Thank you ",5,1,False,self,,,,,
82,deeplearning,t5_2t5eh,2018-4-15,2018,4,15,23,8cff96,github.com,Deep learning project template using PyTorch,https://www.reddit.com/r/deeplearning/comments/8cff96/deep_learning_project_template_using_pytorch/,vic964404,1523802214,,0,10,False,https://b.thumbs.redditmedia.com/XyDp4IAqVsAOs49LAptXnaI_WSKMKbC1Tgas7sdSc8I.jpg,,,,,
83,deeplearning,t5_2t5eh,2018-4-16,2018,4,16,1,8cgb8v,users.cg.tuwien.ac.at,Gaussian Material Synthesis  ACM Transactions on Graphics (SIGGRAPH 2018),https://www.reddit.com/r/deeplearning/comments/8cgb8v/gaussian_material_synthesis_acm_transactions_on/,keghn,1523810358,,1,7,False,https://b.thumbs.redditmedia.com/b76-bBP5RDnD4KkhAoZVxKv95uXcE-Kyz9coc26DLws.jpg,,,,,
84,deeplearning,t5_2t5eh,2018-4-16,2018,4,16,1,8cgce6,self.deeplearning,Why use convolution on character embeddings before using RNN/CNN?,https://www.reddit.com/r/deeplearning/comments/8cgce6/why_use_convolution_on_character_embeddings/,rinkujadhav2014,1523810632,"Why does everyone use convolution operations on character embeddings before passing them to RNNs (or CNNs if it's Facebook)?
Actually, I'm trying to build a character level model for sentiment analysis and using character embeddings doesn't seem to work at all. Gradients are all 0 except for the output layer and I've verified that it's neither a coding error nor a vanishing gradient problem. I tried to google a character level model for sentiment analysis but all of them seem to use CNN over embeddings before using an RNN",2,4,False,self,,,,,
85,deeplearning,t5_2t5eh,2018-4-16,2018,4,16,17,8cm2bx,self.deeplearning,{CNN}Multi labels classification: Sparse labels,https://www.reddit.com/r/deeplearning/comments/8cm2bx/cnnmulti_labels_classification_sparse_labels/,Moni93,1523867727,"I am working on a model where i need to predict multiple attributes from an image: So, I am in a multi label classification situation. For each image, there are 36 possible labels: still in average, every image has a maximum of 3 labels : which means in my label vector there are three 1 and thirty three 0 in average.   
My question is as follows: does the label being sparse affect badly the CNN ??  I know that the answer is a Yes if the data ( X ) is sparse, but what about Y ( labels) ???",7,5,False,self,,,,,
86,deeplearning,t5_2t5eh,2018-4-16,2018,4,16,20,8cmx0q,hub.packtpub.com,Deep learning methodologies to extend image based application to videos,https://www.reddit.com/r/deeplearning/comments/8cmx0q/deep_learning_methodologies_to_extend_image_based/,chris_shpak,1523879293,,0,1,False,https://b.thumbs.redditmedia.com/4rBKugevFG3BC50Eqt9rwJgCjJieQmbKXikbZtEKzBU.jpg,,,,,
87,deeplearning,t5_2t5eh,2018-4-16,2018,4,16,20,8cmxau,blog.otoro.net,Recurrent Neural Network Tutorial for Artists,https://www.reddit.com/r/deeplearning/comments/8cmxau/recurrent_neural_network_tutorial_for_artists/,joey_php,1523879365,,0,13,False,https://b.thumbs.redditmedia.com/0Mp7NL9q0tG73YikIVhiNOsidmwANJR5LLEzWau_CjY.jpg,,,,,
88,deeplearning,t5_2t5eh,2018-4-16,2018,4,16,20,8cmyus,medium.com,3D generated annotated data,https://www.reddit.com/r/deeplearning/comments/8cmyus/3d_generated_annotated_data/,Bulbali,1523879877,,0,2,False,https://a.thumbs.redditmedia.com/B4pa32N7C9sP7lwOVKnlsekz2PqEYQIaf9E7njklO-8.jpg,,,,,
89,deeplearning,t5_2t5eh,2018-4-16,2018,4,16,23,8cny46,gigadom.wordpress.com,"Deep Learning from first principles in Python, R and Octave  Part 6",https://www.reddit.com/r/deeplearning/comments/8cny46/deep_learning_from_first_principles_in_python_r/,tvganesh,1523889238,,0,1,False,https://b.thumbs.redditmedia.com/cayk-TkaMC73LX-BycvXcR9SbKcZxXAW5pEt02DG96k.jpg,,,,,
90,deeplearning,t5_2t5eh,2018-4-17,2018,4,17,5,8cqsss,self.deeplearning,What is the difference between conditional NNs and multiple independent NNs?,https://www.reddit.com/r/deeplearning/comments/8cqsss/what_is_the_difference_between_conditional_nns/,jackcmlg,1523910904,"Assuming there are two different types of data but in the same format: {X_1, Y_1} and {X_2, Y_2}, with a binary variable t indicating the type, we want to build a model to do some regression/classification tasks: when t=0(or 1), Y_1(or Y_2) can be estimated given X_1(or X_2). In general, there are two choices:

1) We train two separate NNs: Y_1=NN_1(X_1) for t=0 and Y_2=NN_2(X_2) for t=1

2) We train a conditional NNs: Y = NN(X, t) where X=X_1(or X_2), Y=Y_1(or Y_2) when t=0(or 1)

In theory, what is the difference between them?",1,1,False,self,,,,,
91,deeplearning,t5_2t5eh,2018-4-17,2018,4,17,10,8cswoj,business.asiaone.com,AI with minimum data,https://www.reddit.com/r/deeplearning/comments/8cswoj/ai_with_minimum_data/,parthiv9,1523929151,,0,2,False,https://b.thumbs.redditmedia.com/VtrIGellaNLTt3OeYKW0qeZdscYflOfEb9cYIQxRNAw.jpg,,,,,
92,deeplearning,t5_2t5eh,2018-4-17,2018,4,17,21,8cw9t5,self.deeplearning,How to implement general machine learning algorithms?,https://www.reddit.com/r/deeplearning/comments/8cw9t5/how_to_implement_general_machine_learning/,k920049,1523969498," So I'm in the middle of implementing an algorithm based on probabilistic graphical model and the thing is that I have no idea how to implement it with Tensorflow. 

 Tensorflow is one of the most popular framework in deep learning society and many people use it to implement lots of deep learning algorithm. However, when it comes to implementing many algorithms other than deep learning algorithms, I think choosing Tensorflow to do such jobs is a bad idea. 

 The reason why people use Tensorflow is probably because it has many good features, let alone with autograd. But Tensorflow narrows so many options like subscription(indexing), debugger and so on just to provide operator tree for tractable gradient computation. 
 
 Anyway, is there any other options for implementing general m/l algorithms? It seems like a good idea to use cuBLAS for doing it. Matlab is another solution for this problem but I heard that it is almost impossible to write a Matlab code and deploy it online.

",3,2,False,self,,,,,
93,deeplearning,t5_2t5eh,2018-4-17,2018,4,17,22,8cwdf9,exastax.com,Top 7 Big Data Use Cases in Insurance Industry,https://www.reddit.com/r/deeplearning/comments/8cwdf9/top_7_big_data_use_cases_in_insurance_industry/,y-emre,1523970437,,0,0,False,https://a.thumbs.redditmedia.com/zeEpcbvYBnZkYncR1ro8wkW6F_3hF_Oo55bmfRUz1H8.jpg,,,,,
94,deeplearning,t5_2t5eh,2018-4-17,2018,4,17,22,8cwdjy,imimic.bitbucket.io,iMIMIC - Interpretability of Machine Intelligence in Medical Image Computing Workshop,https://www.reddit.com/r/deeplearning/comments/8cwdjy/imimic_interpretability_of_machine_intelligence/,pereirasrm,1523970473,,0,6,False,default,,,,,
95,deeplearning,t5_2t5eh,2018-4-18,2018,4,18,8,8d11en,youtube.com,How do Neural Networks learn?,https://www.reddit.com/r/deeplearning/comments/8d11en/how_do_neural_networks_learn/,ajhalthor,1524007347,,0,0,False,https://b.thumbs.redditmedia.com/zeZPqCZSB3t6GADPEJg7W_bL939hzLdQJ3dtJBQnfOg.jpg,,,,,
96,deeplearning,t5_2t5eh,2018-4-18,2018,4,18,9,8d1o9c,blog.datumbox.com,The Batch Normalization layer of Keras is broken,https://www.reddit.com/r/deeplearning/comments/8d1o9c/the_batch_normalization_layer_of_keras_is_broken/,datumbox,1524012906,,1,10,False,https://b.thumbs.redditmedia.com/ECES8aVgvb8N9mTr9AV2xabNYshwcNzozO0NY5_2CPY.jpg,,,,,
97,deeplearning,t5_2t5eh,2018-4-18,2018,4,18,15,8d3owb,self.deeplearning,Links to the April issue of COMPUTER VISION NEWS,https://www.reddit.com/r/deeplearning/comments/8d3owb/links_to_the_april_issue_of_computer_vision_news/,Gletta,1524034677,"Here is the April 2018 issue of Computer Vision News, published by RSIP Vision: a 34-pages magazine about Computer Vision, Image Processing, Deep Learning and Artificial Intelligence.
Great articles about advanced technologies and their applications.
Free subscription at page 34.
HTML5 version (recommended) ==&gt; http://www.rsipvision.com/ComputerVisionNews-2018April/ and
PDF version ==&gt; http://www.rsipvision.com/computer-vision-news-2018-april-pdf/
Enjoy!",0,0,False,self,,,,,
98,deeplearning,t5_2t5eh,2018-4-18,2018,4,18,19,8d4pnq,blog.riseml.com,Training ImageNet on a TPU in 12.5 hours with GKE and RiseML,https://www.reddit.com/r/deeplearning/comments/8d4pnq/training_imagenet_on_a_tpu_in_125_hours_with_gke/,dearpetra,1524048739,,0,4,False,https://b.thumbs.redditmedia.com/Ubj0x-OgDYMHwW4HGkzmEjwoaLE0J-1oT2LeVHoM2ws.jpg,,,,,
99,deeplearning,t5_2t5eh,2018-4-18,2018,4,18,20,8d4t3e,kdnuggets.com,5 Free Resources for Furthering Your Understanding of Deep Learning,https://www.reddit.com/r/deeplearning/comments/8d4t3e/5_free_resources_for_furthering_your/,magneticono,1524049922,,0,15,False,default,,,,,
100,deeplearning,t5_2t5eh,2018-4-18,2018,4,18,22,8d5m0y,self.deeplearning,multi-label classfication project: how to improve bad performance,https://www.reddit.com/r/deeplearning/comments/8d5m0y/multilabel_classfication_project_how_to_improve/,Moni93,1524058144,"Contextualization:   
I am building a model that identifes three categories in a given image.
There are three categories:

Gender: male/female

Type clotes: Blazers,Blazers&amp;Jacket,Blouses,Cardigan,Coats,Coats&amp;Jackets,Culottes,Dresses,Jeans,Jumper,Jumpsuits&amp;Dungarees,Knitwear&amp;Sweatshirts,Leggings&amp;CigaretteTrousers,Maternity,Polo,Pololong,Shirts,Shorts,Skirts,Suits,Swimwear,Swimwear &amp; Beachwear,T-shirts,T-shirts &amp; Tops,Trousers,Tunics.

Color clothes: beige,black,blue,brown,green,grey,orange,pink,red,white,yellow.
In other words every image should have these 3 categories ( one value per category).

Data
My database for training my model is composed of 1812 images and an excel file containing the values of the three categories for each image ( and its url).
Here are some information about my database:

number of males: 759
number of females: 1055
I also have the number of times each attribute ( from each category) is appearing in my database ( I can't list all of them, but if it's something usefull for interpretation I can send you that information)
most appearing triplet is (Male,Jeans,blue): 66 times
What I have done
It seemed pretty clear that I am in a multi-label classification context.
1. Clean &amp; preprocess my data
I created (X,Y) data where X is is of shape (1814,204,204,3) and Y is of shape (1814,39) '' 39 corresponds to the dummy variable : category 1 has 2 attributes, category 2 has 26 attribute , category 3 has 11 attributes: so total makes 39 ''.
2. Building my neural neural network
the different parameters of my model are :

epochs = 100
lrate = 0.001
decay = lrate/epochs
sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)
loss=binary_crossentropy
optimizer=sgd
metrics=accuracy
The structure of my trained network is as follows:

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 204, 204, 32)      896       
_________________________________________________________________
dropout_3 (Dropout)          (None, 204, 204, 32)      0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 204, 204, 32)      9248      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 102, 102, 32)      0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 332928)            0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               170459648 
_________________________________________________________________
dropout_4 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 39)                20007     
_________________________________________________________________
activation_1 (Activation)    (None, 39)                0         

=================================================================
Total params: 170,489,799
Trainable params: 170,489,799
Non-trainable params: 0
Questions

I don't think my metric ='accuracy' is a good choice: it doesn't reflect the reality of what happens. For example, I executed an evaluation test on my training data and got 0.95 ( 95% of all bins are well classified), but that doesn't mean the model is doing well because in every output: there should be 3 ones out of the 39 components and all the remaining are zeros.. so there is a high probability to have a lot of zeros and thus even in the worse case the 39 values are predicted to be 0 ( nothing is detected) than we have 36/39 accuracy: which doesn't reflect the real issue? ( That's what I got as a result, for a given X, i got many Values near to zeros , so when I use a threshold (0.5) it makes everything equal to zero: I tried to implement a threshold based on statistical approach using mathiew correlation coefficient: but still doesn't add anything usefull) .. So , what do you think is a good metric for a multi-label classification problem with many (39) labels output?
Do you think that the bad performance of my model comes from the fact that I don't have many images? ( images per label ) ?
Do you think my model has bad performance because the structure of Neural network is not good? I tried to used a pretrained model where I fix first layers since state of the art says that these layers are responsible for detecting edges, and I trained only next layers: In that case I have also bad results (calcaluated through the 'accuracy' metric?
To sum up , i Know that maybe there is not a universal solution to my issues, but at least I want to know what may cause these kind of issues and how to remedy them? So any help especially from people who worked on multi-label classifications with many labels at the output, is welcome",5,2,False,self,,,,,
101,deeplearning,t5_2t5eh,2018-4-18,2018,4,18,23,8d63pz,github.com,Microsoft Releases Deep Learning Web Service Deployment on Spark,https://www.reddit.com/r/deeplearning/comments/8d63pz/microsoft_releases_deep_learning_web_service/,mhamilton723,1524062331,,2,13,False,https://b.thumbs.redditmedia.com/yggddBOGKXuZ3dSasR9lG85142ADwJd8zkQuBIu8Orw.jpg,,,,,
102,deeplearning,t5_2t5eh,2018-4-19,2018,4,19,1,8d6sh0,tryolabs.com,"Announcing Luminoth 0.1: new object detection models, checkpoints and more!",https://www.reddit.com/r/deeplearning/comments/8d6sh0/announcing_luminoth_01_new_object_detection/,minmidinosaur,1524067560,,0,1,False,https://b.thumbs.redditmedia.com/id6bSAd535d5pefI86nuD6_H_vmWgGsSuJR8-PFZrUA.jpg,,,,,
103,deeplearning,t5_2t5eh,2018-4-19,2018,4,19,12,8dbtot,self.deeplearning,Question: Why don't we use 2*2 kernel (or other even 4*4) in CNN?,https://www.reddit.com/r/deeplearning/comments/8dbtot/question_why_dont_we_use_22_kernel_or_other_even/,zbwby,1524109703,,4,3,False,self,,,,,
104,deeplearning,t5_2t5eh,2018-4-19,2018,4,19,13,8dc1hs,self.deeplearning,Problems installing CUDA on Ubuntu 16?,https://www.reddit.com/r/deeplearning/comments/8dc1hs/problems_installing_cuda_on_ubuntu_16/,74throwaway,1524112038,"I downloaded the deb version of CUDA from here: https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1604&amp;target_type=deblocal

I then followed steps 3.6 and 7.1 from here: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html

I also noticed that in `additional drivers`, it was at Nvidia 387 by default, and I also saw Nvidia 384. I clicked on Nvidia 384, clicked apply changes, and then clicked back on Nvidia 387 and hit apply changes. I remember when I typed `nvidia-smi`, I got an error message or nothing showed up

After doing all of the above and rebooting, this is what my screen looks like now:

https://imgur.com/a/6pTYN

After I enter my password, it accepts my password and appears to log me in, then the log in page just shows back up again. I see the system menu on the top right, but I cannot launch any programs or see any files/icons on the desktop. This keeps happening even though I've rebooted and tried to re-login over 10 times now

In the GUI environment (Ctrl+Alt+F7), I'm unable to launch a shell session window from the GUI environment

I then accessed the text-based login screen after typing Ctrl+Alt+F1, and typed:

    lspci -v
    apt search nvidia | grep -P ""nvidia-\d+""
    sudo apt install --reinstall nvidia-384

The results I got are here: https://imgur.com/a/5hjCGlb

The top image for when I type `lspci -v`. I saw a ton of stuff being displayed fast, but I couldn't see alot of what was displayed

`apt search nvidia | grep -P ""nvidia-\d+""`

I saw the most recent Nvidia was 387 and 384. I reinstalled 387, rebooted, and I still get the abnormal login screen

I then tried removing CUDA with `sudo apt-get remove cuda` and `sudo apt autoremove`, rebooted, and the screen *still* looks like the ones in the imgur link

What else can I do about this?

**EDIT**: After I just typed Ctrl-Alt-F1, in the terminal there, I just saw some nvidia-graphics file. I changed it so it ends in `.no` instead of `.conf`

I rebooted and now I get the normal desktop!! I can see the files on my desktop and the program icons on the left toolbar

what do I do now to confirm CUDA works?",7,1,False,self,,,,,
105,deeplearning,t5_2t5eh,2018-4-19,2018,4,19,18,8ddha6,self.deeplearning,Architecture to match between documents and search terms,https://www.reddit.com/r/deeplearning/comments/8ddha6/architecture_to_match_between_documents_and/,niujin,1524131469,"I have a lot of search logs like this:

* user searches for term A
* user searches for term B
* user clicks on document C THEREFORE document C is a better match for term B than term A

I have already repurposed TensorFlow NMT (a seq2seq model) to recommend search terms for documents when they are uploaded to the database. So it ""translates"" from a 1000-word long document, to a 10-word long search term. This works very well.

However I would now like to make a model that will map from term + document combinations to a probability or score:

* input: term B + doc C, output 79%
* input: term A + doc C, output 43%

What architecture should I use for this? 

I am thinking of taking TensorFlow CNN for text classification (https://github.com/dennybritz/cnn-text-classification-tf), and modifying it to have 2 inputs.",0,1,False,self,,,,,
106,deeplearning,t5_2t5eh,2018-4-19,2018,4,19,19,8ddlzo,lczero.org,Leela Chess Zero - The public collaborative project chess AI - Better then Alpha Zero,https://www.reddit.com/r/deeplearning/comments/8ddlzo/leela_chess_zero_the_public_collaborative_project/,DrWhatNoName,1524133247,,3,1,False,default,,,,,
107,deeplearning,t5_2t5eh,2018-4-19,2018,4,19,20,8ddy2e,mckinsey.com,Sizing the potential value of AI and advanced analytics,https://www.reddit.com/r/deeplearning/comments/8ddy2e/sizing_the_potential_value_of_ai_and_advanced/,molode,1524137470,,0,4,False,https://b.thumbs.redditmedia.com/popttQ_Z2lawq5sqTLmlCW5FKg6faheoqNRpyHwAroo.jpg,,,,,
108,deeplearning,t5_2t5eh,2018-4-19,2018,4,19,20,8de0nf,vision.mustapp.com,AI based movies recommendations,https://www.reddit.com/r/deeplearning/comments/8de0nf/ai_based_movies_recommendations/,alta1r,1524138302,,2,0,False,default,,,,,
109,deeplearning,t5_2t5eh,2018-4-19,2018,4,19,20,8de2cq,self.deeplearning,Lets build an Open-Source Image Database,https://www.reddit.com/r/deeplearning/comments/8de2cq/lets_build_an_opensource_image_database/,dewayneroyj,1524138844,"What if we could just take a photograph ourselves, of anything, and label it based on the object. Then, upload it to a server. I adamantly believe that the only way for us to build an extensive dataset to train our models on is for us to collectively come together. ",10,18,False,self,,,,,
110,deeplearning,t5_2t5eh,2018-4-19,2018,4,19,23,8df2sh,kdnuggets.com,Derivation of Convolutional Neural Network from Fully Connected Network Step-By-Step,https://www.reddit.com/r/deeplearning/comments/8df2sh/derivation_of_convolutional_neural_network_from/,AhmedGadFCIT,1524148388,,0,1,False,default,,,,,
111,deeplearning,t5_2t5eh,2018-4-20,2018,4,20,5,8dhv83,self.deeplearning,Which parts of the deep learning stack will end up automated and which will matter?,https://www.reddit.com/r/deeplearning/comments/8dhv83/which_parts_of_the_deep_learning_stack_will_end/,gagejustins,1524169734,"In any situation where infrastructure is complicated, there's a chance that something open source (e.g. Docker) or otherwise obviates the need for deep underlying technical knowledge about the systems being used (to an extent). What parts of deep learning are going to get automated?",1,13,False,self,,,,,
112,deeplearning,t5_2t5eh,2018-4-20,2018,4,20,5,8di0xd,self.deeplearning,GPU version of Tensorflow not working in Ubuntu 16,https://www.reddit.com/r/deeplearning/comments/8di0xd/gpu_version_of_tensorflow_not_working_in_ubuntu_16/,74throwaway,1524170955,"    from tensorflow.python.client import device_lib
    print(device_lib.list_local_devices())

returns
 
    The TensorFlow library wasn't compiled to use FMA instructions, but these    are available on your machine and could speed up CPU computations.
    [name: ""/cpu:0""
    device_type: ""CPU""

even though the GPU version seemed to successfully install with `sudo pip3 install tensorflow-gpu` and under `pip3 list`, I see `tensorflow-gpu     1.7.0`
 
I also noticed that under `pip list`, there was `tensorflow`. So I removed it with `pip uninstall tensorflow`

When I try the python commands above, I now get `ModuleNotFoundError: No module named 'tensorflow'`

I even uninstalled the gpu version and re-installed it:

    sudo pip3 uninstall tensorflow-gpu
    sudo pip3 install tensorflow-gpu

but I still get the `No module named 'tensorflow'` error

why is this?

",14,3,False,self,,,,,
113,deeplearning,t5_2t5eh,2018-4-20,2018,4,20,12,8dkm6i,youtube.com,Neural network Learning - Step by Step,https://www.reddit.com/r/deeplearning/comments/8dkm6i/neural_network_learning_step_by_step/,ajhalthor,1524195266,,0,1,False,https://b.thumbs.redditmedia.com/zeZPqCZSB3t6GADPEJg7W_bL939hzLdQJ3dtJBQnfOg.jpg,,,,,
114,deeplearning,t5_2t5eh,2018-4-20,2018,4,20,13,8dl363,medium.com,New Mathematical Optimization Method That Could Revolutionize Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/8dl363/new_mathematical_optimization_method_that_could/,deapest1989,1524200310,,2,0,False,https://b.thumbs.redditmedia.com/JOgYmBq-f2GYKlXNKQ3NvGZRi3gVbFR_kbQf6HcG5TQ.jpg,,,,,
115,deeplearning,t5_2t5eh,2018-4-20,2018,4,20,19,8dmmbk,kdnuggets.com,Deep Learning With Apache Spark: Part 1,https://www.reddit.com/r/deeplearning/comments/8dmmbk/deep_learning_with_apache_spark_part_1/,jackblun,1524220882,,0,6,False,default,,,,,
116,deeplearning,t5_2t5eh,2018-4-20,2018,4,20,19,8dmp3m,aboveintelligent.com,The Circular Relationship Between Mind and Matter,https://www.reddit.com/r/deeplearning/comments/8dmp3m/the_circular_relationship_between_mind_and_matter/,magneticono,1524221896,,0,0,False,https://b.thumbs.redditmedia.com/peS4QaXfNhb3hrQhQ5oLFg6BPkp2DJypYPDgmxzbqxM.jpg,,,,,
117,deeplearning,t5_2t5eh,2018-4-20,2018,4,20,20,8dmv10,towardsdatascience.com,Solving internal co-variate shift in deep learning with linked Neurons with Interactive Code,https://www.reddit.com/r/deeplearning/comments/8dmv10/solving_internal_covariate_shift_in_deep_learning/,polllyyy,1524223829,,0,2,False,https://b.thumbs.redditmedia.com/TvHSwFeyHTieHvloBJqdONhPDvysv-t1qh9X-WGpFEs.jpg,,,,,
118,deeplearning,t5_2t5eh,2018-4-21,2018,4,21,0,8dok2o,self.deeplearning,Suggested Paper to work with RNN Models,https://www.reddit.com/r/deeplearning/comments/8dok2o/suggested_paper_to_work_with_rnn_models/,ragas_,1524238925,"Hi,
I've basic understanding of RNN structure. To practice further I want to implement RNN from research papers. If someone can suggest me research papers to implement RNN architecture from there, it will be of great help. I'm looking for vanilla RNN, Seq2Seq model &amp; Attention model papers. 
Thanks!",0,0,False,self,,,,,
119,deeplearning,t5_2t5eh,2018-4-21,2018,4,21,3,8dpwng,medium.com,Adaptive Meta-heuristically Intelligent Particle - Newly Discovered Optimization Method,https://www.reddit.com/r/deeplearning/comments/8dpwng/adaptive_metaheuristically_intelligent_particle/,deapest1989,1524249363,,2,10,False,https://b.thumbs.redditmedia.com/JOgYmBq-f2GYKlXNKQ3NvGZRi3gVbFR_kbQf6HcG5TQ.jpg,,,,,
120,deeplearning,t5_2t5eh,2018-4-21,2018,4,21,7,8drs0j,self.deeplearning,"I want to make some project related to vehicle detection and tracking. I may be using Vehicle Image Dataset, or Kitti vehicle dataset. Please suggest some worthy idea/ project. I have looked at implementation of track to detect and detect to track paper also.",https://www.reddit.com/r/deeplearning/comments/8drs0j/i_want_to_make_some_project_related_to_vehicle/,Darshb34,1524265152,"
https://arxiv.org/abs/1710.03958",0,2,False,self,,,,,
121,deeplearning,t5_2t5eh,2018-4-21,2018,4,21,8,8dryby,self.deeplearning,Training an unsupervised network with a supervised network,https://www.reddit.com/r/deeplearning/comments/8dryby/training_an_unsupervised_network_with_a/,mount_sumInt,1524266821,"Let's say that you would like to train a neural network to be as nice as possible in textual interactions. What would be the ideal way to train it? To sit there for a few years and reward it based on how nice it's being. Failing that, if you had another neural network that could do that for you, except for a lot less time and a lot quicker, that would also be nice.

You could train a GAN to score a regression network on how nice it's being, then train a regression network to get the best score possible from the GAN.

If you train a GAN to train an unsupervised neural network to do an abstract goal, you can now give unsupervised neural networks abstract goals. Why would you want to do that? Because an unsupervised network can sometimes perform a task better than a human can.

This technique might one day be involved in creating machines that behave more ethically than humans can.

Has this technique ever been employed before? What is it called and what do you think of it?

Thank you for reading and thank you for responding. :)",0,1,False,self,,,,,
122,deeplearning,t5_2t5eh,2018-4-21,2018,4,21,17,8dujfl,self.deeplearning,Improving Naive Bates Sentiment Analysis,https://www.reddit.com/r/deeplearning/comments/8dujfl/improving_naive_bates_sentiment_analysis/,errminator,1524299440,"I have implemented a Naive Bayes classifier trained on wordnet movie reviews to do live sentiment analysis from Twitter. I'm curious how I could improve this further?

Finding a bigger dataset to train on top positive and negative words would probably help - any recommendations for such datasets with labels?

What about the Naive Bayes classifier itself. I read that it's simplicity allows it to scale easily but perhaps at a cost of accuracy. I'm tempted to try using a neural network to get higher accuracy but I guess it might not scale well or there may be a significant lag in my algorithm? Any advice on what I could do here?

Thanks.",1,1,False,self,,,,,
123,deeplearning,t5_2t5eh,2018-4-21,2018,4,21,23,8dw1re,self.deeplearning,Asking for feedback - I'm building a web app to convert models between frameworks,https://www.reddit.com/r/deeplearning/comments/8dw1re/asking_for_feedback_im_building_a_web_app_to/,dar_1978,1524320696,"Hi! Im currently building a web app to convert models between frameworks, especially for mobile applications. I ran into lots of problems when converting from PyTorch to Caffe or to Keras.

Made a prototype and posted it here: https://convertmodel-ai.carrd.co Currently collecting feedback on the most annoying problems, so that I can prioritize accordingly. Would love to hear of any problems you had plus if and how you solved them. Thanks! :)",0,3,False,self,,,,,
124,deeplearning,t5_2t5eh,2018-4-22,2018,4,22,0,8dw9uz,theaijournal.com,"The first article in a series exploring Deep Learning in Computer Vision using PyTorch. In this, we set the goal of getting into the top 1% in a Kaggle Competition (you need to be in top 10% to be an expert).",https://www.reddit.com/r/deeplearning/comments/8dw9uz/the_first_article_in_a_series_exploring_deep/,databiryani,1524322992,,9,38,False,https://b.thumbs.redditmedia.com/wYzXs-YRW6reLC5NyUTuc6Pm3hzENJ5IcxfXtGuRErQ.jpg,,,,,
125,deeplearning,t5_2t5eh,2018-4-22,2018,4,22,3,8dxsb5,theaigeek.com,AI Weekly 21 April 2018,https://www.reddit.com/r/deeplearning/comments/8dxsb5/ai_weekly_21_april_2018/,TomekB,1524337041,,0,1,False,https://a.thumbs.redditmedia.com/wiWj5LjLBXe204MyqEclskW7r_lkZZv8hnWGc3bX6i0.jpg,,,,,
126,deeplearning,t5_2t5eh,2018-4-22,2018,4,22,15,8e1krs,self.deeplearning,Has anyone tried implementing STARGAN here?,https://www.reddit.com/r/deeplearning/comments/8e1krs/has_anyone_tried_implementing_stargan_here/,sksiitb,1524378117,,3,7,False,self,,,,,
127,deeplearning,t5_2t5eh,2018-4-23,2018,4,23,10,8e7y7d,self.deeplearning,Automated Grading Possibility?,https://www.reddit.com/r/deeplearning/comments/8e7y7d/automated_grading_possibility/,errminator,1524448149,"Automated graded has been applied to essays (see Kaggle competition) using LSTMs amongst other things. I was wondering if anybody has tried applying similar techniques to grading mathematical calculations - even simple ones such as 3 figure addition.

If so, is there any datasets out there on this?",2,3,False,self,,,,,
128,deeplearning,t5_2t5eh,2018-4-23,2018,4,23,22,8ebagp,fullstackanalytics.tumblr.com,Areas That Enterprises Should Consider When Developing Deep Learning Platforms,https://www.reddit.com/r/deeplearning/comments/8ebagp/areas_that_enterprises_should_consider_when/,fullstackanalytics1,1524488723,,0,2,False,https://b.thumbs.redditmedia.com/C7CH1_HcDHldHJ9VcQyfpEpT2qPU5bzhwWqfKGe1ptM.jpg,,,,,
129,deeplearning,t5_2t5eh,2018-4-23,2018,4,23,22,8ebevt,blogs.technet.microsoft.com,Deploying Deep Learning Models on Kubernetes with GPUs,https://www.reddit.com/r/deeplearning/comments/8ebevt/deploying_deep_learning_models_on_kubernetes_with/,digitalson,1524489854,,0,6,False,https://b.thumbs.redditmedia.com/t0ftVVQTIszc6UYZHTtn6tfAGPavuGi0Cdadq81ex7s.jpg,,,,,
130,deeplearning,t5_2t5eh,2018-4-24,2018,4,24,4,8ee29d,self.deeplearning,https://stackoverflow.com/questions/49987614/how-does-one-create-a-data-set-in-pytorch-and-save-it-into-a-file-to-later-be-us,https://www.reddit.com/r/deeplearning/comments/8ee29d/httpsstackoverflowcomquestions49987614howdoesonecr/,real_charlie_parker,1524510662,"I want to extract data from cifar10 in a specific order according to some criterion f\(Image,label\) \(for the sake of an example lets say f\(Image,label\) simply computes the sum of all the pixels in Image\). Then it I want to generate 1 file for the train set and 1 file for the test set that I can later load in a dataloader to use for training a neural net.

How do I do this? My current idea was simply to loop through the data with data loader with shuffle off and remember the indices of the images and the score and then sort the indices according to the score and then loop through everything again and create some giant numpy array and save it. After I save it Id use torch.utils.data.TensorDataset\(X\_train, X\_test\) to wrap with TensorDataset and feed to DataLoader.

I think it might work for a small data set like cifar10 at the very least, right?

Another very important thing for me is that I also want to only train on the first K images \(especially since I already sorted them the first K have a special meaning which I want to keep\) so respecting but training only with a fraction will be important.

[https://stackoverflow.com/questions/49987614/how\-does\-one\-create\-a\-data\-set\-in\-pytorch\-and\-save\-it\-into\-a\-file\-to\-later\-be\-us](https://stackoverflow.com/questions/49987614/how-does-one-create-a-data-set-in-pytorch-and-save-it-into-a-file-to-later-be-us)",0,0,False,self,,,,,
131,deeplearning,t5_2t5eh,2018-4-24,2018,4,24,12,8ehbcg,hashtagstatistics.com,How Deep The Deep Learning Is? - Measuring The Depth of Deep Learning,https://www.reddit.com/r/deeplearning/comments/8ehbcg/how_deep_the_deep_learning_is_measuring_the_depth/,LearningFromData,1524538987,,0,0,False,default,,,,,
132,deeplearning,t5_2t5eh,2018-4-24,2018,4,24,16,8eiqz4,v.redd.it,When #DeepLearning learns #basketball ,https://www.reddit.com/r/deeplearning/comments/8eiqz4/when_deeplearning_learns_basketball/,odingah,1524556505,,8,109,False,https://b.thumbs.redditmedia.com/yUaLFXKa35aMOfQXLjfpJSytTdiGC-7WdfbDR6DeOdw.jpg,,,,,
133,deeplearning,t5_2t5eh,2018-4-24,2018,4,24,17,8eiwqy,self.deeplearning,Multi-label classifciation: keras custom metrics,https://www.reddit.com/r/deeplearning/comments/8eiwqy/multilabel_classifciation_keras_custom_metrics/,Moni93,1524558893,"**Contextualization**   
I am working on a multi_label classification problem with images. I am trying to predict 39 labels. In other words, I am trying to identifying which one of the 39 characteristics is present in a given image( many characteristics can be found in one image that's why I am on a multi label classification situation.   

**Data**    

My input data are (X,Y): X is of shape (1814,204,204,3) and Y is of shape (1814,39). So basically X are the set of images and Y are the labels associated to each images which will be used for the supervised learning process.

**Model**  

I am building a Convolutional neural network in order to make predictions. For this task, I am using Keras in order to create my model.

**What I have done**  

In order to validate my model, I need to choose a metric. However, metrics available in Keras are irreverent in my case and won't help me validate my model since I am in multi-label classification situation. That's why I decided to create my custom metric. I created recall and precision metrics applied to columns of Y and Y_predict . In other words, I will calculate recall and precision for each class of the 39 classes. So here is the code of my metrics:

    def recall(y_true, y_pred):
    #Recall metric.

    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)),axis=0)
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)),axis=0)
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

    def precision(y_true, y_pred):
    #Precision metric.

    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)),axis=0)
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)),axis=1)
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

My vector Y is of shape (n,39) that's why I am doing operations over axis=0. In other words, for each label, I am caluclating precision and recall.

Next step, I called these two metrics by precising it to keras fit function. In other words I used this line of code:

model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=[precision,recall])
Code for building, compiling and fitting model:
Here is the code that I use for building the model an training it + its result . ( I am not putting the part of code where I split data into train and validation: Train on 1269 samples, validate on 545 samples)


    def recall(y_true, y_pred):
    # Model: CNN
     model = Sequential()
     model.add(Conv2D(32, (3, 3), input_shape=(204, 204, 3), padding='same', activation='relu', 
     kernel_constraint=maxnorm(3)))
     model.add(Dropout(0.2))
     model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))
     model.add(MaxPooling2D(pool_size=(2, 2)))
     model.add(Flatten())
     model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))
     model.add(Dropout(0.5))
     model.add(Dense(39))
     model.add(Activation('sigmoid'))
     # Compile model
     epochs = 5
     lrate = 0.001
     decay = lrate/epochs
     sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)
     model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=[precision,recall])

    # fitting the model 
     model.fit(X_train, Y_train, epochs=epochs, batch_size=32,validation_data=(X_valid,Y_valid))


**Results**

     Train on 1269 samples, validate on 545 samples
     Epoch 1/5
     96/1269 [=&gt;............................] - ETA: 6:40 - loss: 0.6668 - precision: 0.1031 - recall: 0.2493   

**Issues/Questions**   

**Question 1:** In the log of the results section , there are precision and recall values. I don't know why I got real values instead of vector of values. The way I constructed my two metrics should give me an array of shape (1,39) for precision and (1,39) for recall, which should contain precision and recall for each class, still The output is only a number?  

**Question 2:** these values of precision and recall given by the log, they represent metric calculation for a data of size= batch? How can I calculate the metric over an epoch ( which is more useful as an information than just a calculation over a batch? Some may say, just calculate the average over all batches? Sure , that's what I am thinking of but I don't know how to do it since KERAS is kinda of a black box to me and I don't exactly what is happening ''behind the scenes'' in order to follow/modify the adequate part of code?",0,3,False,self,,,,,
134,deeplearning,t5_2t5eh,2018-4-24,2018,4,24,18,8ej9cx,blackholetec.com,Nvidia's AI Realistically Reconstructs Photos,https://www.reddit.com/r/deeplearning/comments/8ej9cx/nvidias_ai_realistically_reconstructs_photos/,BlackHoleTec,1524563911,,0,2,False,default,,,,,
135,deeplearning,t5_2t5eh,2018-4-24,2018,4,24,19,8ejean,dzone.com,What Is Deep Learning?,https://www.reddit.com/r/deeplearning/comments/8ejean/what_is_deep_learning/,molode,1524565808,,0,1,False,https://b.thumbs.redditmedia.com/QunBSJnRy93VSBuUzdAUA3ACslynF4vB4vVCtVF48QY.jpg,,,,,
136,deeplearning,t5_2t5eh,2018-4-24,2018,4,24,19,8ejia0,kdnuggets.com,Why Deep Learning is perfect for NLP (Natural Language Processing),https://www.reddit.com/r/deeplearning/comments/8ejia0/why_deep_learning_is_perfect_for_nlp_natural/,molode,1524567279,,0,1,False,default,,,,,
137,deeplearning,t5_2t5eh,2018-4-24,2018,4,24,21,8ejzka,exastax.com,How to Win with Predictive Analytics in Retail?,https://www.reddit.com/r/deeplearning/comments/8ejzka/how_to_win_with_predictive_analytics_in_retail/,y-emre,1524572701,,0,1,False,https://a.thumbs.redditmedia.com/xV6RqrtIB9AR1uBZd42uxNJEQ8ZxDwfARNpcNMId2c8.jpg,,,,,
138,deeplearning,t5_2t5eh,2018-4-24,2018,4,24,23,8ekxrp,github.com,"Train and Integrate Tensorflow models, utilizing PySpark ML Pipelines",https://www.reddit.com/r/deeplearning/comments/8ekxrp/train_and_integrate_tensorflow_models_utilizing/,lodev12,1524581119,,0,2,False,https://a.thumbs.redditmedia.com/HDht4HCL15EKtzvxHCKwiRLCYbpWUXeMd4IcfaDC-h4.jpg,,,,,
139,deeplearning,t5_2t5eh,2018-4-25,2018,4,25,0,8el8bm,readmypalm.co.in,"We made a platform to get your palm read accurately by trained artificial intelligence! Give it a go, reviews and feedback are welcome :)",https://www.reddit.com/r/deeplearning/comments/8el8bm/we_made_a_platform_to_get_your_palm_read/,readmypalm,1524583403,,2,0,False,https://b.thumbs.redditmedia.com/WZpKfFS8b1koeEztm_cYQ7xlrD24MLQiDdMDv5OgQuI.jpg,,,,,
140,deeplearning,t5_2t5eh,2018-4-25,2018,4,25,0,8elaon,self.deeplearning,Visual Domain Adaptation Challenge 2018,https://www.reddit.com/r/deeplearning/comments/8elaon/visual_domain_adaptation_challenge_2018/,nkaushik1,1524583914,"Announcing the 2018 Visual Domain Adaptation (VisDA) Challenge!

The VisDA challenge aims to test domain adaptation methods ability to transfer source knowledge and adapt it to novel target domains. The goal is to develop a method of unsupervised adaptation for synthetic-to-real visual domain shifts.
The competition will take place during the months of May - August 2018, and the top performing teams will be invited to present their results at the TASK-CV workshop at ECCV 2018 in Munich, Germany. This years challenge includes two tracks:

1) open-set image classification
2) object detection

We invite participants to enter in one or both tracks. Registration open now.

http://ai.bu.edu/visda-2018/",0,2,False,self,,,,,
141,deeplearning,t5_2t5eh,2018-4-25,2018,4,25,0,8elegv,ai.bu.edu,Visual Domain Adaptation Challenge 2018,https://www.reddit.com/r/deeplearning/comments/8elegv/visual_domain_adaptation_challenge_2018/,nkaushik1,1524584709,,0,3,False,https://b.thumbs.redditmedia.com/5qpqq4yqARVbGmlvTwu7JPSslmuIi0ZELi-w8mJifpg.jpg,,,,,
142,deeplearning,t5_2t5eh,2018-4-25,2018,4,25,13,8eqrf5,self.deeplearning,How do i create simple neural network in tensorflow?,https://www.reddit.com/r/deeplearning/comments/8eqrf5/how_do_i_create_simple_neural_network_in/,SusmithHCK,1524629221,"i have this dataset:

|A|B|label|
|:-|:-|:-|
|1|6|1|
|10|11|0|
|20|54|0|
|32|33|0|
|44|49|1|
|10|5|1|

as you can see there is a pattern, If the difference between A and B is 5 it should return 1. Actually there is no need of NN here but i just want to learn the basics and working of tensorflow.

can someone help me write code for this nn ?

Every other tutorials seems to be advanced. Even though i have worked with other tensorflow project i couldn't understand it completely.",6,0,False,self,,,,,
143,deeplearning,t5_2t5eh,2018-4-25,2018,4,25,15,8erfb4,youtube.com,What Is Deep Learning - Very Well Explained Video,https://www.reddit.com/r/deeplearning/comments/8erfb4/what_is_deep_learning_very_well_explained_video/,pooja307,1524637046,,1,4,False,https://b.thumbs.redditmedia.com/Olu6-oKPypDwfyC4kppwYgQsblao_vXuIg7QrZUZZZc.jpg,,,,,
144,deeplearning,t5_2t5eh,2018-4-25,2018,4,25,16,8ers3t,hashtagstatistics.com,What Makes Naive Bayes Classification So Naive? | How Does Naive Bayes Classifier Work,https://www.reddit.com/r/deeplearning/comments/8ers3t/what_makes_naive_bayes_classification_so_naive/,LearningFromData,1524641747,,0,2,False,default,,,,,
145,deeplearning,t5_2t5eh,2018-4-25,2018,4,25,19,8esksa,kdnuggets.com,Top 16 Open Source Deep Learning Libraries and Platforms,https://www.reddit.com/r/deeplearning/comments/8esksa/top_16_open_source_deep_learning_libraries_and/,polllyyy,1524652984,,0,3,False,default,,,,,
146,deeplearning,t5_2t5eh,2018-4-25,2018,4,25,19,8esmrs,blogs.technet.microsoft.com,Deep Learning for Emojis with VS Code Tools for AI,https://www.reddit.com/r/deeplearning/comments/8esmrs/deep_learning_for_emojis_with_vs_code_tools_for_ai/,molode,1524653697,,0,8,False,default,,,,,
147,deeplearning,t5_2t5eh,2018-4-25,2018,4,25,23,8eu5n0,self.deeplearning,Looking for a good tutorial explaining coding aspect of lstm in detail with example.,https://www.reddit.com/r/deeplearning/comments/8eu5n0/looking_for_a_good_tutorial_explaining_coding/,sachinky20,1524667998,,1,3,False,self,,,,,
148,deeplearning,t5_2t5eh,2018-4-26,2018,4,26,1,8euyf8,self.deeplearning,n-grams in deep learning,https://www.reddit.com/r/deeplearning/comments/8euyf8/ngrams_in_deep_learning/,rotronic,1524674056,"I am trying to use n-grams in deep learning but unable to figure out how to give an input to the network. I have checked out the sklearn count vectorizer which outputs n-grams but then how can I use these n-grams as input to a MLP in keras?
The output of count vectorizer is a sparse vector which when converted to dense does not make sense to me.

I have also tried nltk which gives the output as a list of tuples of n-grams but how do I convert this into an input that the MLP will understand?

More information if it helps: I am doing sentiment analysis on the imdb dataset using keras.",4,1,False,self,,,,,
149,deeplearning,t5_2t5eh,2018-4-26,2018,4,26,2,8evh5g,self.deeplearning,I have a dream,https://www.reddit.com/r/deeplearning/comments/8evh5g/i_have_a_dream/,[deleted],1524677988,[deleted],0,1,False,default,,,,,
150,deeplearning,t5_2t5eh,2018-4-26,2018,4,26,2,8evm52,self.deeplearning,Newbie needs some advice,https://www.reddit.com/r/deeplearning/comments/8evm52/newbie_needs_some_advice/,professorhojoz,1524679031,"Hey guys!

I'm an entrepreneur with a dream of using Deep Learning to automatically create better websites for businesses. We have a traditional website builder platform right now, and I want to make it more useful by incorporating DL into it, but at this stage, I'm not sure even the right questions to ask to get me started.

I guess I'm looking for a legit way to incorporate Deep Learning in a way that'll actually handle much of the work for the customer and come up with something that's as good or better than what they'd do on their own if they put in the time or if they hired someone.

What do you recommend I read/study/learn right away for the problem I'm trying to solve?

Long term - I'm looking for someone with a knowledge of all this stuff who's interested in this challenge that I can partner with.",0,0,False,self,,,,,
151,deeplearning,t5_2t5eh,2018-4-26,2018,4,26,4,8ewgt6,youtube.com,Deep Learning Tutorial Video With TensorFlow - Loved the part especially from 21 mins when he explains how neural network works with animation!,https://www.reddit.com/r/deeplearning/comments/8ewgt6/deep_learning_tutorial_video_with_tensorflow/,pooja307,1524685484,,0,8,False,https://a.thumbs.redditmedia.com/pQ2wD4VATyG_GE5IBQhrnOeym-t6DXSXIjhJQJENwD0.jpg,,,,,
152,deeplearning,t5_2t5eh,2018-4-26,2018,4,26,7,8exk2j,self.deeplearning,Using RNN (LSTM) for Gesture Recognition System,https://www.reddit.com/r/deeplearning/comments/8exk2j/using_rnn_lstm_for_gesture_recognition_system/,Anasovich,1524693968,"https://datascience.stackexchange.com/q/30829/51143

any help would be appreciated.",2,5,False,self,,,,,
153,deeplearning,t5_2t5eh,2018-4-26,2018,4,26,11,8ezeq7,self.deeplearning,What would be a good curriculum to learn optimization for Deep Learning?,https://www.reddit.com/r/deeplearning/comments/8ezeq7/what_would_be_a_good_curriculum_to_learn/,QinLu,1524710810,"I have started to learn more about optimization for Deep Learning. The obvious starting point is http://www.deeplearningbook.org/contents/optimization.html.  Yet, It would be great to have learning material that expands the content introduced in the book,  or introduces more recent development.",0,5,False,self,,,,,
154,deeplearning,t5_2t5eh,2018-4-26,2018,4,26,12,8ezjvl,hanxiao.github.io,[R] Teach Machine to Comprehend Text and Answer Question with Tensorflow - Part I,https://www.reddit.com/r/deeplearning/comments/8ezjvl/r_teach_machine_to_comprehend_text_and_answer/,h_xiao,1524712216,,1,13,False,https://a.thumbs.redditmedia.com/TuGI27DlqYKKpj0dEkBx3p2I5OOgGOdemkG4_5MKfJ8.jpg,,,,,
155,deeplearning,t5_2t5eh,2018-4-26,2018,4,26,20,8f1sm9,self.deeplearning,Detecting small features in large images. Is cutting the original image into small tiles and running CNN on each tile a good solution?,https://www.reddit.com/r/deeplearning/comments/8f1sm9/detecting_small_features_in_large_images_is/,eobermuhlner,1524740865,"I want to detect small features \(50 \- 200 pixels\) in pretty large images \(6720x4480 pixels\).

I am afraid that I lose the feature when I downscale too much.

Currently I am considering of cutting the original image into many small tiles \(for example 128x128 or 256x256\) and use a CNN on each of the smaller tiles to categorize into \[background, feature1, fature2, ...\]. Downscaling by a small factor \(for example 2\-4\) is still an option.

Is this a feasible approach or is there some different approach?",4,3,False,self,,,,,
156,deeplearning,t5_2t5eh,2018-4-26,2018,4,26,21,8f29ab,headctstudy.qure.ai,"Deep Learning for Head CT scans: 9 Emergency Findings, Validation on ~22k scans, &gt;0.9 AUCs, Publicly Available Dataset",https://www.reddit.com/r/deeplearning/comments/8f29ab/deep_learning_for_head_ct_scans_9_emergency/,saucysassy,1524745832,,1,8,False,https://b.thumbs.redditmedia.com/a-jJLTN7bwN0jNNLbNA_FAhGMj_UCEFg7Mxg-WuWGJg.jpg,,,,,
157,deeplearning,t5_2t5eh,2018-4-27,2018,4,27,1,8f47j3,self.deeplearning,What's the best DL framework for text?,https://www.reddit.com/r/deeplearning/comments/8f47j3/whats_the_best_dl_framework_for_text/,professorhojoz,1524761742,"Hey DL!

We are starting a test project and want to train a Deep Learning framework with a couple thousand high-quality pieces of text (advertising headlines) to examine patterns and eventually write its own high-quality headlines.

I'm not sure which framework to use -- I see SageMaker works with a bunch of them, including TensorFlow, Pytorch, etc..  

In your experience what's the best DL framework for analyzing and producing text?

thank you!",0,0,False,self,,,,,
158,deeplearning,t5_2t5eh,2018-4-27,2018,4,27,4,8f5gcg,self.deeplearning,Possible to expect net loss of &lt;$300 for building deep learning machine?,https://www.reddit.com/r/deeplearning/comments/8f5gcg/possible_to_expect_net_loss_of_300_for_building/,74throwaway,1524771162,"I am considering building my own machine for deep learning. I am interested in using this to work on hobby and personal projects \(I already have a full\-time job\) related to computer vision and deep learning. I am about to receive a Raspberry Pi, so I was thinking of using them together

I saw some webpages showing how to build a Deep Learning machine for around $800:

[https://www.oreilly.com/learning/build\-a\-super\-fast\-deep\-learning\-machine\-for\-under\-1000](https://www.oreilly.com/learning/build-a-super-fast-deep-learning-machine-for-under-1000)

[https://towardsdatascience.com/build\-a\-deep\-learning\-rig\-for\-800\-4434e21a424f](https://towardsdatascience.com/build-a-deep-learning-rig-for-800-4434e21a424f)

These were both written last year. For the latter one, I checked the prices of the parts that sold on Ebay, and found that the used working ones were able to sell for as low as:

|Component|Price paid by guy in towardsdatascience link|Lowest prices for used component on eBay|
|:-|:-|:-|
|[GeForce GTX 1060](https://www.amazon.com/gp/product/B01LW14DG7/ref=oh_aui_detailpage_o00_s00?ie=UTF8&amp;th=1) 6GB|218|$150\-158|
|240 GB Sandisk SSD|70, 50| $45\-60, $20\-30|
|CPU Intel Core i3\-6100|110|$70\-80|
|Case|40|Didn't check|
|Power Supply EVGA 750W 80\+|89|$50\-70|
|RAM 2x [8GB of Corsair Vengeanc](https://www.amazon.com/gp/product/B01HKF450S/ref=oh_aui_search_detailpage?ie=UTF8&amp;psc=1)e|100|$74\-110|
|Motherboard MSI Z170A Krait Gaming 3x|\~$108?|$56\-76|
|Total|785|\~$470\-586 \(excluding Case\)|

Now because I'm on a rather low budget, I would be hesitant to pay around $500\-600 for this, considering that I would probably only get to use this as a hobby for at most 30 hours/week, since I have a full\-time job and other things to worry about. Moreover, it is possible I could only use this for at most 6\-12 months because I could quit the job and travel, or other unforseen possibilities. However, I would be much more willing to spend this money if I knew I could eventually re\-sell them and get half the money back. 

Would it be reasonable to expect to use these for around 6\-12 months, and then re\-sell them on ebay/Craigslist/whatever and get around $250\-300 back? Or could I get away with being newer, more expensive components than in the table above, and still expect to have a net loss of at most $300?",3,2,False,self,,,,,
159,deeplearning,t5_2t5eh,2018-4-27,2018,4,27,6,8f6f5u,self.deeplearning,Data consisting of variable number of 2 dimensional points?,https://www.reddit.com/r/deeplearning/comments/8f6f5u/data_consisting_of_variable_number_of_2/,aulisaulisaulis,1524778844,"I'm sort of a beginner to DL, but I'm working on a small project in keras where each sample has a variable amount of dimensions \(think bar graph data, or experimental spectra\). Each of my samples basically consists of a set of \(x,y\) pairs. However, I'm not really sure how to convert my raw data into data that I could use in a neural net.

One naive idea I had was just to pad the data for every single point that shows up \(and have their y values at 0\), but that seems like it wouldn't work very well, since the data would become extremely high dimensional \(and sparse\). 

Does anybody have any ideas of how I could best represent the data?",0,1,False,self,,,,,
160,deeplearning,t5_2t5eh,2018-4-27,2018,4,27,12,8f8n2r,blog.ntrlab.com,Why Do Neural Networks Need An Activation Function? (by Computer Vision Specialist),https://www.reddit.com/r/deeplearning/comments/8f8n2r/why_do_neural_networks_need_an_activation/,Batareika_1,1524799716,,2,7,False,https://b.thumbs.redditmedia.com/49w-DBDJ-brV248WctzFJXBzakXNbm42hs7Sy-J5AKg.jpg,,,,,
161,deeplearning,t5_2t5eh,2018-4-27,2018,4,27,14,8f9df3,self.deeplearning,Why cnn are much deeper than fully connected ?,https://www.reddit.com/r/deeplearning/comments/8f9df3/why_cnn_are_much_deeper_than_fully_connected/,bushaev,1524808037,"Practice shows that convolutions neural networks work better as they get deeper, the same cant be said about fully connected networks, where 3-layer network can be as good as 7-layer network, why is that ?",4,4,False,self,,,,,
162,deeplearning,t5_2t5eh,2018-4-27,2018,4,27,17,8fa0is,blog.riseml.com,Comparing Googles TPUv2 against Nvidias V100 on ResNet-50,https://www.reddit.com/r/deeplearning/comments/8fa0is/comparing_googles_tpuv2_against_nvidias_v100_on/,digitalson,1524816590,,1,19,False,https://b.thumbs.redditmedia.com/6ZOZVz7d_yBnctnp7N_0JHiw4NNy9PgUdYZb_ieWcIE.jpg,,,,,
163,deeplearning,t5_2t5eh,2018-4-27,2018,4,27,17,8fa1gx,medium.com,Hyperparameters tuning with Polyaxon  Polyaxon,https://www.reddit.com/r/deeplearning/comments/8fa1gx/hyperparameters_tuning_with_polyaxon_polyaxon/,trumtra,1524816971,,0,1,False,https://a.thumbs.redditmedia.com/pAqkv0IJZEHBpcM1zjWbt9C3_ej6PFs0O9nHhmV26I8.jpg,,,,,
164,deeplearning,t5_2t5eh,2018-4-27,2018,4,27,17,8fa672,kdnuggets.com,Implementing Deep Learning Methods and Feature Engineering for Text Data: The GloVe Model,https://www.reddit.com/r/deeplearning/comments/8fa672/implementing_deep_learning_methods_and_feature/,jackblun,1524818995,,0,4,False,https://b.thumbs.redditmedia.com/ZcjdGZSv6b_ILUjD2fIAlKVEpmFItJmFr8HC6eSlfRo.jpg,,,,,
165,deeplearning,t5_2t5eh,2018-4-28,2018,4,28,2,8fdhqt,self.deeplearning,iMac with eGPU ???,https://www.reddit.com/r/deeplearning/comments/8fdhqt/imac_with_egpu/,2141rika,1524850471,Is it possible to connect iMac desktop with eGPU (Titan or GTX 1080 Ti) for deep learning research??,3,3,False,self,,,,,
166,deeplearning,t5_2t5eh,2018-4-28,2018,4,28,4,8fe9z4,theaigeek.com,AI Weekly 27 April 2018,https://www.reddit.com/r/deeplearning/comments/8fe9z4/ai_weekly_27_april_2018/,TomekB,1524856722,,0,2,False,default,,,,,
167,deeplearning,t5_2t5eh,2018-4-28,2018,4,28,15,8fi5du,github.com,mozilla/DeepSpeech - A TensorFlow implementation of Baidu's DeepSpeech architecture.,https://www.reddit.com/r/deeplearning/comments/8fi5du/mozilladeepspeech_a_tensorflow_implementation_of/,stephentt-me,1524896437,,0,14,False,https://b.thumbs.redditmedia.com/E9dZLeWFeDF7TtvlBdMqto0SG8AwZ9wPD5ZCvigiUWY.jpg,,,,,
168,deeplearning,t5_2t5eh,2018-4-28,2018,4,28,18,8fiy9j,medium.com,A step by-step guide for tensorflow gpu installation on ubuntu 18.04,https://www.reddit.com/r/deeplearning/comments/8fiy9j/a_step_bystep_guide_for_tensorflow_gpu/,kekayan,1524909210,,2,15,False,https://b.thumbs.redditmedia.com/kZthqpHBPrlEYbk-OjrbkspcF04gNJs8kUxOGErfauA.jpg,,,,,
169,deeplearning,t5_2t5eh,2018-4-28,2018,4,28,22,8fjwny,self.deeplearning,"Do you think RNN (including LSTM, attention model) can really do time-series prediction?",https://www.reddit.com/r/deeplearning/comments/8fjwny/do_you_think_rnn_including_lstm_attention_model/,helmetti,1524922431,"I'm disappointed a bit about RNN. I've never seen ""real"" time-series prediction. Even in Kaggle, I only can see boring ""one step aheaded"" Bitcoin price prediction. Especially it seems miserable on multi valiate prediction. How do you think?",5,5,False,self,,,,,
170,deeplearning,t5_2t5eh,2018-4-29,2018,4,29,0,8fkkfz,self.deeplearning,"[Question] If the training data is licensed one (e.g. images), the trained model's licence belong to whom? Me? Who has the licence of training data? Or Machine?",https://www.reddit.com/r/deeplearning/comments/8fkkfz/question_if_the_training_data_is_licensed_one_eg/,helmetti,1524929167,Many people scraping training data from websites which has copyright. Is it legal?,5,6,False,self,,,,,
171,deeplearning,t5_2t5eh,2018-4-29,2018,4,29,1,8fkywy,youtube.com,Ohad Shamir (Weizman Institute) -- Is depth needed for Deep Learning?,https://www.reddit.com/r/deeplearning/comments/8fkywy/ohad_shamir_weizman_institute_is_depth_needed_for/,DrJohanson,1524932977,,0,8,False,https://b.thumbs.redditmedia.com/Jw4_d4uXPcO4qt9pKhZJCIKM2DJ_M69kJP3eu6oAiPs.jpg,,,,,
172,deeplearning,t5_2t5eh,2018-4-29,2018,4,29,14,8fpfzs,self.deeplearning,Can a recurrent neural network perform the same functions as a Kalman filter?,https://www.reddit.com/r/deeplearning/comments/8fpfzs/can_a_recurrent_neural_network_perform_the_same/,interstellarhighway,1524979543,"I've read that RNNs are particularly well suited for time series predictions, especially equipped with LSTM units that can learn from past data and estimate dependence between instants. 

This makes me wonder: can RNNs perform estimation like conventional Kalman filters do? For example, in the case of an IMU, typically Kalman filters predict the orientations given raw data from the individual sensors. Would the RNN be able to learn the mapping between raw IMU data and filtered orientations, and predict for future timesteps? If so, it brings me to my second question: would they also be able to 'learn' the parameters that model the IMU: such as bias, noise etc.?",2,14,False,self,,,,,
173,deeplearning,t5_2t5eh,2018-4-29,2018,4,29,17,8fq47g,hashtagstatistics.com,Factor Analysis And Its Applications | Understanding Factor Analysis,https://www.reddit.com/r/deeplearning/comments/8fq47g/factor_analysis_and_its_applications/,LearningFromData,1524989979,,0,1,False,default,,,,,
174,deeplearning,t5_2t5eh,2018-4-29,2018,4,29,19,8fqmjk,self.deeplearning,"Using deep learning to detect relationships between patterns (number of occurrences, order, etc)",https://www.reddit.com/r/deeplearning/comments/8fqmjk/using_deep_learning_to_detect_relationships/,wa3dbk,1524998688,"Deep learning models such as CNNs try to find a number a simple patterns (edges,lines, etc) from which it can infer more complex shapes like a car or a face and each layer represents a higher level of abstraction leading to the final prediction.

My problem is being able to find relationships between patters like repetition and order without paying much attention to the patterns presented to the network. I've been reading Hinton's paper on capsule networks I don't think that's the right way of going about this. Any suggestions about the kind of system/architecture to be used for this kind of problems is welcome.",1,1,False,self,,,,,
175,deeplearning,t5_2t5eh,2018-4-29,2018,4,29,22,8fr7ed,gigadom.wordpress.com,"Deep Learning from first principles in Python, R and Octave  Part 7",https://www.reddit.com/r/deeplearning/comments/8fr7ed/deep_learning_from_first_principles_in_python_r/,tvganesh,1525006950,,0,1,False,https://b.thumbs.redditmedia.com/QTtmHr3aVWWlu4SIMwh3LGjq3WxTD9d0oScKN5LLEas.jpg,,,,,
176,deeplearning,t5_2t5eh,2018-4-29,2018,4,29,23,8frjn6,github.com,Terraform + AWS: Fully Automated Provisioning of AWS Spot Instances for GPU-based Deep Learning Workloads,https://www.reddit.com/r/deeplearning/comments/8frjn6/terraform_aws_fully_automated_provisioning_of_aws/,brownmamba94,1525011000,,3,12,False,https://b.thumbs.redditmedia.com/V2IHBUnd9hCnfhzaUu7i5XbJTenvl0uxaWp_NsI93uA.jpg,,,,,
177,deeplearning,t5_2t5eh,2018-4-30,2018,4,30,9,8fvo1z,self.deeplearning,Looking for books and white papers on deep learning and CNNs (pdf),https://www.reddit.com/r/deeplearning/comments/8fvo1z/looking_for_books_and_white_papers_on_deep/,RikiMaro18,1525048765,"Hello, I'm new to deep learning and I'm trying to learn deep learning and CNNs but I have trouble finding good free books/whitepapers with detailed explanations on google. ",7,7,False,self,,,,,
178,deeplearning,t5_2t5eh,2018-4-30,2018,4,30,15,8fxefh,self.deeplearning,Is there any AI chat app based on deep learning?,https://www.reddit.com/r/deeplearning/comments/8fxefh/is_there_any_ai_chat_app_based_on_deep_learning/,everytalker,1525068482,"I want to talk to AI machine.
But I hope the machine have AI based on deep learning.
Do you know it?",2,0,False,self,,,,,
179,deeplearning,t5_2t5eh,2018-4-30,2018,4,30,18,8fyamg,self.deeplearning,Feedback on a neural net API for my written-from-scratch tensor library (x-post /r/neuralnetworks),https://www.reddit.com/r/deeplearning/comments/8fyamg/feedback_on_a_neural_net_api_for_my/,Karyo_Ten,1525081749,"Hey, I've been working for a bit more than a year on my own tensor library from scratch (first commit on April 13, 2017).

What started as a hobby and curiosity project to learn more about linear algebra, machine learning, deep learning and a young programming language called Nim became a huge evening time sink.

After implementing Numpy-like ndarrays, Torch/Tensorflow like primitives, I just finalised the first part of my high-level API which hopefully takes the best from Keras and PyTorch.

Id like your feedback on that. Quick note on Nim, it is a strongly typed language, hence why you see f32/float32 from time to time.

For example, declaring a two-layers NN currently is like this:

    # ##################################################################
    # Environment variables
    
    # N is batch size; D_in is input dimension;
    # H is hidden dimension; D_out is output dimension.
    let (N, D_in, H, D_out) = (64, 1000, 100, 10)
    
    # Create the autograd context that will hold the computational graph
    let ctx = newContext Tensor[float32]
    
    # Create random Tensors to hold inputs and outputs, and wrap them in Variables.
    let
      x = ctx.variable(randomTensor[float32](N, D_in, 1'f32))
      y = randomTensor[float32](N, D_out, 1'f32)
    
    # ##################################################################
    # Define the model.
    
    network ctx, TwoLayersNet:
      layers:
        fc1: Linear(D_in, H)
        fc2: Linear(H, D_out)
      forward x:
        x.fc1.relu.fc2
    
    let
      model = ctx.init(TwoLayersNet)
      optim = model.optimizerSGD(learning_rate = 1e-4'f32)
    
    # ##################################################################
    # Training
    
    for t in 0 ..&lt; 500:
      let
        y_pred = model.forward(x)
        loss = mse_loss(y_pred, y)
    
      echo &amp;""Epoch {t}: loss {loss.value[0]}""
    
      loss.backprop()
      optim.update()
This is a port of Jcjohnson PyTorch example: https://github.com/jcjohnson/pytorch-examples#pytorch-autograd.

3 examples are available directly in my repo: https://github.com/mratsim/Arraymancer/tree/master/examples.

A MNIST simple convnet with 2 conv layers, 1 hidden layer and automatic shape inference would be like this:

    randomize(42) # Random seed for reproducibility
    
    let
      ctx = newContext Tensor[float32] # Autograd/neural network graph
      n = 32                           # Batch size
    
    let
      x_train = read_mnist_images(""build/train-images.idx3-ubyte"").astype(float32) / 255'f32
      X_train = ctx.variable x_train.unsqueeze(1) # Change shape from [N, H, W] to [N, C, H, W], with C = 1
    
      y_train = read_mnist_labels(""build/train-labels.idx1-ubyte"").astype(int)
    
      x_test = read_mnist_images(""build/t10k-images.idx3-ubyte"").astype(float32) / 255'f32
      X_test = ctx.variable x_test.unsqueeze(1) Change shape from [N, H, W] to [N, C, H, W], with C = 1
      y_test = read_mnist_labels(""build/t10k-labels.idx1-ubyte"").astype(int)
    
    network ctx, DemoNet:
      layers:
        x:          Input([1, 28, 28])
        cv1:        Conv2D(x.out_shape, 20, 5, 5)
        mp1:        MaxPool2D(cv1.out_shape, (2,2), (0,0), (2,2))
        cv2:        Conv2D(mp1.out_shape, 50, 5, 5)
        mp2:        MaxPool2D(cv2.out_shape, (2,2), (0,0), (2,2))
        hidden:     Linear(mp2.out_shape.flatten, 500)
        classifier: Linear(500, 10)
      forward x:
        x.cv1.relu.mp1.cv2.relu.mp2.flatten.hidden.relu.classifier
    
    let model = ctx.init(DemoNet)
    let optim = model.optimizerSGD(learning_rate = 0.01'f32)
    
    . &lt; Training loop &gt; 
    
So what I would like to know is:

   - What are your main grips with the current neural networks library?
   - If you could do it yourself what syntax would you prefer to use for which use cases?
   - What do you think of my network declaration section?
",0,11,False,self,,,,,
180,deeplearning,t5_2t5eh,2018-4-30,2018,4,30,18,8fyax1,self.deeplearning,How do I tackle problems where the size of the input and output layer can change?,https://www.reddit.com/r/deeplearning/comments/8fyax1/how_do_i_tackle_problems_where_the_size_of_the/,jtfidje,1525081861,"Hi all. I'm trying to do some research related to a project I'm current working on, but I'm struggling to find any related research.

&amp;nbsp;

In my problem the mapping from input to output can be either of the following:

- One-to-one
- One-to-many
- Many-to-one
- Many-to-many

&amp;nbsp;

In practice it means my input is a matrix which can have an arbitrary number of rows, and the same goes for the output - the model should be able to produce a matrix with the correct number of rows where the columns can be both classes or continuous  numbers.

&amp;nbsp;

I hope I've managed to phrase the problem well enough for you all to understand what I'm looking for. Thank you all in advance for any help or guidance :-)",3,1,False,self,,,,,
181,deeplearning,t5_2t5eh,2018-4-30,2018,4,30,20,8fymfs,exastax.com,The Fin-ternet of Things: The Impact of IoT on Financial Services,https://www.reddit.com/r/deeplearning/comments/8fymfs/the_finternet_of_things_the_impact_of_iot_on/,y-emre,1525086178,,0,3,False,default,,,,,
182,deeplearning,t5_2t5eh,2018-4-30,2018,4,30,20,8fyu9r,self.deeplearning,"Hi, guys. Do you know how to aggregate the result of sentiment analysis for further Machine Learning?",https://www.reddit.com/r/deeplearning/comments/8fyu9r/hi_guys_do_you_know_how_to_aggregate_the_result/,InterestingPea,1525088813,"My final paper is about a prediction model for Bitcoin Price based on comments which I've extracted from Reddit and Twitter, I collected over 1000 short text per day, and used VADER to analyze them. My question is how can I calculate a specific kind of vector to represent a whole day's sentiment, I really stuck in here since I have 1000 results for a single day and it is definitely not the input of LSTM model, how should I do? do you guys have any suggestion? or should I use Doc2Vec to transfer them into word vectors which seems reasonable inputs for a Deep Learning model?",1,1,False,self,,,,,
183,deeplearning,t5_2t5eh,2018-4-30,2018,4,30,20,8fyvkm,self.deeplearning,Python GTA5,https://www.reddit.com/r/deeplearning/comments/8fyvkm/python_gta5/,errminator,1525089233,"Hello, a very basic question here: in the Sentdex YouTube tutorials of GTA5 self driving cars, is he using a purchased version of the game or is there now some version u can download online  (don't really play games so not sure whether I need buy it or not to follow along). 

Thanks",1,1,False,self,,,,,
184,deeplearning,t5_2t5eh,2018-4-30,2018,4,30,21,8fyyea,ai.works-hub.com,What's New in Deep Learning Research: Parameter Noise &amp; The Sentiment Neuron,https://www.reddit.com/r/deeplearning/comments/8fyyea/whats_new_in_deep_learning_research_parameter/,EdmundWorks,1525090129,,0,1,False,default,,,,,
