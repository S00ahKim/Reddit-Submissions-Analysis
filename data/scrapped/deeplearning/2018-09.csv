,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,deeplearning,t5_2t5eh,2018-9-1,2018,9,1,15,9c0xpa,youtube.com,Demo: Accelerate Deep Learning Inference on Raspberry Pi (2018 ver.),https://www.reddit.com/r/deeplearning/comments/9c0xpa/demo_accelerate_deep_learning_inference_on/,9_ties,1535782646,,5,52,False,default,,,,,
1,deeplearning,t5_2t5eh,2018-9-1,2018,9,1,18,9c1sqs,trumptraveling.blogspot.com,US News top Computer Science Artificial Intelligence schools,https://www.reddit.com/r/deeplearning/comments/9c1sqs/us_news_top_computer_science_artificial/,dt_magic,1535793946,,0,1,False,default,,,,,
2,deeplearning,t5_2t5eh,2018-9-1,2018,9,1,18,9c1uu3,theaigeek.com,AI Weekly 1 September 2018,https://www.reddit.com/r/deeplearning/comments/9c1uu3/ai_weekly_1_september_2018/,TomekB,1535794652,,0,1,False,default,,,,,
3,deeplearning,t5_2t5eh,2018-9-2,2018,9,2,2,9c4wez,i.redd.it,,https://www.reddit.com/r/deeplearning/comments/9c4wez/_/,c00l_boi,1535823123,,0,0,False,image,,,,,
4,deeplearning,t5_2t5eh,2018-9-2,2018,9,2,16,9caikq,self.deeplearning,Someone knows a good course on video analysis using deep learning?,https://www.reddit.com/r/deeplearning/comments/9caikq/someone_knows_a_good_course_on_video_analysis/,milions90,1535875014,,3,0,False,self,,,,,
5,deeplearning,t5_2t5eh,2018-9-2,2018,9,2,18,9cayyl,self.deeplearning,I have an interview tomorrow,https://www.reddit.com/r/deeplearning/comments/9cayyl/i_have_an_interview_tomorrow/,ninenerd,1535881625,"I need to know the use of C++ in ML/DL.  
I have not used C++ for ML, HR asked me if I know C++ and I know.  
So which concepts from C++ can come handy for interview ?  
ANd why we prefer it over java/python ?  
Thanks",6,0,False,self,,,,,
6,deeplearning,t5_2t5eh,2018-9-2,2018,9,2,20,9cbdet,medium.com,Polyaxon v0.2 (DL/ML on Kuberentes),https://www.reddit.com/r/deeplearning/comments/9cbdet/polyaxon_v02_dlml_on_kuberentes/,mmourafiq,1535887316,,0,1,False,default,,,,,
7,deeplearning,t5_2t5eh,2018-9-3,2018,9,3,2,9cdok9,self.deeplearning,"Any recommended cloud for training NN? (preferably free of cost, just for hobby)",https://www.reddit.com/r/deeplearning/comments/9cdok9/any_recommended_cloud_for_training_nn_preferably/,Cannikin18,1535908206,I started to learn about deep learning(online course) and found out that my laptop can't handle the NN training. I have look through some website but not sure if it is what I'm looking for.,4,0,False,self,,,,,
8,deeplearning,t5_2t5eh,2018-9-3,2018,9,3,2,9cdpib,self.deeplearning,Deep learning retreat scholarships,https://www.reddit.com/r/deeplearning/comments/9cdpib/deep_learning_retreat_scholarships/,urlwolf,1535908382,"Hi guys,

&amp;#x200B;

I run Deep learning retreat, a 3-month school that takes pretty advanced machine learners and gets them to work together with mentors to produce a killer deep learning portfolio project. We want these projects to have social impact (example: a malaria microscope). 

&amp;#x200B;

We are launching our first batch in SF. We are going to live together (participants and mentors) at walking distance from the office. It's going to be great. 

&amp;#x200B;

It costs 12k. And this is clearly a problem for many, many people. So I'm happy to announce that a benefactor that wishes to remain anonymous contributed money to start up a scholarship program. This is really amazing because we while we didnt know each other before we were still united by our mental model of how deep learning can change the world.

&amp;#x200B;

The scholarships will work as a pay it forward model. That is, if you got one, whenever you are well-to-do in your life, give one to someone who needs it. Be anonymous.

&amp;#x200B;

Since a lot of influential people hang out here, I want to ask you. Can you recommend someone for the scholarship? It's merit first, then need. We want to get the best people possible, and have the maximum amount of impact.

&amp;#x200B;

If you want to apply yourself, head to  [https://deeplearningretreat.com/deep-learning-retreat-scholarships/](https://deeplearningretreat.com/deep-learning-retreat-scholarships/)

&amp;#x200B;",5,14,False,self,,,,,
9,deeplearning,t5_2t5eh,2018-9-3,2018,9,3,14,9ciytu,self.deeplearning,Anyone familiar with platforms that I can rent out my GPUs power for deep learning besides Vectordash?,https://www.reddit.com/r/deeplearning/comments/9ciytu/anyone_familiar_with_platforms_that_i_can_rent/,AnonymousGOAT08,1535954357,"I built a rig awhile back and seen the whole Vectordash movement and long story short, seems like the founders are heavily dragging their feet. Extremely frustrating.. Via Reddit and my own experiences I got a message back inquiring about my hosting application and responded myself but havent seen anything since. Wondering if there are any other places that I can use my GPU power to rent out for deep learning such as what Vectordash was trying to provide?",4,6,False,self,,,,,
10,deeplearning,t5_2t5eh,2018-9-3,2018,9,3,17,9cjtna,github.com,[P] MagNet: High-Level PyTorch API for Quick Experimentation,https://www.reddit.com/r/deeplearning/comments/9cjtna/p_magnet_highlevel_pytorch_api_for_quick/,svaisakh,1535963878,,5,19,False,default,,,,,
11,deeplearning,t5_2t5eh,2018-9-3,2018,9,3,21,9cl902,sciencealert.com,Scientists Have Trained an AI to Spot Obesity From Space,https://www.reddit.com/r/deeplearning/comments/9cl902/scientists_have_trained_an_ai_to_spot_obesity/,asifrazzaq1988,1535979313,,4,13,False,default,,,,,
12,deeplearning,t5_2t5eh,2018-9-3,2018,9,3,23,9clsan,hackernoon.com,Can you solve a person detection task in 10 minutes?,https://www.reddit.com/r/deeplearning/comments/9clsan/can_you_solve_a_person_detection_task_in_10/,tdionis,1535984010,,0,0,False,default,,,,,
13,deeplearning,t5_2t5eh,2018-9-4,2018,9,4,17,9ctssi,valohai.com,Real World Example of Deep Learning: Sexual Abuse Material Detection,https://www.reddit.com/r/deeplearning/comments/9ctssi/real_world_example_of_deep_learning_sexual_abuse/,freducom,1536050408,,1,4,False,default,,,,,
14,deeplearning,t5_2t5eh,2018-9-4,2018,9,4,17,9cttvo,self.deeplearning,Machine Learning India,https://www.reddit.com/r/deeplearning/comments/9cttvo/machine_learning_india/,hamir_s,1536050750,"Hi all,

This is an invite to all Indians on this community to /r/MLIndia. This community is focused on particular problems unique to Indians in the journey to learn ML/DL in India.

Thanks! ",2,1,False,self,,,,,
15,deeplearning,t5_2t5eh,2018-9-5,2018,9,5,0,9cwqhk,qz.com,Deep-learning algorithms are being used to detect lithium-ion batteries in airport luggage,https://www.reddit.com/r/deeplearning/comments/9cwqhk/deeplearning_algorithms_are_being_used_to_detect/,asifrazzaq1988,1536075476,,0,12,False,default,,,,,
16,deeplearning,t5_2t5eh,2018-9-5,2018,9,5,8,9d0r62,self.deeplearning,"too many AI model, such as: lstm,reinforcement learning, qlearning, dqn,ddqn, rainbow........ any good idea help people to easy understand and remember ?",https://www.reddit.com/r/deeplearning/comments/9d0r62/too_many_ai_model_such_as_lstmreinforcement/,asda43asdf23423,1536102906,"too many AI model,  such as:  lstm,reinforcement learning, qlearning, dqn,ddqn, rainbow........

any  good idea help people to easy understand and remember ?",3,1,False,self,,,,,
17,deeplearning,t5_2t5eh,2018-9-5,2018,9,5,11,9d2abk,self.deeplearning,Can someone explain the OneHotEncoder and train_test_split?,https://www.reddit.com/r/deeplearning/comments/9d2abk/can_someone_explain_the_onehotencoder_and_train/,Pawin3210,1536115381,I am learning Deep Learning through books and Udemy courses ( I'm very very new ) and I find the documents quite hard to understand.,7,3,False,self,,,,,
18,deeplearning,t5_2t5eh,2018-9-5,2018,9,5,12,9d2irc,self.deeplearning,What is the best options to use an remote GPU on the cloud while I only have a notebook with CPU ?,https://www.reddit.com/r/deeplearning/comments/9d2irc/what_is_the_best_options_to_use_an_remote_gpu_on/,Laurence-Lin,1536117166,"I want to get start on deep learning practice, but due to the hardware restrict, I need to get access of the cloud GPU server in order to run the program successfully. Some website have suggest the Jupyter can enables the access to GPU server, I would like to ask if anyone recommend it? Or is there any other better choice to get access ?  
Thanks for helping.  
",20,3,False,self,,,,,
19,deeplearning,t5_2t5eh,2018-9-5,2018,9,5,15,9d3tlk,self.deeplearning,How to explain why some weights are bigger in MLP,https://www.reddit.com/r/deeplearning/comments/9d3tlk/how_to_explain_why_some_weights_are_bigger_in_mlp/,cyph_r,1536129514,"I noticed that after a deep learning training using MLP, if I look to the first layer weights, then some weights are much bigger than others, and usually the biggest weights corresponds to the weights which are connected to the inputs nodes where the information is.

&amp;#x200B;

For example using some data like MNIST, let say that the relevant pixels are usually in the center of the image, then the weights connected to the central pixels will be bigger than the weights on the edges.

&amp;#x200B;

It seems obvious, but how can we explain this mathematically. Why the weights connected to the relevant inputs are higher than the weights connected to the non-relevant inputs nodes?

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",2,1,False,self,,,,,
20,deeplearning,t5_2t5eh,2018-9-5,2018,9,5,22,9d6dwc,arxiv.org,Generative Adversial Networks,https://www.reddit.com/r/deeplearning/comments/9d6dwc/generative_adversial_networks/,shaswat98,1536152971,,0,0,False,default,,,,,
21,deeplearning,t5_2t5eh,2018-9-6,2018,9,6,1,9d8e0f,self.deeplearning,Should I learn concepts from blogs or books?,https://www.reddit.com/r/deeplearning/comments/9d8e0f/should_i_learn_concepts_from_blogs_or_books/,Pawin3210,1536166005,,0,1,False,self,,,,,
22,deeplearning,t5_2t5eh,2018-9-6,2018,9,6,7,9dbn65,/r/deeplearning/comments/9dbn65/yolov2_for_object_detection_task_pytorch/,Yolov2 for object detection task (Pytorch implementation),https://www.reddit.com/r/deeplearning/comments/9dbn65/yolov2_for_object_detection_task_pytorch/,1991viet,1536185745,,3,55,False,default,,,,,
23,deeplearning,t5_2t5eh,2018-9-6,2018,9,6,8,9dcbls,self.deeplearning,Should I go to college for AI / data science?,https://www.reddit.com/r/deeplearning/comments/9dcbls/should_i_go_to_college_for_ai_data_science/,Ducknado1337,1536190291,"Not sure if this is the right place to ask, but I was wondering what you guys think. Should I go to college for AI or something similar, or just keep learning on my own? I'm currently in highschool and have a year or two, but I know I want to go into this field. I've seen mixed feelings on the topic, what do you guys think? Thanks ahead of time.",2,1,False,self,,,,,
24,deeplearning,t5_2t5eh,2018-9-6,2018,9,6,12,9de9ev,youtu.be,Everybody Dance now explained! Latest research from Berkeley AI Research,https://www.reddit.com/r/deeplearning/comments/9de9ev/everybody_dance_now_explained_latest_research/,vector_machines,1536204046,,0,7,False,image,,,,,
25,deeplearning,t5_2t5eh,2018-9-6,2018,9,6,16,9dg4kk,self.deeplearning,Alternatives to NIPS,https://www.reddit.com/r/deeplearning/comments/9dg4kk/alternatives_to_nips/,dmilushev,1536220101,"Now for the ones who were not able to get into NIPS, are there any reasonable alternatives/similar venues to NIPS between now and the end of February 2019. I know about about ICML and ICLR, but they are outside of the mentioned time-window. Is there something else worth attending, even it is more on the technical/development side than the above -mentioned?
",0,1,False,self,,,,,
26,deeplearning,t5_2t5eh,2018-9-6,2018,9,6,17,9dgibz,blog.ntrlab.com,Company events in Russian software development company,https://www.reddit.com/r/deeplearning/comments/9dgibz/company_events_in_russian_software_development/,Batareika_1,1536223798,,0,2,False,default,,,,,
27,deeplearning,t5_2t5eh,2018-9-6,2018,9,6,18,9dgp2q,self.deeplearning,Reinforcement learning for NLP,https://www.reddit.com/r/deeplearning/comments/9dgp2q/reinforcement_learning_for_nlp/,pcidev,1536225656,"What do you think of RL use in NLP.? 
Could someone suggest me some interesting tutorials to read  about this topic. ",4,5,False,self,,,,,
28,deeplearning,t5_2t5eh,2018-9-6,2018,9,6,18,9dgq4n,vast.ai,Vast.ai -&gt; Insanely cheap GPU instances while in beta,https://www.reddit.com/r/deeplearning/comments/9dgq4n/vastai_insanely_cheap_gpu_instances_while_in_beta/,sparky_the_unicorn,1536225922,,10,9,False,default,,,,,
29,deeplearning,t5_2t5eh,2018-9-6,2018,9,6,19,9dh1r2,self.deeplearning,How can I use stacked autoencoder to initialize weight for my neural network in Pytorch?,https://www.reddit.com/r/deeplearning/comments/9dh1r2/how_can_i_use_stacked_autoencoder_to_initialize/,namnguyen_hust,1536228886,"Dear experienced ones,  


Any suggestions for my question?

&amp;#x200B;

Thanks in advance.",0,1,False,self,,,,,
30,deeplearning,t5_2t5eh,2018-9-6,2018,9,6,22,9dik6t,self.deeplearning,September 2018 issue of Computer Vision News,https://www.reddit.com/r/deeplearning/comments/9dik6t/september_2018_issue_of_computer_vision_news/,Gletta,1536240423,"Hot off the Press! Links to Computer Vision News of September

Here is the September 2018 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: 30 pages worth reading about Artificial Intelligence, Deep Learning, Image Processing and Computer Vision. Technical review of a new paper at page 4 and free subscription at page 30.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2018September/)

[PDF version](http://www.rsipvision.com/computer-vision-news-2018-september-pdf/)

Enjoy!

&amp;#x200B;

&amp;#x200B;",0,5,False,self,,,,,
31,deeplearning,t5_2t5eh,2018-9-6,2018,9,6,22,9distp,self.deeplearning,PyCM: Multiclass confusion matrix library in Python,https://www.reddit.com/r/deeplearning/comments/9distp/pycm_multiclass_confusion_matrix_library_in_python/,sepandhaghighi,1536242040," PyCM is a multi-class confusion matrix library written in Python that supports both input data vectors and direct matrix, and a proper tool for post-classification model evaluation that supports most classes and overall statistics parameters. PyCM is the swiss-army knife of confusion matrices, targeted mainly at data scientists that need a broad array of metrics for predictive models and an accurate evaluation of large variety of classifiers. 

&amp;#x200B;

[Github Repo](https://github.com/sepandhaghighi/pycm)

[Webpage](http://pycm.shaghighi.ir/)

[JOSS Paper](http://joss.theoj.org/papers/10.21105/joss.00729)",0,6,False,self,,,,,
32,deeplearning,t5_2t5eh,2018-9-7,2018,9,7,1,9dkcrf,sumo.ly,Deep Learning  Learn Recurrent Neural Networks in Python,https://www.reddit.com/r/deeplearning/comments/9dkcrf/deep_learning_learn_recurrent_neural_networks_in/,atkarti,1536251745,,0,2,False,default,,,,,
33,deeplearning,t5_2t5eh,2018-9-7,2018,9,7,2,9dl63a,mlwhiz.com,Multi input transfer learning - Check it out,https://www.reddit.com/r/deeplearning/comments/9dl63a/multi_input_transfer_learning_check_it_out/,mlwhiz,1536256527,,2,3,False,default,,,,,
34,deeplearning,t5_2t5eh,2018-9-7,2018,9,7,3,9dln0t,self.deeplearning,What was the path that lead you to your Deep Learning job?,https://www.reddit.com/r/deeplearning/comments/9dln0t/what_was_the_path_that_lead_you_to_your_deep/,DerSteppenWulf,1536259238,What someone should do after completing something like a degree in CS or nanodegree programs or any other course that could give you a potential job in a CS field? You started to make your own personal projects or just went straight looking for jobs and you gained experience in the field there without knowing much? ,1,0,False,self,,,,,
35,deeplearning,t5_2t5eh,2018-9-7,2018,9,7,4,9dm2u0,self.deeplearning,Deep learning cluster setup suggestions,https://www.reddit.com/r/deeplearning/comments/9dm2u0/deep_learning_cluster_setup_suggestions/,adi1709,1536261928,"We are planning to setup a deep learning cluster for about 8-10 people. I was looking for suggestions for the GPUs, criteria to keep in mind while setting one up. What is the latest offering from NVIDIA in terms of architecture if we are not looking at a high end one?",1,0,False,self,,,,,
36,deeplearning,t5_2t5eh,2018-9-7,2018,9,7,4,9dm7uh,reddit.com,Introduction to Reinforcement Learning using MXNet   r/MachineLearning,https://www.reddit.com/r/deeplearning/comments/9dm7uh/introduction_to_reinforcement_learning_using/,tomtx0,1536262756,,0,16,False,default,,,,,
37,deeplearning,t5_2t5eh,2018-9-7,2018,9,7,6,9dn8lb,medium.com,Megvii UPerNet Performs Multi-Level Visual Scene Interpretation at a Glance,https://www.reddit.com/r/deeplearning/comments/9dn8lb/megvii_upernet_performs_multilevel_visual_scene/,trcytony,1536268854,,0,1,False,default,,,,,
38,deeplearning,t5_2t5eh,2018-9-7,2018,9,7,10,9dpest,self.deeplearning,Is there any python code for neural network for pattern recognition?,https://www.reddit.com/r/deeplearning/comments/9dpest/is_there_any_python_code_for_neural_network_for/,VenyWun1729,1536283481,,2,0,False,self,,,,,
39,deeplearning,t5_2t5eh,2018-9-7,2018,9,7,17,9ds6wz,self.deeplearning,AI can now program in HTML,https://www.reddit.com/r/deeplearning/comments/9ds6wz/ai_can_now_program_in_html/,as_ninja6,1536307966,"Web developers need to run fast, AI is catching up... Microsoft's sketch2code provides html code from hand sketch 

*Processing img z927ztuayrk11...*",11,12,False,self,,,,,
40,deeplearning,t5_2t5eh,2018-9-7,2018,9,7,17,9ds85y,self.deeplearning,Interesting Podcast where Raia Hadsell from DeepMind discusses 'Deep Reinforcement Learning in Complex Environments',https://www.reddit.com/r/deeplearning/comments/9ds85y/interesting_podcast_where_raia_hadsell_from/,teamrework,1536308361,"Where am I, and where am I going, and where have I been before? Answering these questions requires cognitive navigation skills--fundamental skills which are employed by every intelligent biological species to find food, evade predators, and return home. On this week's episode of the Podcast, Raia discusses her work on Deep Reinforcement Learning in Complex Environments. [http://videos.re-work.co/podcast](http://videos.re-work.co/podcast) ",0,1,False,self,,,,,
41,deeplearning,t5_2t5eh,2018-9-7,2018,9,7,22,9dubts,self.deeplearning,Can WiFi frequencies reflect off objects ?,https://www.reddit.com/r/deeplearning/comments/9dubts/can_wifi_frequencies_reflect_off_objects/,saadmrb,1536326822,"Can we see through-wall(Clothes/Objects etc..) Estimation for an object(i.e keys/t-shirt) using Radio Signals ?  
 ",6,0,False,self,,,,,
42,deeplearning,t5_2t5eh,2018-9-8,2018,9,8,0,9dve9f,self.deeplearning,Using Video synthesis to generate semantic segmentation,https://www.reddit.com/r/deeplearning/comments/9dve9f/using_video_synthesis_to_generate_semantic/,zurister,1536333897,"I was wondering**can video segmentation be viewed as a video synthesis problem**? All we need to do is to generate a video with label colors given the original video. Video synthesis networks try to learn the detailed intricacies of the video and doing segmentation for them wont be too hard. Even a slightly less performing model on cityscapes can perform good in semantic segmentation domain. Models like Vid2Vid should perform very good on such task.

Does this make sense? Any insights on this?",0,5,False,self,,,,,
43,deeplearning,t5_2t5eh,2018-9-8,2018,9,8,5,9dyabn,thefashionrobot.com,"Q&amp;A: Spirit &amp; Glitch, A Fashion Brand Designed with Neural Networks",https://www.reddit.com/r/deeplearning/comments/9dyabn/qa_spirit_glitch_a_fashion_brand_designed_with/,continuaco,1536352599,,0,1,False,default,,,,,
44,deeplearning,t5_2t5eh,2018-9-8,2018,9,8,5,9dyho2,self.deeplearning,How does dilated convolution (a.k.a atrous convolution) help?,https://www.reddit.com/r/deeplearning/comments/9dyho2/how_does_dilated_convolution_aka_atrous/,zurister,1536353879,I am not able to understand - how does atrous convolution help in dense feature prediction?,11,8,False,self,,,,,
45,deeplearning,t5_2t5eh,2018-9-8,2018,9,8,7,9dz0t4,self.deeplearning,[x-post] Cheat sheet: Deep learning losses &amp; optimizers,https://www.reddit.com/r/deeplearning/comments/9dz0t4/xpost_cheat_sheet_deep_learning_losses_optimizers/,hergertarian,1536357834,"**tl;dr:** Sane defaults for deep learning loss functions and optimizers, followed by in-depth descriptions.

https://www.hergertarian.com/cheat-sheet-deep-learning-losses-optimizers",0,3,False,self,,,,,
46,deeplearning,t5_2t5eh,2018-9-8,2018,9,8,15,9e27tv,towardsdatascience.com,Making Music: When Simple Probabilities Outperform Deep Learning,https://www.reddit.com/r/deeplearning/comments/9e27tv/making_music_when_simple_probabilities_outperform/,FollowSteph,1536388134,,1,15,False,default,,,,,
47,deeplearning,t5_2t5eh,2018-9-8,2018,9,8,22,9e49ai,theaigeek.com,AI Weekly 8 September 2018,https://www.reddit.com/r/deeplearning/comments/9e49ai/ai_weekly_8_september_2018/,TomekB,1536412498,,0,1,False,default,,,,,
48,deeplearning,t5_2t5eh,2018-9-9,2018,9,9,13,9eaj9q,twitter.com,"Humble Book Bundle: Machine Learning by O'Reilly. $641 worth of Machine Learning Books like Introduction to Machine Learning with Python, Learning TensorFlow, 1Ed, and Thoughtful Machine Learning with Python, 1Ed is 97% OFF !",https://www.reddit.com/r/deeplearning/comments/9eaj9q/humble_book_bundle_machine_learning_by_oreilly/,Ariana675,1536468539,,0,1,False,default,,,,,
49,deeplearning,t5_2t5eh,2018-9-9,2018,9,9,15,9eb5f7,reddit.com,Stanford's Deep Learning cheatsheet  r/MachinesLearn,https://www.reddit.com/r/deeplearning/comments/9eb5f7/stanfords_deep_learning_cheatsheet_rmachineslearn/,lohoban,1536476253,,0,36,False,default,,,,,
50,deeplearning,t5_2t5eh,2018-9-9,2018,9,9,20,9ec7ou,self.deeplearning,Using K-fold cross-validation in Keras,https://www.reddit.com/r/deeplearning/comments/9ec7ou/using_kfold_crossvalidation_in_keras/,suraty,1536491323,"Hello,
I would like to use K-fold cross-validation on my data of my model.

My codes in Keras is :

    a = np.array(  
    [[283, 95, 72, 65],
    [290, 100, 80, 72],
    [120,170,130,122],
    [100,230,110,200],
    [300,100,200,500]]
        )
    X = a[:,0:2]
    Y = a[:,3]

    from sklearn.model_selection import KFold, cross_val_score
    k_fold = KFold(n_splits=3)    
    model = models.Sequential()
    model.add(Dense(12, input_shape=(3,)))
    model.add(LeakyReLU())
    model.summary()
    
    cross_val_score(model,X,Y)

But, It makes this error:

&gt;If no scoring is specified, the estimator passed should have a 'score' method. The estimator &lt;keras.engine.sequential.Sequential object at 0x00000138D28D2E10&gt; does not.

And when I select a scoring parameter as:

    cross_val_score(model,X,Y, scoring= 'accuracy')

It makes another error:
&gt;TypeError: Cannot clone object '&lt;keras.engine.sequential.Sequential object at 0x00000138D28D2E10&gt;' (type &lt;class 'keras.engine.sequential.Sequential'&gt;): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods.

How can I use K-fold cross-validation correctly?
Thank you",1,2,False,self,,,,,
51,deeplearning,t5_2t5eh,2018-9-9,2018,9,9,23,9ed7t1,codingwoman.com,Generative Adversarial Networks  An Entertaining Introduction,https://www.reddit.com/r/deeplearning/comments/9ed7t1/generative_adversarial_networks_an_entertaining/,codingwoman_,1536502251,,0,4,False,default,,,,,
52,deeplearning,t5_2t5eh,2018-9-10,2018,9,10,1,9eegj2,reddit.com,Practical Advice for Building Deep Neural Networks  r/MachinesLearn,https://www.reddit.com/r/deeplearning/comments/9eegj2/practical_advice_for_building_deep_neural/,lohoban,1536511918,,0,1,False,default,,,,,
53,deeplearning,t5_2t5eh,2018-9-10,2018,9,10,13,9ejpgs,self.deeplearning,Papers with Code,https://www.reddit.com/r/deeplearning/comments/9ejpgs/papers_with_code/,fvzaur,1536554273,I'm working on making a list of Machine Learning papers that has open source code on GitHub. My initial version can be reached at the link included below. I think it will be helpful to this community to select their next paper to read. Please also include your comments and suggestions for improvement. https://github.com/zziz/pwc,5,38,False,self,,,,,
54,deeplearning,t5_2t5eh,2018-9-11,2018,9,11,12,9etzo6,self.deeplearning,Sensitivity analysis,https://www.reddit.com/r/deeplearning/comments/9etzo6/sensitivity_analysis/,cyph_r,1536636852,"I want to know which input pixels contribute the most to the classification.

&amp;#x200B;

I heard about sensitivity analysis which is based on computing derivative with regards to the input directly.

&amp;#x200B;

However, should I compute the derivative of the loss or of the network output? (with regards to the input)

&amp;#x200B;

Thanks",5,6,False,self,,,,,
55,deeplearning,t5_2t5eh,2018-9-11,2018,9,11,17,9evo36,self.deeplearning,Deep Learning Market Worth 18.16 Billion USD by 2023,https://www.reddit.com/r/deeplearning/comments/9evo36/deep_learning_market_worth_1816_billion_usd_by/,marketsandmarkets,1536654007,[removed],0,1,False,self,,,,,
56,deeplearning,t5_2t5eh,2018-9-11,2018,9,11,21,9ex5v7,self.deeplearning,Multivariate Time Series Deep Learning Models,https://www.reddit.com/r/deeplearning/comments/9ex5v7/multivariate_time_series_deep_learning_models/,liftoff01,1536669429,"I was wondering if there are any specific deep learning models designed to handle multivariate time series data.

Classical multivariate models will be vector autoregressive models (VAR) and univariate models includes the arima class. 

I maybe wrong but RNNs are more akin to arima models than VAR models, no? ",13,10,False,self,,,,,
57,deeplearning,t5_2t5eh,2018-9-11,2018,9,11,23,9ey0i4,self.MachinesLearn,Practical guide to hyperparameters search for deep learning models,https://www.reddit.com/r/deeplearning/comments/9ey0i4/practical_guide_to_hyperparameters_search_for/,pirate7777777,1536675977,,0,1,False,default,,,,,
58,deeplearning,t5_2t5eh,2018-9-12,2018,9,12,3,9f02or,blogs.unity3d.com,"ML-Agents reference paper, Gym interface support, and Marathon Environments",https://www.reddit.com/r/deeplearning/comments/9f02or/mlagents_reference_paper_gym_interface_support/,leonchenzhy,1536690390,,0,7,False,default,,,,,
59,deeplearning,t5_2t5eh,2018-9-12,2018,9,12,8,9f2dib,datascience.stackexchange.com,Preserve colour in autoencoder,https://www.reddit.com/r/deeplearning/comments/9f2dib/preserve_colour_in_autoencoder/,__Lau__,1536707600,,0,1,False,default,,,,,
60,deeplearning,t5_2t5eh,2018-9-12,2018,9,12,13,9f4phr,self.deeplearning,Implementation of Batch normalization and instance normalization from scratch in Python?,https://www.reddit.com/r/deeplearning/comments/9f4phr/implementation_of_batch_normalization_and/,kailashahirwar12,1536727232,Batch normalization is a very important method to speedup training of neural networks. Instance normalization is relatively new and promises more. I am looking for a very good explanation of batch normalization and instance normalization in Python.,1,2,False,self,,,,,
61,deeplearning,t5_2t5eh,2018-9-12,2018,9,12,13,9f4pwh,v.redd.it,Multi-Person Pose Estimation (Python / C++),https://www.reddit.com/r/deeplearning/comments/9f4pwh/multiperson_pose_estimation_python_c/,spmallick,1536727351,,3,49,False,default,,,,,
62,deeplearning,t5_2t5eh,2018-9-12,2018,9,12,23,9f82fq,self.deeplearning,Training seq2seq on smaller datasets,https://www.reddit.com/r/deeplearning/comments/9f82fq/training_seq2seq_on_smaller_datasets/,pchelina,1536761231,"I wonder if anybody had experience with pretraining a seq2seq model when you don't have millions of message-response pairs. I want to train a chatbot and i have good dialogue data but it makes just a few thousands pairs. The dataset is in a fairly restricted domain (therapy sessions), but it is still much smaller than datasets i see conmonly used to train a chatbot. I hear some people pre-train their models on larger 'garbage' datasets like twitter, but i fail to see how it would work exactly. Does it mean the weights pretrained on this large dataset capture some low-level features like common ngram patterns, and then when you retrain it on the clean data it just learns to mimic the style? Or does it mean you are still likely to generate twitter-like comments? ",6,2,False,self,,,,,
63,deeplearning,t5_2t5eh,2018-9-12,2018,9,12,23,9f82pg,self.deeplearning,I'm finding a Image Captioning paper,https://www.reddit.com/r/deeplearning/comments/9f82pg/im_finding_a_image_captioning_paper/,curaai00,1536761278,Is there CRNN applied image captioning paper??,1,2,False,self,,,,,
64,deeplearning,t5_2t5eh,2018-9-13,2018,9,13,5,9fbf2d,self.deeplearning,Mixing text and numeric features for text classification using deep learning,https://www.reddit.com/r/deeplearning/comments/9fbf2d/mixing_text_and_numeric_features_for_text/,mathcircler,1536784256,"I have a problem about classification of text into several categories (topics). Apart from text, I have some numeric features that I believe may be useful (there are also missing values among those features). But the most important information is, of course, presented in the text. Therefore, I think deep learning  approach (with common pipeline: embedding layer + CNN or RNN with dropout + Dense layer) would be the best choice. What is the best practice to mix the current model that works only on text input with numeric features? Are there any tricks, best practices? Are there any papers/experiments (on GitHub maybe) on this topic?",3,7,False,self,,,,,
65,deeplearning,t5_2t5eh,2018-9-13,2018,9,13,5,9fbk3x,self.deeplearning,Best deep learning practices in NLP for text classification,https://www.reddit.com/r/deeplearning/comments/9fbk3x/best_deep_learning_practices_in_nlp_for_text/,mathcircler,1536785212,"Are there any list of best practices on text classification (not only in English language, but in general)? In particular, I'm interested:

\- what kind of text preprocessing techniques are usually useful? Can you share some good open-source text preprocessors?

\- what kind of neural networks architectures one should try first on a new text classification problem? What kind of architectures should be solid baselines?

\- what are the ""rules of thumb"" for choosing the size of the dictionary? maximum number of words to be left (in sequence padding)? word embeddings dimension?  


Would be great if you could share articles or (even better!) the must-read research papers or anything else you find useful about this topic.",2,19,False,self,,,,,
66,deeplearning,t5_2t5eh,2018-9-13,2018,9,13,13,9ff17o,self.deeplearning,foobar.edu deep foobar dataset http server is very slow!!,https://www.reddit.com/r/deeplearning/comments/9ff17o/foobaredu_deep_foobar_dataset_http_server_is_very/,Yusuke_Suzuki,1536813583,"Many labs of many universities provides very useful dataset for deeplearning.

Bat their http servers are very very poor.

Why don't they use cloud server?

I spent a day to download a dataset.

Other day, I can't download dataset for connection timeout, response timeout, disconnection ...",0,1,False,self,,,,,
67,deeplearning,t5_2t5eh,2018-9-13,2018,9,13,18,9fgl2m,hackernoon.com, Traveling the ML. Next hop: step by step guide to recognize drivable area,https://www.reddit.com/r/deeplearning/comments/9fgl2m/traveling_the_ml_next_hop_step_by_step_guide_to/,tdionis,1536831743,,0,8,False,default,,,,,
68,deeplearning,t5_2t5eh,2018-9-13,2018,9,13,21,9fhqxb,self.deeplearning,Adam Optimizer with large learning rate doesn't converge,https://www.reddit.com/r/deeplearning/comments/9fhqxb/adam_optimizer_with_large_learning_rate_doesnt/,varian97,1536843501,I try to implement a Deep Neural Network by myself and I use adam as the optimizer. Then I try different value of learning rate to it. When the learning rate = 0.0007 the algorithm produces low error ( approx. 0.76 ) but for larger learning rate (ex. 0.1) it produces higher error ( &gt; 3 ). Does adam optimizer behave like that? or is it my implementation that buggy? ( same thing happen to the RMSProp ),5,2,False,self,,,,,
69,deeplearning,t5_2t5eh,2018-9-14,2018,9,14,0,9fj7v0,sumo.ly,Deep Learning  Learn Recurrent Neural Networks in Python,https://www.reddit.com/r/deeplearning/comments/9fj7v0/deep_learning_learn_recurrent_neural_networks_in/,plpface,1536854306,,0,7,False,default,,,,,
70,deeplearning,t5_2t5eh,2018-9-14,2018,9,14,2,9fk7er,blog.paperspace.com,[P] New series on data augmentation for object detection - Code + open source augmentation library included,https://www.reddit.com/r/deeplearning/comments/9fk7er/p_new_series_on_data_augmentation_for_object/,taltal13,1536861106,,0,1,False,default,,,,,
71,deeplearning,t5_2t5eh,2018-9-14,2018,9,14,10,9fnvdd,hanxiao.github.io,"Machine Reading Comprehension Part II: Learning to Ask &amp; Answer  Han Xiao Tech Blog - Deep Learning, Tensorflow, Machine Learning and more!",https://www.reddit.com/r/deeplearning/comments/9fnvdd/machine_reading_comprehension_part_ii_learning_to/,h_xiao,1536888726,,1,6,False,default,,,,,
72,deeplearning,t5_2t5eh,2018-9-14,2018,9,14,13,9fp5pk,towardsdatascience.com,"Understanding Neural Networks. From neuron to RNN, CNN, and Deep Learning",https://www.reddit.com/r/deeplearning/comments/9fp5pk/understanding_neural_networks_from_neuron_to_rnn/,nigamv01,1536900382,,0,1,False,default,,,,,
73,deeplearning,t5_2t5eh,2018-9-14,2018,9,14,23,9fsk2h,github.com,GitHub - lezwon/DeepGamingAI_FIFARL: Using Reinforcement Learning to play FIFA,https://www.reddit.com/r/deeplearning/comments/9fsk2h/github_lezwondeepgamingai_fifarl_using/,lezwon,1536936046,,0,2,False,default,,,,,
74,deeplearning,t5_2t5eh,2018-9-15,2018,9,15,0,9fswk2,codingwoman.com,Generative Adversarial Networks  Paper Reading Road Map,https://www.reddit.com/r/deeplearning/comments/9fswk2/generative_adversarial_networks_paper_reading/,codingwoman_,1536938546,,3,20,False,default,,,,,
75,deeplearning,t5_2t5eh,2018-9-15,2018,9,15,2,9fu635,self.deeplearning,What are the advantages of cupy library over Eigen library?,https://www.reddit.com/r/deeplearning/comments/9fu635/what_are_the_advantages_of_cupy_library_over/,sriharsha_0806,1536947404,"Currently cupy library is used by chainer. Eigen library is used by Pytorch, Tensorflow.",4,6,False,self,,,,,
76,deeplearning,t5_2t5eh,2018-9-15,2018,9,15,7,9fwhw2,medium.com,MIT &amp; Google Propose AutoML for Model Compression,https://www.reddit.com/r/deeplearning/comments/9fwhw2/mit_google_propose_automl_for_model_compression/,trcytony,1536964384,,1,2,False,default,,,,,
77,deeplearning,t5_2t5eh,2018-9-15,2018,9,15,15,9fzahi,self.deeplearning,HIP Vs CUDA,https://www.reddit.com/r/deeplearning/comments/9fzahi/hip_vs_cuda/,Keysmart_Andy,1536991552,"Hey, Im relatively new to the machine learning/deep learning space.  
I have been using SPSS and then Statistica since I was in college.  
(Pretty lame I know) :(  
Anyways... I love econ and am going through [https://quantecon.org/](https://quantecon.org/).  
(I love Macro)  
Anyways... I have an RX Vega 64...   
I know the AMD card won't work with CUDA.  
But does anyone here have experience with HIP? [https://github.com/ROCm-Developer-Tools/HIP](https://github.com/ROCm-Developer-Tools/HIP)  
Is working with HIP on par with working directly on CUDA?  
Would you guys recommend I get a Nvidia card just so I could use CUDA?  
Also, do you guys think its worth investing in one of these new nVidia cards to speed up my training?  ",2,2,False,self,,,,,
78,deeplearning,t5_2t5eh,2018-9-15,2018,9,15,17,9fzwbj,self.deeplearning,"[Question] RNN-LSTM ,Make it to learn anomalies.",https://www.reddit.com/r/deeplearning/comments/9fzwbj/question_rnnlstm_make_it_to_learn_anomalies/,Abhishek_Advance,1536999265," (Some depth in understanding of LSTM required): 

I'm trying to make LSTM learn multivariate time series ,I have been successful to an extent. Now I want to make the LSTM learn anomalies in time series(eg. an unusual drop in values ,when rendering a sine wave in a cyclic manner ). I tried introducing such anomalies in training data,LSTM did not learn.

&gt;**I****s there a way to increase the weightage on parts of time series that has anomalies or some other ways to make LSTM learn that pattern and produce it later.** 

&amp;#x200B;",2,4,False,self,,,,,
79,deeplearning,t5_2t5eh,2018-9-15,2018,9,15,19,9g0iql,self.deeplearning,How to become deep learning researcher?,https://www.reddit.com/r/deeplearning/comments/9g0iql/how_to_become_deep_learning_researcher/,sanchit2843,1537007526,"I am an undergrad student in india and want to be researcher in field of robotics. For the same I started with machine learning and deep learning. I will start studying reinforcement learning and robotics techniques like slam,pid etc next year. But I was thinking of how to study machine learning(more concentration on deep learning) of ms/phd level in my under graduation. Reply will be grateful

Peace",9,10,False,self,,,,,
80,deeplearning,t5_2t5eh,2018-9-15,2018,9,15,21,9g16qo,self.deeplearning,Attention based models for machine comprehension,https://www.reddit.com/r/deeplearning/comments/9g16qo/attention_based_models_for_machine_comprehension/,ImaginaryAnon,1537015479,"Currently, I am understanding Attention models. I specifically need it to build a machine comprehension model (a model which can find answer to a question from a given comprehension). But I want to understand the model generally and not specifically to this topic. I have a question about attention layer but before that I would like to share what I understood.

&amp;#x200B;

\## The things I understood so that you can correct me if I made some mistakes

For this, I have referred an article online which I am sharing here - [http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/)

It gave basic intuition of what the attention layer does - It asks the model the model to focus on a specific part of the input in order to generate the output. Here's an image of it - [http://www.wildml.com/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.51.19-PM.png](http://www.wildml.com/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.51.19-PM.png)

The pink shades are defined by attention variables 'a(i)'. These variables are actually probability distribution that shows 'the probability that the model should focus on the area represented by that variable'. So, a general figure on any attention based model is as - [http://www.wildml.com/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.16.08-PM.png](http://www.wildml.com/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.16.08-PM.png) \- where 'a's are the attention variables (weights). These variables are trained by the model.

&amp;#x200B;

\## The question

I have a question in mind. Are the attention weights same for every inputs (in machine comprehension, input = 'comprehension'). If so, then independent of the comprehension, the model will focus on a very small part of every comprehension to find an answer. And it isn't necessary that the answer lies in same part of all comprehensions.

If the weights are different for different inputs, then how will we train them. Because, as per my knowledge, in every neural network, the weights are trained for all the input data irrelevant of the input identifier i.e the final weight values at the end of training is same for all the inputs. And after training, these weights are the final values which are used in real-time application.",0,2,False,self,,,,,
81,deeplearning,t5_2t5eh,2018-9-15,2018,9,15,21,9g1909,self.deeplearning,New exciting Deep learning Project !!!,https://www.reddit.com/r/deeplearning/comments/9g1909/new_exciting_deep_learning_project/,pcidev,1537016166,"I was looking for some cool deep leaning project. Could any one suggest me list of new deep learning project, that I can work on from scratch. 

May be more related to the language, but every suggestion is welcomed. :)

Also would any one interested in working on some group project. I was thinking of work  on some research on Machine Translation Using Monolingual Corpora. If interested ping me, personally we could discuss.  ",0,0,False,self,,,,,
82,deeplearning,t5_2t5eh,2018-9-16,2018,9,16,12,9g7f1i,self.deeplearning,CVPR 2018 | Paper Review: LayoutNet,https://www.reddit.com/r/deeplearning/comments/9g7f1i/cvpr_2018_paper_review_layoutnet/,steeveHuang,1537067005,"This week, I would like to share with you another CVPR paper, ""LayoutNet"", regarding 3D layout reconstruction from 2D images. In this video, I will explain the detail of the Network structure and how it optimizes the parameters. Hope you like it. :)

r/https://www.youtube.com/watch?v=NBxsfyDaPuk&amp;t=71s",0,11,False,self,,,,,
83,deeplearning,t5_2t5eh,2018-9-16,2018,9,16,17,9g97ab,self.deeplearning,"How can I understand the maths of back propagation of neural network, CNN and RNN?",https://www.reddit.com/r/deeplearning/comments/9g97ab/how_can_i_understand_the_maths_of_back/,kitgary,1537088019,"I have been struggling for over 3 months to understand the maths (especially multivariable calculus part) of back propagation algorithm, I have read many resources, taking online courses such as taking Andrew Ng's Deep Learning Specialization, reading books and blog articles but none of them help to teach me back propagation step by step, I am totally lost and really want to give me. Can anyone help?",6,6,False,self,,,,,
84,deeplearning,t5_2t5eh,2018-9-17,2018,9,17,2,9gci26,self.deeplearning,Could you use reinforcement learning to generate a model,https://www.reddit.com/r/deeplearning/comments/9gci26/could_you_use_reinforcement_learning_to_generate/,CzoKc,1537119888,Could you use reinforcement learning to generate different models for e.g. for object detection. So in a way you will be using machine learning to generate machine learning ,4,13,False,self,,,,,
85,deeplearning,t5_2t5eh,2018-9-17,2018,9,17,4,9gdbjw,self.deeplearning,Capsule networks vs one pixel attack,https://www.reddit.com/r/deeplearning/comments/9gdbjw/capsule_networks_vs_one_pixel_attack/,Numanrsheidat,1537125751,Are capsnets resistant to one pixel attacks or are they just better than cnn?,1,6,False,self,,,,,
86,deeplearning,t5_2t5eh,2018-9-17,2018,9,17,6,9ge9b0,github.com,"Semantic Segmentation Suite in TensorFlow. Implement, train, and test new Semantic Segmentation models easily!",https://www.reddit.com/r/deeplearning/comments/9ge9b0/semantic_segmentation_suite_in_tensorflow/,gseif94,1537132551,,0,7,False,default,,,,,
87,deeplearning,t5_2t5eh,2018-9-17,2018,9,17,7,9gf177,self.deeplearning,"Google's tpu have a lot of performance far exceeds gpu, will TPU completely replace gpu in artificial intelligence ?",https://www.reddit.com/r/deeplearning/comments/9gf177/googles_tpu_have_a_lot_of_performance_far_exceeds/,asda43asdf23423,1537138707,the  gpu  will not be necessary in artificial intelligence  ?,3,1,False,self,,,,,
88,deeplearning,t5_2t5eh,2018-9-17,2018,9,17,23,9gkr1q,self.deeplearning,CPU power for deep learning model processing,https://www.reddit.com/r/deeplearning/comments/9gkr1q/cpu_power_for_deep_learning_model_processing/,suraty,1537194260,"Hello,
In a system
CPU = Intel(R) Xeon(R) CPU E5-2699 v4 @ 2.20GHz 2.20 GHz (2 processor)
Ram = 64.0 GB
Windows10

I installed Keras on it to deep learning programming.
My models often contain about 20 million parameters. 
Is it a suitable system to run the deep learning models?
Thank you",3,2,False,self,,,,,
89,deeplearning,t5_2t5eh,2018-9-18,2018,9,18,1,9glk4o,self.deeplearning,How does a deconvolution layer work?,https://www.reddit.com/r/deeplearning/comments/9glk4o/how_does_a_deconvolution_layer_work/,thepixelatedguy,1537200053,"I have read some literature of deconvolutional layers of transpose convolutions but i am still confused about the complete architecture of these networks,why do we substract bias from the input before multiplying with filters and is the a non-linear activation used after a transpose convolution?",0,2,False,self,,,,,
90,deeplearning,t5_2t5eh,2018-9-18,2018,9,18,1,9glyhr,self.deeplearning,Does horizontally flipping a face during data augmentation helps in face recognition?,https://www.reddit.com/r/deeplearning/comments/9glyhr/does_horizontally_flipping_a_face_during_data/,rexlow0823,1537202576,"Had a weird thought this whole day and decided to get it out. As per title, so when doing face recognition we generally want to acquire as many samples of faces of a person as possible. So one of the ways I came up is to horizontally flip the face of an image sample, as what we would usually do in object recognition. 

If anyone has done it before, how does it affect the Embeddings, lets take FaceNet for example. 

Thanks. ",0,0,False,self,,,,,
91,deeplearning,t5_2t5eh,2018-9-18,2018,9,18,3,9gmx3z,hackaday.com,AI FINDS MORE SPACE CHATTER,https://www.reddit.com/r/deeplearning/comments/9gmx3z/ai_finds_more_space_chatter/,keghn,1537208943,,0,5,False,default,,,,,
92,deeplearning,t5_2t5eh,2018-9-18,2018,9,18,15,9gscwp,self.deeplearning,A dataset contained spatial and temporal features and CNN model,https://www.reddit.com/r/deeplearning/comments/9gscwp/a_dataset_contained_spatial_and_temporal_features/,suraty,1537251830,"Hello, 

A dataset is contained of spatial and temporal features.

It contains the time series data (2 min intervals) of the sections of a map.

It is 320*480 (320 map sections and 480-time intervals). Each row belongs to a section and each column is a time interval. So each cell in the dataset is a value of data in a map section in a time interval.

I would like to make a model to import all map sections in 40 min and predict the following 10 next min of all map sections.

So the input shape equals 320*20 and the output shape will be 320*5.

I split data to 320*20 as X and 320*5 as Y samples.

The input and the output of the model are 2-dimensional matrixes.

I can consider the input as a one channel image (320*20*1) and it is possible to use a CNN model.

The codes of the final architecture of my model:

    model = models.Sequential()
    model.add(Conv2D(256,(3, 3),
                 activation='relu',
                 input_shape=(320,20,1), padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2,2)))

    model.add(Flatten())
    model.add(Dense(1600))

    model.summary()

The Loss value (MSE) is about 70. Is it lower than the random prediction?

I reshaped the output to 1600 (320*5) which the final Dense layer expects.

While the output is 2d. Does it make the model erroneous?

Thank you",0,6,False,self,,,,,
93,deeplearning,t5_2t5eh,2018-9-18,2018,9,18,18,9gtc9s,self.deeplearning,Trainable vs Non Trainable Parameters,https://www.reddit.com/r/deeplearning/comments/9gtc9s/trainable_vs_non_trainable_parameters/,PiAreSqured,1537263355,"I am using LSTM's for a project, I am using keras for prototyping. This is what the summary looks like

    Layer (type)                 Output Shape              Param #   
    =================================================================
    embedding_12 (Embedding)     (None, 30, 300)           29372700  
    _________________________________________________________________
    bidirectional_21 (Bidirectio (None, 30, 64)            85248     
    _________________________________________________________________
    dropout_11 (Dropout)         (None, 30, 64)            0         
    _________________________________________________________________
    bidirectional_22 (Bidirectio (None, 40)                13600     
    _________________________________________________________________
    dense_11 (Dense)             (None, 2)                 82        
    =================================================================
    Total params: 29,471,630
    Trainable params: 29,471,630
    Non-trainable params: 0

I have 661119 training samples, and from what I have read online and from discussions is that ideally one should have less trainable parameters then the training examples. I am using pre-trained word embedding. 

So the questions are:

1. As I know a little bit about using pre-trained weights, one has to train it for few iterations and then freeze them, but if it train them then the trainable parameters exceeds the number of samples and I can not justify if my model is not just memorizing instead of learning something. 
2. If I freeze the embedding layer, the performance of the model decrease by 10% (when I do not freeze the embedding layer, I am using early stopping to make sure that my model do not overfit, training pre-trained models generally overfits, but I am making sure mine doesn't).  So the question is should I take 10% dip and ensure that my trainable parameters are less than my training samples or not?
3. How to interpret these trainable parameters?

It would be really helpful if some one could point me out in this direction, some resources or papers explaining this. 

Thank You!

&amp;#x200B;

&amp;#x200B;",6,3,False,self,,,,,
94,deeplearning,t5_2t5eh,2018-9-19,2018,9,19,0,9gw0xi,self.deeplearning,How to calculate memory usage of NNs,https://www.reddit.com/r/deeplearning/comments/9gw0xi/how_to_calculate_memory_usage_of_nns/,DuckDuckFooGoo,1537285943,What are the steps to theoretically calculate the needed CPU or GPU RAM per processor,4,2,False,self,,,,,
95,deeplearning,t5_2t5eh,2018-9-19,2018,9,19,1,9gwkjq,github.com,convert videos (eg. .avi) to TensorFlow's tfrecords file format,https://www.reddit.com/r/deeplearning/comments/9gwkjq/convert_videos_eg_avi_to_tensorflows_tfrecords/,whiletrue2,1537289598,,0,2,False,default,,,,,
96,deeplearning,t5_2t5eh,2018-9-19,2018,9,19,5,9gykjc,mukul-rathi.github.io,Backpropagation for any Network,https://www.reddit.com/r/deeplearning/comments/9gykjc/backpropagation_for_any_network/,mrathi12,1537303286,,2,7,False,default,,,,,
97,deeplearning,t5_2t5eh,2018-9-19,2018,9,19,16,9h30fx,self.MachineLearning,[D] Anyone having trouble reading a particular paper ? Post it here and we'll help figure out any parts you are stuck on | Anyone having trouble finding papers on a particular concept ? Post it here and we'll help you find papers on that topic [ROUND 3],https://www.reddit.com/r/deeplearning/comments/9h30fx/d_anyone_having_trouble_reading_a_particular/,harshalmittal4,1537341255,,2,1,False,default,,,,,
98,deeplearning,t5_2t5eh,2018-9-19,2018,9,19,16,9h34p7,self.deeplearning,Attention mechanism,https://www.reddit.com/r/deeplearning/comments/9h34p7/attention_mechanism/,suraty,1537342678,"Hello,
I am a beginner in deep learning.
What is the attention mechanism in CNN and LSTM networks in simple words?
IS there any simple and short code for example?

Thank you",3,11,False,self,,,,,
99,deeplearning,t5_2t5eh,2018-9-20,2018,9,20,0,9h605w,self.deeplearning,Profiling user's preferences based on tagged pictures,https://www.reddit.com/r/deeplearning/comments/9h605w/profiling_users_preferences_based_on_tagged/,Iddogal,1537369993,"Hello, I would like to create a DL model using a dataset with pictures tagged from 1 to 5 by a specific user.
I was hoping it will learn his specific preferences on those pictures, understand and predict his specific preferences on pictures of the same kind. 
I have read about surrogate modeling and wondered if there are algorithms of that kind that models a person point of view, and if not then any other kind of profiling models. Specific on pictures of faces would really help and models with academic research are even better. Thanks in advance.",0,1,False,self,,,,,
100,deeplearning,t5_2t5eh,2018-9-20,2018,9,20,2,9h73vn,towardsdatascience.com,Semantic Segmentation with Deep Learning: A guide and code,https://www.reddit.com/r/deeplearning/comments/9h73vn/semantic_segmentation_with_deep_learning_a_guide/,lohoban,1537377582,,0,2,False,default,,,,,
101,deeplearning,t5_2t5eh,2018-9-20,2018,9,20,3,9h7uq4,self.deeplearning,use-cases of variational autoencoders,https://www.reddit.com/r/deeplearning/comments/9h7uq4/usecases_of_variational_autoencoders/,kei_kuro,1537382757,"I've been reading about VAE's, and I'm really excited about different ways to apply them. Does this idea make sense in theory?

Let's say that we have a bunch of people and their messages (just an example), and we want to learn the distribution of people based on the words they use. For example, male &amp; female / young &amp; old people would speak differently. For simplicity, let's represent a person as an MxD matrix of their top M most used D-dimensional word embeddings.

Could we expect a variational autoencoder to be able to learn concept vectors like male vs female and young vs old from data like this? To be more explicit, we would train a variational autoencoder to reconstruct this matrix, and use the decoder as a way to vectorize users.",0,2,False,self,,,,,
102,deeplearning,t5_2t5eh,2018-9-20,2018,9,20,3,9h7xo4,techxplore.com,Fast object detection in videos using region-of-interest packing,https://www.reddit.com/r/deeplearning/comments/9h7xo4/fast_object_detection_in_videos_using/,keghn,1537383322,,0,16,False,default,,,,,
103,deeplearning,t5_2t5eh,2018-9-20,2018,9,20,4,9h881n,jackterwilliger.com,"Attractor Networks, (A bit of) Computational Neuroscience Part III",https://www.reddit.com/r/deeplearning/comments/9h881n/attractor_networks_a_bit_of_computational/,dergthemeek,1537385324,,0,5,False,default,,,,,
104,deeplearning,t5_2t5eh,2018-9-20,2018,9,20,5,9h8vti,deep3d-descriptor.informatik.uni-freiburg.de,A learned feature descriptor for 3D LiDAR Scans (IROS-2018),https://www.reddit.com/r/deeplearning/comments/9h8vti/a_learned_feature_descriptor_for_3d_lidar_scans/,deep_descriptor,1537389826,,2,3,False,default,,,,,
105,deeplearning,t5_2t5eh,2018-9-20,2018,9,20,7,9h9pnw,datasciencecentral.com,Introduction to Deep Learning,https://www.reddit.com/r/deeplearning/comments/9h9pnw/introduction_to_deep_learning/,psangrene,1537395931,,0,1,False,default,,,,,
106,deeplearning,t5_2t5eh,2018-9-20,2018,9,20,17,9hdnte,self.deeplearning,Usecases of estimating object's velocity from vibrations and audio,https://www.reddit.com/r/deeplearning/comments/9hdnte/usecases_of_estimating_objects_velocity_from/,Northpaw42,1537433712,"Hey everyone, I have a following setup: microphone and a sensor capable of capturing vibrations attached to an object (position of the sensors is not yet strictly defined). As the object moves over a surface it creates vibrations and some audio signal. I want to use deep learning to estimate speed of the object from those information. I'm now in a early phase where I'm trying to figure out what this could be used for. I have come up with few ideas (such as improving precision of gaming mice on surfaces where optical flow sensor isn't optimal) but I'm looking for more. Any suggestions? ",4,5,False,self,,,,,
107,deeplearning,t5_2t5eh,2018-9-20,2018,9,20,22,9hfd2c,towardsdatascience.com,How to train Deep Learning models on AWS Spot Instances using Spotty (with an example for Tacotron 2 speech synthesis model),https://www.reddit.com/r/deeplearning/comments/9hfd2c/how_to_train_deep_learning_models_on_aws_spot/,apls777,1537450580,,0,1,False,default,,,,,
108,deeplearning,t5_2t5eh,2018-9-21,2018,9,21,2,9hhdo7,reddit.com,Illustrated Guide to Recurrent Neural Networks,https://www.reddit.com/r/deeplearning/comments/9hhdo7/illustrated_guide_to_recurrent_neural_networks/,lohoban,1537465905,,0,19,False,default,,,,,
109,deeplearning,t5_2t5eh,2018-9-21,2018,9,21,2,9hhfr8,github.com,Luminoth: Deep Learning toolkit for Computer Vision,https://www.reddit.com/r/deeplearning/comments/9hhfr8/luminoth_deep_learning_toolkit_for_computer_vision/,lohoban,1537466339,,0,0,False,default,,,,,
110,deeplearning,t5_2t5eh,2018-9-21,2018,9,21,3,9hhwum,self.deeplearning,"Can curriculum learning, GANs and others be considered as ""metaheuristics""?",https://www.reddit.com/r/deeplearning/comments/9hhwum/can_curriculum_learning_gans_and_others_be/,perilo,1537469794,Thanks.,1,1,False,self,,,,,
111,deeplearning,t5_2t5eh,2018-9-21,2018,9,21,4,9hie61,flyelephant.net,Overview of the TOP 10 Machine Learning Frameworks,https://www.reddit.com/r/deeplearning/comments/9hie61/overview_of_the_top_10_machine_learning_frameworks/,flyelephant,1537473187,,0,0,False,default,,,,,
112,deeplearning,t5_2t5eh,2018-9-21,2018,9,21,19,9hocki,self.deeplearning,Already trained model data for FakeApp,https://www.reddit.com/r/deeplearning/comments/9hocki/already_trained_model_data_for_fakeapp/,mltraningmodels,1537526004,"Hi iam looking for already trained data file of a face for Fakeapp,i don't have much GPU resources that is why.

P.s: This is just for my own curiosity and learning,and would'nt be used for any adult purposes,the modelled data can be either be of male or female face.

Thanks",1,1,False,self,,,,,
113,deeplearning,t5_2t5eh,2018-9-21,2018,9,21,21,9hpiwj,marktechpost.com,Deep Learning : Write your own Bible ( An Application of Generative Adversarial Networks (GAN)),https://www.reddit.com/r/deeplearning/comments/9hpiwj/deep_learning_write_your_own_bible_an_application/,asifrazzaq1988,1537534336,,6,14,False,default,,,,,
114,deeplearning,t5_2t5eh,2018-9-22,2018,9,22,0,9hr5vf,self.deeplearning,Attention Layer of BiDAF Model - Intuition,https://www.reddit.com/r/deeplearning/comments/9hr5vf/attention_layer_of_bidaf_model_intuition/,ImaginaryAnon,1537544580,"I am currently studying the BiDAF model for using it in Machine Comprehension task. I looked at the mathematics they implemented in the model. And I kind of understood the mathematics. But I didn't get the intuition of it. I still have a question like ""Why they did this? What's the outcome of implementing such complex functionality?"" Someone in here said that ""There is nothing like magic in any model, there's always a reason behind it's implementation"".

## Here's what I know so that you can correct me if I made any mistake
The main idea in BiDAF model is that attention should flow both waysfrom the context to the question and from the question to the context. I will be using notations ci for ith word in the comprehension/context and qi for ith word in question.

We first compute the similarity matrix S  RNM, which contains a similarity score Sij for each pair (ci , qj ) of context and question hidden states. Sij = wT sim[ci ; qj ; ci  qj ]  R Here, ci  qj is an elementwise product and wT is a weight vector. Described in equation below:

Next, we perform Context-to-Question (C2Q) Attention. (This is similar to the dot product attention). We take the row-wise softmax of S to obtain attention distributions i , which we use to take weighted sums of the question hidden states qj , yielding C2Q attention outputs ai.
https://cdn-images-1.medium.com/max/1000/1*kcckGB2g7rHT_lbKV85wUg.png

Next, we perform Question-to-Context(Q2C) Attention. For each context location i  {1, . . . , N}, we take the max of the corresponding row of the similarity matrix, mi = max_over_j(Sij)  R. Then we take the softmax over the resulting vector m  RNthis gives us an attention distribution   RN over context locations. We then use  to take a weighted sum of the context hidden states cithis is the Q2C attention output c prime.
https://cdn-images-1.medium.com/max/1000/1*VVOiMKLn1MLav3blYyPrYw.png

Finally we combine both the outputs of C2Q and Q2C as below:
https://cdn-images-1.medium.com/max/1000/1*PXdIGEJrrn3VuTlQRodAaQ.png

## My question
I got the mathematics implemented by I don't know what each step in here does intuitively. Can someone explain this please.. Thank you.",0,1,False,self,,,,,
115,deeplearning,t5_2t5eh,2018-9-22,2018,9,22,1,9hrtyg,self.deeplearning,Pose detection accurate enough to detect finger movement.,https://www.reddit.com/r/deeplearning/comments/9hrtyg/pose_detection_accurate_enough_to_detect_finger/,GingerBoredMan,1537548771,"I've been working on a robotic arm that shadows a human arm via camera as a pet project. While i can get it to move along the larger joints using PoseNet, I'm having a tough time doing the same with fingers. Anyone have any ideas to overcome this?",2,5,False,self,,,,,
116,deeplearning,t5_2t5eh,2018-9-22,2018,9,22,2,9hs98t,sumo.ly,Learn Data Science - Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/9hs98t/learn_data_science_deep_learning_in_python/,cntcee,1537551442,,0,0,False,default,,,,,
117,deeplearning,t5_2t5eh,2018-9-22,2018,9,22,10,9hvr44,news.mit.edu,"Machine-learning system tackles speech and object recognition, all at once",https://www.reddit.com/r/deeplearning/comments/9hvr44/machinelearning_system_tackles_speech_and_object/,asifrazzaq1988,1537578107,,0,1,False,default,,,,,
118,deeplearning,t5_2t5eh,2018-9-22,2018,9,22,16,9hxydd,self.deeplearning,Computing MSE loss in a model,https://www.reddit.com/r/deeplearning/comments/9hxydd/computing_mse_loss_in_a_model/,suraty,1537601789,"Hello,
I know that the MSE value is the average squared difference between the estimated values and what is estimated. 

In a model, there are several inputs and outputs (15000 samples), while each output is a tuple of numbers (1000 cells). 

How will the MSE calculate for all of the inputs? Is it the average of MSEs of each output?

Each input is a number between 0 and 80, what will be the maximum value of the MSE?

Thank you

",1,2,False,self,,,,,
119,deeplearning,t5_2t5eh,2018-9-23,2018,9,23,2,9i1915,self.deeplearning,ACL 2018 | Paper Review: Hierarchical Neural Story Generation,https://www.reddit.com/r/deeplearning/comments/9i1915/acl_2018_paper_review_hierarchical_neural_story/,steeveHuang,1537635947,"This week, I am going to talk about an ACL'18 paper with title ""Hierarchical Neural Story Generation"", published by FAIR.

The majority of this video is about the algorithm and the Neural Net structure. It also explain concepts such as Gated Linear Units, Multi-head Attention, and Convolutional Seq2Seq. 

I hope you enjoy it :)

[https://youtu.be/U4TQoRZsj7M](https://youtu.be/U4TQoRZsj7M)",0,12,False,self,,,,,
120,deeplearning,t5_2t5eh,2018-9-23,2018,9,23,6,9i318e,hashtagstatistics.com,How Deep The Deep Learning Is? - Measuring The Depth of Deep Learning,https://www.reddit.com/r/deeplearning/comments/9i318e/how_deep_the_deep_learning_is_measuring_the_depth/,LearningFromData,1537650035,,0,1,False,default,,,,,
121,deeplearning,t5_2t5eh,2018-9-23,2018,9,23,14,9i69mx,self.deeplearning,Instaling Tensorflow on GPU,https://www.reddit.com/r/deeplearning/comments/9i69mx/instaling_tensorflow_on_gpu/,suraty,1537681844,"Hello,
I would like to install Tensorflow on GPU. 

I searched and I found out the Nvidia graphics cards needed. Then I looked at the Device manager window for Display adapters. 

There are two items in it:

* Intel(R) HD Graphics 4600
* NVIDIA GeForce GTX 950M

How can I use the NVIDIA card for installation?

Thank you",3,1,False,self,,,,,
122,deeplearning,t5_2t5eh,2018-9-23,2018,9,23,18,9i77et,self.deeplearning,Is there any other free gpu service like google colab.,https://www.reddit.com/r/deeplearning/comments/9i77et/is_there_any_other_free_gpu_service_like_google/,sanchit2843,1537694869,,12,4,False,self,,,,,
123,deeplearning,t5_2t5eh,2018-9-23,2018,9,23,18,9i78aw,self.deeplearning,Text/Speech classification (natural language -&gt; commands to a machine) using bidirectional LSTM.,https://www.reddit.com/r/deeplearning/comments/9i78aw/textspeech_classification_natural_language/,MountainDrool,1537695229,"Hi, I'd like your honest opinion about my idea and if it's feasible as a school project/masters thesis. 

I've been delving into LSTM neural networks using TensorFlow lately and would like to use them in an automation/control application, which is mainly what my classes specialize on (sensors, controllers, PLCs etc.). During the summer break, due to an arm injury, I've gotten fascinated by speech recognition using deep neural networks, especially recurrent ones (RNNs), but I feel like all the applications are not really applicable in the field of automation. When I went to my project supervisor with this, he came up with using an RNN to classify textual inputs (ideally in my native language ... Czech) to a set of commands (left, right, up, down, lift, ...) which could then be used to control a simple machine (that I would build/simulate) like a crane or something  similar. The main problem I have with this is that i feel like it would be difficult to gather enough data that can be used for training the network for this specific application. The way I see it, I would have to manually come up with enough diverse sentences and then label them with the correct commands to be executed, which seems pretty  time consuming for just one person. Alternatively I could use unsupervised learning, but I've no experience with that and don't know if it would be applicable to something like this.

&amp;#x200B;

I'd be glad for any suggestions for improvement/alteartion of this topic. Also, if you have a suggestion about another aplication that would be better fit for automation using LSTMs, I'd really appreciate it.

&amp;#x200B;

Thank you and have a nice day.",5,7,False,self,,,,,
124,deeplearning,t5_2t5eh,2018-9-23,2018,9,23,20,9i7lmz,self.deeplearning,Graph Convolution Network,https://www.reddit.com/r/deeplearning/comments/9i7lmz/graph_convolution_network/,pcidev,1537700579,Could some one suggest some good reading sources for the graphical convolution network. Any implementation would be nice. ,1,2,False,self,,,,,
125,deeplearning,t5_2t5eh,2018-9-23,2018,9,23,20,9i7usw,self.deeplearning,Object detection easy explanation,https://www.reddit.com/r/deeplearning/comments/9i7usw/object_detection_easy_explanation/,mlwhiz,1537703860,Object Detection using Deep Learning Approaches: An End to End Theoretical Perspective @MLWhiz https://medium.com/@rahulagarwal_20850/object-detection-using-deep-learning-approaches-an-end-to-end-theoretical-perspective-4ca27eee8a9a,1,17,False,self,,,,,
126,deeplearning,t5_2t5eh,2018-9-23,2018,9,23,22,9i8cpl,self.deeplearning,Print the predicted values by a model,https://www.reddit.com/r/deeplearning/comments/9i8cpl/print_the_predicted_values_by_a_model/,suraty,1537709262,"Hello,
I use the Keras (Tensorflow backend).

After building a model, it should train and test the model by data.

My codes:

    model.compile(optimizer='adamax', loss='mse', metrics=['mae'])

    model.fit(train_x, train_y, batch_size=batch_size,
                    epochs=epochs, verbose=2,
                    callbacks=early_stopping,
                    validation_data=(val_x, val_y))


    model.evaluate(test_x, test_y)

The output of the evaluation of the model on the test data shows the loss and the metrics values and the predicted time.
I would like to print the predicted values. In other words, the numbers or values whom the model produces in the evaluation.
I like to look at the predicted numbers and compare them with expected numbers.
How can I print the output?
Thank you",1,1,False,self,,,,,
127,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,2,9i9ycv,self.deeplearning,Combining improvements in deep reinforcement learning,https://www.reddit.com/r/deeplearning/comments/9i9ycv/combining_improvements_in_deep_reinforcement/,user180921,1537722338,,0,1,False,self,,,,,
128,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,2,9ia3t6,rebrand.ly,Review (YouTube): Combining Improvements in Deep Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/9ia3t6/review_youtube_combining_improvements_in_deep/,user180921,1537723446,,0,1,False,default,,,,,
129,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,3,9iae90,self.deeplearning,Methods for speeding up inference performance?,https://www.reddit.com/r/deeplearning/comments/9iae90/methods_for_speeding_up_inference_performance/,eovf,1537725619,"Does anyone know of a good recent review article that covers different methods for speeding up inference? Methods that work for the typical CNN that I know of are e.g.

1. Quantization
2. Pruning
3. Architectural tricks (e.g. separable convolutions)

I would especially be interested in what general tools currently exist in category (3) as well as a good intro to (1).",0,2,False,self,,,,,
130,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,4,9iazlu,self.deeplearning,How is the best approach to execute a multilabel classification problem when you have a lots of zeroes?,https://www.reddit.com/r/deeplearning/comments/9iazlu/how_is_the_best_approach_to_execute_a_multilabel/,Khiel_Arclight,1537729848,"Hello!

&amp;#x200B;

I'm trying to run a multilabel classification where I use title and description of a video. However, My dataset has over 2 million videos and more than 400 classes. The main issue I'm facing is that the classes have a lot of zeroes (the most frequent class represents about 19% of the whole dataset). Is there a more comfortable way to approach this problem?",0,1,False,self,,,,,
131,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,6,9ic9lo,youtube.com,Depthwise Separable Convolution - A FASTER CONVOLUTION!,https://www.reddit.com/r/deeplearning/comments/9ic9lo/depthwise_separable_convolution_a_faster/,italo3d,1537739265,,2,11,False,image,,,,,
132,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,7,9ickdn,self.deeplearning,Multivariate DA-RNN multi-step forecasting PyTorch,https://www.reddit.com/r/deeplearning/comments/9ickdn/multivariate_darnn_multistep_forecasting_pytorch/,ThrwKps,1537741620,"I've implemented a DA-RNN model mostly [following this example in PyTorch](http://chandlerzuo.github.io/blog/2017/11/darnn) which works well for 1-step predictions for my problem. 

Now I wanted to test multi-step predictions, but I can't seem to understand how to do it without inadvertently using 'future' data from my test sample. The trivial approach would be to append the prediction at each step and use the appended input to get the next prediction and repeat for however many steps I want. However, I also need to input all exogenous factors for each time step which, unless I'm missing something obvious, I don't have unless I use future data. 

Another approach would've been training the model over a lagged time series by however many steps I want to forecast, but because previous values of the target series are used as an input for the decoder I also cannot do that, since the lagged series technically wouldn't exist ""today"" for me to forecast ""tomorrow"".

In the end, the solution I could come up with would be to also predict the exogenous factors with other models in parallel to predicting my target series so I'd have the full input for each time step without looking ahead in my test data, but this doesn't feel like a good approach. 

Is there any other way of doing a multi-step forecast that I'm missing or is this model just not suited for it?

Thanks in advance.",3,2,False,self,,,,,
133,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,10,9idx3e,self.deeplearning,"Batch size greater than data length, what happens?",https://www.reddit.com/r/deeplearning/comments/9idx3e/batch_size_greater_than_data_length_what_happens/,Monster-Zero,1537753073,"I'm experimenting with batch size versus data size, but am unclear on what happens when batch size is significantly larger than the amount of rows in my data. 


Let's say the data is 800 rows long, but my batch size is 1000. What happens with the extra 200 allocated batches? Is the data just repeating to fill the extra size? Is it filled with null entries?


I seem to get better models when I increase the batch size to like 2000 (the data is approx 800 rows long) but I'm wondering why the numbers returned are better...?",1,1,False,self,,,,,
134,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,14,9if965,self.deeplearning,#DeepStories,https://www.reddit.com/r/deeplearning/comments/9if965/deepstories/,1adamj,1537765788,"[\#Moment](https://www.facebook.com/hashtag/moment?source=feed_text&amp;__xts__%5B0%5D=68.ARAuQOPSehHI-xh6rjRPuFIirek3nJQ28NtJbQF3i5rlvJUySmLcu5j_93Rsw2jH1oFGGotZ4fPCp7WloYn3OlkvvnfuW8pAuNRMa3dVCUqpyGVTLXH6MYADCT2mc6_IG8Sq5GfRlDum52CVKx3MMA8LYsErYEOmDSQf6sRbP6SqIsgXGDYijvg&amp;__tn__=%2ANK-R)

Imagine belief succeeding grief.  
Shouldn't this soul already know?   
Trust not and find again, within.   
Do you believe?

Eternal adjournment, we may never, cease to find.  
Yet, we seek such in others in hopes to survive.   
Drain and drought for days, we seek. And seep. [\#Deep](https://www.facebook.com/hashtag/deep?source=feed_text&amp;__xts__%5B0%5D=68.ARAuQOPSehHI-xh6rjRPuFIirek3nJQ28NtJbQF3i5rlvJUySmLcu5j_93Rsw2jH1oFGGotZ4fPCp7WloYn3OlkvvnfuW8pAuNRMa3dVCUqpyGVTLXH6MYADCT2mc6_IG8Sq5GfRlDum52CVKx3MMA8LYsErYEOmDSQf6sRbP6SqIsgXGDYijvg&amp;__tn__=%2ANK-R)  
Let this sink..

For no one is right and two sensing, is still less than five.   
Thrive. And Survive.   
For I to exist, we must exhaust ourselves.  
Delve into you. Dive with me.

From the depths, I yearn to reach an understanding of what my life purpose may be. In a deep thinking mind-set, I spin and continue not to win. I spin &amp; sin..  
Yet, here I am, again.

Think attention seeking, speak for your self. Now let that sink.. I attack posed threats head on and forgive the stubborn. For I am..  
And in this I say,   
I forgive the author. [\#Lessthan10](https://www.facebook.com/hashtag/lessthan10?source=feed_text&amp;__xts__%5B0%5D=68.ARAuQOPSehHI-xh6rjRPuFIirek3nJQ28NtJbQF3i5rlvJUySmLcu5j_93Rsw2jH1oFGGotZ4fPCp7WloYn3OlkvvnfuW8pAuNRMa3dVCUqpyGVTLXH6MYADCT2mc6_IG8Sq5GfRlDum52CVKx3MMA8LYsErYEOmDSQf6sRbP6SqIsgXGDYijvg&amp;__tn__=%2ANK-R)",1,2,False,self,,,,,
135,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,17,9ig7ib,self.deeplearning,Personal profiling algorithm,https://www.reddit.com/r/deeplearning/comments/9ig7ib/personal_profiling_algorithm/,Iddogal,1537777468,"Hello, I am trying to build a photo based tinder like application, that tries to profile a person's preferences, in order to predict future choices. 

Is there any known algorithm for deep learning picture based profiling? (Looking for academic researched algorithm)",2,3,False,self,,,,,
136,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,17,9ig7o7,self.deeplearning,Need help for active learning,https://www.reddit.com/r/deeplearning/comments/9ig7o7/need_help_for_active_learning/,rmfajri,1537777543,"Hi guys, I need help converting my raw text data to work in active learning. I found one library that seem promising [https://github.com/cosmic-cortex/modAL](https://github.com/cosmic-cortex/modAL). Since I am not familiar with deep learning. How do I convert my raw text data to work in this library. Thank you for your help guys. ",0,1,False,self,,,,,
137,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,21,9ihgcs,self.deeplearning,"Is this multi-class, multi-label, or something else?",https://www.reddit.com/r/deeplearning/comments/9ihgcs/is_this_multiclass_multilabel_or_something_else/,lillojohn,1537791773,"
0
down vote
favorite
I want to create a simple deep learning model in keras. I have the data of a webshop. For my model I want to use the order data. Each order has different products, those products have a category.

My goal is to know which category match with each other. Example: Computer -&gt; Keyboard , Screen -&gt; HDMI cable.

I want to do this by matching categories with each other in Keras.

The data looks like this:

[""Computer""] -&gt; [""Keyboard"", ""Mouse"", ""Monitor""]

[""Monitor""] -&gt; [""HDMI cable""]

[""Printer""] -&gt; [""Paper"", ""Cartridge""]
So, I thought to use the MultiLabelBinarizer for the y_train. There are 205 different categories. And for the X_train, I gave all the answers a unique integer.

X_train[0]:

[0]
y_train[0]:

[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]
I tried a lot of different things.

model = Sequential()
model.add(Dense(len(lb.classes_),input_shape=(1,),
kernel_initializer='he_normal', activation='softmax'))
model.compile(loss='categorical_crossentropy',
  optimizer=eval('Adam(lr=0.1)'),
  metrics=['accuracy'])
model.fit(X_train, y_train, epochs=5, verbose=1)
I tried using different kind of batch sizes, optimizers, activations, learning rates, losses. But the model seems no to be learning. It only gives a max of 3 different categories, to 205 categories.

I want to know if the MultiLabelBinarizer, is the right thing to use. X can be one of the answers, But X can not be multiple answers.

Example:

Input | Prediction | Answer | Result

Computer -&gt; Printer -&gt; Monitor, Keyboard, Mouse -&gt; False

Computer -&gt; Monitor -&gt; Monitor, Keyboard, Mouse -&gt; True

Computer -&gt; Keyboard -&gt; Monitor, Keyboard, Mouse -&gt; True

The deep learning model should only predict one category, and check if one of the Answers is true.",4,0,False,self,,,,,
138,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,23,9iicf2,self.deeplearning,reinforcement learning for spam classification?,https://www.reddit.com/r/deeplearning/comments/9iicf2/reinforcement_learning_for_spam_classification/,s1korrrr,1537799067,"Hello all, I was wondering about that.

I have model prepared with MLP Classifier. I have 41 features and trying to predict is it/or will be spam or not.

Everything is real-time read and written in the MySQL DB. So I have constant updates. It has around 95% average precision/recall/accuracy. I want to achieve better recall to lower false-negatives.

I was thinking about implementing some reinforcement learning algorithms. What do you think? Does it make sense at all?",3,3,False,self,,,,,
139,deeplearning,t5_2t5eh,2018-9-24,2018,9,24,23,9iicq7,self.deeplearning,Request for Quotation of a Use Case from the DL Community; Parse Chinese Character Subtitles Physically Embedded from Videos,https://www.reddit.com/r/deeplearning/comments/9iicq7/request_for_quotation_of_a_use_case_from_the_dl/,WholesaleDreamBoy,1537799134,"I'm interested in creating a tool that can parse Chinese Character subtitles that are physically embedded in videos and output them to text with timestamps.

&amp;#x200B;

There can sometimes be additional character overlays present, static/dynamic:

*Processing img aixn3vrz17o11...*

Subtitles appear to be:

1. static
2. refresh periodically
3. pop up in the same general area
4. a solid color
5. generally standardized size

This is intended to be a SaaS product where customers would provide videos as input which I imagine should be used to further train the network; I have general development experience but no DL.  


How much resources would you estimate would be required to develop this application? Hours to code, length/size of dataset to train application, monetary costs including hiring an engineer, maintenance and other potential considerations? Thank you.",4,3,False,self,,,,,
140,deeplearning,t5_2t5eh,2018-9-25,2018,9,25,1,9ijany,self.deeplearning,Can I deploy pytorch model on web?,https://www.reddit.com/r/deeplearning/comments/9ijany/can_i_deploy_pytorch_model_on_web/,sanchit2843,1537805755,,4,4,False,self,,,,,
141,deeplearning,t5_2t5eh,2018-9-26,2018,9,26,5,9ivkht,codingwoman.com,My First Deep Learning Workshop,https://www.reddit.com/r/deeplearning/comments/9ivkht/my_first_deep_learning_workshop/,codingwoman_,1537905845,,0,9,False,default,,,,,
142,deeplearning,t5_2t5eh,2018-9-26,2018,9,26,10,9ixy6q,datasciencecentral.com,Sequence Modeling with Neural Networks - Part I,https://www.reddit.com/r/deeplearning/comments/9ixy6q/sequence_modeling_with_neural_networks_part_i/,psangrene,1537924071,,0,2,False,default,,,,,
143,deeplearning,t5_2t5eh,2018-9-26,2018,9,26,12,9iysrq,reddit.com,Deep Learning Framework Power Scores 2018,https://www.reddit.com/r/deeplearning/comments/9iysrq/deep_learning_framework_power_scores_2018/,lohoban,1537931127,,2,5,False,default,,,,,
144,deeplearning,t5_2t5eh,2018-9-26,2018,9,26,19,9j1fbi,medium.com,Image Classification on the Real-World,https://www.reddit.com/r/deeplearning/comments/9j1fbi/image_classification_on_the_realworld/,marceloboeira,1537959219,,1,2,False,default,,,,,
145,deeplearning,t5_2t5eh,2018-9-26,2018,9,26,20,9j1k51,self.deeplearning,What is difference between blackbox and whitebox attack in adversarial attack domain,https://www.reddit.com/r/deeplearning/comments/9j1k51/what_is_difference_between_blackbox_and_whitebox/,postero20,1537960490," Nowadays I really interested in adversarial attack and defense against to adversarial attack. In almost paper, they said about blackbox attack and whitebox attack. Of course, there is an explanation about those things such as blackblox can not know about the model's parameters, while whitebox know about the ones. However, I can't intuitively understand this concept. Someone who knows the concept PLEASE help me! ",0,0,False,self,,,,,
146,deeplearning,t5_2t5eh,2018-9-27,2018,9,27,0,9j3lax,self.NLP_readingGroup,SUGGESTION !!!,https://www.reddit.com/r/deeplearning/comments/9j3lax/suggestion/,pcidev,1537976213,,1,0,False,default,,,,,
147,deeplearning,t5_2t5eh,2018-9-27,2018,9,27,1,9j3tf1,self.deeplearning,Segmentation using UNET,https://www.reddit.com/r/deeplearning/comments/9j3tf1/segmentation_using_unet/,ganLover,1537977674,"I am performing Segmentation using UNET

&amp;#x200B;

The input images are GREYSCALE and goundtruth images are Binary (Black/ White)

My network outputs GREYSCALE Images

I am using scikit learn- Precision and Recall for measuring the accuracy.

For that I need to have the output images in Binary, so that TP and FP can be calculated.

I can convert the  GREYSCALE Images to Binary, but I do not know how to choose the Threshold value???

Any Threshold value can change the accuracy severly.

&amp;#x200B;",4,4,False,self,,,,,
148,deeplearning,t5_2t5eh,2018-9-27,2018,9,27,1,9j3zu5,self.deeplearning,What is the future of Deep Learning?,https://www.reddit.com/r/deeplearning/comments/9j3zu5/what_is_the_future_of_deep_learning/,codingwoman_,1537978828,Where are we going with the new Deep Learning architectures? What do you think that can be or can not be improved? Will we get stuck at some point?,3,3,False,self,,,,,
149,deeplearning,t5_2t5eh,2018-9-27,2018,9,27,2,9j4lth,self.deeplearning,How does face unlocking on modern phones work?,https://www.reddit.com/r/deeplearning/comments/9j4lth/how_does_face_unlocking_on_modern_phones_work/,ILikeCheapWater,1537982886,"Particularly, I'm interested in how the Samsung Galaxy S9's face unlocking feature works. I guess it uses some form of face recognition and spoof detection (to help against images, videos, masks). Do you guys know of any resource that describes how face unlocking on modern phones work? (the more detailed the better)

I'm asking here because problems such as face recognition seem to have public state of the art solutions. I guess that a lot of companies adopt such public solutions when implementing a feature such as face unlock. I'm interested to learn more about how exactly these face unlocking features work, I mean on phones such as the Galaxy S9, the Galaxy Note 8, the OnePlus 6, the Asus ZenFone 5Z, and [other modern phones](http://blog.awok.com/10-best-face-recognition-phones-2018-face-unlock/) that use only the front camera for the face unlocking feature (everything except the iPhone X).

Main reason why I'm posting this here is that on their [website](https://news.samsung.com/global/in-depth-look-3-how-samsung-streamlined-the-galaxy-s9s-security-features) they call their combination of face recognition and iris scanning a ""deep learning-based verification solution"". Specifically for the face recognition they say ""The Galaxy S9s advanced facial-recognition technology utilizes an immense amount of data to recognize your faces distinct features from a wide range of angles"". What [approach](https://arxiv.org/abs/1804.06655) do they use? Do you guys have any resource/intuition about what exactly they are using? ",9,11,False,self,,,,,
150,deeplearning,t5_2t5eh,2018-9-27,2018,9,27,2,9j4viz,medium.com,Google Brain &amp; Georgia Techs GAN Lab Visualizes Model Training in Browsers,https://www.reddit.com/r/deeplearning/comments/9j4viz/google_brain_georgia_techs_gan_lab_visualizes/,gwen0927,1537984714,,0,3,False,default,,,,,
151,deeplearning,t5_2t5eh,2018-9-27,2018,9,27,16,9jawgi,self.deeplearning,[D] Detecting region of interest in documents using deep learning?.,https://www.reddit.com/r/deeplearning/comments/9jawgi/d_detecting_region_of_interest_in_documents_using/,soulrapier,1538034840,"I have scanned documents in which the regions of interest are either  circled, or ticked and there\`s a lot of variation. I was wondering if I could segment this circled text using YOLO or any other method?. I have many such images, and thus training data is not an issue.",1,1,False,self,,,,,
152,deeplearning,t5_2t5eh,2018-9-27,2018,9,27,17,9jb4o9,self.deeplearning,"Should I get RTX 2080TI, Titan Xp, or GTX 108TI?",https://www.reddit.com/r/deeplearning/comments/9jb4o9/should_i_get_rtx_2080ti_titan_xp_or_gtx_108ti/,iamalotaibi,1538037772,"TL;TR:
As the title suggests, should I get RTX 2080TI, Titan Xp, or GTX 108TI?

Why I need a newer GPU:
I have GTX 670 and I have noticed a huge amount wasted in training, like 3-4 days on average, on my PC. In the other hand, have used K80 x4 for my school's ML/AI club when doing final model by training a larger set of data, but it requires queuing tasks, which might take a longer time than  In both cases, I am annoyed on the waiting time although I have seen my friends who has 1080TI to train the same model that took me 3 days to fully train in my machine, and it took them 7-8 hours of training, which is way better than waiting days to train my models.

Comparing GPUs:
I have saved some money for RTX 2080TI, but I have researched online and they stated that RTX 2080TI performance in training isn't that much good compared to GTX 1080TI performance and the price of RTX 2080TI. In addition, I have noticed that Titan Xp has better benchmarks than GTX 1080TI that's why I am also considering Titan Xp.

Question:
However, I have read an article saying that CUDA 10 will use RTX 2080TI's architecture fully to make the training process x10 faster than GTX 1080TI. Is that true?",6,5,False,self,,,,,
153,deeplearning,t5_2t5eh,2018-9-27,2018,9,27,18,9jb7p1,self.deeplearning,Do i still nedd to go deep into machine learning or should i study only deep learning deeply to become deep learning researcher?,https://www.reddit.com/r/deeplearning/comments/9jb7p1/do_i_still_nedd_to_go_deep_into_machine_learning/,sanchit2843,1538038837,I know basics of machine learning and few algorithms of classification and regression like decision tree svm etc. ,5,7,False,self,,,,,
154,deeplearning,t5_2t5eh,2018-9-27,2018,9,27,19,9jbp17,eleks.com,Attention Models: Amplifying Machine Learning Benefits for Enterprise,https://www.reddit.com/r/deeplearning/comments/9jbp17/attention_models_amplifying_machine_learning/,Victor_Stakh,1538044276,,0,1,False,default,,,,,
155,deeplearning,t5_2t5eh,2018-9-27,2018,9,27,22,9jcyln,self.deeplearning,"[Hardware] NVLink on GeForce RTX, does it pool memory?",https://www.reddit.com/r/deeplearning/comments/9jcyln/hardware_nvlink_on_geforce_rtx_does_it_pool_memory/,Karyo_Ten,1538055610,"I'm on the market for a fresh new workstation dedicated to deep learning. With the 2080ti being released today and 2080 released last week I'm very curious about the consumer NVLink.

Quadro/Tesla NVLink allows GPU to pool their memory together which enables training bigger models or using bigger batch sizes.

Can someone confirm that on consumer RTX 2080 (16GB pooled) or RTX 2080ti (22GB pooled) NVlinked?",12,3,False,self,,,,,
156,deeplearning,t5_2t5eh,2018-9-28,2018,9,28,0,9jdvww,medium.com,What is a neural net exactly?  Medium,https://www.reddit.com/r/deeplearning/comments/9jdvww/what_is_a_neural_net_exactly_medium/,CuttingWithScissors,1538062468,,0,0,False,default,,,,,
157,deeplearning,t5_2t5eh,2018-9-28,2018,9,28,1,9jeimh,evilmartians.com,Learning how to learn deep learninga personal view,https://www.reddit.com/r/deeplearning/comments/9jeimh/learning_how_to_learn_deep_learninga_personal_view/,progapandist,1538066904,,0,25,False,default,,,,,
158,deeplearning,t5_2t5eh,2018-9-28,2018,9,28,3,9jfczx,self.deeplearning,AC-GAN Training,https://www.reddit.com/r/deeplearning/comments/9jfczx/acgan_training/,ganLover,1538072723,"While training the Discriminator for FAKE images from Generator-&gt;

I defined the loss function as-&gt;

True/Fake = criterionTF(discriminator\_output, discriminator\_groundTruth)

Where-&gt; discriminator\_groundTruth=0

&amp;#x200B;

Aux\_Classifier = aux\_criterion(aux\_output, aux\_label) 

&amp;#x200B;

My question is should-&gt; ""aux\_label""  have Ground Truth labels OR any random value because the inputs to Discriminator are fake, so classification does not matter.

&amp;#x200B;

Same goes for Training the Generator from Discriminator's loss

Here discriminator\_groundTruth=1

But what should be the value for-&gt; aux\_label

&amp;#x200B;

PLS HELP!!!!

&amp;#x200B;",0,1,False,self,,,,,
159,deeplearning,t5_2t5eh,2018-9-28,2018,9,28,6,9jgute,self.deeplearning,Project ideas,https://www.reddit.com/r/deeplearning/comments/9jgute/project_ideas/,Shubham3694,1538083342,"\[Suggestions\]

Hello, I'm planning on doing a project (research paper implementation, competition etc) which will have applications in Autonomous (Self-driving) cars. Can you guys me state-of-the-art papers from top conferences(CVPR, NIPS, ICCV, ECCV, ICML etc) published in 2018 or 2017?

Thanks in advance.

 ",0,0,False,self,,,,,
160,deeplearning,t5_2t5eh,2018-9-28,2018,9,28,6,9jh1kw,self.deeplearning,"Papers on Deep Learning approaches for Search Engine problems such as Ranking, Query Processing",https://www.reddit.com/r/deeplearning/comments/9jh1kw/papers_on_deep_learning_approaches_for_search/,satyapk_y12uc231,1538084679,"Hi, 

&amp;#x200B;

Are there any good papers on deep learning for query understanding/ Ranking/ relevance function?

&amp;#x200B;

I know that ad hoc relevance has few models such as DRMM, etc. Have not been able to find many deep learning papers for search engine.

&amp;#x200B;

&amp;#x200B;",0,3,False,self,,,,,
161,deeplearning,t5_2t5eh,2018-9-28,2018,9,28,8,9jhv4d,computerworld.com.au,Insect brain inspired AI better than deep learning models?: No honey bee has ever gone Skynet and decided they would kill all humans,https://www.reddit.com/r/deeplearning/comments/9jhv4d/insect_brain_inspired_ai_better_than_deep/,GtothePtotheN,1538091003,,1,3,False,default,,,,,
162,deeplearning,t5_2t5eh,2018-9-28,2018,9,28,10,9jitbx,onclick360.com,"Still curious about ""What is reinforcement learning?""",https://www.reddit.com/r/deeplearning/comments/9jitbx/still_curious_about_what_is_reinforcement_learning/,onclick360,1538098982,,3,0,False,default,,,,,
163,deeplearning,t5_2t5eh,2018-9-28,2018,9,28,17,9jl392,self.deeplearning,"Updated for Sep 2018 post ""Hardware for Deep Learning. Part 3: GPU"". Added Turing cards",https://www.reddit.com/r/deeplearning/comments/9jl392/updated_for_sep_2018_post_hardware_for_deep/,aleph_two,1538121887,[https://blog.inten.to/hardware-for-deep-learning-part-3-gpu-8906c1644664](https://blog.inten.to/hardware-for-deep-learning-part-3-gpu-8906c1644664),4,4,False,self,,,,,
164,deeplearning,t5_2t5eh,2018-9-28,2018,9,28,23,9jnczi,self.deeplearning,Limiting the model prediction values,https://www.reddit.com/r/deeplearning/comments/9jnczi/limiting_the_model_prediction_values/,suraty,1538144405,"Hello,

There is a deep model for prediction.

The outputs are some numbers between 0 and 80. (In the dataset the outputs are the mean of vehicles speed and they are 0-80)

The model:

    model = models.Sequential()
    model.add(Conv2D(256,(3, 3),
                 activation='relu',
                 input_shape=(236,20,1), padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D((2,2)))

    model.add(Flatten())
    model.add(Dense(1180))

    model.summary()


The model Loss value equals to 70 and I would like to reduce it.

I printed the outputs after evaluating the model by test values and some of the predicted values are more than 80 or less than 0.

How can I limit the model prediction values?

Is it a standard work?

Thank you

",1,1,False,self,,,,,
165,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,0,9jnv1x,medium.com,Facebook Open-Sources SKIP Programming Language,https://www.reddit.com/r/deeplearning/comments/9jnv1x/facebook_opensources_skip_programming_language/,gwen0927,1538148015,,1,2,False,default,,,,,
166,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,2,9joxj4,self.deeplearning,First public 2080 Ti Deep Learning Benchmarks,https://www.reddit.com/r/deeplearning/comments/9joxj4/first_public_2080_ti_deep_learning_benchmarks/,sabalaba,1538155404,[https://lambdalabs.com/blog/2080-ti-deep-learning-benchmarks/](https://lambdalabs.com/blog/2080-ti-deep-learning-benchmarks/),11,19,False,self,,,,,
167,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,3,9jpcmq,self.deeplearning,Calculating the uncertainty in deep learning,https://www.reddit.com/r/deeplearning/comments/9jpcmq/calculating_the_uncertainty_in_deep_learning/,deeplearner4,1538158326,"Hi,  
In the field of deep learning, I'm interested in calculating the uncertainty directly, for example without optimization, but with a function to do so.

I've been googling it, but couldn't find much about it, so I'd appreciate if you could direct me or share your thoughts about that.

Thanks!  
",1,1,False,self,,,,,
168,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,5,9jqg33,self.deeplearning,Deep Learning setup,https://www.reddit.com/r/deeplearning/comments/9jqg33/deep_learning_setup/,Flajt,1538165928,"Hey guys, my question is about my Deep Learning setup:[https://de.pcpartpicker.com/list/Mzkv29](https://de.pcpartpicker.com/list/Mzkv29) . I want to know if it's a good setup and if I can save some money, because currently it's to much. So I would appreciate some feedback and some tips. The server should be for Deep Learning, project hosting/development and NAS (That are the reason behind the big HDD). Maybe it's useful to build two machines (But this might become very expensive)?",8,4,False,self,,,,,
169,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,7,9jreeh,self.deeplearning,Deep Exploration via Bootstrapped DQN Implementation,https://www.reddit.com/r/deeplearning/comments/9jreeh/deep_exploration_via_bootstrapped_dqn/,platinumbjj,1538173121,"So I'm a Master's student taking a deep learning course this semester. As part of our course, I've been asked to do a project by the end of the semester where I have to work on Ian Osband's paper of Deep Exploration via Bootstrapped DQN. 

Unfortunately, however, we won't be covering any reinforcement learning in the course. So I have to teach myself the material. I am allowed to look at any code or resources online to complete the project. Does anyone have an idea on how I should get started? I do have a background in probability models and stochastic processes so I understand the theory of Markov decision processes and Q learning. However, I am not sure about how to get started with the code and implementing the research paper. Would appreciate your input!

Heres' the paper for reference (https://papers.nips.cc/paper/6501-deep-exploration-via-bootstrapped-dqn.pdf)",0,1,False,self,,,,,
170,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,15,9jugry,self.deeplearning,Udacity AI in trading course-free,https://www.reddit.com/r/deeplearning/comments/9jugry/udacity_ai_in_trading_coursefree/,create_urself,1538202991," Hi! I found this course on udacity:[https://in.udacity.com/course/ai-for-trading--nd880](https://in.udacity.com/course/ai-for-trading--nd880),  but I don't have the money to buy this course. Is there any way I can  get the course material for free? If not, can you please suggest some  similar resources? Thanks in advance! ",4,1,False,self,,,,,
171,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,16,9jus70,self.deeplearning,Ian Goodfellow: Input/Parameter linearity in DNNs,https://www.reddit.com/r/deeplearning/comments/9jus70/ian_goodfellow_inputparameter_linearity_in_dnns/,bluesky314,1538207022,"&amp;#x200B;

Ian Goodfellow says at 18:20 in [https://www.youtube.com/watch?v=CIfsB\_EYsVI](https://www.youtube.com/watch?v=CIfsB_EYsVI) : The input of the model to the output of the model is close to being linear or piecewise linear with relatively few pieces. The mapping of the parameters of the model to the output is highly non linear. So the parameters have highly non linear interactions and thats what makes training much harder. Thats why optimising parameters is much harder than optimising inputs.

I don't understand how the inputs are linear and parameters non linear. Can someone pls explain this. He goes on to show an image to illustrate this as well.",0,3,False,self,,,,,
172,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,17,9jv3q3,sumo.ly,"Learn Data Science, Machine and Deep Learning with Python",https://www.reddit.com/r/deeplearning/comments/9jv3q3/learn_data_science_machine_and_deep_learning_with/,atkarti,1538211528,,0,1,False,default,,,,,
173,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,19,9jve1q,i.redd.it,Hierarchical Attention Networks for Document Classification with web demo (Pytorch implementation),https://www.reddit.com/r/deeplearning/comments/9jve1q/hierarchical_attention_networks_for_document/,1991viet,1538215476,,2,1,False,image,,,,,
174,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,19,9jvecz,i.redd.it,Hierarchical Attention Networks for Document Classification with web demo (Pytorch implementation),https://www.reddit.com/r/deeplearning/comments/9jvecz/hierarchical_attention_networks_for_document/,1991viet,1538215595,,7,46,False,image,,,,,
175,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,21,9jwdmx,sumo.ly,"Learn Data Science, Machine and Deep Learning with Python",https://www.reddit.com/r/deeplearning/comments/9jwdmx/learn_data_science_machine_and_deep_learning_with/,frstnm,1538225436,,0,1,False,default,,,,,
176,deeplearning,t5_2t5eh,2018-9-29,2018,9,29,22,9jwqmc,self.deeplearning,Convolutional Sequence to Sequence Learning Detailed Explanation,https://www.reddit.com/r/deeplearning/comments/9jwqmc/convolutional_sequence_to_sequence_learning/,steeveHuang,1538228088,"This video is about Convolutional Sequence to Sequence. It explains the model structure in tail, how it is trained, and how it generates sequences. 

I made this video because some of you PM me about the detail of Conv Seq2Seq, and I was struggling understanding this paper while preparing for the last video, ""ACL 2018 | Paper Review: Hierarchical Neural Story Generation"".

Hope you enjoy it.:)

[https://www.youtube.com/watch?v=iXGFm7oC9TE&amp;t=7s&amp;ab\_channel=SteeveHuang](https://www.youtube.com/watch?v=iXGFm7oC9TE&amp;t=7s&amp;ab_channel=SteeveHuang)",0,3,False,self,,,,,
177,deeplearning,t5_2t5eh,2018-9-30,2018,9,30,3,9jzaan,self.deeplearning,How to finetune a network with batch normalization?,https://www.reddit.com/r/deeplearning/comments/9jzaan/how_to_finetune_a_network_with_batch_normalization/,Arsenal591,1538245386,"Let's say there is a pre-trained network, containing multiple batch-normalization stages, is used for finetuning on another  dataset. 

However, the moving means/variances are usually highly different between different datasets(while weights are usually similar). So how do I fix this problem? Do I need to first compute statistics on the new dataset?",1,2,False,self,,,,,
178,deeplearning,t5_2t5eh,2018-9-30,2018,9,30,13,9k3j9v,self.deeplearning,"Regarding the meaning of ""Eq"",",https://www.reddit.com/r/deeplearning/comments/9k3j9v/regarding_the_meaning_of_eq/,nodejsprogrammer,1538282396,"I'm not sure about the meaning of Eq in following sentence:  

Fully-Connected (FC) layers refer to the standard neural network layers from Eq .

convolution layers use Eq.

&amp;#x200B;

This Eq means equation? ",1,1,False,self,,,,,
179,deeplearning,t5_2t5eh,2018-9-30,2018,9,30,14,9k3ork,self.deeplearning,"Fairly new to deep learning, need some direction.",https://www.reddit.com/r/deeplearning/comments/9k3ork/fairly_new_to_deep_learning_need_some_direction/,thealsomepanda,1538283719,"Hey everyone!

So I am fairly new to deep learning. I know my way pretty well around Python but I still have quite a way to go. But I wanted to take on a project with a friend who creates art for an apparel company. We want to be able to have the program look at designs that are currently on shirts and with those designs create a few designs of its own. 

I've looked around for something like this but I'm having a hard time finding a place to start with this project. Can anybody help point me in the right direction?

Any help is much appreciated!",6,6,False,self,,,,,
180,deeplearning,t5_2t5eh,2018-9-30,2018,9,30,15,9k44n5,i.redd.it,What is Unsupervised Machine learning ??,https://www.reddit.com/r/deeplearning/comments/9k44n5/what_is_unsupervised_machine_learning/,onclick360,1538287915,,3,0,False,image,,,,,
181,deeplearning,t5_2t5eh,2018-9-30,2018,9,30,18,9k4ww2,self.deeplearning,How to use jupter notebook with google cloud ubuntu vm,https://www.reddit.com/r/deeplearning/comments/9k4ww2/how_to_use_jupter_notebook_with_google_cloud/,sanchit2843,1538298626,,3,1,False,self,,,,,
