,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,deeplearning,t5_2t5eh,2019-3-1,2019,3,1,17,aw2h19,self.deeplearning,AI Project - Web application for Object Identification,https://www.reddit.com/r/deeplearning/comments/aw2h19/ai_project_web_application_for_object/,nalinee_choudhary,1551428644,"Using Django &amp; Keras we can develop an web application where user can upload any image &amp; website tells what it is. We can use pretrained Keras model in the backend for the same. 

[AI Project - Web application for Object Identification](https://www.edyoda.com/course/1185/) \- this is the link to the project. ",2,4,False,self,,,,,
1,deeplearning,t5_2t5eh,2019-3-1,2019,3,1,18,aw2yyl,go.learn4startup.com,Sentiment Analysis with Deep Learning of Netflix Reviews,https://www.reddit.com/r/deeplearning/comments/aw2yyl/sentiment_analysis_with_deep_learning_of_netflix/,ObsidianAge,1551432925,,0,2,False,default,,,,,
2,deeplearning,t5_2t5eh,2019-3-1,2019,3,1,20,aw3ojx,self.deeplearning,Great Course on Deep Learning,https://www.reddit.com/r/deeplearning/comments/aw3ojx/great_course_on_deep_learning/,Ta-7,1551438662,"[https://skillsmatter.com/courses/652-deep-learning-fundamentals](https://skillsmatter.com/courses/652-deep-learning-fundamentals)

Skills Matter are also sponsoring a free ticket to infiniteconf 2019 [https://skillsmatter.com/conferences/11187-infiniteconf-2019-the-conference-on-big-data-and-ai](https://skillsmatter.com/conferences/11187-infiniteconf-2019-the-conference-on-big-data-and-ai)

their biggest Data Ai conference, if you sign-up to the course. 

&amp;#x200B;

If you are interested let me know as I can get you a employee discount. ",0,0,False,self,,,,,
3,deeplearning,t5_2t5eh,2019-3-1,2019,3,1,20,aw41v8,badootech.badoo.com,Deep Neural Networks &amp; Image Captioning  badoo_tech,https://www.reddit.com/r/deeplearning/comments/aw41v8/deep_neural_networks_image_captioning_badoo_tech/,lauram16_hello,1551441428,,0,1,False,default,,,,,
4,deeplearning,t5_2t5eh,2019-3-1,2019,3,1,22,aw4m90,medium.com,"""Topology of Learning in Artificial Neural Networks"" 21 Feb 2019 article",https://www.reddit.com/r/deeplearning/comments/aw4m90/topology_of_learning_in_artificial_neural/,BrighterAI,1551445220,,4,38,False,default,,,,,
5,deeplearning,t5_2t5eh,2019-3-1,2019,3,1,23,aw5guh,self.deeplearning,How early is it ok to conclude that your model is overfitting?,https://www.reddit.com/r/deeplearning/comments/aw5guh/how_early_is_it_ok_to_conclude_that_your_model_is/,dchasani,1551450258,"Say you're training a model (transfer learning) which was originally trained on the imagenet dataset (this may be irrelevant).
After how many epochs can you be sure that your model is overfitting and so you should early stop the training so it's not a huge waste of time?

",1,1,False,self,,,,,
6,deeplearning,t5_2t5eh,2019-3-1,2019,3,1,23,aw5o3j,youtu.be,"""Deep Learning for Developers"" with Julien Simon (55min talk from GOTO Amsterdam 2018)",https://www.reddit.com/r/deeplearning/comments/aw5o3j/deep_learning_for_developers_with_julien_simon/,goto-con,1551451407,,1,1,False,image,,,,,
7,deeplearning,t5_2t5eh,2019-3-2,2019,3,2,0,aw6d6v,self.deeplearning,CNN training in bfloat16,https://www.reddit.com/r/deeplearning/comments/aw6d6v/cnn_training_in_bfloat16/,CArchGuy,1551455322,"Are there any efforts so far for training CNNs end-to-end with bfloat16 format? especially the convolution part, i.e. both multiplication and addition is done in bfloat16. Can this scale to large datasets such ImageNet? Intel has a published white paper about supporting bfloat16 in their next-generation FPGAs, where they claim that accumulating in FP32 format is essential to avoid losing accuracy on an application level. Would people building custom hardware for training have to stick with the FP32 accumulation?",0,1,False,self,,,,,
8,deeplearning,t5_2t5eh,2019-3-2,2019,3,2,0,aw6hid,youtube.com,"Genetic Algorithm Tutorial Full Explanation, Calculations and uses 2019",https://www.reddit.com/r/deeplearning/comments/aw6hid/genetic_algorithm_tutorial_full_explanation/,DevTechRetopall,1551455993,,0,5,False,default,,,,,
9,deeplearning,t5_2t5eh,2019-3-2,2019,3,2,1,aw7228,self.deeplearning,How can I deploy my image caption model to flask?,https://www.reddit.com/r/deeplearning/comments/aw7228/how_can_i_deploy_my_image_caption_model_to_flask/,Vinceeeent,1551459105,"Hi guys, I have this image-caption model and I want it to deploy in a flask app. All I can see in google is a image classifier but there are no tutorials on image-captioning.

Any ideas/tips would be appreciated. Thanks!",0,1,False,self,,,,,
10,deeplearning,t5_2t5eh,2019-3-2,2019,3,2,4,aw8t1u,blog.snark.ai,Training Object Recognition Model,https://www.reddit.com/r/deeplearning/comments/aw8t1u/training_object_recognition_model/,ashotarzumanyan,1551469180,,0,3,False,default,,,,,
11,deeplearning,t5_2t5eh,2019-3-2,2019,3,2,5,aw90uc,tutorials.retopall.com,Autonomous Driving Simulation,https://www.reddit.com/r/deeplearning/comments/aw90uc/autonomous_driving_simulation/,DevTechRetopall,1551470408,,3,3,False,default,,,,,
12,deeplearning,t5_2t5eh,2019-3-2,2019,3,2,16,awfcxd,self.deeplearning,Why do I get different results for a single forward pass when I only change one dimension?,https://www.reddit.com/r/deeplearning/comments/awfcxd/why_do_i_get_different_results_for_a_single/,MasterSama,1551512416,"I tried to implement a very simple RNN step and compare it with Andrew Ng's function to see if I understood everything correcly.  

however, my results differ from his, but all I did was to place batch size in the first dimension rather than in the second! everything else is the same (except the fact that, I had to change the order of multiplication so the right dimensions sit next to eachother.)  

Here is his my function implementation : 

    import numpy as np
    
    def softmax(x): 
            e_x = np.exp(x - np.max(x))
            return e_x / e_x.sum(axis=0)
        
    class RNNClass(object):
        def __init__(self, vocab_size, outputsize, hidden_state_size=100):
            
            np.random.seed(1)
            #our weight size, is determined by hidden_state_size and vocab_size because
            # they are multiplied by input and also hidden_state, which ultimately should 
            # result in the hidden_size 
            # W1 is multiplied by xt which has the shape (batch, vocabsize)
            self.W1 = np.random.randn(vocab_size, hidden_state_size)
            # W2 is multiplied by hidden_state, which has the shape h=(batchsize, hiddensize) 
            # since w1 and w2 are added together, therefore, the dimension of h0.w2 
            # must have the same shape of the result of xt.w1. 
            self.W2 = np.random.randn(hidden_state_size, hidden_state_size)
            # W3 is multiplied by hidden_state, and it should ultimately have the shape of vocabsize
            # h1.w3
            self.W3 = np.random.randn(outputsize, hidden_state_size)
            # should have size of 1
            self.bh = np.random.randn(hidden_state_size)
            # should have size of 1
            self.bo = np.random.randn(outputsize)
            
            self.outputsize = outputsize
            self.hidden_state_size = hidden_state_size
            print(self.W1.shape)
            print(self.W2.shape)
            print(self.W3.shape)
            print(self.bh.shape)
            print(self.bo.shape)
            
        def rnn_cell_foward(self, xt, h0):
            """"""
                Run the forward pass for a single timestep of a vanilla RNN that uses a tanh
                activation function.
                The input data has dimension D(vocabsize), the hidden state has dimension H(HiddenSize), and we use
                a minibatch size of N(Batch_size).
                Inputs:
                - x: Input data for this timestep, of shape (Batch_size, vocabsize_or_basically_input_dim_size).
                - h0: Hidden state from previous timestep, of shape (Batch_size, HiddenSize)
                - W1: Weight matrix for input-to-hidden connections, of shape (vocabsize, HiddenSize)
                - W2: Weight matrix for hidden-to-hidden connections, of shape (HiddenSize, HiddenSize)
                - W3: Weight matrix for hiddent-to-output connections, of shape(vocabsize_or_output_dim_size, hidden_state_size)
                - bh: Biases of shape (HiddenSize,)
                - bo: Biases of shape (vocabsize_or_output_dim_size,)
                
           """"""
            
            h_t = np.tanh(np.dot(xt, self.W1) + np.dot(h0, self.W2) + self.bh)
            o_t = softmax(np.dot( h_t, self.W3.T) + self.bo)
            print('o_t.shape in cell forward: ', o_t.shape)
            print('h_t.shape in cell forward: ', h_t.shape)
            return o_t, h_t
    

and the output is :

    vocabsize=3
    hidden_state_size=5
    outputsize=2
    batch=10
    Xt = np.random.rand(batch, vocabsize)
    h0 = np.zeros(shape=(batch, hidden_state_size))
    
    rnn = RNNClass(vocab_size=vocabsize, outputsize=outputsize, hidden_state_size=hidden_state_size)
    yt_pred,a_next = rnn.rnn_cell_foward(Xt, h0)
    # so the output looks like andrew's result.
    a_next = a_next.transpose(1,0)
    yt_pred = yt_pred.transpose(1,0)
    
    print(""a_next.shape = "", a_next.shape)
    print(""yt_pred.shape = "", yt_pred.shape)
    print(""a_next[4] = "", a_next[4])
    print(""yt_pred[1] ="", yt_pred[1])
    
    

output : 

  

|**a\_next\[4\]** =| \[0.84867458     0.77846452     0.58705883    0.88028079   0.46130119       0.39808808     0.01003178    0.406457   0.41351936       0.9144255 \]|
|:-|:-|
|**a\_next.shape** = | (5, 10) |
|**yt\_pred\[1\]** = |\[0.06592572      0.06621226      0.13315296   0.06556298 0.08856467       0.14952982      0.13894541   0.13843746 0.08882247       0.06484625\] |
|**yt\_pred.shape=**| (2, 10) |

and this is his implementation : 

    def rnn_cell_forward(xt, a_prev, parameters):
        """"""
        Implements a single forward step of the RNN-cell as described in Figure (2)
    
        Arguments:
        xt -- your input data at timestep ""t"", numpy array of shape (n_x, m).
        a_prev -- Hidden state at timestep ""t-1"", numpy array of shape (n_a, m)
        parameters -- python dictionary containing:
                            Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)
                            Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)
                            Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)
                            ba --  Bias, numpy array of shape (n_a, 1)
                            by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)
        Returns:
        a_next -- next hidden state, of shape (n_a, m)
        yt_pred -- prediction at timestep ""t"", numpy array of shape (n_y, m)
        cache -- tuple of values needed for the backward pass, contains (a_next, a_prev, xt, parameters)
        """"""
        
        # Retrieve parameters from ""parameters""
        Wax = parameters[""Wax""]
        Waa = parameters[""Waa""]
        Wya = parameters[""Wya""]
        ba = parameters[""ba""]
        by = parameters[""by""]
        
        ### START CODE HERE ### (2 lines)
        a_next = np.tanh(np.dot(Wax,xt) + np.dot(Waa,a_prev) + ba)
        # compute output of the current cell using the formula given above
        yt_pred = softmax(np.dot(Wya,a_next)+by)   
        ### END CODE HERE ###
        
        # store values you need for backward propagation in cache
        cache = (a_next, a_prev, xt, parameters)
        
        return a_next, yt_pred, cache
    
    np.random.seed(1)
    xt = np.random.randn(3,10)
    a_prev = np.random.randn(5,10)
    Waa = np.random.randn(5,5)
    Wax = np.random.randn(5,3)
    Wya = np.random.randn(2,5)
    ba = np.random.randn(5,1)
    by = np.random.randn(2,1)
    parameters = {""Waa"": Waa, ""Wax"": Wax, ""Wya"": Wya, ""ba"": ba, ""by"": by}
    
    a_next, yt_pred, cache = rnn_cell_forward(xt, a_prev, parameters)

and the output it generates is : 

&amp;#x200B;

|**a\_next\[4\]** =| \[ 0.59584544      0.18141802      0.61311866   0.99808218  0.85016201         0.99980978     -0.18887155   0.99815551  0.6531151          0.82872037\]  |
|:-|:-|
|**a\_next.shape** = | (5, 10) |
|**yt\_pred\[1\]** = | \[ 0.9888161      0.01682021        0.21140899    0.36817467  0.98988387       0.88945212        0.36920224    0.9966312   0.9982559         0.17746526\]|
|**yt\_pred.shape=**| (2, 10) |

As you can see, I also used `np.random.seed(1)` 

but the results are different. I'm puzzled , is  this expected or not? 

Your help is greatly appreciated . 

&amp;#x200B;",0,2,False,self,,,,,
13,deeplearning,t5_2t5eh,2019-3-3,2019,3,3,2,awk6dn,self.deeplearning,Training I3D model.,https://www.reddit.com/r/deeplearning/comments/awk6dn/training_i3d_model/,crazy_lazy_life,1551548610,"I have a video dataset of ~230 videos, each divided into two classes. All the information with the video title and the corresponding class's is stored in a csv file and the videos are together in the same folder. 
I am having problem with training an I3D network on this video dataset. I tried to do all that was said in the github repo, but their format for the dataset is different. 
Any help or article suggestion is highly appreciated.
Thanks in advance. ",0,6,False,self,,,,,
14,deeplearning,t5_2t5eh,2019-3-3,2019,3,3,6,awms0j,self.deeplearning,Evaluation Metrics RMSE and MAPE,https://www.reddit.com/r/deeplearning/comments/awms0j/evaluation_metrics_rmse_and_mape/,armod_reddit,1551563083,I wanted to use the metrics RMSE and MAPE to measure prediction using deep learning techniques like LSTM but I couldn't understand how the values of these metrics change for different numbers of samples in the output of the neural network. Do their value change different samples of the output or not?,0,1,False,self,,,,,
15,deeplearning,t5_2t5eh,2019-3-3,2019,3,3,12,awq60t,self.deeplearning,deeplearning.ai Specialization Progress | Shaik Asad,https://www.reddit.com/r/deeplearning/comments/awq60t/deeplearningai_specialization_progress_shaik_asad/,theshaikasad,1551584924,"Hey, to anyone interested in the [deeplearning.ai](https://deeplearning.ai/) Specialization, I've made a vlog documenting my progress and I've built an AI to classify numbers in the form of hand-signs. At the end the model didn't do well on my image because examples from the test and train set were hand signs in vertical () and not horizontal ()

Check it out 

[https://youtu.be/yCNpQYbw7vM](https://youtu.be/yCNpQYbw7vM) ",0,0,False,self,,,,,
16,deeplearning,t5_2t5eh,2019-3-3,2019,3,3,19,awt0at,github.com,Unsupervised learning using TensorForce and RL-techniques to control mouse movements.,https://www.reddit.com/r/deeplearning/comments/awt0at/unsupervised_learning_using_tensorforce_and/,ZeroMaxinumXZ,1551610575,,5,15,False,default,,,,,
17,deeplearning,t5_2t5eh,2019-3-4,2019,3,4,10,ax0ytl,self.deeplearning,Is the GTX 1050 good enough to learn the basics of deep learning?,https://www.reddit.com/r/deeplearning/comments/ax0ytl/is_the_gtx_1050_good_enough_to_learn_the_basics/,drummerboxer,1551661259,"I am a manager and want to learn the basics of deep learning -- the tools,  training process, and structure of the main types of deep learning architectures, etc. I  don't think I will be designing very large networks with large data sets, but at the same time I am not sure. I would rather do this on my laptop than on the cloud initially. I can get access to a server in the future to train large models once I get a good grasp of the tools on my laptop. 

I can buy one of two laptops from work: a nice corporate laptop with a 1050 gpu or a new razer blade 15 with a 2070 gpu. Both cost about the same. I have tried the razer at best buy and didn't like the ergonomics much, and hence am considering the corporate laptop. 

Would the 1050 gpu be good enough to properly learn deep learning? I will most likely be running tensor flow under windows, or can dual boot if needed. Also, I usually split my time between a couple of campuses and also spend about 30-50% of my time in meetings. Thus I will probably be doing this work in the evenings at home.",16,7,False,self,,,,,
18,deeplearning,t5_2t5eh,2019-3-4,2019,3,4,20,ax6889,youtube.com,3D Advanced Neural Network Simulation - Computer vision - Digit Recognition,https://www.reddit.com/r/deeplearning/comments/ax6889/3d_advanced_neural_network_simulation_computer/,DevTechRetopall,1551699933,,7,26,False,default,,,,,
19,deeplearning,t5_2t5eh,2019-3-4,2019,3,4,22,ax6zzm,self.deeplearning,What is the difference between a custom cnn and lets say googlenet or alexnet?,https://www.reddit.com/r/deeplearning/comments/ax6zzm/what_is_the_difference_between_a_custom_cnn_and/,superibr,1551705259,"Can someone please explain me this question?For example if i use a model like below. 

&amp;#x200B;

 model = tf.keras.models.Sequential() #model.add(tf.keras.layers.Flatten())  

&amp;#x200B;

model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu, input\_shape= x\_train.shape\[1:\])) 

&amp;#x200B;

model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) 

&amp;#x200B;

model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax)) 

&amp;#x200B;

&amp;#x200B;

are googlenet and alexnet the way to make this model? like more layers less dence, different convolution matrix size etc?",1,1,False,self,,,,,
20,deeplearning,t5_2t5eh,2019-3-4,2019,3,4,22,ax7akt,self.deeplearning,Is MSI GeForce GTX 1080 TI ARMOR 11G OC Graphics Card suitable for Deeplearning?,https://www.reddit.com/r/deeplearning/comments/ax7akt/is_msi_geforce_gtx_1080_ti_armor_11g_oc_graphics/,MasterSama,1551707162,"Hello everyone. 

I have a Gigabyte G1 Gaming GTX1080 and it has worked for me just fine. today I found a second hand MSI GeForce GTX 1080 TI ARMOR 11G OC Graphics Card, that might be a good deal. it was used for mining , but the guy says the temp were around 60 degree Celsius (he had the room cooled with an air conditioner!) 

I have searched the internet and noticed, there are many people complaining about its cooling capability and that this card easily thermal throttles. now this has me worried so I'm asking about those of you who have experience working with such card. 

Do you think its worth it or not? (The card is being sold as 43% less than the actual card and it has warrantee for the next 2 years)   

(I'll be most likely training on ImageNet like datasets for weeks. )",8,2,False,self,,,,,
21,deeplearning,t5_2t5eh,2019-3-4,2019,3,4,23,ax7qeu,self.deeplearning,Can Transformer networks be applied in audio classification tasks?,https://www.reddit.com/r/deeplearning/comments/ax7qeu/can_transformer_networks_be_applied_in_audio/,Rytis_kap,1551709854,"I was working on audio classification with CNNs (music genre classification in particular) . And now I'm generating ideas for my next project in this field. I was thinking of using CRNN, but I came across Transformer networks ([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)) and found out that it is performing well in machine translation tasks. But I couldn't find anything about using it in audio-related problems. I was wondering, maybe someone has tried applying Transformer networks in audio domain and could share their experience? Or could nod in the right direction? ",0,1,False,self,,,,,
22,deeplearning,t5_2t5eh,2019-3-5,2019,3,5,15,axhs4t,self.deeplearning,Using instance segmentation for data cleaning. Need help! xpost /r/computervision,https://www.reddit.com/r/deeplearning/comments/axhs4t/using_instance_segmentation_for_data_cleaning/,kimbler69,1551766083,[removed],0,1,False,self,,,,,
23,deeplearning,t5_2t5eh,2019-3-5,2019,3,5,16,axik2t,medium.com,Using deep learning to read your thoughts  with Keras and an EEG sensor,https://www.reddit.com/r/deeplearning/comments/axik2t/using_deep_learning_to_read_your_thoughts_with/,quasci,1551771893,,0,45,False,default,,,,,
24,deeplearning,t5_2t5eh,2019-3-5,2019,3,5,21,axkw0t,self.deeplearning,"A PyTorch implementation of ""A Higher-Order Graph Convolutional Layer"" (NeurIPS 2018).",https://www.reddit.com/r/deeplearning/comments/axkw0t/a_pytorch_implementation_of_a_higherorder_graph/,benitorosenberg,1551790789,"&amp;#x200B;

*Processing img qd1n78i2tak21...*

&amp;#x200B;

**PyTorch:** [https://github.com/benedekrozemberczki/NGCN](https://github.com/benedekrozemberczki/NGCN)

**Paper:** [http://sami.haija.org/papers/high-order-gc-layer.pdf](http://sami.haija.org/papers/high-order-gc-layer.pdf)

**Abstract:**

Recent  methods generalize convolutional layers from Euclidean domains to   graph-structured data by approximating the eigenbasis of the graph   Laplacian. The computationally-efficient and broadly-used Graph ConvNet   of Kipf &amp; Welling, over-simplifies the approximation, effectively   rendering graph convolution as a neighborhood-averaging operator. This   simplification restricts the model from learning delta operators, the   very premise of the graph Laplacian.  In this work, we propose a new   Graph Convolutional layer which mixes multiple powers of the adjacency   matrix, allowing it to learn delta operators. Our layer exhibits the   same memory footprint and computational complexity as a GCN. We   illustrate the strength of our proposed layer on both synthetic graph   datasets, and on several real-world citation graphs, setting the record   state-of-the-art on Pubmed.",0,6,False,self,,,,,
25,deeplearning,t5_2t5eh,2019-3-5,2019,3,5,22,axlbv7,self.deeplearning,Using instance segmentation for data cleaning. Need help! xpost /r/computervision,https://www.reddit.com/r/deeplearning/comments/axlbv7/using_instance_segmentation_for_data_cleaning/,kimbler69,1551793653,[removed],0,1,False,self,,,,,
26,deeplearning,t5_2t5eh,2019-3-5,2019,3,5,23,axlvcp,muens.co,Learning Deep Learning - A Curriculum,https://www.reddit.com/r/deeplearning/comments/axlvcp/learning_deep_learning_a_curriculum/,pmuens,1551796980,,2,6,False,default,,,,,
27,deeplearning,t5_2t5eh,2019-3-5,2019,3,5,23,axlyof,self.deeplearning,papers on learning by Exploration,https://www.reddit.com/r/deeplearning/comments/axlyof/papers_on_learning_by_exploration/,sriharsha_0806,1551797524,"Hi, I want to get started on learning by Exploration for computer vision.  What are the papers I should read to get started with the topic?",0,1,False,self,,,,,
28,deeplearning,t5_2t5eh,2019-3-5,2019,3,5,23,axlyxb,i.redd.it,Overfitting in pointer generator network,https://www.reddit.com/r/deeplearning/comments/axlyxb/overfitting_in_pointer_generator_network/,fridayc13,1551797557,,0,0,False,image,,,,,
29,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,0,axm7b4,ailab.microsoft.com,Microsoft Unveils Website to Create Art with GANs,https://www.reddit.com/r/deeplearning/comments/axm7b4/microsoft_unveils_website_to_create_art_with_gans/,mhamilton723,1551798884,,0,32,False,default,,,,,
30,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,1,axmsi8,youtu.be,Deep learning for recommendations systems,https://www.reddit.com/r/deeplearning/comments/axmsi8/deep_learning_for_recommendations_systems/,robotics89,1551802073,,0,1,False,image,,,,,
31,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,3,axo85c,medium.com,Human Pose Estimation Model HRNet Breaks Three COCO Records; CVPR Accepts Paper,https://www.reddit.com/r/deeplearning/comments/axo85c/human_pose_estimation_model_hrnet_breaks_three/,gwen0927,1551809533,,0,11,False,default,,,,,
32,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,3,axo8ii,self.deeplearning,Is BERT model suitable for NMT?,https://www.reddit.com/r/deeplearning/comments/axo8ii/is_bert_model_suitable_for_nmt/,KorChris,1551809586,"As I know, BERT puts the input contains the source and the target with \[SEP\]

&amp;#x200B;

Now I'm trying to BERT and attention RNN code(which has the source input and the target output) for NMT.

&amp;#x200B;

But as the BERT encoder puts the input has the source and the target, I have no idea how it can fit.

&amp;#x200B;

Is it possible to adapt BERT model to NMT attention RNN model?",0,4,False,self,,,,,
33,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,3,axoil0,self.deeplearning,GPU Box Build Advice,https://www.reddit.com/r/deeplearning/comments/axoil0/gpu_box_build_advice/,doyer,1551811014,"Hey all, I'm trying to build a gpu box with a budget of 3-4k (obviously less would be better :P). Don't know too much about this side of the house. 

&amp;#x200B;

Goals: Decent GPU box for now which can be upgraded to \~6-8 gpus and hundreds of gigs of ram in the future

&amp;#x200B;

Use Case: At first I will primarily be using this for training models. Switching between one model/gpu and a few gpus for the same model depending on the situation. Within 6 months, a couple other people will be using this system at the same time as me for training models. May also use it for algo trading so up-time, rapid ingestion of data from sockets, etc is also important but if that is not feasible I am not opposed to building another system for that in a couple months. 

&amp;#x200B;

Thoughts so far:

(1) AMD EPYC 7281@ amazon $680

(1) Kingston 64GB (16 x 4) 2666mgz @amazon $480

(1) Asus KNPA-U16 Motherboard @ amazon $380

(2) Zotac GeForce RTX 2070 Blower 8gb @ amazon $500/each

(1) Samsung 860 evo 500gb ssd @ amazon $80

OS: probably Ubuntu Server

&amp;#x200B;

I still need an hdd, case, cooling system (?) , and ..not really sure what else. Definitely have no idea how to pick a case but I'm presuming I can just buy some sort of server case and that'll work itself out. 

&amp;#x200B;

I have been googling a bunch and I've read something about NUMA architectures but I'm not really sure how that impacts my usecase. 

&amp;#x200B;

I would love any suggestions or ideas if you all have any!",4,2,False,self,,,,,
34,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,6,axqkvy,self.deeplearning,Want to model a conditional probability p(y|x) with NN? We report best practices for cond density estimation and compare against baseline density estimators typically used in finance.,https://www.reddit.com/r/deeplearning/comments/axqkvy/want_to_model_a_conditional_probability_pyx_with/,whiletrue2,1551821862,"Want to model a conditional probability p(y|x) with NN? We report best practices for cond density estimation and compare against baseline density estimators for a finance application. 

We open-sourced code here with various estimators, data normalization and regularization, data generating processes, statistical divergences for evaluation (KL-divergence, Hellinger, Jensen-Shannon) and other (quantiles, expected shortfalls, likelihood etc.), see here: https://github.com/freelunchtheorem/Conditional_Density_Estimation

Our report can be found here: https://arxiv.org/abs/1903.00954

Take away message: Normalization &amp; regularization helps, Kernel Mixture Models and Mixture Density Models perform better than semi- and non-parametric methods.",0,2,False,self,,,,,
35,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,8,axs0lb,self.deeplearning,Hyperbolic N-Space encodings for TensorFlow,https://www.reddit.com/r/deeplearning/comments/axs0lb/hyperbolic_nspace_encodings_for_tensorflow/,kousun12,1551829771,"I still think hyperbolic geometry hasn't been appreciated enough in the ML world, following the first few papers by [facebook research](https://papers.nips.cc/paper/7213-poincare-embeddings-for-learning-hierarchical-representations). Here's an implementation of some basic functions to support the Poincare model for word embeddings in TF. Lorentz model coming eventually...

[https://github.com/kousun12/tf\_hyperbolic](https://github.com/kousun12/tf_hyperbolic)",2,4,False,self,,,,,
36,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,13,axuomg,self.deeplearning,Xeus-Cling: Run C++ code in Jupyter Notebook,https://www.reddit.com/r/deeplearning/comments/axuomg/xeuscling_run_c_code_in_jupyter_notebook/,spmallick,1551846390,"Have you ever used a Jupyter notebook? If yes, you know it is a pleasure to use it for interactive programming. If no, you should try it! Or you may be a C++ programmer and thinking Jupyter notebooks are not for you, but wait, imagine our joy when we came across the Xeus-Cling kernel! But what does it do?  
[https://www.learnopencv.com/xeus-cling-run-c-code-in-jupyter-notebook/](https://www.learnopencv.com/xeus-cling-run-c-code-in-jupyter-notebook/?fbclid=IwAR3El5cgG2FojF_Hn8f40EVe1JXvu7pkvsrWQuVg9Y5r9wALJouu4ypRJtQ)  
Read this blog post wherein we show how you can use OpenCV and Dlib C++ code in a Jupyter notebook using the Xeus-Cling kernel. Mention reviews and what you want us to work on next, in the comments!

![video](euaaocsiefk21)",1,21,False,self,,,,,
37,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,19,axxa4q,datasciencedigest.org,DataScience Digest - Issue #17,https://www.reddit.com/r/deeplearning/comments/axxa4q/datascience_digest_issue_17/,flyelephant,1551867301,,0,3,False,default,,,,,
38,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,21,axy3j6,self.deeplearning,Is deep reinforcement learning a promising career?,https://www.reddit.com/r/deeplearning/comments/axy3j6/is_deep_reinforcement_learning_a_promising_career/,TheHawkGriffith,1551873915,[removed],0,1,False,self,,,,,
39,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,22,axz399,self.deeplearning,A collection of graph embedding research papers with implementations.,https://www.reddit.com/r/deeplearning/comments/axz399/a_collection_of_graph_embedding_research_papers/,benitorosenberg,1551880599,"An exhaustive collection of important graph embedding, classification and representation learning papers with implementations.

&amp;#x200B;

[https://github.com/benedekrozemberczki/awesome-graph-embedding](https://github.com/benedekrozemberczki/awesome-graph-embedding)

https://i.redd.it/efplfi268ik21.png

&amp;#x200B;",0,4,False,self,,,,,
40,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,23,axzivj,github.com,"Microsoft Releases New Version of Open Source Distributed ML Library, MMLSpark",https://www.reddit.com/r/deeplearning/comments/axzivj/microsoft_releases_new_version_of_open_source/,mhamilton723,1551883217,,0,21,False,default,,,,,
41,deeplearning,t5_2t5eh,2019-3-6,2019,3,6,23,axzptk,self.deeplearning,Reproducing experimental results from SysML'19 papers (the Conference on Systems and Machine Learning),https://www.reddit.com/r/deeplearning/comments/axzptk/reproducing_experimental_results_from_sysml19/,gfursin,1551884361,"We had a very interesting experience when evaluating artifacts and reproducing experimental results from several accepted [SysML'19](http://cTuning.org/ae/sysml2019.html) papers on deep learning. You can now find the results [online](http://reuseresearch.com/index.php?a=papers-sysml-2019). We plan to discuss the [SysML reproducibility initiative](http://cTuning.org/ae/sysml2019.html) and brainstorm how to improve, simplify and automate validation of experimental results at ML, AI and systems conferences at [SysML'19](http://sysml.cc) on April 2 (1:30-2pm, Fisher Conference Center, Stanford University). Looking forward to further discussions!",0,2,False,self,,,,,
42,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,1,ay0iev,medium.com,Reinforced Cross-Modal Matching &amp; Self-Supervised Imitation Learning for Vision-Language Navigation,https://www.reddit.com/r/deeplearning/comments/ay0iev/reinforced_crossmodal_matching_selfsupervised/,gwen0927,1551888687,,0,2,False,default,,,,,
43,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,1,ay0p59,medium.com,Triple Strong Accept for CVPR 2019: Reinforced Cross-Modal Matching &amp; Self-Supervised Imitation,https://www.reddit.com/r/deeplearning/comments/ay0p59/triple_strong_accept_for_cvpr_2019_reinforced/,Yuqing7,1551889661,,0,1,False,default,,,,,
44,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,1,ay0xoz,self.deeplearning,AMD Vega VII same performance as 2080Ti for Resnet50,https://www.reddit.com/r/deeplearning/comments/ay0xoz/amd_vega_vii_same_performance_as_2080ti_for/,jpdowlin,1551890927,"Some people are trying out ROCm - TensorFlow and there are some benchmarks here:  
[https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/issues/173](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/issues/173)

&amp;#x200B;

The Vega 7 costs about 800 dollars and has 16GB ram and fp64 and fp16 have not been gimped. It has potential to be a mass market GPU for deep learning. ROCm may not have been upstreamed to tensorflow yet, but it's basically ""pip install tensorflow-rocm"" to get it working. Some will say ROCm is flakey, untested - which may be true, but they will get there this year with stability, IMO.

Opinions?",4,3,False,self,,,,,
45,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,2,ay19hg,self.deeplearning,"Wow, this is insane!",https://www.reddit.com/r/deeplearning/comments/ay19hg/wow_this_is_insane/,CocoFormerChild,1551892627,"I just realized that all adults are just former children, how is this not something everyone realizes?",6,0,False,self,,,,,
46,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,3,ay1zn9,blog.goodaudience.com,CNN for RNNs  A gentle approach to use CNNs for NLP,https://www.reddit.com/r/deeplearning/comments/ay1zn9/cnn_for_rnns_a_gentle_approach_to_use_cnns_for_nlp/,DataScienceReporter,1551896353,,0,1,False,default,,,,,
47,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,3,ay20ct,blockdelta.io,Deep Learning in Finance Summit - London,https://www.reddit.com/r/deeplearning/comments/ay20ct/deep_learning_in_finance_summit_london/,BlockDelta,1551896453,,0,4,False,default,,,,,
48,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,6,ay3yta,github.com,GIPHY open-sources their celebrity detection deep learning model and code,https://www.reddit.com/r/deeplearning/comments/ay3yta/giphy_opensources_their_celebrity_detection_deep/,giphy,1551906467,,2,39,False,default,,,,,
49,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,6,ay48a9,medium.com,NeurIPS 2019 Dates and Details Announced,https://www.reddit.com/r/deeplearning/comments/ay48a9/neurips_2019_dates_and_details_announced/,Yuqing7,1551907768,,0,3,False,default,,,,,
50,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,6,ay4j4v,medium.com,NeurIPS 2019 Dates and Details Announced,https://www.reddit.com/r/deeplearning/comments/ay4j4v/neurips_2019_dates_and_details_announced/,Yuqing7,1551909310,,0,1,False,default,,,,,
51,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,10,ay6t22,self.deeplearning,Need advise on deep learning,https://www.reddit.com/r/deeplearning/comments/ay6t22/need_advise_on_deep_learning/,happywildrose,1551922046,"Hello all,

&amp;#x200B;

I hope you will give me some constructive opinion and feedback. First all of I would tell little bit about myself.

I have degree in Chemical Engineering (graduated about 13 years ago). Unfortunately, due to different reasons I don't have a stable career. Currently, I am employed but job is not permanent and it's more clerical. I am hoping company will not lay me off. That means I have some time at home every evening which I can invest to some positive activity. My weekends are free too.  I am thinking to start self-taught learning in Computer Science specifically in Deep Learning. I have zero programming knowledge. I am married, 35 years old. 

&amp;#x200B;

My question is for person like myself who has no knowledge of programming how practical it is to switch career if I learn 20 to 25 hours every week. Would I be able to have a decent level knowledge to present myself in an interview after 2-3 years. 

&amp;#x200B;

From where should I start. I have done little bit of browsing which reveals along with some programming languages I also need to get command on statistics (linear regression etc.)

&amp;#x200B;

Please guide me what should be VERY FIRST STEP. I happy and ready to take baby steps :)

&amp;#x200B;

Thank you in advance!

&amp;#x200B;

&amp;#x200B;",10,4,False,self,,,,,
52,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,11,ay79wn,lambdalabs.com,Deep Learning GPU Benchmarks -- RTX 2080 Ti vs Tesla V100 vs RTX 2080 vs Titan RTX vs Titan V vs GTX 1080 Ti vs Titan Xp,https://www.reddit.com/r/deeplearning/comments/ay79wn/deep_learning_gpu_benchmarks_rtx_2080_ti_vs_tesla/,mippie_moe,1551924890,,3,12,False,default,,,,,
53,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,16,ay9x1a,self.deeplearning,How to get started with Python for Deep Learning and Data Science,https://www.reddit.com/r/deeplearning/comments/ay9x1a/how_to_get_started_with_python_for_deep_learning/,MaryDBlackwell,1551943166,[http://on.geeklearn.net/64d9d6db70](http://on.geeklearn.net/64d9d6db70),0,1,False,self,,,,,
54,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,18,ayax84,self.deeplearning,"Comprehensive Deep Learning Git Codebook, Video Tutorials and Projects",https://www.reddit.com/r/deeplearning/comments/ayax84/comprehensive_deep_learning_git_codebook_video/,nalinee_choudhary,1551952274,"&amp;#x200B;

https://i.redd.it/4y6inwe65ok21.jpg

&amp;#x200B;

**Comprehensive** **Deep Learning tutorials** [(Free Video Tutorials)](https://www.edyoda.com/course/1429) [(Github codebook)](https://github.com/zekelabs/AI101-DeepLearning)  


**Build Deep Learning Projects (Complete Video Series for FREE )**  


**1.** [Making your RL Projects in 20 Minutes](https://www.edyoda.com/course/1421)  


**2.** [Style Transfer, Face Generation using GANs in 20 minutes](https://www.edyoda.com/course/1418)  


**3.** [Language and Machine Learning in 20 minutes](https://www.edyoda.com/course/1419)  


**4.** [AI Project - Web application for Object Identification](https://www.edyoda.com/course/1185)  


**5.** [Dog Breed Prediction](https://www.edyoda.com/course/1336)  


**Free** **Video Series for Beginners to advanced users**  


**1.** [Machine Learning - Mastering NumPy](https://www.edyoda.com/course/1263)  


**2.** [Machine Learning using Tensorflow](https://www.edyoda.com/course/99)  


**3.** [Step by step guide to Tensorflow](https://www.edyoda.com/course/1429)  


**4.** [Introduction to Neural Networks](https://www.edyoda.com/course/1417)  


**5.** [Knowledge Graphs, Deep Learning and Reasoning](https://www.edyoda.com/course/1420)",0,1,False,self,,,,,
55,deeplearning,t5_2t5eh,2019-3-7,2019,3,7,23,ayd147,self.deeplearning,"Comprehensive Deep Learning Git Codebook, Video Tutorials and Projects",https://www.reddit.com/r/deeplearning/comments/ayd147/comprehensive_deep_learning_git_codebook_video/,nalinee_choudhary,1551968029,"**Comprehensive** **Deep Learning tutorials** [(Free Video Tutorials)](https://www.edyoda.com/course/1429) [(Github codebook)](https://github.com/zekelabs/AI101-DeepLearning)  


**Build Deep Learning Projects (Complete Video Series for FREE )**  


**1.** [Making your RL Projects in 20 Minutes](https://www.edyoda.com/course/1421)  


**2.** [Style Transfer, Face Generation using GANs in 20 minutes](https://www.edyoda.com/course/1418)  


**3.** [Language and Machine Learning in 20 minutes](https://www.edyoda.com/course/1419)  


**4.** [AI Project - Web application for Object Identification](https://www.edyoda.com/course/1185)  


**5.** [Dog Breed Prediction](https://www.edyoda.com/course/1336)  


**Free** **Video Series for Beginners to advanced users**  


**1.** [Machine Learning - Mastering NumPy](https://www.edyoda.com/course/1263)  


**2.** [Machine Learning using Tensorflow](https://www.edyoda.com/course/99)  


**3.** [Step by step guide to Tensorflow](https://www.edyoda.com/course/1429)  


**4.** [Introduction to Neural Networks](https://www.edyoda.com/course/1417)  


**5.** [Knowledge Graphs, Deep Learning and Reasoning](https://www.edyoda.com/course/1420)",0,31,False,self,,,,,
56,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,1,aye70b,medium.com,Google Open-Sources GPipe Library for Training Large-Scale Neural Network Models,https://www.reddit.com/r/deeplearning/comments/aye70b/google_opensources_gpipe_library_for_training/,gwen0927,1551974704,,0,13,False,default,,,,,
57,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,1,ayebb3,self.deeplearning,"A PyTorch Implementation of ""Predict then Propagate: Graph Neural Networks meet Personalized PageRank"" (ICLR 2019)",https://www.reddit.com/r/deeplearning/comments/ayebb3/a_pytorch_implementation_of_predict_then/,benitorosenberg,1551975327,"&amp;#x200B;

&amp;#x200B;

https://i.redd.it/2acxf6ox1qk21.jpg

**Paper:** [https://arxiv.org/abs/1810.05997](https://arxiv.org/abs/1810.05997)

**PyTorch implementation:** [https://github.com/benedekrozemberczki/APPNP/](https://github.com/benedekrozemberczki/APPNP/)

**Abstract:**

Neural  message passing algorithms for semi-supervised classification on graphs  have recently achieved great success. However, these methods only  consider nodes that are a few propagation steps away and the size of  this utilized neighborhood cannot be easily extended. In this paper, we  use the relationship between graph convolutional networks (GCN) and  PageRank to derive an improved propagation scheme based on personalized  PageRank. We utilize this propagation procedure to construct  personalized propagation of neural predictions (PPNP) and its  approximation, APPNP. Our model's training time is on par or faster and  its number of parameters on par or lower than previous models. It  leverages a large, adjustable neighborhood for classification and can be  combined with any neural network. We show that this model outperforms  several recently proposed methods for semi-supervised classification on  multiple graphs in the most thorough study done so far for GCN-like  models.",0,2,False,self,,,,,
58,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,3,ayfl9j,medium.com,ICLR 2019 | Fast as Adam &amp; Good as SGD  New Optimizer Has Both,https://www.reddit.com/r/deeplearning/comments/ayfl9j/iclr_2019_fast_as_adam_good_as_sgd_new_optimizer/,gwen0927,1551981787,,8,18,False,default,,,,,
59,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,5,ayhejk,medium.com,TensorFlow Privacy: Learning with Differential Privacy for Training Data,https://www.reddit.com/r/deeplearning/comments/ayhejk/tensorflow_privacy_learning_with_differential/,ConfidentMushroom,1551991172,,0,2,False,default,,,,,
60,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,7,ayid2t,self.deeplearning,3-D Imaging with deep learning brings together holography and microscopy,https://www.reddit.com/r/deeplearning/comments/ayid2t/3d_imaging_with_deep_learning_brings_together/,FindLight2017,1551996296,"What impacts could this have on medical imaging? Could this be a better way for neural networks to predict outcomes through collecting diagnostic data?

[https://phys.org/news/2019-03-deep-merges-advantages-holography-bright-field.html](https://phys.org/news/2019-03-deep-merges-advantages-holography-bright-field.html)",0,1,False,self,,,,,
61,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,11,aykte5,self.deeplearning,Assessing quality of downsampled point cloud,https://www.reddit.com/r/deeplearning/comments/aykte5/assessing_quality_of_downsampled_point_cloud/,gwynbleidd2099,1552010739,"How does one measure quality of downsampled point clouds which are being fed to classification network? For example, Pointnet can use ModelNet40 as test and train data, with point clouds consisting of eg. 1024 points. If I were to reduce this number to 128, with some algorithm, how do I know if the new point cloud is actually decent? Feed it to another network and compare accuracy to not-resampled datasets, resampled with another algorithm or is there another way?",0,1,False,self,,,,,
62,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,11,ayl7lo,self.deeplearning,Why Doesn't Meta-Learning Overfit the Meta-Training Set?,https://www.reddit.com/r/deeplearning/comments/ayl7lo/why_doesnt_metalearning_overfit_the_metatraining/,purboo,1552013286,"I am always wondering why meta-learning works. The meta-learner is trained on tasks that are built from a meta-training set, and it can perform generally well on totally unseen tasks from a meta-testing set. Why doesn't the meta-learner overfit the meta-training tasks?  What if the meta-testing set differs greatly from the meta-training set? What is the deep, essential magic that contributes to the high generalizability of the meta-learner? ",3,1,False,self,,,,,
63,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,15,aymy9o,self.deeplearning,Udacity's updated tutorial course for Tensorflow2.0!,https://www.reddit.com/r/deeplearning/comments/aymy9o/udacitys_updated_tutorial_course_for_tensorflow20/,shawnmanuel000,1552025459,"Hey guys, some of you might have seen the release of Tensorflow2.0 alpha that came out a few days ago. Just wanted to share the updated [Udacity tutorial](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187) for getting started with it. 

However I did find that it doesn't cover how to actually create your own custom loss function optimizer operations for applying the new 2.0 API for more complex reinforcement learning applications so I'm going to try and make a YouTube coding tutorial for that soon.",6,40,False,self,,,,,
64,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,17,ayo1i9,go.geeklearn.net,Deploying a Keras Deep Learning Model as a Web Application in Python,https://www.reddit.com/r/deeplearning/comments/ayo1i9/deploying_a_keras_deep_learning_model_as_a_web/,MarkOliver908,1552034552,,0,1,False,default,,,,,
65,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,18,ayoc67,self.deeplearning,SimGNN: A Neural Network Approach to Fast Graph Similarity Computation (WSDM 2019),https://www.reddit.com/r/deeplearning/comments/ayoc67/simgnn_a_neural_network_approach_to_fast_graph/,benitorosenberg,1552037188,"&amp;#x200B;

https://i.redd.it/a1uid1av5vk21.jpg

&amp;#x200B;

Paper: [http://web.cs.ucla.edu/\~yzsun/papers/2019\_WSDM\_SimGNN.pdf](http://web.cs.ucla.edu/~yzsun/papers/2019_WSDM_SimGNN.pdf)

PyTorch implementation: [https://github.com/benedekrozemberczki/SimGNN](https://github.com/benedekrozemberczki/SimGNN)

Abstract:

Graph similarity search is among the most important graph-based applications, e.g. finding the chemical compounds that are most similar to a query compound. Graph similarity/distance computation, such as Graph Edit Distance (GED) and Maximum Common Subgraph (MCS), is the core operation of graph similarity search and many other applications, but very costly to compute in practice. Inspired by the recent success of neural network approaches to several graph applications, such as node or graph classification, we propose a novel neural network based approach to address this classic yet challenging graph problem, aiming to alleviate the computational burden while preserving a good performance. The proposed approach, called SimGNN, combines two strategies. First, we design a learnable embedding function that maps every graph into an embedding vector, which provides a global summary of a graph. A novel attention mechanism is proposed to emphasize the important nodes with respect to a specific similarity metric. Second, we design a pairwise node comparison method to sup plement the graph-level embeddings with fine-grained node-level information. Our model achieves better generalization on unseen graphs, and in the worst case runs in quadratic time with respect to the number of nodes in two graphs. Taking GED computation as an example, experimental results on three real graph datasets demonstrate the effectiveness and efficiency of our approach. Specifically, our model achieves smaller error rate and great time reduction compared against a series of baselines, including several approximation algorithms on GED computation, and many existing graph neural network based models. Our study suggests SimGNN provides a new direction for future research on graph similarity computation and graph similarity search.",0,3,False,self,,,,,
66,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,21,aypt5k,self.deeplearning,"Is there an ELI5 for Python? I'm no CS, and I've never been good at reading/coding... Yet, I work with deep learning on a daily basis.",https://www.reddit.com/r/deeplearning/comments/aypt5k/is_there_an_eli5_for_python_im_no_cs_and_ive/,MightBeKatie,1552048671,"I watched a few ""Basic Python in an hour"" on YouTube but was overwhelmed about 3 minutes in when the prof/speaker started talking about and utilizing a variable he hadn't explained. CS profs seem to talk like football coaches: there's substance there but no connection. ",4,1,False,self,,,,,
67,deeplearning,t5_2t5eh,2019-3-8,2019,3,8,23,ayqxd5,medium.com,Machine learning on google cloud platform,https://www.reddit.com/r/deeplearning/comments/ayqxd5/machine_learning_on_google_cloud_platform/,frenchdic,1552055627,,0,1,False,default,,,,,
68,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,0,ayrhml,self.deeplearning,I want to be a researcher in deep learning but I don't know what to do ....code/ learn research papers,https://www.reddit.com/r/deeplearning/comments/ayrhml/i_want_to_be_a_researcher_in_deep_learning_but_i/,arshad_221b,1552058867,"I'm currently a undergraduate student in India and I want to do research in deep learning. I'm more interested in finding new techniques than using existing techniques on certain data sets. 
So what should I do? Focus more on coding or finding more algorithms theoretically? (_  )",2,0,True,nsfw,,,,,
69,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,1,aysat9,self.deeplearning,Large Dataset for Speech Recognition,https://www.reddit.com/r/deeplearning/comments/aysat9/large_dataset_for_speech_recognition/,limapedro,1552063205,"Hi guys! The new Common Voice datasets were released a few days ago and I created a torrent with all the datasets, so you can usually train your models with different languages.

&amp;#x200B;

Link:  magnet:?xt=urn:btih:6318a9e4735b4cdc6c88ccbd9f16e9c1c016ed88&amp;dn=Common+Voice+V2+March+2019.rar ",1,1,False,self,,,,,
70,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,2,ayt1sh,github.com,Algernon -- the curious mouse pointer.,https://www.reddit.com/r/deeplearning/comments/ayt1sh/algernon_the_curious_mouse_pointer/,ZeroMaxinumXZ,1552067135,,9,1,False,default,,,,,
71,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,2,ayt4mp,medium.com,Google Debuts TensorFlow 2.0 Alpha,https://www.reddit.com/r/deeplearning/comments/ayt4mp/google_debuts_tensorflow_20_alpha/,Yuqing7,1552067566,,1,29,False,default,,,,,
72,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,3,ayt828,self.ArtificialInteligence,Help please,https://www.reddit.com/r/deeplearning/comments/ayt828/help_please/,DustyCakeRendy,1552068065,,0,2,False,default,,,,,
73,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,6,ayvu09,self.deeplearning,How to deal with image data captured from different camera sources,https://www.reddit.com/r/deeplearning/comments/ayvu09/how_to_deal_with_image_data_captured_from/,naboo_random,1552081915,"Hi, 

I am trying to object classification of a kind, where the image data that I have has been captured via different sources. Can someone suggest ways or models that are unaffected by the source of the data, but can still perform well to identify the object?

The train images are captured using a microscope, dslr and phone camera. Where as the test images are captured using a phone. 

&amp;#x200B;

Again, there are differences in each of their backgrounds, and lightning conditions as well. I know there are image preprocessing techniques that I can use to equalize images on the lightning part, but there is a lot of difference in their resolutions as well. 

&amp;#x200B;

Any help will be appreciated! 

Thanks!",2,1,False,self,,,,,
74,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,9,ayxppn,self.deeplearning,Weird losses with resnet,https://www.reddit.com/r/deeplearning/comments/ayxppn/weird_losses_with_resnet/,CreativeElephant,1552092586,"I have been trying resnet-18 on CIFAR-10, I did not normalize the data and feed cifar-10 images (0-1 range) as it is to train the model. I see some weird loss behaviour, is it normal? I see that loss goes down initially and accuracy improves but as training progresses loss increases a lot but accuracy plateaus. What confounds me is test loss and test accuracy are not at all correlated!! Optimizer is SGD/ADAM with initial lr=0.1 and varies as initial\_lr\*10\^{-epoch/100}. I train for 300 epochs  

[Accuracy and Loss curves](https://i.redd.it/09hzwa9g9zk21.png)",8,1,False,self,,,,,
75,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,13,ayzntz,self.deeplearning,Good papers on curiosity in reinforcement-learning.,https://www.reddit.com/r/deeplearning/comments/ayzntz/good_papers_on_curiosity_in_reinforcementlearning/,ZeroMaxinumXZ,1552105981,"I'm looking for some good academic papers on curiosity in reinforcement learning, I've created a curious agent using Tensorforce and Keras as shown here: [https://github.com/ZeroMaxinumXZ/algernon](https://github.com/ZeroMaxinumXZ/algernon), but would like to improve the agent further...  if possible. Any suggestions/recommendations?",1,5,False,self,,,,,
76,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,16,az0v8m,self.deeplearning,Resources on implementing YOLO.,https://www.reddit.com/r/deeplearning/comments/az0v8m/resources_on_implementing_yolo/,ragingpot,1552115384,I'm looking to implement YOLO from scratch (minus the pretrained model and weights). Any resources which could help me understand the model as I'm a relative beginner in deep learning. Thank you!,4,2,False,self,,,,,
77,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,17,az1cfc,self.deeplearning,TensorFlow nan Loss,https://www.reddit.com/r/deeplearning/comments/az1cfc/tensorflow_nan_loss/,arjundupa,1552119775,"I am trying to de-noise a signal by training a model based on the IndRNN architecture ([https://arxiv.org/abs/1803.04831](https://arxiv.org/abs/1803.04831)) using TensorFlow. I am using curriculum learning, which in the context of my problem simply means that I started off training the model with data with high signal-to-noise ratio (SNR), and gradually decreased it.

Training was going extremely well until SNR = 1.5 (I originally started at SNR = 4.0 and worked my way down), which is when I began getting this nan loss. I have tried reducing the learning rate (by a factor of 10 of the original), but this hasn't helped either.

Any ideas about the cause of this issue and what I can try to resolve it?

Any ideas will be much appreciated, thanks in advance.",6,4,False,self,,,,,
78,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,19,az2cd4,self.deeplearning,"Suggestions for multi-input pipeline with ""convolution"" over one of the inputs in keras/tensorflow?",https://www.reddit.com/r/deeplearning/comments/az2cd4/suggestions_for_multiinput_pipeline_with/,nobodywillobserve,1552128835,"Am trying to get a pipeline working in Keras and am hitting up against a lot of issues, wondering if I need to drop to vanilla tf or if there is something wrong with my approach. 

&amp;#x200B;

I have two inputs X, Z. In a naive implementation I can simply repeat X and use the inputs \[\[X, Z0\], \[X, Z1\], ... \[X, Zn\]\] into a regular single input pipeline. This works but involves potentially wasting a lot of memory replicating X across the values of Z.

&amp;#x200B;

I was trying to write this as a a two input pipeline where there is a Conv1D over Z which is then combined with a VectorRepeater or a K.repeat\_elements of X. Ideally, the input Z is of dynamic shape (plus the batch size of X is dynamic). 

&amp;#x200B;

The biggest issue seems to come with trying to get the repeat dimension for X from the Z (which is dynamic and not known until call time). I could potentially have Z dimension be more hard-coded.

&amp;#x200B;

I am reading things that basically when you break the notion of batch size and have \*other\* dynamic dimension, Keras becomes tricky and it is best to descend to pure tensorflow. But am not clear if I can still use some of the layer constructors from Keras and simply some other components from tf.  


&amp;#x200B;

&amp;#x200B;",8,4,False,self,,,,,
79,deeplearning,t5_2t5eh,2019-3-9,2019,3,9,20,az2ic8,self.deeplearning,Neural ODEs.,https://www.reddit.com/r/deeplearning/comments/az2ic8/neural_odes/,ragingpot,1552130235,Has anyone understood and implemented https://arxiv.org/abs/1806.07366 Neural Differential Equations paper? Any help would be appreciated. Thank you!,2,6,False,self,,,,,
80,deeplearning,t5_2t5eh,2019-3-10,2019,3,10,3,az6r1j,self.deeplearning,Audio Embeddings,https://www.reddit.com/r/deeplearning/comments/az6r1j/audio_embeddings/,pk12_,1552157827,"I'm looking to investigate audio embeddings for voice recognition. 

Do you guys know of a resource which provides pre trained models",0,2,False,self,,,,,
81,deeplearning,t5_2t5eh,2019-3-10,2019,3,10,4,az71dg,mlwhiz.com,"NLP Learning Series: Part 3 - Attention, CNN and what not for Text Classification",https://www.reddit.com/r/deeplearning/comments/az71dg/nlp_learning_series_part_3_attention_cnn_and_what/,kiser_soze,1552159481,,0,18,False,default,,,,,
82,deeplearning,t5_2t5eh,2019-3-10,2019,3,10,5,az7pka,self.deeplearning,GAN Human Facial Expression Style Transfer - But Small Dataset?,https://www.reddit.com/r/deeplearning/comments/az7pka/gan_human_facial_expression_style_transfer_but/,wypbusy,1552163300,"Hello guys,

&amp;#x200B;

I am working on a course project and find this [paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Azadi_Multi-Content_GAN_for_CVPR_2018_paper.pdf) fairly interesting and want to apply and modify the idea to modify human face according to different expression (such as happy, angry, surprise, etc). 

&amp;#x200B;

However, it seems the dataset for different human expressions are pretty limited (the original paper used 10K dataset), for example, I found [this dataset](https://mug.ee.auth.gr/fed/) that provides only 86 subjects with 6 different expressions. 

&amp;#x200B;

Is it possible to use such a limited dataset for my project? Any ideas or suggestions are appreciated!. ",0,3,False,self,,,,,
83,deeplearning,t5_2t5eh,2019-3-10,2019,3,10,12,azbkkq,medium.com,Bengio at Tsinghua University on Maturing Deep Learning and BabyAI,https://www.reddit.com/r/deeplearning/comments/azbkkq/bengio_at_tsinghua_university_on_maturing_deep/,Yuqing7,1552188010,,0,12,False,default,,,,,
84,deeplearning,t5_2t5eh,2019-3-10,2019,3,10,18,aze0e9,github.com,A deep learning approach for end-to-end visual odometry,https://www.reddit.com/r/deeplearning/comments/aze0e9/a_deep_learning_approach_for_endtoend_visual/,redditball000,1552209186,,1,7,False,default,,,,,
85,deeplearning,t5_2t5eh,2019-3-10,2019,3,10,20,azen4u,self.deeplearning,"A PyTorch implementation of ""Graph Wavelet Neural Network"" (ICLR 2019)",https://www.reddit.com/r/deeplearning/comments/azen4u/a_pytorch_implementation_of_graph_wavelet_neural/,benitorosenberg,1552215702,"&amp;#x200B;

&amp;#x200B;

https://i.redd.it/8e3pwq7nw9l21.jpg

Paper: [https://openreview.net/forum?id=H1ewdiR5tQ](https://openreview.net/forum?id=H1ewdiR5tQ)

PyTorch: [https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork](https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork)

Abstract:

We  present graph wavelet neural network (GWNN), a novel graph   convolutional neural network (CNN), leveraging graph wavelet transform   to address the shortcomings of previous spectral graph CNN methods that   depend on graph Fourier transform. Different from graph Fourier   transform, graph wavelet transform can be obtained via a fast algorithm   without requiring matrix eigendecomposition with high computational   cost. Moreover, graph wavelets are sparse and localized in vertex   domain, offering high efficiency and good interpretability for graph   convolution. The proposed GWNN significantly outperforms previous   spectral graph CNNs in the task of graph-based semi-supervised   classification on three benchmark datasets: Cora, Citeseer and Pubmed.",0,24,False,self,,,,,
86,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,0,azgw5r,self.deeplearning,IBM new Floating Point (FP8) DNN training format in NeurIPS2018,https://www.reddit.com/r/deeplearning/comments/azgw5r/ibm_new_floating_point_fp8_dnn_training_format_in/,CArchGuy,1552232750,"IBM uses FP8 in the forward pass and FP16 in the backprop. with stochastic rounding scheme. What do you think of this paper? Will it scale to train networks larger than ResNet50 (what they report in their paper), and will it be the training standard for the next few years ? 

What about bfloat16 which Intel and Google went to support in their HW ?

For people building custom hardware, which format should they select?",1,1,False,self,,,,,
87,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,5,azk7ms,youtu.be,"""(Deep) Learning to Fly"" with Krzysztof Kudrynski &amp; Blazej Kubiak (45min talk from GOTO Berlin 2018)",https://www.reddit.com/r/deeplearning/comments/azk7ms/deep_learning_to_fly_with_krzysztof_kudrynski/,goto-con,1552250770,,1,8,False,default,,,,,
88,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,8,azlqmi,youtube.com,Implementing Neural Networks from Scratch,https://www.reddit.com/r/deeplearning/comments/azlqmi/implementing_neural_networks_from_scratch/,DiscoverAI,1552259023,,0,0,False,image,,,,,
89,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,11,aznkxh,self.deeplearning,Will tickets for ICML2019 be sold out in 10-20 min.? (Just like NIPS),https://www.reddit.com/r/deeplearning/comments/aznkxh/will_tickets_for_icml2019_be_sold_out_in_1020_min/,dhjjjj,1552270081,"Registration for ICML starts on March 12th.  
What do you guys think?

On the other hand, it is still possible to register for CVPR2019 which starts right after ICML in Long Beach.   
Will it be sold-out in 20 mins as NIPS was?",0,8,False,self,,,,,
90,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,11,aznusj,self.deeplearning,What is happening in this basic rnn?,https://www.reddit.com/r/deeplearning/comments/aznusj/what_is_happening_in_this_basic_rnn/,begooboi,1552271753,"I have a lot of confusion in rnn so I am re-learning it. Found this basic implementation in tensorflow https://github.com/StephenOman/TensorFlowExamples/blob/master/Basic%20RNN.ipynb
What is X0 and X1 means here?
      Y0 = tf.tanh(tf.matmul(X0, Wx) + b)
      Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)

I believe rnn follows this struture
      (input+prev_hidden) -&gt; hidden -&gt; output

where Y0 can be taken as hidden value and Y1's input should be current input plus previous hidden value `tf.matmul(Y0, Wy) + tf.matmul(X0, Wx) + b` but here its given as `tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b` (look at X0 and X1). What is happening here?",6,1,False,self,,,,,
91,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,12,azoeq1,self.deeplearning,Google Colab,https://www.reddit.com/r/deeplearning/comments/azoeq1/google_colab/,pk12_,1552275134,"I read that we need to keep Google colab browser window open in order to keep it running for 12 hours

Does keeping it open in the second monitor count?",1,0,False,self,,,,,
92,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,12,azojgn,self.deeplearning,NYUv2 Dataset Download Available?,https://www.reddit.com/r/deeplearning/comments/azojgn/nyuv2_dataset_download_available/,kairos9603,1552275960,The NYUv2 download link is not working... Any one can do this?,0,1,False,self,,,,,
93,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,15,azpuwe,self.deeplearning,How to visualize the accuracy of a neural network in Pytorch?,https://www.reddit.com/r/deeplearning/comments/azpuwe/how_to_visualize_the_accuracy_of_a_neural_network/,Vinceeeent,1552284574,"I want to visualize the accuracy of a neural network I got from github [here](https://github.com/paraschopra/one-network-many-uses/blob/master/four-in-one-network.ipynb). The code was written in Pytorch, is there a way to find the accuracy of this network? I know in keras can visualize the training but in pytorch I can't find any. Hope someone can help me :)",12,5,False,self,,,,,
94,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,18,azr7r3,self.deeplearning,Any ideas or suggestions for my reinforcement learning AI ...,https://www.reddit.com/r/deeplearning/comments/azr7r3/any_ideas_or_suggestions_for_my_reinforcement/,ZeroMaxinumXZ,1552295280,"So basically I built a reinforcement learning AI that can curiously explore it's environment using aKeras dense neural network's loss (input is the environment, and output is the action) as a reward... The mouse pointer moves based on the actions of the reinforcement learning AI, and the keys are pressable by this agent... I'm using the PPOAgent provided by Tensorforce and the model is a whole bunch of convolutional layers coupled with the swish activation function... So, what should I do next to improve my reinforcement learning agent? It feels like I've done quite a bit, but agent will barely move if at all...",12,1,False,self,,,,,
95,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,18,azrjah,youtube.com,AI JavaScript Rocks,https://www.reddit.com/r/deeplearning/comments/azrjah/ai_javascript_rocks/,DmitriyGenzel,1552297869,,0,0,False,image,,,,,
96,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,20,azs2t7,self.deeplearning,"A PyTorch Implementation of ""Watch Your Step: Learning Node Embeddings via Graph Attention"" (NeurIPS 2018).",https://www.reddit.com/r/deeplearning/comments/azs2t7/a_pytorch_implementation_of_watch_your_step/,benitorosenberg,1552302003,"&amp;#x200B;

https://i.redd.it/17g6nrfa1hl21.jpg

Paper: [https://github.com/benedekrozemberczki/AttentionWalk/blob/master/paper.pdf](https://github.com/benedekrozemberczki/AttentionWalk/blob/master/paper.pdf)

Python: [https://github.com/benedekrozemberczki/AttentionWalk](https://github.com/benedekrozemberczki/AttentionWalk)

Abstract:

Graph  embedding methods represent nodes in a continuous vector space,   preserving different types of relational information from the graph.   There are many hyper-parameters to these methods (e.g. the length of a   random walk) which have to be manually tuned for every graph. In this   paper, we replace previously fixed hyper-parameters with trainable ones   that we automatically learn via backpropagation. In particular, we   propose a novel attention model on the power series of the transition   matrix, which guides the random walk to optimize an upstream objective.   Unlike previous approaches to attention models, the method that we   propose utilizes attention parameters exclusively on the data itself   (e.g. on the random walk), and are not used by the model for inference.   We experiment on link prediction tasks, as we aim to produce embeddings   that best-preserve the graph structure, generalizing to unseen   information. We improve state-of-the-art results on a comprehensive   suite of real-world graph datasets including social, collaboration, and   biological networks, where we observe that our graph attention model  can  reduce the error by up to 20%-40%. We show that our   automatically-learned attention parameters can vary significantly per   graph, and correspond to the optimal choice of hyper-parameter if we   manually tune existing methods.",0,21,False,self,,,,,
97,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,22,aztle3,badootech.badoo.com,Deep Neural Networks &amp; Image Captioning,https://www.reddit.com/r/deeplearning/comments/aztle3/deep_neural_networks_image_captioning/,lauram16_hello,1552311757,,0,2,False,default,,,,,
98,deeplearning,t5_2t5eh,2019-3-11,2019,3,11,23,aztxg7,ai-jobs.net,Find AI and deep learning jobs,https://www.reddit.com/r/deeplearning/comments/aztxg7/find_ai_and_deep_learning_jobs/,ai_jobs,1552313682,,3,8,False,default,,,,,
99,deeplearning,t5_2t5eh,2019-3-12,2019,3,12,2,azw0bj,medium.com,Introducing TensorFlow Federated,https://www.reddit.com/r/deeplearning/comments/azw0bj/introducing_tensorflow_federated/,Karthik9999,1552324672,,0,20,False,default,,,,,
100,deeplearning,t5_2t5eh,2019-3-12,2019,3,12,3,azx5iv,self.deeplearning,What is the time complexity of object localization?,https://www.reddit.com/r/deeplearning/comments/azx5iv/what_is_the_time_complexity_of_object_localization/,skyline678,1552330356,"## Given an image of size O(N) pixels, or some features of size O(N), how fast is modern-day object localization, in big-O notation?

## For example, I'd like my model to localize cars. I use some SVM to obtain features, then pass those to a localizer. Based on the O(N) features, it's possible to find the maximum within them in O(N^1.5) time.",4,1,False,self,,,,,
101,deeplearning,t5_2t5eh,2019-3-12,2019,3,12,8,b008vj,youtube.com,How Neural Networks Work- Simply Explained,https://www.reddit.com/r/deeplearning/comments/b008vj/how_neural_networks_work_simply_explained/,DiscoverAI,1552345651,,1,6,False,image,,,,,
102,deeplearning,t5_2t5eh,2019-3-12,2019,3,12,10,b021c6,self.deeplearning,What are good DL topics for research in 2019?,https://www.reddit.com/r/deeplearning/comments/b021c6/what_are_good_dl_topics_for_research_in_2019/,GabiruAttack,1552355840,I'm looking for a topic for my master degree but I can't decide. Is NLP or reinforcement learning still hot this year? Thanks.,12,15,False,self,,,,,
103,deeplearning,t5_2t5eh,2019-3-12,2019,3,12,11,b02fu6,self.deeplearning,[Help] Variable length CNN in Keras,https://www.reddit.com/r/deeplearning/comments/b02fu6/help_variable_length_cnn_in_keras/,pk12_,1552358309,How to make CNNs work when I have variable length signals?,0,1,False,self,,,,,
104,deeplearning,t5_2t5eh,2019-3-12,2019,3,12,17,b05a06,self.deeplearning,Year-Long AI Fellowships,https://www.reddit.com/r/deeplearning/comments/b05a06/yearlong_ai_fellowships/,the_new_scientist,1552378795,"Other than Google, Facebook, and OpenAI, what other companies offer 1 year research fellowships for post masters students?",3,14,False,self,,,,,
105,deeplearning,t5_2t5eh,2019-3-12,2019,3,12,17,b05heu,self.deeplearning,Needing a cloud desktop with a GPU... Any good services out there?,https://www.reddit.com/r/deeplearning/comments/b05heu/needing_a_cloud_desktop_with_a_gpu_any_good/,ZeroMaxinumXZ,1552380647,"Hello.  I'm a self-proclaimed ""AI researcher"" (double quotes to not insult the real AI researchers here). I'd like a GPU-enabled cloud desktop to continue my research, as I'm running Tensorflow on a pretty ok but definitely not a GPU, CPU.. I'm wondering if anyone has any good recommendations. I know about Colab but I need a desktop preferably running Ubuntu...",9,3,False,self,,,,,
106,deeplearning,t5_2t5eh,2019-3-12,2019,3,12,18,b05l0f,self.deeplearning,[  ] /,https://www.reddit.com/r/deeplearning/comments/b05l0f/__/,Afault,1552381462,"Location: Shenzhen, Beijing

&amp;#x200B;

Jobs provided : Software Engineer (C/C++/Java/Python/Golang/PHP), Big Data Engineer, Algorithm Engineer , Data Mining Engineer and Front-end Engineer. (internship/ full time)

&amp;#x200B;

Who we are We are ByteDance risk-control department. We have offices in Shenzhen, Beijing and you are free to choose where you work.

&amp;#x200B;

We are looking for several different  kind of engineers, and we have work like big data processing, build system, data mining, machine learning and NLP algorithms. We welcome different technical backgrounds engineer and we value problem solving skills more than specific language or framework. 

&amp;#x200B;

Requirements:

&amp;#x200B;

B.S. or M.S. (preferred) degree in Computer Science or related technical field. We also welcome self-taught programmers but you need to show equivalent knowledge or experience, especially basic data structures and algorithm.

&amp;#x200B;

Specific jobs and requirements see this link:

[https://mp.weixin.qq.com/s?\_\_biz=Mzg2NTA2MTI3OQ==&amp;mid=100000022&amp;idx=1&amp;sn=76461bcf2fc66624f5f6beffa79d2123&amp;chksm=4e5e91e6792918f0b46ab0abba76b663e332116a3d2dc4b200642f133fb4a127affa64e10f30&amp;mpshare=1&amp;scene=1&amp;srcid=0309M1ykbvLYpqrRHvkxSmyv#rd](https://mp.weixin.qq.com/s?__biz=Mzg2NTA2MTI3OQ==&amp;mid=100000022&amp;idx=1&amp;sn=76461bcf2fc66624f5f6beffa79d2123&amp;chksm=4e5e91e6792918f0b46ab0abba76b663e332116a3d2dc4b200642f133fb4a127affa64e10f30&amp;mpshare=1&amp;scene=1&amp;srcid=0309M1ykbvLYpqrRHvkxSmyv#rd)

&amp;#x200B;

Contact:

&amp;#x200B;

PM  (I will refer you if you are qualified) or send your resume to guanjianchun@bytedance.com",0,1,False,self,,,,,
107,deeplearning,t5_2t5eh,2019-3-12,2019,3,12,19,b06ejy,youtu.be,"""Build a Q&amp;A bot with DeepLearning4J"" with Willem Meints (45min from GOTO Berlin 2018)",https://www.reddit.com/r/deeplearning/comments/b06ejy/build_a_qa_bot_with_deeplearning4j_with_willem/,goto-con,1552388140,,1,0,False,image,,,,,
108,deeplearning,t5_2t5eh,2019-3-12,2019,3,12,21,b06zsn,self.deeplearning,"A PyTorch implementation of ""Signed Graph Convolutional Network"" (ICDM 2018).",https://www.reddit.com/r/deeplearning/comments/b06zsn/a_pytorch_implementation_of_signed_graph/,benitorosenberg,1552392262,"&amp;#x200B;

https://i.redd.it/uvbm9d7phol21.jpg

&amp;#x200B;

Paper: [https://github.com/benedekrozemberczki/SGCN/blob/master/sgcn.pdf](https://github.com/benedekrozemberczki/SGCN/blob/master/sgcn.pdf)

Python: [https://github.com/benedekrozemberczki/SGCN/](https://github.com/benedekrozemberczki/SGCN/)

ABSTRACT:

Due  to the fact much of today's data can be represented as graphs, there   has been a demand for generalizing neural network models for graph   data. One recent direction that has shown fruitful results, and   therefore growing interest, is the usage of graph convolutional neural   networks (GCNs). They have been shown to provide a significant   improvement on a wide range of tasks in network analysis, one of which   being node representation learning. The task of learning low-dimensional   node representations has shown to increase performance on a plethora  of  other tasks from link prediction and node classification, to  community  detection and visualization. Simultaneously, signed networks  (or graphs  having both positive and negative links) have become  ubiquitous with the  growing popularity of social media. However, since  previous GCN models  have primarily focused on unsigned networks (or  graphs consisting of  only positive links), it is unclear how they could  be applied to signed  networks due to the challenges presented by  negative links. The primary  challenges are based on negative links  having not only a different  semantic meaning as compared to positive  links, but their principles are  inherently different and they form  complex relations with positive  links. Therefore we propose a dedicated  and principled effort that  utilizes balance theory to correctly  aggregate and propagate the  information across layers of a signed GCN  model. We perform empirical  experiments comparing our proposed signed  GCN against state-of-the-art  baselines for learning node  representations in signed networks. More  specifically, our experiments  are performed on four real-world datasets  for the classical link sign  prediction problem that is commonly used as  the benchmark for signed  network embeddings algorithms.",0,2,False,self,,,,,
109,deeplearning,t5_2t5eh,2019-3-13,2019,3,13,0,b0973h,github.com,"DeepCamera: Turn digital camera into AI-powered video surveillance on embedded Linux/Android. ArcFace, MTCNN, Object Detection and REiD for production",https://www.reddit.com/r/deeplearning/comments/b0973h/deepcamera_turn_digital_camera_into_aipowered/,solderzzc,1552405223,,1,25,False,default,,,,,
110,deeplearning,t5_2t5eh,2019-3-13,2019,3,13,1,b09tgg,self.deeplearning,[Q] is there a percentage of actual to augmented data?,https://www.reddit.com/r/deeplearning/comments/b09tgg/q_is_there_a_percentage_of_actual_to_augmented/,pk12_,1552408343,"Should I have 20% augmented data in training with 80% actual data?

Are there any such guidelines?",1,0,False,self,,,,,
111,deeplearning,t5_2t5eh,2019-3-13,2019,3,13,2,b0a8gm,self.deeplearning,"Indian student, no interest in education system and want to do research in deep learning",https://www.reddit.com/r/deeplearning/comments/b0a8gm/indian_student_no_interest_in_education_system/,arshad_221b,1552410404,"I'm an Indian **engineering** student. I want to do my career in deep learning. I'm in 3rd year now. I've been studying machine learning from last 6 months now. I've done some courses online and done some basic projects. Thing is, I don't have any interest in education system. This University syllabus feels like I'm learning what they want to teach me, not what I want to learn. 
I'm confused and somewhat scared. I don't want job in TCS like mass recruiters(I'm will end up there if I don't do anything,low pointer guy). I want to do research in deep learning. Right now I don't have any exposure for that. 
I don't want to go abroad and do PhD. (most researchers say we don't need a PhD to do research in ML(just a fact)) 
What should I do? Where to find a job like that? (_  ) ",4,0,False,self,,,,,
112,deeplearning,t5_2t5eh,2019-3-13,2019,3,13,6,b0d6wp,self.deeplearning,Dataset recommendation,https://www.reddit.com/r/deeplearning/comments/b0d6wp/dataset_recommendation/,khronoskaiross,1552425263,"Hey guys,
So I've been working on a computer vision problem. And would like a dataset with 3D models and their corresponding 2D images. I read about ObjectNet3D, does anybody have any experience on that? And also would it be better to use a set like ShapeNet and then calculate viewpoints and maybe use ray tracing to extract 2d shape? ",1,5,False,self,,,,,
113,deeplearning,t5_2t5eh,2019-3-13,2019,3,13,12,b0h8h1,self.deeplearning,Tensorflow2.0 YouTube Tutorial!!,https://www.reddit.com/r/deeplearning/comments/b0h8h1/tensorflow20_youtube_tutorial/,shawnmanuel000,1552447936,"Hey guys, I made a YouTube tutorial to help beginners learn to code their own neural networks with the high level API of Tensorflow2.0 as well as from the low level building blocks for custom models. Hope it helps with adapting to the new version of tf which is much easier to use than the first version!

Link: [https://www.youtube.com/watch?v=fQCKxzHvYnw](https://www.youtube.com/watch?v=fQCKxzHvYnw)

PS: My next tutorial would probably be something similar for tensorflow.js which I can also post here if people are interested.",3,39,False,self,,,,,
114,deeplearning,t5_2t5eh,2019-3-13,2019,3,13,14,b0i2zx,en.d2l.ai,"Dive into Deep Learning (2019) Book By: Aston Zhang, Zachary C. Lipton, Mu Li, Alexander J. Smola Reference: Introduction to Deep Learning STAT 157, University of California, Berkeley, Spring, 2019 UC Berkeley #DeepLearning #machinelearning #artificialintelligence",https://www.reddit.com/r/deeplearning/comments/b0i2zx/dive_into_deep_learning_2019_book_by_aston_zhang/,aiforworld2,1552453705,,0,12,False,default,,,,,
115,deeplearning,t5_2t5eh,2019-3-13,2019,3,13,18,b0jswp,self.deeplearning,Trouble building caffe from source,https://www.reddit.com/r/deeplearning/comments/b0jswp/trouble_building_caffe_from_source/,atinesh229,1552467863,"I am trying to install caffe by building it from [source](https://github.com/BVLC/caffe)

After issuing the following command from the caffe root directory

    $ make all -j4

I am getting an error

    ...
    CXX src/caffe/layer_factory.cpp
    CXX src/caffe/blob.cpp
    AR -o .build_release/lib/libcaffe.a
    LD -o .build_release/lib/libcaffe.so.1.0.0 
    /usr/bin/x86_64-linux-gnu-ld: cannot find -lpython3.6
    collect2: error: ld returned 1 exit status
    Makefile:582: recipe for target '.build_release/lib/libcaffe.so.1.0.0' failed
    make: *** [.build_release/lib/libcaffe.so.1.0.0] Error 1

**Dependencies installed**

    $ sudo apt install python3-opencv
    $ sudo apt-get install libatlas-base-dev
    $ sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler
    $ sudo apt-get install --no-install-recommends libboost-all-dev
    $ sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev
    $ sudo apt-get install the python3-dev

**CUDA**: CUDA 9, CuDnn 7.4

**Ubuntu**: Ubuntu 18.04

[Makefile.config](https://www.dropbox.com/s/yib5afza5zyytfx/Makefile.config?dl=0)

&amp;#x200B;

I have looked at all the [issues](https://github.com/BVLC/caffe/issues) in the source Github repository but couldn't find anything useful.",0,1,False,self,,,,,
116,deeplearning,t5_2t5eh,2019-3-13,2019,3,13,23,b0mfjp,self.deeplearning,Latest research papers on deep reinforcement learning?,https://www.reddit.com/r/deeplearning/comments/b0mfjp/latest_research_papers_on_deep_reinforcement/,ZeroMaxinumXZ,1552486156,"I want some of the latest research papers on deep reinforcement learning,  Any recommendations?",0,2,False,self,,,,,
117,deeplearning,t5_2t5eh,2019-3-14,2019,3,14,2,b0optk,self.deeplearning,ChatBot With WhatsApp Conversation.,https://www.reddit.com/r/deeplearning/comments/b0optk/chatbot_with_whatsapp_conversation/,code_crawler,1552498249,"Anyone here created or tried to create a chatBot with WhatsApp Conversation as a the Train Data?
I wonder how sarcastic the Bot's gonna be....!!",0,1,False,self,,,,,
118,deeplearning,t5_2t5eh,2019-3-14,2019,3,14,2,b0otgs,self.deeplearning,[P] Reinforcement Learning With Unity 3D: Cleaning up at the Oktoberfest!,https://www.reddit.com/r/deeplearning/comments/b0otgs/p_reinforcement_learning_with_unity_3d_cleaning/,dtransposed,1552498729,"&amp;#x200B;

https://i.redd.it/al7p0eq8axl21.png

Hello! Me and my team have recently created a prototype of an intelligent agent for garbage collection.  

The goal of the agent is collect relevant pieces of garbage, while avoiding collisions with static objects (such as chairs or tables). The  agent navigates in the environment (a mock-up of German Oktoberfest  tent) using camera RBG-D input. 

&amp;#x200B;

The blog post also contains a link to GitHub Repo:

[https://dtransposed.github.io/blog/GEAR.html](https://dtransposed.github.io/blog/GEAR.html)",2,18,False,self,,,,,
119,deeplearning,t5_2t5eh,2019-3-14,2019,3,14,11,b0v2dh,go.learn4startup.com,PyTorch 1.0 Now and In the Future || Adam Paszke,https://www.reddit.com/r/deeplearning/comments/b0v2dh/pytorch_10_now_and_in_the_future_adam_paszke/,MarkOliver908,1552531740,,0,4,False,default,,,,,
120,deeplearning,t5_2t5eh,2019-3-14,2019,3,14,15,b0ws77,self.deeplearning,What deep learning applications do you find to be too slow?,https://www.reddit.com/r/deeplearning/comments/b0ws77/what_deep_learning_applications_do_you_find_to_be/,thevillaincassiopeia,1552543690,I am interested in working on parallel computing and deep learning. I know that training time is the most obvious problem in deep learning. But I am wondering if there are any applications that you find to be very slow. I could maybe work on accelerating that for my next project. ,2,1,False,self,,,,,
121,deeplearning,t5_2t5eh,2019-3-14,2019,3,14,16,b0xldh,self.deeplearning,How would I create a spiking neural network in tensorflow?,https://www.reddit.com/r/deeplearning/comments/b0xldh/how_would_i_create_a_spiking_neural_network_in/,ZeroMaxinumXZ,1552550170,"I know very little about SNNs, so... From what I can infer, a spiking neural network consists of spikes of energy using a biological model of neurons... I don't really know much about them. So, where can I go to learn about these, and more importantly how would I create one in tensorflow?",9,12,False,self,,,,,
122,deeplearning,t5_2t5eh,2019-3-14,2019,3,14,17,b0xvc6,self.deeplearning,Best tutorial to get started with TensorFlow,https://www.reddit.com/r/deeplearning/comments/b0xvc6/best_tutorial_to_get_started_with_tensorflow/,AdventurousMine8,1552552551,"So I have been reading Goodfellow's and now I want to get my hands dirty and implement some things in TensorFlow. What tutorial do you guys suggest?

&amp;#x200B;

I already have experience in programming in Python.",2,7,False,self,,,,,
123,deeplearning,t5_2t5eh,2019-3-14,2019,3,14,18,b0y57i,self.deeplearning,"A PyTorch implementation of ""Graph Classification Using Structural Attention"" (KDD 2018).",https://www.reddit.com/r/deeplearning/comments/b0y57i/a_pytorch_implementation_of_graph_classification/,benitorosenberg,1552554967,"&amp;#x200B;

https://i.redd.it/4zl5d7agx1m21.jpg

&amp;#x200B;

Python: [https://github.com/benedekrozemberczki/GAM](https://github.com/benedekrozemberczki/GAM)

Paper: [https://github.com/benedekrozemberczki/GAM/blob/master/paper.pdf](https://github.com/benedekrozemberczki/GAM/blob/master/paper.pdf)

Abstract:

Graph  classification is a problem with practical applications in many   different domains. To solve this problem, one usually calculates certain   graph statistics (i.e., graph features) that help discriminate between   graphs of different classes. When calculating such features, most   existing approaches process the entire graph. In a graphlet-based   approach, for instance, the entire graph is processed to get the total   count of different graphlets or subgraphs. In many real-world   applications, however, graphs can be noisy with discriminative patterns   confined to certain regions in the graph only. In this work, we study   the problem of attention-based graph classification . The use of   attention allows us to focus on small but informative parts of the   graph, avoiding noise in the rest of the graph. We present a novel RNN   model, called the Graph Attention Model (GAM), that processes only a   portion of the graph by adaptively selecting a sequence of informative   nodes. Experimental results on multiple real-world datasets show that   the proposed method is competitive against various well-known methods  in  graph classification even though our method is limited to only a  portion of the graph.",0,4,False,self,,,,,
124,deeplearning,t5_2t5eh,2019-3-14,2019,3,14,18,b0y8tm,self.deeplearning,Awesome papers and reviews [with codes!] on Computer Vision News of March. Links for free reading!,https://www.reddit.com/r/deeplearning/comments/b0y8tm/awesome_papers_and_reviews_with_codes_on_computer/,Gletta,1552555829,"Here are the links to the March 2019 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: many articles about Artificial Intelligence, Deep Learning, Computer Vision and more. Free subscription on page 34.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019March/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-march-pdf/)

Enjoy!",0,43,False,self,,,,,
125,deeplearning,t5_2t5eh,2019-3-14,2019,3,14,21,b0zx7y,link.medium.com,Just wrote a Medium post on how to serve TensorFlow models with Docker via REST API. It's an end-to-end minimum example with documented Notebook. Hope it helps.,https://www.reddit.com/r/deeplearning/comments/b0zx7y/just_wrote_a_medium_post_on_how_to_serve/,jingw222,1552567635,,0,13,False,default,,,,,
126,deeplearning,t5_2t5eh,2019-3-15,2019,3,15,0,b11tew,self.deeplearning,Intro To Deep Learning: Taught by a 14-Year-Old,https://www.reddit.com/r/deeplearning/comments/b11tew/intro_to_deep_learning_taught_by_a_14yearold/,jakemalis,1552578088,"Hello everyone! I just wrote an article for a website, Medium, where I talk about how AI and Deep Learning will impact our future, how it works, and why it may be dangerous. Feel free to check it out and give it a clap @ [https://medium.com/@jakemalis/intro-to-deep-learning-taught-by-a-14-year-old-6c49fc94d66](https://medium.com/@jakemalis/intro-to-deep-learning-taught-by-a-14-year-old-6c49fc94d66).",0,0,False,self,,,,,
127,deeplearning,t5_2t5eh,2019-3-15,2019,3,15,3,b13ymp,self.deeplearning,What skills to gain if I want to become deep learning engineer?,https://www.reddit.com/r/deeplearning/comments/b13ymp/what_skills_to_gain_if_i_want_to_become_deep/,sanchit2843,1552588557,"Hello,

I am an undergraduate and studying deep learning for last two years. Can anyone suggest some skills such as sql that companies expect from deep learning engineer. Also, what should I study now so that I can become better in the field. Please suggest. 

Thanks in advance. ",1,1,False,self,,,,,
128,deeplearning,t5_2t5eh,2019-3-15,2019,3,15,4,b14vg8,self.deeplearning,Deep Learning: When Should You Use It?,https://www.reddit.com/r/deeplearning/comments/b14vg8/deep_learning_when_should_you_use_it/,edxsocial,1552593039,"The author writes: there are alternatives that may not be as complex, such as traditional machine learning. In cases with smaller datasets and simpler correlations, techniques like KNN or random forest may be more appropriate and effective said Sheldon Fernandez, who is the CEO of [DarwinAI](https://darwinai.ca/). A deep learning model might easily get a problematic or nonsensical correlation, said Sheldon,. That is, the network might draw conclusions based on quirks in the dataset that are catastrophic from a practical point of view.

[https://www.forbes.com/sites/tomtaulli/2019/03/09/deep-learning-when-should-you-use-it/](https://www.forbes.com/sites/tomtaulli/2019/03/09/deep-learning-when-should-you-use-it/#6bfc01e94e36)",2,1,False,self,,,,,
129,deeplearning,t5_2t5eh,2019-3-15,2019,3,15,7,b16z1n,self.deeplearning,3D UNet in TensorFlow,https://www.reddit.com/r/deeplearning/comments/b16z1n/3d_unet_in_tensorflow/,bayeslaw,1552603387,"If anyone interested

[repo](https://github.com/danielhomola/3D_UNet)",0,7,False,self,,,,,
130,deeplearning,t5_2t5eh,2019-3-15,2019,3,15,11,b196lr,self.deeplearning,How to modify Adaline Stochastic gradient descent,https://www.reddit.com/r/deeplearning/comments/b196lr/how_to_modify_adaline_stochastic_gradient_descent/,vokoyo,1552616132,"&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

**Dear**

&amp;#x200B;

May I know how to modify my own Python programming so that I will get the

**same picture** as refer to the attached file - Adaline Stochastic gradient descent

(I am using the Anaconda Python 3.7)

&amp;#x200B;

**Prayerfully**

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

Tron Orino Yeong

[tcynotebook@yahoo.com](mailto:tcynotebook@yahoo.com)

0916643858

  


&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

    from matplotlib.colors import ListedColormap
    import matplotlib.pyplot as plt
    import numpy as np
    from numpy.random import seed
    import pandas as pd
    
    # Stochastic Gradient Descent
    class SGD(object):
       def __init__(self, rate = 0.01, niter = 10,
                    shuffle=True, random_state=None):
          self.rate = rate
          self.niter = niter
          self.weight_initialized = False
    
          # If True, Shuffles training data every epoch
          self.shuffle = shuffle
    
          # Set random state for shuffling and initializing the weights.
          if random_state:
             seed(random_state)
    
       def fit(self, X, y):
          """"""Fit training data
          X : Training vectors, X.shape : [#samples, #features]
          y : Target values, y.shape : [#samples]
          """"""
    
          # weights
          self.initialize_weights(X.shape[1])
    
          # Cost function
          self.cost = []
    
          for i in range(self.niter):
             if self.shuffle:
                X, y = self.shuffle_set(X, y)
             cost = []
             for xi, target in zip(X, y):
                cost.append(self.update_weights(xi, target))
             avg_cost = sum(cost)/len(y)
             self.cost.append(avg_cost)
          return self
    
       def partial_fit(self, X, y):
          """"""Fit training data without reinitializing the weights""""""
          if not self.weight_initialized:
             self.initialize_weights(X.shape[1])
          if y.ravel().shape[0] &gt; 1:
             for xi, target in zip(X, y):
                self.update_weights(xi, target)
          else:
             self.up
          return self
    
       def shuffle_set(self, X, y):
          """"""Shuffle training data""""""
          r = np.random.permutation(len(y))
          return X[r], y[r]
    
       def initialize_weights(self, m):
          """"""Initialize weights to zeros""""""
          self.weight = np.zeros(1 + m)
          self.weight_initialized = True
    
       def update_weights(self, xi, target):
          """"""Apply SGD learning rule to update the weights""""""
          output = self.net_input(xi)
          error = (target - output)
          self.weight[1:] += self.rate * xi.dot(error)
          self.weight[0] += self.rate * error
          cost = 0.5 * error**2
          return cost
    
       def net_input(self, X):
          """"""Calculate net input""""""
          return np.dot(X, self.weight[1:]) + self.weight[0]
    
       def activation(self, X):
          """"""Compute linear activation""""""
          return self.net_input(X)
    
       def predict(self, X):
          """"""Return class label after unit step""""""
          return np.where(self.activation(X) &gt;= 0.0, 1, -1)
    
    def plot_decision_regions(X, y, classifier, resolution=0.02):
       # setup marker generator and color map
       markers = ('s', 'x', 'o', '^', 'v')
       colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
       cmap = ListedColormap(colors[:len(np.unique(y))])
    
       # plot the decision surface
       x1_min, x1_max = X[:,  0].min() - 1, X[:, 0].max() + 1
       x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
       xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),
       np.arange(x2_min, x2_max, resolution))
       Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
       Z = Z.reshape(xx1.shape)
       plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)
       plt.xlim(xx1.min(), xx1.max())
       plt.ylim(xx2.min(), xx2.max())
    
       # plot class samples
       for idx, cl in enumerate(np.unique(y)):
          plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],
          alpha=0.8, c=cmap(idx),
          marker=markers[idx], label=cl)
    
    df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)
    
    y = df.iloc[0:100, 4].values
    y = np.where(y == 'Iris-setosa', -1, 1)
    X = df.iloc[0:100, [0, 2]].values
    
    # standardize
    X_std = np.copy(X)
    X_std[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()
    X_std[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()
    
    sgd1 = SGD(niter=100, rate=0.01, random_state=1)
    sgd2 = SGD(niter=50, rate=0.01, random_state=1)
    sgd3 = SGD(niter=10, rate=0.01, random_state=1)
    
    sgd1.fit(X_std, y)
    sgd2.fit(X_std, y)
    sgd3.fit(X_std, y)
    
    plt.plot(range(1, len(sgd1.cost) + 1), sgd1.cost, 
             marker='o', linestyle='oo', label='batch=1')
    plt.plot(range(1, len(sgd2.cost_) + 1), np.array(sgd2.cost_) / len(y_train), 
             marker='o', linestyle='--', label='batch=2')
    plt.plot(range(1, len(sgd3.cost_) + 1), np.array(sgd3.cost_) / len(y_train), 
             marker='o', linestyle='xx', label='batch=3')
    
    plt.xlabel('Epochs')
    plt.ylabel('Average Cost')
    plt.show()
    
    

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/9aw6sjf7z6m21.jpg

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/7c59caj8z6m21.jpg

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",0,0,False,self,,,,,
131,deeplearning,t5_2t5eh,2019-3-15,2019,3,15,21,b1e8y6,self.deeplearning,Is there going to be a part 2 of the machine learning course by fastai?,https://www.reddit.com/r/deeplearning/comments/b1e8y6/is_there_going_to_be_a_part_2_of_the_machine/,sanjaynath,1552652388,In the first part part Jeremy mentions that he will go into Gradient Boosting etc. in part 2. Is part 2 out already? If not any idea when is it going to be out? ,5,4,False,self,,,,,
132,deeplearning,t5_2t5eh,2019-3-15,2019,3,15,21,b1ekkr,self.deeplearning,How to do parameters estimation and choice of machine?,https://www.reddit.com/r/deeplearning/comments/b1ekkr/how_to_do_parameters_estimation_and_choice_of/,nisucuk,1552654297," 

Dear Friends, I have to work on concept detection(treated as a multi-label classification) problem.

I have to choose between 

1) SGI UV 2000 (venus) ,

For highly parallel and data intensive HPC applications

\- ca. 6400 Cores Intel Sandy Bridge and Westmere, 34000 Cores Intel Haswell and ca. 900 Intel Broadwell Cores with various memory configurations,\- 344 GPUs (K80, K20Xm),\- Bullx Linux, Batch system Slurm 

And 
2) Bull Cluster (Taurus)

for memory intensive calculations

\- 512 Cores Intel Sandy Bridge, 2,6 GHz, \- 8 TB shared memory,\- SuSE Linux Enterprise Server

\- Batch system SLURM, \- 10,6 TFlop/s Peak PerformancE 

I have to estimate  several parameters such as CPU time, GPU-count(hrs), CPU-count per unit job, memory per core(Gbyte), Scratch -temporary(G-Byte)

i have a training set of 56,630 Images(max. size=220kb), validation set of 14,120 images .

can anybody kindly guide me on how to estimate it, and on what factors does it depend?",0,1,False,self,,,,,
133,deeplearning,t5_2t5eh,2019-3-15,2019,3,15,22,b1f5dr,self.deeplearning,Deep Autoencoder-like Nonnegative Matrix Factorization for Community Detection (CIKM 2018).,https://www.reddit.com/r/deeplearning/comments/b1f5dr/deep_autoencoderlike_nonnegative_matrix/,benitorosenberg,1552657574,"&amp;#x200B;

https://i.redd.it/zmzh8g9leam21.jpg

&amp;#x200B;

Paper: [https://github.com/benedekrozemberczki/DANMF/blob/master/18DANMF.pdf](https://github.com/benedekrozemberczki/DANMF/blob/master/18DANMF.pdf)

Python: [https://github.com/benedekrozemberczki/DANMF](https://github.com/benedekrozemberczki/DANMF)

ABSTRACT:

Community  structure is ubiquitous in real-world complex networks. The  task of  community detection over these networks is of paramount  importance in a  variety of applications. Recently, nonnegative matrix  factorization  (NMF) has been widely adopted for community detection due  to its great  interpretability and its natural fitness for capturing the  community  membership of nodes. However, the existing NMF-based community   detection approaches are shallow methods. They learn the community   assignment by mapping the original network to the community membership   space directly. Considering the complicated and diversified topology   structures of real-world networks, it is highly possible that the   mapping between the original network and the community membership space   contains rather complex hierarchical information, which cannot be   interpreted by classic shallow NMF-based approaches. Inspired by the   unique feature representation learning capability of deep autoencoder,   we propose a novel model, named Deep Autoencoder-like NMF (DANMF), for   community detection. Similar to deep autoencoder, DANMF consists of an   encoder component and a decoder component. This architecture empowers   DANMF to learn the hierarchical mappings between the original network   and the final community  assignment  with  implicit  low-to-high  level    hidden attributes of the original network learnt in the intermediate   layers. Thus, DANMF should be better suited to the community detection   task. Extensive experiments on benchmark datasets demonstrate that DANMF   can achieve better performance than the state-of-the-art NMF-based   community detection approaches.",0,13,False,self,,,,,
134,deeplearning,t5_2t5eh,2019-3-15,2019,3,15,23,b1fqd1,self.deeplearning,Questions regarding chapter 19 of Deep Learning textbook,https://www.reddit.com/r/deeplearning/comments/b1fqd1/questions_regarding_chapter_19_of_deep_learning/,sriharsha_0806,1552660770,"Are there any coding repositories with toy datasets which explains EM and MAP Inference algorithms of chapter 19 of deep learning textbook? At the end of fourth paragraph of Expectation Maximization, The book mentions ""The E-step reduces the gap to zero again as we enter the loop for the next time"". How does E-step reduces the gap?",2,1,False,self,,,,,
135,deeplearning,t5_2t5eh,2019-3-16,2019,3,16,0,b1ggpu,medium.com,Stanford University Launches Human-Centered AI Institute Led by John Etchemendy &amp; Fei-Fei Li,https://www.reddit.com/r/deeplearning/comments/b1ggpu/stanford_university_launches_humancentered_ai/,Yuqing7,1552664713,,0,5,False,default,,,,,
136,deeplearning,t5_2t5eh,2019-3-16,2019,3,16,2,b1htwf,self.deeplearning,Keras for Beginners,https://www.reddit.com/r/deeplearning/comments/b1htwf/keras_for_beginners/,limapedro,1552671694,"I made a 15 videos series on Keras for beginners, when I was starting learning I thought that was a lack on how to start using keras, so I did this series help this can be useful for you too. [https://www.youtube.com/playlist?list=PLJ1jRXwHYGNpSKcSVm117e5hy\_xTwsNrS](https://www.youtube.com/playlist?list=PLJ1jRXwHYGNpSKcSVm117e5hy_xTwsNrS)",4,60,False,self,,,,,
137,deeplearning,t5_2t5eh,2019-3-16,2019,3,16,2,b1hu73,ailab.microsoft.com,AI For Good Idea Challenge - Microsoft AI Lab,https://www.reddit.com/r/deeplearning/comments/b1hu73/ai_for_good_idea_challenge_microsoft_ai_lab/,ConfidentMushroom,1552671737,,0,8,False,default,,,,,
138,deeplearning,t5_2t5eh,2019-3-16,2019,3,16,7,b1l304,arxiv.org,Deep learning for molecular generation and optimization - a review of the state of the art,https://www.reddit.com/r/deeplearning/comments/b1l304/deep_learning_for_molecular_generation_and/,delton,1552688681,,0,1,False,default,,,,,
139,deeplearning,t5_2t5eh,2019-3-16,2019,3,16,10,b1n6wc,self.deeplearning,Are there any resources for engineering practices in deep learning?,https://www.reddit.com/r/deeplearning/comments/b1n6wc/are_there_any_resources_for_engineering_practices/,alias_is,1552701410,Currently I am able to implement few convolutional architecture as well as recurrent networks. But the way I do is very messy and doesn't seem like engineering solution. I come from computer engineering background and would like to learn some good techniques as well as procedures for creating deep learning based solutions and architectures. ,2,4,False,self,,,,,
140,deeplearning,t5_2t5eh,2019-3-16,2019,3,16,13,b1omhy,self.deeplearning,Deep Learning For Developers,https://www.reddit.com/r/deeplearning/comments/b1omhy/deep_learning_for_developers/,AndyMerskinon,1552711110,[http://on.geeklearn.net/c2110fccf8](http://on.geeklearn.net/c2110fccf8),0,3,False,self,,,,,
141,deeplearning,t5_2t5eh,2019-3-16,2019,3,16,14,b1p518,machinelearninguru.com,Converting dataset into a HDF5 file,https://www.reddit.com/r/deeplearning/comments/b1p518/converting_dataset_into_a_hdf5_file/,root__007,1552715122,,0,1,False,default,,,,,
142,deeplearning,t5_2t5eh,2019-3-16,2019,3,16,14,b1p8bw,self.deeplearning,"hello . I've decided to creat a podcast about deep learning  machine learning  artifical inteligence , neuroscience ,....... which interviews with experts . But unfortunately I can't choose a suitable title for it. Could anyone choose some titles for it ?",https://www.reddit.com/r/deeplearning/comments/b1p8bw/hello_ive_decided_to_creat_a_podcast_about_deep/,Doctor_who1,1552715876," hello . I've decided to creat a podcast about deep learning  machine learning  artifical inteligence  , neuroscience  ,....... which interviews with experts . But unfortunately I can't choose a suitable title for it. Could anyone choose some titles for it ? ",6,0,False,self,,,,,
143,deeplearning,t5_2t5eh,2019-3-16,2019,3,16,15,b1pbm4,self.deeplearning,Converting dataset into a HDF5 file,https://www.reddit.com/r/deeplearning/comments/b1pbm4/converting_dataset_into_a_hdf5_file/,root__007,1552716623,"Hi guys

I wanna convert a facial expressions dataset into a HDF5 file and I don't know how exactly to do it.

from [here](http://www.machinelearninguru.com/deep_learning/data_preparation/hdf5/hdf5.html) I know how to do it with a cat-vs-dog dataset but I wanna know how it's done in general.

(My purpose of all these is to speed up my CNN model training process in google colaboratory and I tried this by mounting google drive and consequently reading my dataset from google drive but it was too slow to train my model (even slower than my pc !) ).",11,1,False,self,,,,,
144,deeplearning,t5_2t5eh,2019-3-17,2019,3,17,2,b1uljc,youtube.com,Autonomous Driving Back Propagation and Genetic Algorithm,https://www.reddit.com/r/deeplearning/comments/b1uljc/autonomous_driving_back_propagation_and_genetic/,DevTechRetopall,1552755604,,0,8,False,default,,,,,
145,deeplearning,t5_2t5eh,2019-3-17,2019,3,17,3,b1vhg3,self.deeplearning,Conv nets vs nlp,https://www.reddit.com/r/deeplearning/comments/b1vhg3/conv_nets_vs_nlp/,endeavour23,1552760557,"I'm a software consultant on middleware technologies, and from the past year, i've been learning ML, deep learning &amp; CNN's. Deep learning blew my mind, and with great passion, I did some certifications on deep learning, and completed lectures like cs231n being in a job that demands atleast 10 hrs of work. I really want to shift my career into AI . 

This qn is to the experts in DL - should I explore more of CNN's and take that route, or explore the field of DL in other fields like recurrent nets, NLP or reinforcement learning. If I wanna plan my future 10 years, should I be learning the full stack? I'm talking in terms of job opportunities and career growth.

&amp;#x200B;

Also, CNN vs NLP - jobs wise - which is better?",4,7,False,self,,,,,
146,deeplearning,t5_2t5eh,2019-3-17,2019,3,17,7,b1y32y,sinxloud.com,"I ranked the Best TensorFlow Courses on the internet, based on your reviews",https://www.reddit.com/r/deeplearning/comments/b1y32y/i_ranked_the_best_tensorflow_courses_on_the/,skj8,1552774656,,8,22,False,default,,,,,
147,deeplearning,t5_2t5eh,2019-3-17,2019,3,17,14,b21t3o,self.deeplearning,How do make a Pytorch dataloader for a pandas dataframe? why do we need a seperate batch everytime we loop the model?,https://www.reddit.com/r/deeplearning/comments/b21t3o/how_do_make_a_pytorch_dataloader_for_a_pandas/,n_unjum,1552799393,"   

I am having a very difficult time making a data loader for pytorch. I have columnar data in train  
 and test  
 set. How do I make a dataloader and how do i implement it on my GPU? Also why do we need seperate batches everytime we loop?",8,7,False,self,,,,,
148,deeplearning,t5_2t5eh,2019-3-17,2019,3,17,16,b22zab,self.deeplearning,Stateless vs Stateful LSTM in practice?,https://www.reddit.com/r/deeplearning/comments/b22zab/stateless_vs_stateful_lstm_in_practice/,jeril_rebooted_2k17,1552809596,"I've read a lot of sources on stateless vs stateful LSTMs, but I couldn't understand the practical difference between the 2, as in what the practical outcome would be, if I apply it in a Keras-powered Python code. And also, where should each type be applied or avoided? Kindly help me understand this better. Thank you.

&amp;#x200B;

P.S.: For stock market price prediction, which type of LSTM is best suited?",0,6,False,self,,,,,
149,deeplearning,t5_2t5eh,2019-3-17,2019,3,17,18,b23btr,self.deeplearning,"A PyTorch Implementation of ""SINE: Scalable Incomplete Network Embedding"" (ICDM 2018).",https://www.reddit.com/r/deeplearning/comments/b23btr/a_pytorch_implementation_of_sine_scalable/,benitorosenberg,1552813250,"&amp;#x200B;

https://i.redd.it/of4p09mg9nm21.jpg

Paper: [https://github.com/benedekrozemberczki/SINE/blob/master/paper.pdf](https://github.com/benedekrozemberczki/SINE/blob/master/paper.pdf)

PyTorch: [https://github.com/benedekrozemberczki/SINE](https://github.com/benedekrozemberczki/SINE)

Abstract:

Attributed  network embedding aims to learn low-dimensional vector  representations  for nodes in a network, where each node contains rich   attributes/features describing node content. Because network topology   structure and node attributes often exhibit high correlation,  incorporating node attribute proximity into network embedding is   beneficial for learning good vector representations. In reality,   large-scale networks often have incomplete/missing node content or   linkages, yet existing attributed network embedding algorithms all   operate under the assumption that networks are complete. Thus, their   performance is vulnerable to missing data and suffers from poor  scalability. In this paper, we propose a Scalable Incomplete Network   Embedding (SINE) algorithm for learning node representations from   incomplete graphs. SINE formulates a probabilistic learning framework   that separately models pairs of node-context and node-attribute   relationships. Different from existing attributed network embedding   algorithms, SINE provides greater flexibility to make the best of useful   information and mitigate negative effects of missing information on   representation learning. A stochastic gradient descent based online   algorithm is derived to learn node representations, allowing SINE to   scale up to large-scale networks with high learning efficiency. We   evaluate the effectiveness and efficiency of SINE through extensive   experiments on real-world networks. Experimental results confirm that   SINE outperforms state-of-the-art baselines in various tasks, including   node classification, node clustering, and link prediction, under   settings with missing links and node attributes. SINE is also shown to  be scalable and efficient on large-scale networks with millions of   nodes/edges and high-dimensional node features.",0,17,False,self,,,,,
150,deeplearning,t5_2t5eh,2019-3-18,2019,3,18,4,b28nb5,linkedin.com,Object Detection Deep Learning Image Analysis for Classification,https://www.reddit.com/r/deeplearning/comments/b28nb5/object_detection_deep_learning_image_analysis_for/,cderekw4224,1552849459,,0,5,False,default,,,,,
151,deeplearning,t5_2t5eh,2019-3-18,2019,3,18,4,b29578,self.deeplearning,"Deep learning + Music, Music Generation using GAN , How to play songs from the midi images",https://www.reddit.com/r/deeplearning/comments/b29578/deep_learning_music_music_generation_using_gan/,prashantkr314,1552852063,"I am exploring to this repository : [musegan](https://github.com/salu133445/musegan) and tried to exectue it.

My shared [Google Colab Link](https://colab.research.google.com/drive/12Vw3-94YXbOKmNhuBh0TrKrgfZeOVmlQ)

&amp;#x200B;

It executes but i have no idea where do i get the generated music samples or how do i run the music.It produces bunch of `.png` images in the `./exp/`  folder but i don't know how is that helpful for generating music

&amp;#x200B;

even in the ReadMe file of this project the [Results](https://github.com/salu133445/musegan#sample-results) if you download it , it give bunch of images. I have no idea how can i use these images.

&amp;#x200B;

I am new to ML and Deep Learning, I picked this project because i have interest in music and i wanted to get inspired how deep learning will solve this problem.

&amp;#x200B;

i have read about ANN, RNN &amp; CNN  and GAN but i am at a very noob level. But i want to learn this.

I did watch this video of project owner, [Video](https://www.youtube.com/watch?v=SHPjZwSbRhs) But it's in Chinese , i did used [Google Translate (Chinese to English)](https://translate.google.com/?rlz=1C5CHFA_enIN831IN831&amp;um=1&amp;ie=UTF-8&amp;hl=en&amp;client=tw-ob#zh-TW/en/) to convert the audio into english text but it wasn't that great experience.

&amp;#x200B;

These are the slides :      [Slide 1](https://salu133445.github.io/bmusegan/pdf/bmusegan-ismir2018-slides.pdf)[Slide 2](https://salu133445.github.io/musegan/pdf/musegan-aaai2018-slides.pdf)

&amp;#x200B;

&amp;#x200B;

I know this is not the best first project to choose, but this is what interests me so i'll be more happy to invest my time to know about this project.

&amp;#x200B;

My background is in web-development both front-end &amp; back-end.

&amp;#x200B;",9,30,False,self,,,,,
152,deeplearning,t5_2t5eh,2019-3-18,2019,3,18,6,b29y88,self.deeplearning,Training a CNN on generated Images,https://www.reddit.com/r/deeplearning/comments/b29y88/training_a_cnn_on_generated_images/,zero_as_a_number,1552856436,"hello r/deeplearning

&amp;#x200B;

i am a first time poster and new to the field. i'm a java developer on and off the job 

hence my tool of choice currently is deeplearning4j. after abstracting away some boilerplate i was able to successfully run a network (like can be found in the dl4j [model zoo](https://deeplearning4j.org/docs/latest/deeplearning4j-zoo-overview) because why re-invent the wheel .. ) . i'm looking into doing image classification using convolutional nets 

&amp;#x200B;

i am trying to solve the following problem: given an image of a target, get me the score based upon the position of the projectile point of impact. for my case we would see an arrow sticking in the target (one of them round things..). score is depending on the position of the arrow. 

&amp;#x200B;

to alleviate the need for data scraping i took an available image of a target board and wrote a little tool which renders an arrow on it in lots of different positions (depending on the image size i got around 150k images out of this). this also takes care of labeling the data correctly. but the data is fairly .. static, as in the only thing that changes is the position of the arrow. i also started randomly transforming the images to hopefully help the network generalize a bit better (color inversion, grayscale, cropping, rotation, .. ) What I'm hoping the network would learn is to associate the \_position\_ of the arrow with a certain label (e.g. score of the shot). this gives me 20 labels since my max score currently is 20. 

&amp;#x200B;

Existing models either converged but did not learn the right features or wouldn't converge at all, 

although i did not yet look into transfer learning. 

  

So I'm kind of stuck and wondering .. 

\- is a conv net the right tool for the job? i feel like what i'm trying to do is understanding a scene, rather than 

\- i think my training data may be problematic. a) the largest portion of the images is the target itself, the arrow is rather small in comparison (when considering amount of pixels .. ) b)  there is very little variance between different images (e.g. the arrow is only moved one pixel over, perspective is always the same).. besides some basic image transformations, is there something else i should do?

\- are there specialized architectures for such scenarios - working with small features?

&amp;#x200B;

hope i'm in the right place for those questions :) 

&amp;#x200B;",2,1,False,self,,,,,
153,deeplearning,t5_2t5eh,2019-3-18,2019,3,18,11,b2d2ql,self.deeplearning,ML in the browser,https://www.reddit.com/r/deeplearning/comments/b2d2ql/ml_in_the_browser/,parmarsuraj,1552874874,"Machine Learning in the Browser using TensorFlow.js

https://link.medium.com/82cl8YX58U",0,1,False,self,,,,,
154,deeplearning,t5_2t5eh,2019-3-18,2019,3,18,11,b2d9z2,self.deeplearning,Stopping training early when accuracy does not change across epochs,https://www.reddit.com/r/deeplearning/comments/b2d9z2/stopping_training_early_when_accuracy_does_not/,randomicly,1552876179,"I have implemented a NN (in keras) which runs for a large number of epochs. Now when I train the model, I see that the accuracy does not seem to change after a set of epochs.

&amp;#x200B;

Is there any issue with stopping training when accuracy does not change for let's say 5 epochs? What is the common practice implemented in such cases?",15,2,False,self,,,,,
155,deeplearning,t5_2t5eh,2019-3-18,2019,3,18,14,b2eulz,self.deeplearning,Paper Review:Automatic Liver Segmentation using Unets with Wasserstein GANs,https://www.reddit.com/r/deeplearning/comments/b2eulz/paper_reviewautomatic_liver_segmentation_using/,sayantandas30011998,1552887283,"\~By Sayantan Das ([https://www.linkedin.com/in/sayantan-das-95b50a125/](https://www.linkedin.com/in/sayantan-das-95b50a125/))

&amp;#x200B;",0,11,False,self,,,,,
156,deeplearning,t5_2t5eh,2019-3-18,2019,3,18,18,b2gscs,youtube.com,Intelligent Video Analytics with e-CAM130_CUXVR &amp; DeepStream SDK 3.0,https://www.reddit.com/r/deeplearning/comments/b2gscs/intelligent_video_analytics_with_ecam130_cuxvr/,shaun272,1552903119,,0,3,False,image,,,,,
157,deeplearning,t5_2t5eh,2019-3-18,2019,3,18,20,b2hj29,self.deeplearning,"A PyTorch implementation of ""Splitter: Learning Node Representations that Capture Multiple Social Contexts"" (WWW 2019).",https://www.reddit.com/r/deeplearning/comments/b2hj29/a_pytorch_implementation_of_splitter_learning/,benitorosenberg,1552908279,"&amp;#x200B;

https://i.redd.it/il9y7hf24vm21.jpg

Github: [https://github.com/benedekrozemberczki/Splitter](https://github.com/benedekrozemberczki/Splitter)

Paper: [http://epasto.org/papers/www2019splitter.pdf](http://epasto.org/papers/www2019splitter.pdf)

ABSTRACT:

Recent  interest in graph embedding methods has focused on learning a  single  representation for each node in the graph. But can nodes really  be best  described by a single vector representation? In this work, we  propose a  method for learning multiple representations of the nodes in a  graph  (e.g., the users of a social network). Based on a principled   decomposition of the ego-network, each representation encodes the role   of the node in a different local community in which the nodes   participate. These representations allow for improved reconstruction of   the nuanced relationships that occur in the graph a phenomenon that we   illustrate through state-of-the-art results on link prediction tasks on  a  variety of graphs, reducing the error by up to 90%. In addition, we   show that these embeddings allow for effective visual analysis of the   learned community structure.",0,2,False,self,,,,,
158,deeplearning,t5_2t5eh,2019-3-18,2019,3,18,23,b2j5tb,self.deeplearning,SC-FEGAN: Face Editing Generative Adversarial Network with Users Sketch and Color,https://www.reddit.com/r/deeplearning/comments/b2j5tb/scfegan_face_editing_generative_adversarial/,BrighterAI,1552918150," \[I**n** this paper, South Korean researchers achieved high quality (512512) completion of face images guided by a user-provided edge sketch and colors for a cut-out part of the original image...\] ",0,1,False,self,,,,,
159,deeplearning,t5_2t5eh,2019-3-19,2019,3,19,3,b2lxe9,medium.com,An introduction to Intel's BigDL and Analytics Zoo,https://www.reddit.com/r/deeplearning/comments/b2lxe9/an_introduction_to_intels_bigdl_and_analytics_zoo/,iamspoilt,1552932272,,0,8,False,default,,,,,
160,deeplearning,t5_2t5eh,2019-3-19,2019,3,19,5,b2ntek,self.deeplearning,Where do you go when you simply need more compute?,https://www.reddit.com/r/deeplearning/comments/b2ntek/where_do_you_go_when_you_simply_need_more_compute/,johnrudolphdrexler,1552941820,"Hey all -- curious to hear what solutions you turn to when you need more compute power to run your models, to do more robust parameter sweeps, or have a computationally expensive job to run. When you have a job that exceeds the resources on your local machine, where do you go first to get more power? Do you guys depend on cloud? Wait in line for a HPC resource in your lab?  All help appreciated! ",1,1,False,self,,,,,
161,deeplearning,t5_2t5eh,2019-3-19,2019,3,19,7,b2p8ol,self.MESAI0,A New Super Accurate Indoor Navigation System using Deep Learning,https://www.reddit.com/r/deeplearning/comments/b2p8ol/a_new_super_accurate_indoor_navigation_system/,MESAI0,1552949044,,0,3,False,default,,,,,
162,deeplearning,t5_2t5eh,2019-3-19,2019,3,19,7,b2p8wm,self.deeplearning,Titan V Machine Learning Training Performance,https://www.reddit.com/r/deeplearning/comments/b2p8wm/titan_v_machine_learning_training_performance/,mippie_moe,1552949076,"[Titan V Machine Learning Training Performance](https://lambdalabs.com/blog/titan-v-deep-learning-benchmarks/)

In general, I don't recommend the Titan V for Machine Learning. At the Titan V price point ($2,999), the Titan RTX ($2,499) is a superior GPU.

**For FP32 training of neural networks, the NVIDIA Titan V is...**

* 42% faster than RTX 2080
* 41% faster than GTX 1080 Ti
* 26% faster than Titan XP
* 4% faster than RTX 2080 Ti
* 90% as fast as Titan RTX
* 75% as fast as Tesla V100 (32 GB)

**For FP16 training of neural networks, the NVIDIA Titan V is..**

* 111% faster than GTX 1080 Ti
* 94% faster than Titan XP
* 70% faster than RTX 2080
* 23% faster than RTX 2080 Ti
* 87% as fast as Titan RTX
* 68% as fast as Tesla V100 (32 GB)

**Multi-GPU training scaling of the Titan V from 1 to 2 to 4 to 8 GPUs:**

* 1 GPU = 1.0x faster than single Titan V
* 2 GPU = 1.62x faster than single Titan V
* 4 GPU = 3.22x faster than single Titan V
* 8 GPU = 5.18x faster than single Titan V",5,27,False,self,,,,,
163,deeplearning,t5_2t5eh,2019-3-19,2019,3,19,10,b2qzag,self.deeplearning,How to validate whether a task has been done or not?,https://www.reddit.com/r/deeplearning/comments/b2qzag/how_to_validate_whether_a_task_has_been_done_or/,EricDZhang,1552958366,"Recently I have found a interesting Computer Vision task when reading conference papers but I don't know whether it has been done or not.

I have searched on Google Scholar with many keywords but found nothing exactly the same.

When is it safe to say ""To the best of our knowledge, we are the first to propose ..."" while writing papers?",0,2,False,self,,,,,
164,deeplearning,t5_2t5eh,2019-3-19,2019,3,19,15,b2u0mc,self.deeplearning,1-D CNN vs MLP performance,https://www.reddit.com/r/deeplearning/comments/b2u0mc/1d_cnn_vs_mlp_performance/,aabidhasan,1552977760,"I have three datasets of sizes 706589, 1436489, and 2143289.

I have built a neural network that contains one 1-D convolution layer and 1 fully connected layer that goes through softmax for classification.

Since I know the features do not have any kind of local patterns in them, so a CNN based neural network isn't the appropriate choice. So I build a neural network with just multiple layers. My DNN contains 4 layers (128, 512, 1024, 1024) which goes through softmax for classification. Activation function relu, optimizer adam, Dropout 0.2, Batch size 32. I have changed the hyper-parameters and the performance are pretty similar.

Now after running experiments on both of the architectures with these datasets, CNN model consistently gives better results than DNN model. I even tried randomly shuffling features and then run CNN, and still its better than DNN. The AUC is better at around 2% to 5% in 10-fold cross-validation for CNN model.

Is there any reason why CNN based model is performing better than DNN even though there isn't a local pattern in the feature set? Is it possible to justify the use of CNN based model over DNN in this case?",1,1,False,self,,,,,
165,deeplearning,t5_2t5eh,2019-3-19,2019,3,19,15,b2u1y9,go.geeklearn.net,Deploying a Keras Deep Learning Model as a Web Application in Python,https://www.reddit.com/r/deeplearning/comments/b2u1y9/deploying_a_keras_deep_learning_model_as_a_web/,BercoviciAdrian,1552978035,,0,26,False,default,,,,,
166,deeplearning,t5_2t5eh,2019-3-19,2019,3,19,18,b2veyw,self.deeplearning,Variable length data for LSTM in Keras,https://www.reddit.com/r/deeplearning/comments/b2veyw/variable_length_data_for_lstm_in_keras/,pk12_,1552988854,"I have variable length sequences of 3D data for which I want to build a combination of CNN-LSTM model

The issue here is the variable length. One solution is to pad zeros to make them equal size, but I'm just wondering if there are better solutions. 

Does anyone have experience in dealing with variable length sequences?",6,5,False,self,,,,,
167,deeplearning,t5_2t5eh,2019-3-19,2019,3,19,19,b2vpd2,gogreatlearning1.tumblr.com,Major Benefits of Deep Learning for Businesses,https://www.reddit.com/r/deeplearning/comments/b2vpd2/major_benefits_of_deep_learning_for_businesses/,greatlearning1,1552991027,,0,1,False,default,,,,,
168,deeplearning,t5_2t5eh,2019-3-19,2019,3,19,23,b2xz6d,self.deeplearning,Semantic Question Classification,https://www.reddit.com/r/deeplearning/comments/b2xz6d/semantic_question_classification/,dpz97,1553005151,"Hey folks.
As part of a college project, me and my partner are trying to build a question classification system. 
The idea is simple - we train the model on a dataset which consists of questions and associated tags. We provide an interface where the user can enter a question of his own choice. The system then tags the question with all possibly appropriate labels, and also retrieves questions that are similar.
We've decided that we'll use neural models for our project.
The first issue is the dataset. We've only managed to find one dataset, TREC-6 for question tagging at [http://cogcomp.org/Data/QA/QC/]() and it doesn't really suit our requirements since we want realistic labels like the ones they have at stack exchange or Quora. We plan to scrape questions from these websites, but for now the TREC-6 is a good starting point.
For question tagging, we're trying to follow Yoon Kim's paper at [https://arxiv.org/abs/1408.5882](). Basically, the guy uses convolutional neural networks and word embeddings on the TREC-6 set. We follow his approach and get good results on the test set.
But when we train the model on the combined train set and test set and use it to classify our own questions, it sometimes fails.
Granted, the dataset is small and scraping questions might be our first solution. But I'd like to know if we're on the right track. Is Cnns the way to go or are there better approaches. I tried C-Lstms but they take too long to train and I didn't notice a huge leap in performance.
Reaosn I'm asking is one of our teachers said our approach was a bad one during a recent presentation.
Also, for our similar question retrieval task, we've identified BERT as a solution. Is there any other better approach.
Suggestions would be appreciated. ",4,5,False,self,,,,,
169,deeplearning,t5_2t5eh,2019-3-19,2019,3,19,23,b2yakh,self.deeplearning,CUB dataset Attribute detection,https://www.reddit.com/r/deeplearning/comments/b2yakh/cub_dataset_attribute_detection/,muneeb2405,1553006821,"Hi, There is a cub dataset [http://www.vision.caltech.edu/visipedia/CUB-200-2011.html](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html) which contain parts and attributes of birds, I want to classify the birds using the attributes and image data. Then detect attributes using some deep learning models. Is there anyone know, how can i prepare the data for classifier&gt;? Can someone point me to example with the similar task. ",0,2,False,self,,,,,
170,deeplearning,t5_2t5eh,2019-3-20,2019,3,20,0,b2ytq9,self.deeplearning,How to log basic (python) scalars to tensorboard in manner consistent with keras callbacks?,https://www.reddit.com/r/deeplearning/comments/b2ytq9/how_to_log_basic_python_scalars_to_tensorboard_in/,nobodywillobserve,1553009541,"If you use keras callbacks you get scalars in tensorboard (val, val\_loss).

&amp;#x200B;

Adding other scalars is very tricky as I think you need to create tensorflow objects and your own tensorflow summary writer and then hope to use the same step and timestamps as keras. So far nothing is working and the custom scalars are not on the same time/step scales as the keras callbacks.

&amp;#x200B;

Is there a standard way to do this? ",2,4,False,self,,,,,
171,deeplearning,t5_2t5eh,2019-3-20,2019,3,20,1,b2zpmm,medium.com,Google Brain SimPLe: Complete Model-Based Reinforcement Learning for Atari,https://www.reddit.com/r/deeplearning/comments/b2zpmm/google_brain_simple_complete_modelbased/,gwen0927,1553013933,,0,3,False,default,,,,,
172,deeplearning,t5_2t5eh,2019-3-20,2019,3,20,1,b2zt7y,self.deeplearning,Help with hardware,https://www.reddit.com/r/deeplearning/comments/b2zt7y/help_with_hardware/,seb59,1553014429,"At my university, I've got a budget to buy several machines for one of our project. We are ""newbies"" in deep learning. We will use the card for image segmentation for autonomous vehicle applications, traffic sign detection, pedestrian recognitions, etc. Basically, we ""only"" want to apply existing network structure to our datasets. Nevertheless, I know that training is be quite demanding in term of computer power.  

Being new to this, I know that we will have to tune the learning algorithm, the network parameters, and being human, I do not like to wait for one week just to find that something is wrong. I believe that we need to have efficient hardware to get a good learning curve.

For once, budget is not an issue (yes, sometimes it can happen !). 

Our hardware provider suggest to buy these expensive QUADRO RTX 6000. I was initially looking for RTX2080Ti, eventually I could use 2 of them. 

Nb : For the computer, I will have the  i9-9900K or KF processor with 64Go RAM + 1To SSD

&amp;#x200B;

So I read the blogs at lambdalabs but there is not Quadro RTX6000 in their chart... Is that a clear indicator that the card is not that well suited?

&amp;#x200B;

1) What are the benefits of the quadro RTX6000 vs RTX 2080 TI with respect to deep learning application (i.e. no graphics, no ray tracing). 

=&gt; For the price of the quadro I can have another computer. Does this card worth its price for deep learning application (I'm not discussing its intrinsic capabilities, but only the deep learning usage). 

2) According to your experience, what's the best value for price.

&amp;#x200B;

&amp;#x200B;

Thanks for your help

&amp;#x200B;",16,3,False,self,,,,,
173,deeplearning,t5_2t5eh,2019-3-20,2019,3,20,3,b318qy,self.MachineLearning,[D] Getting skeletons from the silhouettes,https://www.reddit.com/r/deeplearning/comments/b318qy/d_getting_skeletons_from_the_silhouettes/,akaberto,1553021504,,0,2,False,default,,,,,
174,deeplearning,t5_2t5eh,2019-3-20,2019,3,20,10,b35vo5,self.deeplearning,How do you guys measure the quality of a generated sentences using ROUGE?,https://www.reddit.com/r/deeplearning/comments/b35vo5/how_do_you_guys_measure_the_quality_of_a/,phereVus,1553045481,"As the title says, how do you guys measure the generated sentences of your model using ROUGE? I  used a [library](https://github.com/pcyin/PyRouge) from GitHub to use rouge but I really don't know what it does. ",0,2,False,self,,,,,
175,deeplearning,t5_2t5eh,2019-3-20,2019,3,20,11,b36r0t,self.deeplearning,Keras Autoencoder Issues,https://www.reddit.com/r/deeplearning/comments/b36r0t/keras_autoencoder_issues/,ZeroMaxinumXZ,1553050685,"I'm having trouble with this deep convolutional autoencoder I'm building using Keras.  The input's shape is dependent on the screen size, and the output is  going to be a prediction of the next screen size...  However there seems  to be an error that I cannot figure out...  The input is the screen reduced 400%, and the output is the next screen also reduced 400%...

&amp;#x200B;

Here's the code:

    def model_build():
        input_img = InputLayer(shape=(1, env_size()[1], env_size()[0]))
        x = Conv2D(32, (2, 2), activation='relu', padding='same')(input_img)
        x = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(16, (2, 2), activation='relu', padding='same')(x)
        x = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(8, (2, 2), activation='relu', padding='same')(x)
        encoded = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(8, (2, 2), activation='relu', padding='same')(encoded)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(16, (2, 2), activation='relu', padding='same')(x)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(32, (2, 2), activation='relu')(x)
        x = UpSampling2D((2, 2))(x)
        decoded = Conv2D(2, (2, 2), activation='sigmoid', padding='same')(x)
        model = Model(input_img, decoded)
        return model

And here's my test code:

     aif __name__ == '__main__':
        model = model_build()
        model.compile('adam', 'mean_squared_error')
        y = np.array([env()])
        print(y.shape)
        print(y.ndim)
        debug = model.fit(np.array([[env()]]), np.array([[env()]]))

Error:

    Traceback (most recent call last):
      File ""/home/ai/Desktop/algernon-test/rewarders.py"", line 46, in &lt;module&gt;
        debug = model.fit(np.array([[env()]]), np.array([[env()]]))
      File ""/home/ai/.local/lib/python3.6/site-packages/keras/engine/training.py"", line 952, in fit
        batch_size=batch_size)
      File ""/home/ai/.local/lib/python3.6/site-packages/keras/engine/training.py"", line 789, in _standardize_user_data
        exception_prefix='target')
      File ""/home/ai/.local/lib/python3.6/site-packages/keras/engine/training_utils.py"", line 138, in standardize_input_data
        str(data_shape))
    ValueError: Error when checking target: expected conv2d_7 to have shape (6, 270, 2) but got array with shape (1, 270, 480)

&amp;#x200B;

&amp;#x200B;

The env() function returns a screenshot, again this screenshot is reduced to 4 times the size and is then converted to greyscale...

&amp;#x200B;",6,3,False,self,,,,,
176,deeplearning,t5_2t5eh,2019-3-20,2019,3,20,18,b39qo9,self.deeplearning,"A scalable Gensim implementation of ""Learning Role-based Graph Embeddings"" (IJCAI 2018).",https://www.reddit.com/r/deeplearning/comments/b39qo9/a_scalable_gensim_implementation_of_learning/,benitorosenberg,1553072785,"&amp;#x200B;

https://i.redd.it/lwyi9z95p8n21.png

GitHub: [https://github.com/benedekrozemberczki/role2vec](https://github.com/benedekrozemberczki/role2vec)

Paper: [https://arxiv.org/abs/1802.02896](https://arxiv.org/abs/1802.02896)

ABSTRACT:

Random walks are at the heart of many existing network embedding  methods. However, such algorithms have many limitations that arise from  the use of random walks, e.g., the features resulting from these methods  are unable to transfer to new nodes and graphs as they are tied to  vertex identity. In this work, we introduce the Role2Vec framework which  uses the flexible notion of attributed random walks, and serves as a  basis for generalizing existing methods such as DeepWalk, node2vec, and  many others that leverage random walks. Our proposed framework enables  these methods to be more widely applicable for both transductive and  inductive learning as well as for use on graphs with attributes (if  available). This is achieved by learning functions that generalize to  new nodes and graphs. We show that our proposed framework is effective  with an average AUC improvement of 16.55% while requiring on average  853x less space than existing methods on a variety of graphs.",0,13,False,self,,,,,
177,deeplearning,t5_2t5eh,2019-3-20,2019,3,20,19,b3acup,self.deeplearning,How does RTX 2070 max q compare to non max q versions for deep learning. Is there any comparison for that? I couldn't find any online.,https://www.reddit.com/r/deeplearning/comments/b3acup/how_does_rtx_2070_max_q_compare_to_non_max_q/,ashish421,1553077683,,6,2,False,self,,,,,
178,deeplearning,t5_2t5eh,2019-3-20,2019,3,20,19,b3akey,self.deeplearning,Outlier Detection in Images,https://www.reddit.com/r/deeplearning/comments/b3akey/outlier_detection_in_images/,abhiksark,1553079281,"Is there any way to do outlier detection in images.
Like Blurry or Falsely Labelled images?
Currently I am Using Variance of Laplacian. It's working fine. But I was looking for better alternatives? ",2,1,False,self,,,,,
179,deeplearning,t5_2t5eh,2019-3-20,2019,3,20,22,b3by0i,self.deeplearning,masked language model in BERT,https://www.reddit.com/r/deeplearning/comments/b3by0i/masked_language_model_in_bert/,Hua_Keru,1553088118,Why and how masked LMs give us deep bidirectionality in Google's BERT Model? Any explain on that?,1,2,False,self,,,,,
180,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,0,b3d9rv,self.deeplearning,Is the Deep Learning and AI Bubble Bursting?,https://www.reddit.com/r/deeplearning/comments/b3d9rv/is_the_deep_learning_and_ai_bubble_bursting/,Gabyleon2019,1553095197,What do you think?,22,0,False,self,,,,,
181,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,2,b3esbv,self.deeplearning,"Keras: BATCH_SIZE, STEPS_PER_EPOCH, and fit_generator",https://www.reddit.com/r/deeplearning/comments/b3esbv/keras_batch_size_steps_per_epoch_and_fit_generator/,_sleepyotter,1553102795,"Hi all deep learning newbie here, I have a question regarding the setting of `BATCH_SIZE` and `STEPS_PER_EPOCH` when using `fit_generator` in keras. 

If I have the following:

* 100 images 
* `BATCH_SIZE` = 1 
* `STEPS_PER_EPOCH` = 20

Will `fit_generator` automagically know that my desired `BATCH_SIZE` is 5 and pull 5 images from my data generator? Or is it pulling 20 batches where each batch size is 1, so my model is actually only seeing 20/100 images? ",7,10,False,self,,,,,
182,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,5,b3h9dr,self.deeplearning,Can anyone suggest any evaluation libraries in python?,https://www.reddit.com/r/deeplearning/comments/b3h9dr/can_anyone_suggest_any_evaluation_libraries_in/,RaymondKirk,1553115027,"I dont know if this is the right reddit but if so, Im currently using coco eval, (I want to avoid implementing them myself to ensure I put the right metrics in my papers). However Im finding it difficult to extract a confusion matrix or F1 from it. Any suggestions are welcome!",0,1,False,self,,,,,
183,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,8,b3izrw,self.deeplearning,"Kaggle and Colab free GPU comparison - how to find specs, UX, and deep learning experiments with fastai and mixed precision training",https://www.reddit.com/r/deeplearning/comments/b3izrw/kaggle_and_colab_free_gpu_comparison_how_to_find/,discdiver,1553123752,"I wrote a post comparing Kaggle and Colab for GPUS: Specs, UX, and deep learning experiments with fastai and mixed precision training. Feedback welcome!

[https://towardsdatascience.com/kaggle-vs-colab-faceoff-which-free-gpu-provider-is-tops-d4f0cd625029?source=friends\_link&amp;sk=7eb54f51566742d937b8d41adaee1bb9](https://towardsdatascience.com/kaggle-vs-colab-faceoff-which-free-gpu-provider-is-tops-d4f0cd625029?source=friends_link&amp;sk=7eb54f51566742d937b8d41adaee1bb9)",4,18,False,self,,,,,
184,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,9,b3jy0f,self.deeplearning,Is it advisable to learn deeplearning before learning other types of ML?,https://www.reddit.com/r/deeplearning/comments/b3jy0f/is_it_advisable_to_learn_deeplearning_before/,Dave24x7,1553128912,"I know this question might have been asked plenty of times, but please give me some suggestions. Im a complete beginner to the Artificial Intelligence field. Recently I started to look into it as it was interesting. I've read a few books and have a bare minimum knowledge, atleast I cud recognise the terms. 

Being an electrical engineer, I have a solid base in maths and a basic knowledge of python. Im currently reading DL with python by Franois chollet and I cud understand it without much difficulty. I wish to eventually do a course on self driving cars and robotics and move into that field.

Please tell me, is it possible/advisable to learn deep learning before trying out other types of ml. Im worried that if I learned deep learning without learning other aspects of ml, I would be one trick dog and be at a severe disadvantage. Also I hear about Deeplearning requiring tons of data and expensive GPUs. Are any deeplearning projects possible without these, that beginners can try out?

Should I just go ahead with deeplearning with tensorflow on coursera or udacity? And maybe learn other ml types at a later stage.",2,1,False,self,,,,,
185,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,12,b3leyp,youtube.com,Deep Learning Model Speaks Like Trump (v2),https://www.reddit.com/r/deeplearning/comments/b3leyp/deep_learning_model_speaks_like_trump_v2/,hanyuqn,1553137422,,14,24,False,image,,,,,
186,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,13,b3mfr4,dev.thegeeknews.net,Sentiment Analysis with Deep Learning of Netflix Reviews,https://www.reddit.com/r/deeplearning/comments/b3mfr4/sentiment_analysis_with_deep_learning_of_netflix/,NicholasTower,1553143905,,0,2,False,default,,,,,
187,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,18,b3oadu,self.deeplearning,What are some techniques/areas concerned with a network or algos ability to learn *the absence of relationships* between subsets of inputs and outputs?,https://www.reddit.com/r/deeplearning/comments/b3oadu/what_are_some_techniquesareas_concerned_with_a/,nobodywillobserve,1553159056,"This probably delves into sparse methods but am trying to find if someone has really studied this extensively. 

&amp;#x200B;

For example, if you have some segmentation/separability in your feature and output space that you could represent as a simple (small) causal graph with complexity in the clusters.

&amp;#x200B;

So reality could be

&amp;#x200B;

X = (Astuff, BStuff)

Y = F(Astuff), phi(Astuff) \* psi(Bstuff)

&amp;#x200B;

I'm sure this has been studied in different contexts but trying to find some paper starting points to see the communities of work.

&amp;#x200B;

My feeling is that if you attack that problem in a structureless way it is very challenging (especially in high dimensions) unless you bias your models to discovering sparse structures or input the known causal structure in the network design itself.",0,1,False,self,,,,,
188,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,19,b3ozbm,omgubuntu.co.uk,NVIDIA Jetson Nano is a $99 Computer Built for AI,https://www.reddit.com/r/deeplearning/comments/b3ozbm/nvidia_jetson_nano_is_a_99_computer_built_for_ai/,jaja123789,1553164741,,12,55,False,default,,,,,
189,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,21,b3q57s,self.deeplearning,Out-domain adversarial inputs for GAN generators,https://www.reddit.com/r/deeplearning/comments/b3q57s/outdomain_adversarial_inputs_for_gan_generators/,NoiseKnows,1553172618,What do you think?  [https://github.com/pasquini-dario/OutDomainExamples](https://github.com/pasquini-dario/OutDomainExamples),0,1,False,self,,,,,
190,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,22,b3qf6w,self.deeplearning,Prerequisites for understanding and implementing GANs for various tasks,https://www.reddit.com/r/deeplearning/comments/b3qf6w/prerequisites_for_understanding_and_implementing/,UserPobro,1553174279,"Hello, my task for Master Thesis is Image Generation using Deep Learning. I was thinking about GANs for such task. My questions is: are there anything I should learn before tackling image generation. Previously I have completed Coursera Deep Learning specialization and I am wondering is it enough? Any advice would be greatly appreciated.",1,4,False,self,,,,,
191,deeplearning,t5_2t5eh,2019-3-21,2019,3,21,23,b3rhn5,self.deeplearning,Google Deep Learning Course Online,https://www.reddit.com/r/deeplearning/comments/b3rhn5/google_deep_learning_course_online/,SunilAhujaa,1553180187,If you are looking for Google deep learning course in India then Analytixlabs help you to upgrade yourself and kick-start a career in Deep Learning Course. This is a specialization course which will help you to get a break into AI and Deep Learning domain.,0,0,False,self,,,,,
192,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,0,b3rvhv,medium.com,AttoNets: Compact and Efficient DNNs Realized via Human-Machine Collaborative,https://www.reddit.com/r/deeplearning/comments/b3rvhv/attonets_compact_and_efficient_dnns_realized_via/,gwen0927,1553182145,,1,1,False,default,,,,,
193,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,0,b3rviv,self.deeplearning,Could I get a little guidance on a small project?,https://www.reddit.com/r/deeplearning/comments/b3rviv/could_i_get_a_little_guidance_on_a_small_project/,samblack11,1553182148,"Hi All!

I'm a newb at AI trying to get my bearings. I'm trying to use deep q learning to teach an AI a simple game and it's not going well. I'm sort of lost where to even look and could really use some help/guidance.

The project is here: https://github.com/IWasZeroCool/blocksAI
There is a robust README that explains pretty much everything.

Any help would be greatly appreciated!",2,1,False,self,,,,,
194,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,0,b3s4rm,lilianweng.github.io,Artificial Intelligence : Open AI - Flow-based Deep Generative Models,https://www.reddit.com/r/deeplearning/comments/b3s4rm/artificial_intelligence_open_ai_flowbased_deep/,gokulbalex,1553183403,,0,13,False,default,,,,,
195,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,2,b3t6vb,self.deeplearning,recommendations for balancing data - 'dontcare' categories,https://www.reddit.com/r/deeplearning/comments/b3t6vb/recommendations_for_balancing_data_dontcare/,raggityrag,1553188576,"I'm training a visual Object Detector algorithm (YOLO-spp) on a subset of openimages. There are only a few classes that I actually care about detecting (7) so I have selected all images containing those classes and also, to prevent overfitting, some images that contain negative examples ie. depictions of objects that are \*not\* objects of interest but do have some level of resmeblance to my objects of interest. I have then balanced the data on a per-class basis using upsampling until there are the same number of instances of each class of interest. I have changed the labels of all of the instances of objects that are not of interest to 'dontcare'. I now have many more 'dontcare' instances than objects of interest instances. I'm worried about the model just predicting everything as 'dontcare' so I want to undersample (drop images that have many 'dontcare' examples). My question is: What level should I take 'dontcare' down to? Should it be the same number of instances as the classes of interest? Or, given that it is quite a diverse group of objects, would it make more sense to have more dontcares than other classes?",0,1,False,self,,,,,
196,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,3,b3u86o,self.deeplearning,"A sparsity aware and memory efficient TesnorFlow implementation of ""Attributed Social Network Embedding"" (TKDE 2018).",https://www.reddit.com/r/deeplearning/comments/b3u86o/a_sparsity_aware_and_memory_efficient_tesnorflow/,benitorosenberg,1553193522,"&amp;#x200B;

https://i.redd.it/f341ds77oin21.jpg

Paper: [https://arxiv.org/abs/1705.04969](https://arxiv.org/abs/1705.04969)

GitHub: [https://github.com/benedekrozemberczki/ASNE](https://github.com/benedekrozemberczki/ASNE)

Abstract: 

&gt;Embedding network data into a low-dimensional vector space has shown promising performance for many real-world applications, such as node classification and entity retrieval. However, most existing methods focused only on leveraging network structure. For social networks, besides the network structure, there also exists rich information about social actors, such as user profiles of friendship networks and textual content of citation networks. These rich attribute information of social actors reveal the homophily effect, exerting huge impacts on the formation of social networks. In this paper, we explore the rich evidence source of attributes in social networks to improve network embedding. We propose a generic Social Network Embedding framework (SNE), which learns representations for social actors (i.e., nodes) by preserving both the structural proximity and attribute proximity. While the structural proximity captures the global network structure, the attribute proximity accounts for the homophily effect. To justify our proposal, we conduct extensive experiments on four real-world social networks. Compared to the state-of-the-art network embedding approaches, SNE can learn more informative representations, achieving substantial gains on the tasks of link prediction and node classification. Specifically, SNE significantly outperforms node2vec with an 8.2% relative improvement on the link prediction task, and a 12.7% gain on the node classification task. 

  ",0,1,False,self,,,,,
197,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,3,b3ugm1,tutorials.retopall.com,Self Driving Cars 3D Simulation,https://www.reddit.com/r/deeplearning/comments/b3ugm1/self_driving_cars_3d_simulation/,DevTechRetopall,1553194654,,0,1,False,default,,,,,
198,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,4,b3uibr,pgaleone.eu,Analyzing tf.function to discover AutoGraph strengths and subtleties - part 1,https://www.reddit.com/r/deeplearning/comments/b3uibr/analyzing_tffunction_to_discover_autograph/,pgaleone,1553194890,,0,1,False,default,,,,,
199,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,5,b3vdl4,medium.com,New Study Uses Machine Learning to Predict Sexual Orientation,https://www.reddit.com/r/deeplearning/comments/b3vdl4/new_study_uses_machine_learning_to_predict_sexual/,gwen0927,1553199149,,8,0,False,default,,,,,
200,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,5,b3viw3,self.deeplearning,Convolutional Kernel Size Formula Issue,https://www.reddit.com/r/deeplearning/comments/b3viw3/convolutional_kernel_size_formula_issue/,ZeroMaxinumXZ,1553199898,"So I know about the formula, o = (w-f+2p)/s+1... But I just don't know how to apply it... I'm wanting my output to be the same as my input, which varies based on the screen resolution.. 

So do I have to put each number of the input shape into the formula or something in order to calculate the output shape .. I'm trying to get f from the output and input. I know how to reverse functions so that f comes first... But I don't understand how I'm supposed to get w and o in the function.

I'm new to ML so please forgive me and my stupid questions...",2,2,False,self,,,,,
201,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,11,b3znz2,self.deeplearning,Rtx 2080 vs rtx 2080ti ?,https://www.reddit.com/r/deeplearning/comments/b3znz2/rtx_2080_vs_rtx_2080ti/,zosogreen,1553222638,"I'm building a PC for deep learning side projects. Would you recommend spending extra $400 on rtx 2080ti as compared to 2080? I saw the benchmarks recently and 2080 performs roughly at 73% of ti.

Also any preferences for CPU? I'm thinking if saving some money and getting ryzen 2700x instead of Intel i7-87xx/9xxx.",7,3,False,self,,,,,
202,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,13,b40u56,self.deeplearning,Deep Learning on Mobile Devices,https://www.reddit.com/r/deeplearning/comments/b40u56/deep_learning_on_mobile_devices/,Usama9012,1553230285,[http://tech.learn4startup.com/70c7dfbb63](http://tech.learn4startup.com/70c7dfbb63),0,3,False,self,,,,,
203,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,15,b41mzb,self.deeplearning,denoising image,https://www.reddit.com/r/deeplearning/comments/b41mzb/denoising_image/,johnthron,1553236388,can anyone suggest me how can i denoise images for give that denoise image to neural network?,4,0,False,self,,,,,
204,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,19,b43fhg,self.deeplearning,PSU Upgrade Advice for 2nd GPU?,https://www.reddit.com/r/deeplearning/comments/b43fhg/psu_upgrade_advice_for_2nd_gpu/,eigenvergle42,1553250377,"Hi, not sure if this is the right place to go but thank you for anyone that can advise. My current setup is a GTX 1080 TI with a 850 watt PSU. I really need a 2nd GPU, so I'm going ahead with buying a GTX 2080 TI to supplement. I'll likely be running separate models on these on a near constant daily basis. I'm not a hardware expert and wondering if anyone could help me out in determining whether I need to be upgrading the PSU as well to accommodate.",6,2,False,self,,,,,
205,deeplearning,t5_2t5eh,2019-3-22,2019,3,22,23,b45tyi,self.deeplearning,Hinton's reading list from the removed Coursera MOOC,https://www.reddit.com/r/deeplearning/comments/b45tyi/hintons_reading_list_from_the_removed_coursera/,durmusau,1553265530,"Hi all,

&amp;#x200B;

Geoffrey Hinton's Coursera MOOC was recently discontinued:

[https://twitter.com/geoffreyhinton/status/1085325734044991489?lang=en](https://twitter.com/geoffreyhinton/status/1085325734044991489?lang=en)

&amp;#x200B;

The videos however are still available at both on Youtube and on Hinton's webpage:

[https://www.cs.toronto.edu/\~hinton/coursera\_lectures.html](https://www.cs.toronto.edu/~hinton/coursera_lectures.html)

&amp;#x200B;

However in his MOOC Hinton also had some papers as required (or recommended, I can't really remember) readings after each lecture. They were generally old, seminal papers which provided some good insights and intuitions and were worth reading IMHO for learning purposes. I couldn't find these papers as a reading list online. Does anyone have this list?",3,40,False,self,,,,,
206,deeplearning,t5_2t5eh,2019-3-23,2019,3,23,0,b46m9f,self.deeplearning,Curated List of Arbitrary Text to Image Papers,https://www.reddit.com/r/deeplearning/comments/b46m9f/curated_list_of_arbitrary_text_to_image_papers/,lzhbrian,1553269538,"[lzhbrian/arbitrary-text-to-image-papers](https://github.com/lzhbrian/arbitrary-text-to-image-papers)

Still preliminary. PR, issues, discussions are welcomed!",0,1,False,self,,,,,
207,deeplearning,t5_2t5eh,2019-3-23,2019,3,23,2,b47icv,self.deeplearning,Tableau Training &amp; Certification,https://www.reddit.com/r/deeplearning/comments/b47icv/tableau_training_certification/,HannahHumphreys,1553274044,[removed],0,1,False,self,,,,,
208,deeplearning,t5_2t5eh,2019-3-23,2019,3,23,6,b4aevn,self.deeplearning,[Q] repetition encoder for integer labels?,https://www.reddit.com/r/deeplearning/comments/b4aevn/q_repetition_encoder_for_integer_labels/,pk12_,1553288541,"Is there is an optimised python function to encode integer labels as repetition on binary 1s

For example 

1 =001
2 = 011
3 = 111

Thanks",0,1,False,self,,,,,
209,deeplearning,t5_2t5eh,2019-3-23,2019,3,23,12,b4eluv,self.deeplearning,Sign language recognition using OpenCV,https://www.reddit.com/r/deeplearning/comments/b4eluv/sign_language_recognition_using_opencv/,arshad_221b,1553313229,Sign Language Recognition Using CNN and OpenCV (Beginner Level) by Arshad Kazi https://link.medium.com/VwhBjBLPgV,0,2,False,self,,,,,
210,deeplearning,t5_2t5eh,2019-3-23,2019,3,23,13,b4f4mw,self.deeplearning,V100 or t4? How do i know if my problem is scale up or out?,https://www.reddit.com/r/deeplearning/comments/b4f4mw/v100_or_t4_how_do_i_know_if_my_problem_is_scale/,Jpc204,1553316684,"New to dl/ai/ml. Saw the announcement about Nvidia working with oems to deliver boxes with t4s and v100 architectures - all in their ngc ready program.

How will I know if I need t4s or v100s?

Can I just go with t4 boxes to lower barrier to entry? When will adding t4 boxes not work for me anymore?

Note, I know I could start with titan or similar but I'd like to start with a solution that can be shared and scaled. (And we won't be ready for cloud)

(Warning in advance that I'm not actually ready to buy hardware, still working on path to product....probably getting ahead of myself but this is the biggest knowledge gap)

Thx in advance ",8,3,False,self,,,,,
211,deeplearning,t5_2t5eh,2019-3-23,2019,3,23,14,b4ff3k,self.deeplearning,Good project to get experience with C++ for computer vision/deep learning?,https://www.reddit.com/r/deeplearning/comments/b4ff3k/good_project_to_get_experience_with_c_for/,74throwaway,1553318677,"I have some experience with image processing but I'm interested in transitioning to a job that involves more deep learning and/or computer vision. I had a couple interviews for these roles recently and they mentioned the job duties would be roughly 50% python and 50% C++. I haven't used C++ in awhile so I want to get better at C++ to prepare for these kinds of jobs

Problem is I don't really know where to start in terms of using C++ for a DL/CV project. I've only used Matlab, Python, and Keras for image processing/DL. 

Are there any good projects like Kaggle where I can get practice using C++ for DL/CV? Is having access to a GPU necessary if using C++? What DL framework is easiest to learn for C++?",7,16,False,self,,,,,
212,deeplearning,t5_2t5eh,2019-3-23,2019,3,23,17,b4gpzw,self.deeplearning,Call for AI writers at FloydHub,https://www.reddit.com/r/deeplearning/comments/b4gpzw/call_for_ai_writers_at_floydhub/,pirate7777777,1553328809,[We are hiring AI Writers for the FloydHub blog](https://blog.floydhub.com/write-for-floydhub/). This is a great gig for anyone passionate about the DeepLearning or MachineLearning community. Join the crew.,0,16,False,self,,,,,
213,deeplearning,t5_2t5eh,2019-3-23,2019,3,23,23,b4jj5n,self.deeplearning,Learning resources deep learning,https://www.reddit.com/r/deeplearning/comments/b4jj5n/learning_resources_deep_learning/,durgesh2018,1553350017,"Hello everyone!
I am a new researcher in deep learning. Please suggest few resources to learn deep learning from scratch.
Thank you! ",8,5,False,self,,,,,
214,deeplearning,t5_2t5eh,2019-3-24,2019,3,24,1,b4l70u,self.deeplearning,Fake news detection implementation ?,https://www.reddit.com/r/deeplearning/comments/b4l70u/fake_news_detection_implementation/,yautslil,1553359172,"Hi everyone, I am working on Fake News detection, One implementation I came to know about is using stance detection, But this involves comparison of the article with another true article and then see if both agree.  I want to know if there is some another implementation which doesn't require to compare an article against another. 

P.S. yeah I know about Binary classification but I guess this approach won't be fine for fake news detection as new fake news can be generated without using any of the word combinations that is present on training dataset.",17,8,False,self,,,,,
215,deeplearning,t5_2t5eh,2019-3-24,2019,3,24,2,b4m2wg,self.deeplearning,TPU Supporting Frameworks?,https://www.reddit.com/r/deeplearning/comments/b4m2wg/tpu_supporting_frameworks/,apoorvagni,1553363787,"Hi, I wanted to know which of the frameworks are currently supporting computations on Google's TPUs and upto what extent. I heard that Pytorch supports it somewhat but it doesn't support RNN Networks. 

&amp;#x200B;

Hope to get some ideas about which technologies to focus learning that would save more bucks down the line (by using cheaper TPUs instead of GPUs).

&amp;#x200B;

Thanks

\-aa",3,3,False,self,,,,,
216,deeplearning,t5_2t5eh,2019-3-24,2019,3,24,7,b4oyuk,self.deeplearning,How can I improve a curiosity-driven reinforcement learning AI...?,https://www.reddit.com/r/deeplearning/comments/b4oyuk/how_can_i_improve_a_curiositydriven_reinforcement/,ZeroMaxinumXZ,1553379443,"Besides, you know, RND... 

&amp;#x200B;

My reincforcement-learning AI isn't really improving much, and I'm afraid it's barely learning... So any suggestions...?",0,3,False,self,,,,,
217,deeplearning,t5_2t5eh,2019-3-24,2019,3,24,7,b4pdj9,self.deeplearning,LSTM for text generation?,https://www.reddit.com/r/deeplearning/comments/b4pdj9/lstm_for_text_generation/,RemoteReindeer,1553381924,"Hi, I was following a notebook for text generation with just one LSTM cell.

&amp;#x200B;

The input (about 40 char) predict the next character (only one).

&amp;#x200B;

I was wondering if mapping a series a char to only one char at the output (and not a word or anything else) is the usual way to do it (text generation) ?

&amp;#x200B;

On a side note, if you know some great networks for text generation, give me a link please.

&amp;#x200B;

cheers.",8,9,False,self,,,,,
218,deeplearning,t5_2t5eh,2019-3-24,2019,3,24,8,b4pkzb,youtube.com,How Neural Networks Work- Simply Explained by a Machine Learning Engineer,https://www.reddit.com/r/deeplearning/comments/b4pkzb/how_neural_networks_work_simply_explained_by_a/,DiscoverAI,1553383193,,0,0,False,image,,,,,
219,deeplearning,t5_2t5eh,2019-3-24,2019,3,24,8,b4pqt6,self.deeplearning,"Trying to implement multi-head attention layer, from Transformer",https://www.reddit.com/r/deeplearning/comments/b4pqt6/trying_to_implement_multihead_attention_layer/,anirbankar21,1553384195,"Trying to implement multi-head attention layer, which was published in [""Attention is all you need""](https://arxiv.org/pdf/1706.03762.pdf)

&amp;#x200B;

here is my try using tensorflow  2.0 keras api

&amp;#x200B;

&amp;#x200B;

![img](bfpqvaoxeyn21)

&amp;#x200B;

any thoughts? is it looking good or i am missing something",0,2,False,self,,,,,
220,deeplearning,t5_2t5eh,2019-3-24,2019,3,24,9,b4qdp5,self.deeplearning,What happend to google duplex ai,https://www.reddit.com/r/deeplearning/comments/b4qdp5/what_happend_to_google_duplex_ai/,sometimesguru,1553388188,"I mean common. That cant be real. It was announced like 10month ago and it seemed like google duplex could understand every single word in the phone call and not only that it sounded all natural. My question is : why the hell is there no evidence or a single video out there which shows the ai in a real life scenario? We only have this (probably) faked presentation 10month ago and a video on youtube from the youtuber venturebeat 4 months ago but she/he wrote in the description that google has a 'manual line' and a ai line. The ai line is for calls which are made with the ai (google says its the majority of incoming calls) and the manual line is actually a real human speaking and NOT an ai. So we basically have no real proof and on the other hand we still have the google assistant which understands only half of what you say and you have to speak slowly and clearly... Sorry but i think that this is fake

What do you guys think?",5,6,False,self,,,,,
221,deeplearning,t5_2t5eh,2019-3-24,2019,3,24,18,b4ugd6,bidyutchanda.github.io,Predicting type of art using CNNs and FastAI,https://www.reddit.com/r/deeplearning/comments/b4ugd6/predicting_type_of_art_using_cnns_and_fastai/,bidyutchanda108,1553419247,,0,3,False,default,,,,,
222,deeplearning,t5_2t5eh,2019-3-24,2019,3,24,20,b4vj7w,self.deeplearning,Help on how to start with Machine learning and AI?,https://www.reddit.com/r/deeplearning/comments/b4vj7w/help_on_how_to_start_with_machine_learning_and_ai/,shad282,1553428257,"Hi all, I would like your help since i m planning to get into Machine learning and AI.

I m a graduate in finance, Bachelor and Masters and I m currently working in data analysis, visualization and stuff related. I m amateur in raspberry pi and home automation and a bit of coding.

Recently I m learning more python and i would like to involved python with my data analysis (collection up to prediction) and also in my home automation. I decided that I need also to be up to date with the latest tech and I m becoming really interested in getting involved in AI and Machine learning, that would boost my data analysis skills and my own home automation project and other projects using my pi.

My question is: what should i do next after learning python should I learn more google approach which links to tensorflow, or get myself involved in AWS ML. Also, to fit what is demanded career wise.

Thank you!",14,4,False,self,,,,,
223,deeplearning,t5_2t5eh,2019-3-25,2019,3,25,3,b4zp5m,flancia.org,GPT-2 and Philip K. Dick,https://www.reddit.com/r/deeplearning/comments/b4zp5m/gpt2_and_philip_k_dick/,flancian,1553452418,,1,7,False,default,,,,,
224,deeplearning,t5_2t5eh,2019-3-25,2019,3,25,9,b53m2k,self.deeplearning,Can I run ..m type of files in google colab?,https://www.reddit.com/r/deeplearning/comments/b53m2k/can_i_run_m_type_of_files_in_google_colab/,nisucuk,1553472814,,6,0,False,self,,,,,
225,deeplearning,t5_2t5eh,2019-3-25,2019,3,25,10,b54l1x,self.deeplearning,Curiosity Rewarder Optimizer and Loss Function Suggestions?,https://www.reddit.com/r/deeplearning/comments/b54l1x/curiosity_rewarder_optimizer_and_loss_function/,ZeroMaxinumXZ,1553478413,"So, basically I have a curiosity rewarder and an acting agent. The curiosity rewarder is a 5-layer convnet built using Keras, and it takes in the previous state as input, and the current action as it's expected output. The loss function is mean_squared_error and the optimizer is Adam (set to default Keras values) but I'm wondering if there's something better I can use considering my use case... Thanks.",4,3,False,self,,,,,
226,deeplearning,t5_2t5eh,2019-3-25,2019,3,25,13,b561tt,self.deeplearning,Learn how to make a program that can paint photographs !,https://www.reddit.com/r/deeplearning/comments/b561tt/learn_how_to_make_a_program_that_can_paint/,signal_v_noise,1553487445,"An implementation of ""A Neural Algorithm of Artistic Style"" in Keras

1. Learn how to setup an environment for deep learning.
2. Write a program that is smart enough to paint your photos in the style of whatever painting you like

Code Repository: [https://github.com/devAmoghS/Keras-Style-Transfer](https://github.com/devAmoghS/Keras-Style-Transfer)

Tutorial Blog: [https://medium.com/@singhal.amogh1995/utilising-cnns-to-transform-your-model-into-a-budding-artist-1330dc392e25](https://medium.com/@singhal.amogh1995/utilising-cnns-to-transform-your-model-into-a-budding-artist-1330dc392e25)

[Chicago city as painted with the style of Rain Princess](https://i.redd.it/aq7hfih5y6o21.png)",0,21,False,self,,,,,
227,deeplearning,t5_2t5eh,2019-3-25,2019,3,25,20,b59a2a,self.deeplearning,Highly imbalanced negative class and noise class in scene segmentation,https://www.reddit.com/r/deeplearning/comments/b59a2a/highly_imbalanced_negative_class_and_noise_class/,_userjv,1553511975,"I'm trying to do a semantic segmentation on point data scene. There are 2 classes of interest- class 0 and class 1. Class 1 overwhelms class 0 by a ratio of 100:1. Also, the scene-wise number of points can vary sample to sample. To solve this, I take a constant input size of 1000. This number is kept because that is the maximum possible number of points I can get from a scene. In order to reach this fixed size, I fill all the features with 0 values.

Any suggestions on training, where I can neglect the dummy class i.e. the one filled with 0 values to meet the input size and also have a decent score for the actual points which are already imbalanced 100:1 ?",0,1,False,self,,,,,
228,deeplearning,t5_2t5eh,2019-3-25,2019,3,25,20,b59c9y,self.deeplearning,Visual Agnosia: A Neural Network Analogy,https://www.reddit.com/r/deeplearning/comments/b59c9y/visual_agnosia_a_neural_network_analogy/,aryancodify,1553512375," Recently I read the story The man who mistook his wife for a hat by Dr. Oliver Sacks. I could not help but draw strong parallels between neural network deficit and brain dysfunction. In the following medium story I try to capture this intriguing similarity: 

[https://medium.com/@aryancodify/visual-agnosia-a-neural-network-analogy-8e208438b1ec](https://medium.com/@aryancodify/visual-agnosia-a-neural-network-analogy-8e208438b1ec)  
",0,1,False,self,,,,,
229,deeplearning,t5_2t5eh,2019-3-25,2019,3,25,20,b59omy,self.deeplearning,"A PyTorch implementation of ""Capsule Graph Neural Network"" (ICLR 2019).",https://www.reddit.com/r/deeplearning/comments/b59omy/a_pytorch_implementation_of_capsule_graph_neural/,benitorosenberg,1553514528,"&amp;#x200B;

https://i.redd.it/vff6x48l69o21.jpg

PyTorch: [https://github.com/benedekrozemberczki/CapsGNN](https://github.com/benedekrozemberczki/CapsGNN)

Paper: [https://openreview.net/forum?id=Byl8BnRcYm](https://openreview.net/forum?id=Byl8BnRcYm)

Abstract:

The high-quality node embeddings learned from the Graph Neural Networks (GNNs) have been applied to a wide range of node-based applications and some of them have achieved state-of-the-art (SOTA) performance. However, when applying node embeddings learned from GNNs to generate graph embeddings, the scalar node representation may not suffice to preserve the node/graph properties efficiently, resulting in sub-optimal graph embeddings.  Inspired by the Capsule Neural Network (CapsNet), we propose the Capsule Graph Neural Network (CapsGNN), which adopts the concept of capsules to address the weakness in existing GNN-based graph embeddings algorithms. By extracting node features in the form of capsules, routing mechanism can be utilized to capture important information at the graph level. As a result, our model generates multiple embeddings for each graph to capture graph properties from different aspects. The attention module incorporated in CapsGNN is used to tackle graphs with various sizes which also enables the model to focus on critical parts of the graphs.  Our extensive evaluations with 10 graph-structured datasets demonstrate that CapsGNN has a powerful mechanism that operates to capture macroscopic properties of the whole graph by data-driven. It outperforms other SOTA techniques on several graph classification tasks, by virtue of the new instrument.

&amp;#x200B;

&amp;#x200B;",0,30,False,self,,,,,
230,deeplearning,t5_2t5eh,2019-3-25,2019,3,25,21,b5a6cg,analyticsvidhya.com,OpenCV basics,https://www.reddit.com/r/deeplearning/comments/b5a6cg/opencv_basics/,arshad_221b,1553517519,,0,1,False,default,,,,,
231,deeplearning,t5_2t5eh,2019-3-25,2019,3,25,23,b5bh5l,self.deeplearning,Quickly Train and Deploy a Computer Vision App with fastai and Render,https://www.reddit.com/r/deeplearning/comments/b5bh5l/quickly_train_and_deploy_a_computer_vision_app/,discdiver,1553524746,[removed],0,1,False,self,,,,,
232,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,1,b5cnzj,medium.com,Deploying Deep Learning models using Kubeflow on Azure,https://www.reddit.com/r/deeplearning/comments/b5cnzj/deploying_deep_learning_models_using_kubeflow_on/,brunocborges,1553530615,,0,3,False,default,,,,,
233,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,2,b5date,self.deeplearning,I dont actually know much,https://www.reddit.com/r/deeplearning/comments/b5date/i_dont_actually_know_much/,tymp-anistam,1553533504,"I know that deep learning can be used in countless applications so I just had a thought, could you record a %100 playthrough of a video game and teach a bot to speed run the game? Or something possibly more simple, create a walkthrough book of the game itself? Any thoughts? Does this already exist?",5,0,False,self,,,,,
234,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,3,b5ednh,self.deeplearning,Courses Like CS231n and CS224n,https://www.reddit.com/r/deeplearning/comments/b5ednh/courses_like_cs231n_and_cs224n/,abhiksark,1553538394,"What are some best university courses in Deep Learning.

I am aware of Cs231n and Cs224n.

Any more courses like these? ",7,11,False,self,,,,,
235,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,4,b5f58j,self.deeplearning,Video analytics plausibility question for a basketball app,https://www.reddit.com/r/deeplearning/comments/b5f58j/video_analytics_plausibility_question_for_a/,maholeycow,1553542052,"Hey everyone! So I am a total newb when it comes to AI/ML/DL... and I was hoping to get your insight. Would it be possible to use computer vision to train data sets with videos of professional basketball players shooting a basketball from a few angles and capturing things like the angle of their knee bend, angle of the back, angle of their shooting pocket, jump height, release point at certain jump height, velocity, etc.. and turn that into structured data so that users of say a mobile app can upload videos of themselves shooting and try to mimick the form of their favorite player with feedback from the application?

&amp;#x200B;

If so, what frameworks are out there that I could look into? It'd be cool to get an MVP out there in the next year or two as a side project. I am a software engineer at a pretty great company but I have had this idea in my head for while and wanted to make it as a side project if possible. ",3,1,False,self,,,,,
236,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,6,b5gfka,self.deeplearning,Deep Learning PC Spec... Is it any good.,https://www.reddit.com/r/deeplearning/comments/b5gfka/deep_learning_pc_spec_is_it_any_good/,CoderYo,1553548081,"Hey 

&amp;#x200B;

Just wondering if this is a good setup for deeplearning use only... I have read up on specs for deep learning (wide range of topics I want to be able to do with this system), wondering if I have this right for what I have listed. Any feedback welcome.. Cheers

&amp;#x200B;

DEEP LEARNING

\*Intel Core i9 9900X

\*Gigabyte X299 UD4 Pro Motherboard

\*Corsair CMT64GX4M4C3000C15 Dominator Platinum RGB 64GB 3000MHz DDR4

\*NZXT Kraken X62 Liquid CPU Cooler (With AM4 Bracket)

\*Samsung 860 EVO 2TB M.2 (SATA) SSD

\*2 x Seagate BarraCuda SSD 500GB, 2.5in SATA III

\*Seagate BarraCuda 8TB, ST8000DM004 (Used for previous training data/backup)

\*2 x Gigabyte GeForce RTX 2080 Ti Windforce, 11GB

\*ZOTAC GAMING GeForce RTX NVLink Bridge - 3 Slot

\*Seasonic Prime 1300W Power Supply

\*Fractal Design Meshify S2 Blackout E-ATX Case, T/G Window, No PSU

\*2 x AOC Q27P1 27inch IPS QHD Monitor

\*Logitech Brio Webcam",1,1,False,self,,,,,
237,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,6,b5gw79,self.deeplearning,Quantizing a neutral net to custom data types,https://www.reddit.com/r/deeplearning/comments/b5gw79/quantizing_a_neutral_net_to_custom_data_types/,rafeey,1553550249,"I want to quantize yolo and SSD to custom fixed point data types to study the effect on accuracy. Can anyone who've done that please guide me how to do that?  
I've tried tflite converter but it gives error on custom nets like yolo. Plus it only supports int8 conversion. Is there any other way to do it?",1,2,False,self,,,,,
238,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,8,b5i5sv,dragan.rocks,"Deep Learning from Scratch to GPU: The Backward Pass (CUDA, OpenCL, Nvidia, AMD, Intel)",https://www.reddit.com/r/deeplearning/comments/b5i5sv/deep_learning_from_scratch_to_gpu_the_backward/,dragandj,1553556552,,0,10,False,default,,,,,
239,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,13,b5lbhv,self.deeplearning,"How does mxnet work with the latest RTX GPUs (2070, 2080, etc)",https://www.reddit.com/r/deeplearning/comments/b5lbhv/how_does_mxnet_work_with_the_latest_rtx_gpus_2070/,heroesneverdie,1553574861,"Cannot find much info on their official website. Many public benchmarks use tensorflow. Curious to know if people have experience in this. Thanks. 

&amp;#x200B;",0,1,False,self,,,,,
240,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,14,b5ln56,self.deeplearning,"Error 'Failed to get convolution algorithm' shows up, even though cudNN seems to be installed.",https://www.reddit.com/r/deeplearning/comments/b5ln56/error_failed_to_get_convolution_algorithm_shows/,ZeroMaxinumXZ,1553577079,"So, I have a machine with a RTX 2060, and I want to run tensorflow on it. However, the error, Failed to get convolution algorithm, is showing up despite me installing cudNN on it.

&amp;#x200B;

I have Tensorflow-GPU 1.13.1 running on my Linux (Xubuntu 18.04) machine. I have followed the instructions on the site (which are below), and have installed via pip tensorflow-gpu.

&amp;#x200B;

Instructions I've followed:

    
    
    # Add NVIDIA package repositories
    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb
    sudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb
    sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub
    sudo apt-get update
    wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
    sudo apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
    sudo apt-get update
    
    # Install NVIDIA driver
    sudo apt-get install --no-install-recommends nvidia-driver-410
    # Reboot. Check that GPUs are visible using the command: nvidia-smi
    
    # Install development and runtime libraries (~4GB)
    sudo apt-get install --no-install-recommends \
        cuda-10-0 \
        libcudnn7=7.4.1.5-1+cuda10.0  \
        libcudnn7-dev=7.4.1.5-1+cuda10.0
     https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb sudo dpkg -i cuda-repo-ubunt
    
    # Install TensorRT. Requires that libcudnn7 is installed above.
    sudo apt-get update &amp;&amp; \
            sudo apt-get install nvinfer-runtime-trt-repo-ubuntu1804-5.0.2-ga-cuda10.0 \
            &amp;&amp; sudo apt-get update \
            &amp;&amp; sudo apt-get install -y --no-install-recommends libnvinfer-dev=5.0.2-1+cuda10.0
    

&amp;#x200B;

Error I get:

    2019-03-25 23:16:50.938950: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
    2019-03-25 23:16:52.732720: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
    2019-03-25 23:16:52.736377: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
    Traceback (most recent call last):
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
        return fn(*args)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1319, in _run_fn
        options, feed_dict, fetch_list, target_list, run_metadata)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1407, in _call_tf_sessionrun
        run_metadata)
    tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[{{node ppo/actions-and-internals/layered-network/apply/conv2d0/apply/Conv2D}}]]
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""start.py"", line 54, in &lt;module&gt;
        main()
      File ""start.py"", line 51, in main
        main_loop(agent, curiousity_engine)
      File ""start.py"", line 23, in main_loop
        action1 = agent.act(states=get_screen())
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/agents/agent.py"", line 148, in act
        independent=independent
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/model.py"", line 1393, in act
        fetch_list = self.monitored_session.run(fetches=fetches, feed_dict=feed_dict)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 676, in run
        run_metadata=run_metadata)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1270, in run
        raise six.reraise(*original_exc_info)
      File ""/home/user/.local/lib/python3.6/site-packages/six.py"", line 693, in reraise
        raise value
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1255, in run
        return self._sess.run(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1327, in run
        run_metadata=run_metadata)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1091, in run
        return self._sess.run(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 929, in run
        run_metadata_ptr)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1152, in _run
        feed_dict_tensor, options, run_metadata)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
        run_metadata)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
        raise type(e)(node_def, op, message)
    tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node ppo/actions-and-internals/layered-network/apply/conv2d0/apply/Conv2D (defined at /home/user/.local/lib/python3.6/site-packages/tensorforce/core/networks/layer.py:1079) ]]
    
    Caused by op 'ppo/actions-and-internals/layered-network/apply/conv2d0/apply/Conv2D', defined at:
      File ""start.py"", line 54, in &lt;module&gt;
        main()
      File ""start.py"", line 41, in main
        agent, user_input = agent_build()
      File ""/home/user/Downloads/v2 (2)/agent.py"", line 37, in agent_build
        actions_exploration = 'epsilon_decay'
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/agents/ppo_agent.py"", line 155, in __init__
        entropy_regularization=entropy_regularization
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/agents/learning_agent.py"", line 141, in __init__
        batching_capacity=batching_capacity
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/agents/agent.py"", line 80, in __init__
        self.model = self.initialize_model()
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/agents/ppo_agent.py"", line 183, in initialize_model
        likelihood_ratio_clipping=self.likelihood_ratio_clipping
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/pg_prob_ratio_model.py"", line 88, in __init__
        gae_lambda=gae_lambda
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/pg_model.py"", line 98, in __init__
        requires_deterministic=False
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/distribution_model.py"", line 90, in __init__
        discount=discount
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/memory_model.py"", line 114, in __init__
        reward_preprocessing=reward_preprocessing
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/model.py"", line 217, in __init__
        self.setup()
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/model.py"", line 290, in setup
        independent=independent
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/memory_model.py"", line 605, in create_operations
        independent=independent
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/model.py"", line 1193, in create_operations
        independent=independent
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/model.py"", line 1019, in create_act_operations
        deterministic=deterministic
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 368, in __call__
        return self._call_func(args, kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 311, in _call_func
        result = self._func(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/models/distribution_model.py"", line 187, in tf_actions_and_internals
        return_internals=True
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 368, in __call__
        return self._call_func(args, kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 311, in _call_func
        result = self._func(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/core/networks/network.py"", line 253, in tf_apply
        x = layer.apply(x=x, update=update)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 368, in __call__
        return self._call_func(args, kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/template.py"", line 311, in _call_func
        result = self._func(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorforce/core/networks/layer.py"", line 1079, in tf_apply
        x = tf.nn.conv2d(input=x, filter=self.filters, strides=(1, stride_h, stride_w, 1), padding=self.padding)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1026, in conv2d
        data_format=data_format, dilations=dilations, name=name)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
        op_def=op_def)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
        return func(*args, **kwargs)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
        op_def=op_def)
      File ""/home/user/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
        self._traceback = tf_stack.extract_stack()
    
    UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node ppo/actions-and-internals/layered-network/apply/conv2d0/apply/Conv2D (defined at /home/user/.local/lib/python3.6/site-packages/tensorforce/core/networks/layer.py:1079) ]]
    

&amp;#x200B;",4,3,False,self,,,,,
241,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,16,b5mnup,allainews.com,All AI News in one Place,https://www.reddit.com/r/deeplearning/comments/b5mnup/all_ai_news_in_one_place/,ai_jobs,1553584659,,2,4,False,default,,,,,
242,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,17,b5n5y5,self.deeplearning,Advanced TensorFlow For Advance Deep Learning and Cognotive Computing,https://www.reddit.com/r/deeplearning/comments/b5n5y5/advanced_tensorflow_for_advance_deep_learning_and/,AIhacker99,1553589048,"Watch the latest DL concepts of TensorFlow for developers. I have included my deep-voice-conversion algorithms to convert my voice in this video. Hope you all like it. I practice what I preach it. Please share my latest videos on Deep Learning to all you friends and Data Engineers. Have a good time watching this video

&amp;#x200B;

[https://youtu.be/qh9xhFGEIWo](https://youtu.be/qh9xhFGEIWo)",0,8,False,self,,,,,
243,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,19,b5nwkm,youtu.be,What is Machine Learning? Machine Learning Tutorial With Python,https://www.reddit.com/r/deeplearning/comments/b5nwkm/what_is_machine_learning_machine_learning/,surbhipatel432,1553595300,,1,3,False,default,,,,,
244,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,19,b5nxwf,self.deeplearning,Tensorflow/Pytorch?,https://www.reddit.com/r/deeplearning/comments/b5nxwf/tensorflowpytorch/,arshad_221b,1553595596,What should I learn? I'm a beginner in Deep learning...,4,0,False,self,,,,,
245,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,21,b5p3b0,self.deeplearning,Deploying Pre-trained Pytorch Model,https://www.reddit.com/r/deeplearning/comments/b5p3b0/deploying_pretrained_pytorch_model/,priya90r,1553603333,"I am trying to understand how to deploy Pytorch models to Google Cloud. I was using the pre-trained Pytorch German-to-English translation model. How do I go about making a Flask API for the same and deploying it in Google Cloud?

&amp;#x200B;

Thanks",3,1,False,self,,,,,
246,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,23,b5q6vo,self.deeplearning,Solution approaches and ideas for the development and optimization of a computerized procedure for the recognition of LEGO bricks,https://www.reddit.com/r/deeplearning/comments/b5q6vo/solution_approaches_and_ideas_for_the_development/,melbrssl,1553609524,"In my bachelor thesis I dealt with the question how a computer can recognize LEGO bricks. With multiple object detection, I chose a deep learning approach. I also looked at the existing training set of LEGO brick images and tried to optimize it.

&amp;#x200B;

**Task**

A photo of several LEGO bricks is sent to a program and the program detects the LEGO bricks in the photo.

&amp;#x200B;

**Approach 1: Muliple Object Detection**

In a first approach I used [Tensorflow's Object Detection API](https://github.com/tensorflow/models/tree/a8bb5926525763c1e6a023780573cf3e0e29b916/research/object_detection) to detect several bricks in an image. I trained the network with photos of one LEGO brick at a time, taken with the help of a turntable and a stepper motor. The photos show the LEGO brick from different directions, but always on the same background and from the same angle. The pictures were labelled manually.

The Neural Network could not detect all the LEGO bricks in the test photos. The main reason I suspected was the choice of the training data set.

&amp;#x200B;

**Approach 2: Synthetically generated training set**

To optimize the multiple object detection approach, I looked at the data set. It showed no variation of the lighting conditions or the viewing angle. So I decided to model a LEGO brick in Blender and program a camera to capture the brick from different angles, on different surfaces and under different lighting conditions. The LEGO bricks were automatically labelled by Blender as they were taken.

The training of a new Neural Network with the synthetically generated data set lead to significantly better results. However, the recognition of several LEGO bricks in one photo still has to be improved further.

&amp;#x200B;

**My result**

Through both approaches, the multiple object detection and the generation of a synthetic data set to optimize the training data, I was able to achieve a detection rate of 95.2% for one LEGO brick to be detected. For images with several LEGO bricks, the recognition rate was 73.3%. 

One of the main problems I noticed was, that I tried to distinguish three different 2x4 bricks. However, colors are difficult to distinguish, especially in different lighting conditions. A better approach would have been to distinguish a 2x4 from a 2x2 and a 2x6 LEGO brick.

Furthermore, I have noticed that the training set should best consist of ""normal"" and synthetically generated images. The synthetic images give variations in the lighting conditions, the backgrounds, etc., which the photographed images do not give. However, when using the trained Neural Network, photos and not synthetic images are examined. Therefore, photos should also be included in the training data set.

One last point that would probably lead to even better results is that you train the Neural Network with pictures that show more than one LEGO brick. Because this is exactly what is required by the Neural Network when it is in use.

&amp;#x200B;

**More ideas and solutions**

Can you see any further potential for improvement for the Neural Network?

How would you approach the issue?

Which of my approaches don't seem well chosen?

How do you solve the question?",1,2,False,self,,,,,
247,deeplearning,t5_2t5eh,2019-3-26,2019,3,26,23,b5qh6g,self.deeplearning,I'm trying to train a CNN to classify sound data. How should I preprocess sound files of different lengths?,https://www.reddit.com/r/deeplearning/comments/b5qh6g/im_trying_to_train_a_cnn_to_classify_sound_data/,RnabSanyal,1553611068,"The sound files are of different lengths. This is my first time working with sound data. Based on one of the approaches I read about, I'm gonna try to use a window to get cuts of the sound files to get instances of equal length. Is there a better approach than this? Any help is appreciated!",10,15,False,self,,,,,
248,deeplearning,t5_2t5eh,2019-3-27,2019,3,27,1,b5rsys,self.deeplearning,Stochastic Gradient Descent,https://www.reddit.com/r/deeplearning/comments/b5rsys/stochastic_gradient_descent/,sriharsha_0806,1553617576,"In chapter 5 of Machine learning  Basics of Deep learning textbook of Ian Goodfellow, (5.9 stochastic gradient descent paragraph after equation 5.99). It is mentioned ""The optimization algorithm may not be guaranteed to arrive at even a local minimum in a reasonable amount of time, but it often finds a very low value of the cost function quickly enough to be useful"". 

what is the meaning behind this sentence? If I am not wrong isn't very low value of cost function is itself a local minimum.",1,1,False,self,,,,,
249,deeplearning,t5_2t5eh,2019-3-27,2019,3,27,3,b5t5ra,self.deeplearning,How can i know if i can implement a particular model on my dataset?,https://www.reddit.com/r/deeplearning/comments/b5t5ra/how_can_i_know_if_i_can_implement_a_particular/,nisucuk,1553624174,"I found a paper named "" CNN-RNN: A Unified Framework for Multi-Label Image Classification.""

It had worked on MScoco dataset, NUs-wide, Pascal VOC 2007. I have a datset which is a part of ROCO dataset.

How can i know if i can use the model described in this paper, for my dataset???

&amp;#x200B;",0,1,False,self,,,,,
250,deeplearning,t5_2t5eh,2019-3-27,2019,3,27,6,b5vdy7,self.deeplearning,New to ML,https://www.reddit.com/r/deeplearning/comments/b5vdy7/new_to_ml/,slaptastico,1553634859,"Hello

So i just started learning machine learning and i wanted to attempt to create a model where it colorizes grayscale images.

I am doing this as a final year project that is due in 3 months. Is this enough to write, train and test?

Also in your opinions, is this a good project for university?

And are there any good resources you might suggest i read?

Thank you! ",4,0,False,self,,,,,
251,deeplearning,t5_2t5eh,2019-3-27,2019,3,27,12,b5zgdv,self.deeplearning,Number of bounding boxes in Tensorflow Object detection module,https://www.reddit.com/r/deeplearning/comments/b5zgdv/number_of_bounding_boxes_in_tensorflow_object/,naboo_random,1553657352,"I'm doing inference using one of the pre-trained models, tensorflow object detection. However, the train config of the model limits the number of detections to just 5 boxes. Any idea on how to change this parameter during inference?

The model i'm using is the one trained on [link](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#inaturalist-species-trained-models). It's config is [here](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config), and [here](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config). The max\_total\_detection is set to 5 here. I'm not sure how to update this to get more number of updates.

Any help will be highly appreciated!

I have tried loading the graph and seeing the variables in the pretrained model. I found a variable that says ""num\_detections"", but I'm not sure how to re-assign it with any of the codes that helps in inference.

During inference, I use the code [here](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb)

I add the following line:

    num_detections = tf.get_default_graph().get_tensor_by_name('num_detections:0') sess.run(tf.assign(num_detections, num_detections+10),feed_dict={image_tensor: np.expand_dims(image,0)}) 

But it gives me an error saying the variable doesn't have any assign attribute. I'm assuming it's because I can't change it.

Is there any other way I can update it? Or would I need to re-train it?",2,8,False,self,,,,,
252,deeplearning,t5_2t5eh,2019-3-27,2019,3,27,13,b5zz9o,self.deeplearning,Suggestions for model type,https://www.reddit.com/r/deeplearning/comments/b5zz9o/suggestions_for_model_type/,justanator101,1553660818,"Im fairly new to deep learning outside the realm of cnns and lstms. Im doing a course project comparing ML algorithms to a deep learning one. My data is based on gene expressions and each sample has a list of values for each gene. My set is 900 genes so an input is (1,900). I have a custom feature selection algorithm used for the ml stuff and get good results but Im not sure what I should do for the deep learning. 

Ive been thinking of stacked autoencoders fed into a feed forward network? This way itll learn features without the feature selection algorithm and be a deep net. Any other suggestions or comments are appreciated! ",0,1,False,self,,,,,
253,deeplearning,t5_2t5eh,2019-3-27,2019,3,27,13,b608qr,self.deeplearning,problems when we use Machine Learning to make credit prediction,https://www.reddit.com/r/deeplearning/comments/b608qr/problems_when_we_use_machine_learning_to_make/,GW_KIM,1553662662,"Hi there, is there anyone well knows about make credit prediction using ML/DL ?  
I'm doing a survey about it, but i'm super newbie for financial domain. So it is hard to make some direction of research.

help :)",5,4,False,self,,,,,
254,deeplearning,t5_2t5eh,2019-3-27,2019,3,27,20,b634zp,youtu.be,Creating systems that significantly augment human capabilities with #MachineLearning &amp; #ArtificialInteligence with Wendy Mackay (talk from GOTO Copenhagen 2018),https://www.reddit.com/r/deeplearning/comments/b634zp/creating_systems_that_significantly_augment_human/,mto96,1553684932,,1,1,False,image,,,,,
255,deeplearning,t5_2t5eh,2019-3-27,2019,3,27,20,b635qs,youtube.com,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educational. Do check it out",https://www.reddit.com/r/deeplearning/comments/b635qs/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1553685080,,2,4,False,image,,,,,
256,deeplearning,t5_2t5eh,2019-3-27,2019,3,27,21,b63yom,self.deeplearning,Question about expanding dataset for YOLO v3,https://www.reddit.com/r/deeplearning/comments/b63yom/question_about_expanding_dataset_for_yolo_v3/,MathKlim,1553690241,"Actually I'm making my own dataset of images. After a while I came to the question if it's possible to double this dataset by just inverting the images. By invertion I mean that you just take an image and the result would be as if you look from the other side. If you got an image of a face looking to the right, you invert it and it would look to the left. 

As a result of this invention, all the bounding boxes would be moved in consequence. Is this operation to double the dataset a good idea, or this counts as repeated data?",1,0,False,self,,,,,
257,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,1,b65zdo,blog.nanonets.com,How To Make Deep Learning Models That Dont Suck,https://www.reddit.com/r/deeplearning/comments/b65zdo/how_to_make_deep_learning_models_that_dont_suck/,manneshiva,1553702621,,10,30,False,default,,,,,
258,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,1,b66iv7,kaggle.com,Kaggle Kernel on Hyper Opt + Keras,https://www.reddit.com/r/deeplearning/comments/b66iv7/kaggle_kernel_on_hyper_opt_keras/,polyglotdev,1553705194,,0,1,False,default,,,,,
259,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,3,b67qtv,blog.floydhub.com,Meta-Reinforcement Learning,https://www.reddit.com/r/deeplearning/comments/b67qtv/metareinforcement_learning/,pirate7777777,1553711025,,0,6,False,default,,,,,
260,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,3,b681zd,self.deeplearning,How to put scalars in tensorboard from Keras outside of the callbacks?,https://www.reddit.com/r/deeplearning/comments/b681zd/how_to_put_scalars_in_tensorboard_from_keras/,nobodywillobserve,1553712514,"I am trying to use

&amp;#x200B;

`with K.get_backend() as sess:`

`with tf.name_scope('custom_scalars'):`

`for k, v in tolog.items():`

`if v is not None:`

`v = tf.Variable(v)`

`tf.summary.scalar(k, v)`

`else:`

`print(f'SKIPPING {k}')`

`merged = tf.summary.merge_all()`

`train_writer = tf.summary.FileWriter(os.path.join(tb_output_dir), sess.graph)`

[`sess.run`](https://sess.run)`(merged)`

&amp;#x200B;

&amp;#x200B;

But am not seeing anything appear in tensorboard except for the loss and val\_loss that the callback puts there. 

&amp;#x200B;

How to get a hold of sess and use it. I think files are landing in the output dir due to that writer.",0,1,False,self,,,,,
261,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,8,b6bm5b,self.deeplearning,2D to 3D reconstruction,https://www.reddit.com/r/deeplearning/comments/b6bm5b/2d_to_3d_reconstruction/,kavinash366,1553730152,"What are some good 2D to 3D reconstruction papers?

Most of them I've seen construct the shape from the 2d images given the silhouette or the image itself. But I couldn't find any paper that focuses on actual details in the given image. Are there any papers that explored this?

Context: I'm working on reconstructing an MRI (3D) from a single slice. I need to have as much details as possible. I also can't give silhouettes as inputs because there won't be any detail left. ",1,1,False,self,,,,,
262,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,11,b6d5t7,self.deeplearning,Deep Learning Model for Gait Pattern Recognition,https://www.reddit.com/r/deeplearning/comments/b6d5t7/deep_learning_model_for_gait_pattern_recognition/,supp0rtlife,1553739217,"I am relatively new to deep learning but essentially I am looking for a deep learning courses that will help me in my research which is to recognize Gait Patterns from raw acceleration data, but I am not sure which area of deep learning this concerns, I did work on an LSTM model so would it be RNN? Can someone suggests some university level courses that would help me out in this area. I did check out CS231N but that's more Computer Vision, however I would really appreciate it someone could suggest some university level courses like that. Thanks in advance",13,9,False,self,,,,,
263,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,13,b6eaxr,self.deeplearning,GIS segmentation model's input data format,https://www.reddit.com/r/deeplearning/comments/b6eaxr/gis_segmentation_models_input_data_format/,karthikziffer,1553746639,I have GIS data in Tiff format. How to convert into training data format ?   Relevant weblinks will be helpful. ,0,3,False,self,,,,,
264,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,13,b6efgr,self.deeplearning,Question on output_dim of the Embedding layer in keras,https://www.reddit.com/r/deeplearning/comments/b6efgr/question_on_output_dim_of_the_embedding_layer_in/,randomicly,1553747535,"(This is a toy program and I want to understand common techniques of handling large OHE vectors.)

I am experimenting with a toy LSTM network where I want to pass a bag of words OHE representation rather then the commonly used word-vector.

Now the bag of words is large (about 20k) and the OHE representation is a sparse vector of size 20k for each word, so I am running out of memory as expected.

Im trying to use the Embedding layer of keras here with the input_dim being the size of the vocabulary + 1.

I am unable to understand the output_dim variable there. The documentation states:
&gt; output_dim: int &gt;= 0. Dimension of the dense embedding.
I dont know what and how this is chosen. Can someone tell me how to choose this, and also please comment if I am on the right track.


",6,2,False,self,,,,,
265,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,14,b6eop0,self.deeplearning,Best C++ OpenCL deep learning framework?,https://www.reddit.com/r/deeplearning/comments/b6eop0/best_c_opencl_deep_learning_framework/,iamalex_,1553749387,"I currently use PyTorch for a cross-platform desktop program by converting it to C++ and it can run in production through: [https://pytorch.org/tutorials/advanced/cpp\_export.html](https://pytorch.org/tutorials/advanced/cpp_export.html)

Thing is I would want support Macbooks and AMD's GPU's so I'd like to add OpenCL inference.

&amp;#x200B;

But it either seems like for AMD support everything is heading to RocM, but I don't want that cause I still want to support older and Intel iGPU's.

&amp;#x200B;

Is there any framework that can run in production with C++ and OpenCL that has a good amount of documentation?

The documentation about running PyTorch in a C++ production is really great but sadly it only supports CUDA...

&amp;#x200B;",4,2,False,self,,,,,
266,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,14,b6ey2g,self.deeplearning,Mandarin Speech-to-Text Models,https://www.reddit.com/r/deeplearning/comments/b6ey2g/mandarin_speechtotext_models/,priya90r,1553751272,"Are there any good models that create transcripts of Chinese audios or some articles on how to train one of the existing models for the same?

&amp;#x200B;

Also how do I get Chinese alphabet list for training a model?

Thanks",0,2,False,self,,,,,
267,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,19,b6h4pf,github.com,Built an open source experiment tracker called ModelChimp over past year. Would love to hear your thoughts on the product!,https://www.reddit.com/r/deeplearning/comments/b6h4pf/built_an_open_source_experiment_tracker_called/,kamanjun,1553769058,,3,27,False,default,,,,,
268,deeplearning,t5_2t5eh,2019-3-28,2019,3,28,22,b6ikh3,self.deeplearning,"Artificial Intelligence is The New Electricity, Are you Kidding Me!",https://www.reddit.com/r/deeplearning/comments/b6ikh3/artificial_intelligence_is_the_new_electricity/,Gabyleon2019,1553778440,"Claiming that Deep Learnings impact on humanity will be as monumental as the discovery of electricity, is not only wrong, but also dangerous!!

What do you guys think?

&amp;#x200B;

 [https://www.linkedin.com/pulse/artificial-intelligence-new-electricity-you-kidding-me-l-hijazi/](https://www.linkedin.com/pulse/artificial-intelligence-new-electricity-you-kidding-me-l-hijazi/) ",10,4,False,self,,,,,
269,deeplearning,t5_2t5eh,2019-3-29,2019,3,29,0,b6jyur,medium.com,The Rise of Generative Adversarial Networks,https://www.reddit.com/r/deeplearning/comments/b6jyur/the_rise_of_generative_adversarial_networks/,kailashahirwar12,1553785884,,0,3,False,default,,,,,
270,deeplearning,t5_2t5eh,2019-3-29,2019,3,29,0,b6k2dc,gfycat.com,Grassland v0.2: Tensorflow CNN + Mapbox 3D == Worldwide SimCity,https://www.reddit.com/r/deeplearning/comments/b6k2dc/grassland_v02_tensorflow_cnn_mapbox_3d_worldwide/,00hello,1553786347,,1,15,False,default,,,,,
271,deeplearning,t5_2t5eh,2019-3-29,2019,3,29,1,b6kl9k,dragan.rocks,Deep Learning from Scratch to GPU: A Simple Neural Network Inference API,https://www.reddit.com/r/deeplearning/comments/b6kl9k/deep_learning_from_scratch_to_gpu_a_simple_neural/,dragandj,1553788892,,0,3,False,default,,,,,
272,deeplearning,t5_2t5eh,2019-3-29,2019,3,29,7,b6ozsq,self.deeplearning,Need help understanding backpropogation,https://www.reddit.com/r/deeplearning/comments/b6ozsq/need_help_understanding_backpropogation/,dukes_haven,1553810520,"Am trying to implement a shallow neural network, can somebody explain to me how he coded dZ1?",0,0,False,self,,,,,
273,deeplearning,t5_2t5eh,2019-3-29,2019,3,29,11,b6rpiv,self.deeplearning,Gradient descent,https://www.reddit.com/r/deeplearning/comments/b6rpiv/gradient_descent/,durgesh2018,1553825610,"Hello everyone!
While calculating gradient descent, why can't we linearly increase or decrease the weight? ",11,6,False,self,,,,,
274,deeplearning,t5_2t5eh,2019-3-29,2019,3,29,11,b6s02x,self.deeplearning,CNN and GNN together ?,https://www.reddit.com/r/deeplearning/comments/b6s02x/cnn_and_gnn_together/,StupendousEnzio,1553827430,"Can CNN and GNN be implemented together to increase accuracy without the issue of overfitting ? I am a postgrad student pursuing Deep learning and convolutional neural network. I am thinking of doing something in this area, just wanted to get some experienced advice of how feasible it will be. Shoot me questions if you think I am a bit vague in framing the questions. Cheers!",3,2,False,self,,,,,
275,deeplearning,t5_2t5eh,2019-3-29,2019,3,29,13,b6t3r1,self.deeplearning,Exploring Career Avenues with Deep Learning Certification in 2019,https://www.reddit.com/r/deeplearning/comments/b6t3r1/exploring_career_avenues_with_deep_learning/,SunilAhujaa,1553834990,There are a number of ways you can prepare for future. One surest way to do it is by upgrading your skills and doing Deep Learning Certification. Data literacy and storytelling are the most sought-after skills that the industry is looking it.,0,0,False,self,,,,,
276,deeplearning,t5_2t5eh,2019-3-29,2019,3,29,15,b6txam,self.deeplearning,Random or Unsupervised features(chapter 9.9 of Deep learning textbook of Ian Good Fellow),https://www.reddit.com/r/deeplearning/comments/b6txam/random_or_unsupervised_featureschapter_99_of_deep/,sriharsha_0806,1553841519,"""Learning the features with an unsupervised criterion allows them(convolutional layers) to be determined separately from the classification layer at the top of the architecture. One can then extract the features for the entire training set just once, essentially constructing a new training set for the last layer. Learning the last layer is then typically a convex optimization problem, assuming the last layer is something like logistic regression or SVM.""  I did not understand this paragraph. 

&amp;#x200B;

How does learning features with an unsupervised criterion make the CNN architectures into two disjoint convolutional layers and classification layer(one is not affecting the other)?",8,5,False,self,,,,,
277,deeplearning,t5_2t5eh,2019-3-29,2019,3,29,20,b6vw1r,self.deeplearning,Labeling Audio Data,https://www.reddit.com/r/deeplearning/comments/b6vw1r/labeling_audio_data/,yrajsm,1553857499,I am preparing custom audio dataset for classification project. Are there open source labeling tools for audio dataset?,3,3,False,self,,,,,
278,deeplearning,t5_2t5eh,2019-3-29,2019,3,29,21,b6wlpf,self.deeplearning,DeepSpeech for Mandarin,https://www.reddit.com/r/deeplearning/comments/b6wlpf/deepspeech_for_mandarin/,priya90r,1553862201,"I am trying to train a DeepSpeech model for Mandarin using this [tutorial](https://blog.yuwu.me/?p=3989). I am stuck at finding a generatecsv file that generates a csv file for creating a data for training the model. How do I create/find one?

Thanks",0,4,False,self,,,,,
279,deeplearning,t5_2t5eh,2019-3-30,2019,3,30,0,b6ypkz,self.deeplearning,Issue with keras and cudNN,https://www.reddit.com/r/deeplearning/comments/b6ypkz/issue_with_keras_and_cudnn/,ZeroMaxinumXZ,1553873501,"I'm having issues with Keras and  tensorflow. Basically, it gives me  the following error ""Segmentation  fault (core dumped)"" anytime I try to fit  a model with a conv2d layer.

My  code works on the CPU. It also works without any conv2d layers  (even  though it's ineffective for my use case). I've got cuda, cudnn,  and  tensorflow installed. I've tried reinstalling keras and tensorflow.   I've tried reinstalling the graphics drivers, CUDA, and all the other   packages. I'm on Ubuntu 16.04 (Mint v18, external USB SSD drive) with   CUDA V9.0, and I simply followed the instructions on Tensorflow (under   GPU support. for 1.12 and under.) to install CUDA. Tensorflow version is   1.12. A theory I have is that cuDNN is somehow broken and needs to be   reinstalled... (Even though I've reinstalled it multiple times so...)

&amp;#x200B;

Code Sample:  


    import numpy as np
    import keras
    
    model = keras.models.Sequential() #Sequential model type.
    model.add(keras.layers.Conv2D(filters=1, kernel_size=(3,3), strides = 1, activation=""sigmoid"")) #Convolutional layer.
    model.add(keras.layers.Flatten()) #Flatten layer.
    model.add(keras.layers.Dense(4)) #Dense layer of 4 units.
    model.compile(loss='mean_squared_error', optimizer='adam') #compile model.
    y = np.random.rand(1,4) #Random expected output
    x = np.random.rand(1, 38, 21, 1) # Random input.
    model.fit(x, y) #And fit... Error occurs here.
    

&amp;#x200B;

Error:  


    Using TensorFlow backend. Epoch 1/1 2019-03-29 03:14:25.259882: I tensorflow/core/platform/cpu_feature_guard.cc:141] 
    Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 2019-03-29 03:14:25.573157: 
    I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] 
    successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2019-03-29 03:14:25.574989: 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432]
    Found device 0 with properties: name: GeForce RTX 2060 major: 7 minor: 5 memoryClockRate(GHz): 1.83 pciBusID: 0000:01:00.0 
    totalMemory: 5.73GiB
     freeMemory: 5.49GiB 2019-03-29 03:14:25.575033: 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2019-03-29 03:14:31.770903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 
    Device interconnect StreamExecutor with strength 1 edge matrix: 2019-03-29 03:14:31.770974: 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 2019-03-29 03:14:31.770992: 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2019-03-29 03:14:31.772113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 
    Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5235 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5) 
    Segmentation fault (core dumped) 
    

&amp;#x200B;",10,1,False,self,,,,,
280,deeplearning,t5_2t5eh,2019-3-30,2019,3,30,2,b701i0,self.deeplearning,Creating a Neural Network with item embeddings,https://www.reddit.com/r/deeplearning/comments/b701i0/creating_a_neural_network_with_item_embeddings/,Usually_Awkward_32,1553880166,"Hey guys! 

&amp;#x200B;

I hope it is okay to ask something about a project I'm working on. I want to use the instacart database ([https://www.kaggle.com/c/instacart-market-basket-analysis](https://www.kaggle.com/c/instacart-market-basket-analysis)) to create a deep learning recommender system. I made a traditional recommender system before this (based on collaborative filtering), but the sparsity is too high so the results are not that great. At first, I made an item embedding, by doing a word2vec on the add-to-card order for each user (based on the idea that users will browse a category, select similar items, and then continue to another category). The item embeddings work really well, when I look for a similar item to 'soda' I get lemonade and stuff. So, that's great to start with :)

&amp;#x200B;

However, I'm quite the beginner at deep learning (and not that advanced in python). I now want to create a neural network, to forecast what each user will buy next (and thus, make recommendations based on thus). I have made a dataframe where I have the user ID, the product ID and the quantity they purchased. I also have those item embeddings. Now, I'm quite at a loss where to start combining these two. Does anyone maybe have some tips for me? That would be great :) Thank you very much in advance. ",1,9,False,self,,,,,
281,deeplearning,t5_2t5eh,2019-3-30,2019,3,30,4,b71oxv,self.deeplearning,Training CNN and RNN separately in CRNN,https://www.reddit.com/r/deeplearning/comments/b71oxv/training_cnn_and_rnn_separately_in_crnn/,pk12_,1553888375,"Is it possible to train a CNN first and then add RNN say LSTM to the output of CNN.

Basically, is it possible to load initial layers of the CRNN with weights from the CNN and let the RNN part be trained?

I use keras and wonder if someone has implemented this ",4,5,False,self,,,,,
282,deeplearning,t5_2t5eh,2019-3-30,2019,3,30,7,b73l0o,github.com,DeepCamera: Turn your android device into deep learning surveillance monitor which knows person,https://www.reddit.com/r/deeplearning/comments/b73l0o/deepcamera_turn_your_android_device_into_deep/,solderzzc,1553898240,,0,5,False,default,,,,,
283,deeplearning,t5_2t5eh,2019-3-30,2019,3,30,9,b754lf,self.deeplearning,How essential is it to know C++ well for deep learning jobs?,https://www.reddit.com/r/deeplearning/comments/b754lf/how_essential_is_it_to_know_c_well_for_deep/,74throwaway,1553907136,"I have some experience with image processing but I'm interested in transitioning to a job that involves more deep learning and/or computer vision. I had a couple interviews for these roles recently and a couple of them mentioned C++ would be a major part of the job. They mentioned if I passed the initial phone screen, then they would've test me on my C++ coding. One company worked with autonomous vehicles and the other worked on something else but mentioned they were using C++ to develop their own DL framework similar to Tensorflow

If I want to get a job in DL, am I better off improving my C++? Or just working on any personal project, even if it uses Python and Keras/Pytorch?",19,12,False,self,,,,,
284,deeplearning,t5_2t5eh,2019-3-30,2019,3,30,11,b75tkj,self.deeplearning,How do I calculate regret in a reinforcement learning algorithm?,https://www.reddit.com/r/deeplearning/comments/b75tkj/how_do_i_calculate_regret_in_a_reinforcement/,ZeroMaxinumXZ,1553911510,"How should I calculate regret in a reinforcement learning algorithm to feed as a negative reward? Any (not just super-mathematical, I'm new to ML and RL) explanations or papers  would be helpful.  Thanks.",6,1,False,self,,,,,
285,deeplearning,t5_2t5eh,2019-3-30,2019,3,30,15,b77zap,self.deeplearning,permutation invariant,https://www.reddit.com/r/deeplearning/comments/b77zap/permutation_invariant/,sriharsha_0806,1553926660,"Chapter 9.4 last paragraph of Ian Goodfellow Deeplearning textbook.  

""Models that do not use convolution would be able to learn even if we permuted all the pixels in the images.  For many images datasets there are separate benchmarks for models that are permutation invariant and mist discover the concept of topology via learning ""

&amp;#x200B;

I did not understand first sentence and what is concept of topology and what are the models that are permutation invariant?",5,8,False,self,,,,,
286,deeplearning,t5_2t5eh,2019-3-31,2019,3,31,3,b7ensr,self.deeplearning,Implementing text localization on Natural Image Scenes using tensorflow,https://www.reddit.com/r/deeplearning/comments/b7ensr/implementing_text_localization_on_natural_image/,mutyalu_amballa,1553972324,"I started working on a project in which I want to localize the text in the natural scenery images. For example consider an image that contains text in different parts of the image, with different sizes for each word. So how can I find the locations of all the words in the image.

Previous research:
I found some information in some papers, 
1) which explains that they are using a localization network(CNN + RNN). which produces 'n'(n is total words in the image) affine matrices for each word in the image. 
2) And also other variations which uses the sliding window of different sizes, sliding across the image and trying to find the presence of text. 

I am not able to find any resources that helps me with the implementation in python, tensorflow 

This is a reference link I came across:

https://medium.com/syncedreview/stn-ocr-a-single-neural-network-for-text-detection-and-text-recognition-220debe6ded4

Can anyone suggest me the resources required to achieve this task..!

- Thanks",0,1,False,self,,,,,
287,deeplearning,t5_2t5eh,2019-3-31,2019,3,31,4,b7eukc,self.deeplearning,Implementing text localization on Natural Scene images using tensorflow,https://www.reddit.com/r/deeplearning/comments/b7eukc/implementing_text_localization_on_natural_scene/,mutyalu_amballa,1553973312,"I started working on a project in which I want to localize the text in the natural scenery images. For example consider an image that contains text in different parts of the image, with different sizes for each word. So how can I find the locations of all the words in the image.

Previous research:
I found some information in some papers, 
1) which explains that they are using a localization network(CNN + RNN). which produces 'n'(n is total words in the image) affine matrices for each word in the image. 
2) And also other variations which uses the sliding window of different sizes, sliding across the image and trying to find the presence of text. 

I am not able to find any resources that helps me with the implementation in python, tensorflow 

This is a reference link I came across:

https://medium.com/syncedreview/stn-ocr-a-single-neural-network-for-text-detection-and-text-recognition-220debe6ded4

Can anyone suggest me the resources required to achieve this task..!

- Thanks",9,4,False,self,,,,,
288,deeplearning,t5_2t5eh,2019-3-31,2019,3,31,4,b7f7fq,self.deeplearning,"A parallel implementation of Walklets from ""Don't Walk Skip! Online Learning of Multi-scale Network Embeddings"" (ASONAM 2017).",https://www.reddit.com/r/deeplearning/comments/b7f7fq/a_parallel_implementation_of_walklets_from_dont/,benitorosenberg,1553975309,"&amp;#x200B;

&amp;#x200B;

https://i.redd.it/ck05xupo8bp21.jpg

Github: [https://github.com/benedekrozemberczki/walklets](https://github.com/benedekrozemberczki/walklets)

Paper: [https://arxiv.org/abs/1605.02115](https://arxiv.org/abs/1605.02115)

Abstract:

We present Walklets, a novel approach for learning multiscale representations of vertices in a network. In contrast to previous works, these representations explicitly encode multiscale vertex relationships in a way that is analytically derivable.  Walklets generates these multiscale relationships by subsampling short random walks on the vertices of a graph. By \`skipping' over steps in each random walk, our method generates a corpus of vertex pairs which are reachable via paths of a fixed length. This corpus can then be used to learn a series of latent representations, each of which captures successively higher order relationships from the adjacency matrix. We demonstrate the efficacy of Walklets's latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, DBLP, Flickr, and YouTube. Our results show that Walklets outperforms new methods based on neural matrix factorization. Specifically, we outperform DeepWalk by up to 10% and LINE by 58% Micro-F1 on challenging multi-label classification tasks. Finally, Walklets is an online algorithm, and can easily scale to graphs with millions of vertices and edges.",0,2,False,self,,,,,
289,deeplearning,t5_2t5eh,2019-3-31,2019,3,31,4,b7f96h,medium.com,"DL in production: what tools are in your ""full"" software stack?",https://www.reddit.com/r/deeplearning/comments/b7f96h/dl_in_production_what_tools_are_in_your_full/,PullThisFinger,1553975589,,2,23,False,default,,,,,
290,deeplearning,t5_2t5eh,2019-3-31,2019,3,31,15,b7kusi,self.deeplearning,What will future generations think about us?,https://www.reddit.com/r/deeplearning/comments/b7kusi/what_will_future_generations_think_about_us/,arshad_221b,1554014564,"We are building these neural networks to make our lives better. We are improving each and every field with power of AI. 
But on the other side, AI is stealing the jobs. Robots are becoming stronger and smarter. So what our future generations will think about us? What they will say? We made the world better or stole their jobs? ",8,1,False,self,,,,,
291,deeplearning,t5_2t5eh,2019-3-31,2019,3,31,17,b7lmq5,self.deeplearning,Is it worth to buy 2 EVO 970 plus 1 TB in Raid 0 for my deep learning build?,https://www.reddit.com/r/deeplearning/comments/b7lmq5/is_it_worth_to_buy_2_evo_970_plus_1_tb_in_raid_0/,kitgary,1554021747,"I am building a PC for deep learning, I have already picked up all other parts but just cant decide if I should have a NVME SSD raid 0 setup, I want to build the fastest PC for deep learning. Btw, I am now using 9980xe, 3x2080Ti, 128GB DDR4 Ram.",4,6,False,self,,,,,
292,deeplearning,t5_2t5eh,2019-3-31,2019,3,31,18,b7m0oi,self.deeplearning,Deep Learning PC Spec... Is it any good,https://www.reddit.com/r/deeplearning/comments/b7m0oi/deep_learning_pc_spec_is_it_any_good/,whoisweaknow,1554025294,"Hey

Just wondering if this is a good setup for deeplearning and other AI stuff use only... I have read up on specs for deep learning (wide range of topics I want to be able to do with this system), wondering if I have this right for what I have listed. Any feedback welcome.. Cheers

&amp;#x200B;

* Nvidia Titan RTX
* AMD Ryzen Threadripper 1920X  (12 Core)
* MSI  X399 Gaming Pro Carbon AC
* Thermaltake toughpower 80 plus gold
* Cooler Master Masterliquid ML360 AMD TR4
* Samsung 250 GB 970 Evo Plus NVMe M.2 SSD --------------------------- (x2)
* Thermalleke View 37 Rgb Riing Edition MidT E-ATX Case (With Fans)
* GSKILL 32GB (16x2) SniperX DDR 4 3000Mhz  ---------------------------(x2)",9,1,False,self,,,,,
293,deeplearning,t5_2t5eh,2019-3-31,2019,3,31,19,b7m700,wars64.blogspot.com,Final Wars,https://www.reddit.com/r/deeplearning/comments/b7m700/final_wars/,warlord_64,1554026821,,1,0,False,default,,,,,
