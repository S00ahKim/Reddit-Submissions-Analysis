,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2017-4-1,2017,4,1,13,62qlkb,Rethinking Recurrent Neural Networks,https://www.reddit.com/r/deeplearning/comments/62qlkb/rethinking_recurrent_neural_networks/,jostmey,1491020844,,2,6
1,2017-4-1,2017,4,1,22,62sr64,Microsoft patent could be the ultimate disrupt to the content search market,https://www.reddit.com/r/deeplearning/comments/62sr64/microsoft_patent_could_be_the_ultimate_disrupt_to/,heydude_675,1491053949,,0,0
2,2017-4-3,2017,4,3,9,633goy,NLP Pre-Trained Embeddings Best Practices Question,https://www.reddit.com/r/deeplearning/comments/633goy/nlp_pretrained_embeddings_best_practices_question/,clamman,1491180210,"When performing a NLP task using pre-trained embeddings (such as sentiment analysis), what is the best practice when encountering a word that is in your training word corpus but is not in the pre-trained embeddings corpus? 

Two options off of the top of my head are we could initialize the missing words to just the zero vector or we could initialize them to a random unit vector. Are there others? What are the possible advantages/disadvantages of each? What if I treat my embeddings as constant rather than a trainable variable?

Thanks in advance for any insight/help.",7,2
3,2017-4-3,2017,4,3,18,635rbo,Online Banking is Evolving With NLP &amp;amp; Deep Learning,https://www.reddit.com/r/deeplearning/comments/635rbo/online_banking_is_evolving_with_nlp_amp_deep/,teamrework,1491212946,,0,3
4,2017-4-3,2017,4,3,19,635t1i,How Will Deep Learning Revolutionize Online Banking?,https://www.reddit.com/r/deeplearning/comments/635t1i/how_will_deep_learning_revolutionize_online/,reworksophie,1491213759,,0,1
5,2017-4-4,2017,4,4,18,63d4u0,Computer Vision News - April 2017 (in both HTML5 and PDF),https://www.reddit.com/r/deeplearning/comments/63d4u0/computer_vision_news_april_2017_in_both_html5_and/,Gletta,1491299077,"Here are two links to the April issue of Computer Vision News, published by RSIP Vision: 44 pages with exclusive articles and free subscription at page 44. Following general request, Flash version has been discontinued.

Read it in HTML5: http://www.rsipvision.com/ComputerVisionNews-2017April/ 
Read it in PDF: 
http://www.rsipvision.com/computer-vision-news-2017-april-pdf/ 
Enjoy!",0,2
6,2017-4-5,2017,4,5,7,63hjgt,Semantic Segmentation Domain Adaptation,https://www.reddit.com/r/deeplearning/comments/63hjgt/semantic_segmentation_domain_adaptation/,miat123,1491344940,"I am trying to train a conv net for semantic image segmentation. The problem is that I have a synthetic dataset and a real one and there is an obvious domain shift. What would be a way to do a domain adaptation? I have successfully done the simplest approach where I use 4 mini-batches from the real and 4 mini-batches from the synthetic domain in the SGD optimization.
I believe a more complicated approach would be better.",0,1
7,2017-4-5,2017,4,5,18,63kf44,SECURITY &amp; PRIVACY IS VITAL FOR MACHINE LEARNING TO SUCCEED,https://www.reddit.com/r/deeplearning/comments/63kf44/security_privacy_is_vital_for_machine_learning_to/,nikitaljohnson,1491383230,,1,0
8,2017-4-6,2017,4,6,2,63mu8w,First In-Depth Look at Googles TPU Architecture,https://www.reddit.com/r/deeplearning/comments/63mu8w/first_indepth_look_at_googles_tpu_architecture/,eleitl,1491411756,,0,10
9,2017-4-6,2017,4,6,11,63q4fj,In-depth NVIDIA DGX-1 Architecture White Paper,https://www.reddit.com/r/deeplearning/comments/63q4fj/indepth_nvidia_dgx1_architecture_white_paper/,harrism,1491444415,,0,3
10,2017-4-6,2017,4,6,13,63qpjt,Deep Learning and Quantum Physics : A Fundamental Bridge,https://www.reddit.com/r/deeplearning/comments/63qpjt/deep_learning_and_quantum_physics_a_fundamental/,hammy_bob,1491451540,,4,9
11,2017-4-6,2017,4,6,14,63r1op,What topic or idea in Deep Learning that requires not too much computational power but is still fertile for new development?,https://www.reddit.com/r/deeplearning/comments/63r1op/what_topic_or_idea_in_deep_learning_that_requires/,[deleted],1491456357,[deleted],1,1
12,2017-4-6,2017,4,6,19,63s4gp,Keras example of Pixel Wise classification,https://www.reddit.com/r/deeplearning/comments/63s4gp/keras_example_of_pixel_wise_classification/,S2ica,1491475049,"Hi, I'm new to deep learning (machine learning in general).

Currently I'm trying to implement a residual ConvNet for pixel wise classification, but am not sure how in general to do it. Currently all examples of neural networks in keras just performs image classification. 

Any information or hints towards doing this would help alot.
The implementation of residual CovNet I'm currently looking at is [this here](https://github.com/raghakot/kerasresnet/blob/master/resnet.py). ",1,3
13,2017-4-7,2017,4,7,3,63urt3,Specifying incorrect input dimensions for image classification,https://www.reddit.com/r/deeplearning/comments/63urt3/specifying_incorrect_input_dimensions_for_image/,BoltzmannMachine,1491502858,"What is the behaviour of Keras if an input dimension of (x, y) is specified but an image with dimensions (x', y') are introduced to the first layer of a sequential model? ",1,0
14,2017-4-7,2017,4,7,7,63whnw,AI Painting - Generative Neural Style,https://www.reddit.com/r/deeplearning/comments/63whnw/ai_painting_generative_neural_style/,Hidden_dreamz,1491519159,,0,5
15,2017-4-7,2017,4,7,12,63xz5e,How many images (data) do I need to start training a Deep Neural network from scratch?,https://www.reddit.com/r/deeplearning/comments/63xz5e/how_many_images_data_do_i_need_to_start_training/,Alirezag,1491535462,"I have a naive question.

How can I know the amount of the images (data) that I have is enough to start training a network from scratch?
I guess the amount of data for each DNN architecture would be different, for example, the amount of data that AlexNet requires would be less than the amount of data that ResNet Needs (at least that is what I think).

But How I can figure out that I have the minimum sufficient amount of images to start training a network from scratch?

Is there any paper/explanation/method/logical/non-logical way to compute the minimum required number/amount of images(data)?

Thanks :)",1,7
16,2017-4-8,2017,4,8,16,645wjn,PDF version of MIT DeepLearningBook,https://www.reddit.com/r/deeplearning/comments/645wjn/pdf_version_of_mit_deeplearningbook/,janishar,1491637089,,1,22
17,2017-4-9,2017,4,9,2,64895e,Top 9 Deep Learning and Neural Networks Books,https://www.reddit.com/r/deeplearning/comments/64895e/top_9_deep_learning_and_neural_networks_books/,kjahan,1491672800,,1,1
18,2017-4-9,2017,4,9,14,64bmne,What would be the benefits of image data sets with contour annotations?,https://www.reddit.com/r/deeplearning/comments/64bmne/what_would_be_the_benefits_of_image_data_sets/,dyanson,1491715967,"We have a technology can automatically generate training image data sets for deep learning with true contour annotations, i.e. objects labeled without background. Instead of conventional bounding boxes around annotated objects that contain irrelevant background in the corners / edges, we can provide training images that are cropped to the contour of an object of interest with &gt;90% relevant fill factor (either non-rectangular ROI or rectangular ROI with zero background outside the object contour).

What are the use cases for such data? What benefits can it offer?
",3,3
19,2017-4-9,2017,4,9,17,64c6o4,Question Answering using Deep Learning,https://www.reddit.com/r/deeplearning/comments/64c6o4/question_answering_using_deep_learning/,rajarsheem,1491727423,,4,1
20,2017-4-10,2017,4,10,16,64i5nx,"Books on everything you need to know on Deep Learning and Machine Learning. This list contains books recommended by Nando De Freitas, Michael I Jordan, Juergen Schmidhuber, Alex Lamb and Geoffrey Hinton.",https://www.reddit.com/r/deeplearning/comments/64i5nx/books_on_everything_you_need_to_know_on_deep/,kawaii_potatosan,1491808388,,0,17
21,2017-4-12,2017,4,12,3,64slke,Cognitive Robotics: Learning Semantic Environment Perception,https://www.reddit.com/r/deeplearning/comments/64slke/cognitive_robotics_learning_semantic_environment/,reworksophie,1491934432,,0,1
22,2017-4-12,2017,4,12,3,64stkm,Security &amp; Privacy is Vital For Machine Learning to Succeed,https://www.reddit.com/r/deeplearning/comments/64stkm/security_privacy_is_vital_for_machine_learning_to/,reworksophie,1491936431,,0,1
23,2017-4-12,2017,4,12,6,64tyqj,Quantomic's Tagspire Drives Social Commerce with Innovative Artificial Intelligence (AI),https://www.reddit.com/r/deeplearning/comments/64tyqj/quantomics_tagspire_drives_social_commerce_with/,mediawoman,1491947133,,0,1
24,2017-4-12,2017,4,12,7,64u8xt,Recursive Neural Networks with PyTorch | Parallel Forall,https://www.reddit.com/r/deeplearning/comments/64u8xt/recursive_neural_networks_with_pytorch_parallel/,harrism,1491950034,,0,5
25,2017-4-12,2017,4,12,18,64x0kr,Security &amp; Privacy is Vital For Machine Learning to Succeed,https://www.reddit.com/r/deeplearning/comments/64x0kr/security_privacy_is_vital_for_machine_learning_to/,reworksophie,1491987670,,0,1
26,2017-4-13,2017,4,13,21,65574z,DCGAN for Image Completion in Torch,https://www.reddit.com/r/deeplearning/comments/65574z/dcgan_for_image_completion_in_torch/,fonfonx,1492087150,,0,2
27,2017-4-15,2017,4,15,0,65d79h,"DeepMind CEO, ""Artificial Intelligence (AI) invents new knowledge and teaches human new theories""",https://www.reddit.com/r/deeplearning/comments/65d79h/deepmind_ceo_artificial_intelligence_ai_invents/,scidem,1492184050,,0,1
28,2017-4-15,2017,4,15,2,65e1rn,Measuring Performance for Object Detectors - Part 1,https://www.reddit.com/r/deeplearning/comments/65e1rn/measuring_performance_for_object_detectors_part_1/,geodawg,1492192305,,0,3
29,2017-4-15,2017,4,15,18,65icnm,What Is Deep Learning?,https://www.reddit.com/r/deeplearning/comments/65icnm/what_is_deep_learning/,Mussem17,1492249960,,0,0
30,2017-4-16,2017,4,16,18,65obzd,Visualizing convolutional layers,https://www.reddit.com/r/deeplearning/comments/65obzd/visualizing_convolutional_layers/,svjan5,1492334765,"Please try to answer this question on stackoverflow site:
http://stackoverflow.com/questions/43433734/deconvolution-conv2d-transpose-in-tensor-flow",1,1
31,2017-4-17,2017,4,17,13,65thuf,Deep learning internship: should I take it?,https://www.reddit.com/r/deeplearning/comments/65thuf/deep_learning_internship_should_i_take_it/,chris_munley,1492402664,"I am being offered the choice between deep learning and parallel programming at a university near where I live as a summer internship. I am in high school, I have looked into both topics, and I found parallel programming to be more up my alley and easier to learn, however deep learning is very interesting to me although somewhat hard to understand. Should I challenge myself and try to work on deep learning with the help of a professor and some phd students, or go into parallel programming. Suggestions greatly appreciated. ",14,4
32,2017-4-18,2017,4,18,17,661kam,Cloud-based Deep Learning: Reducing Tedium in Radiology,https://www.reddit.com/r/deeplearning/comments/661kam/cloudbased_deep_learning_reducing_tedium_in/,teamrework,1492503509,,0,0
33,2017-4-18,2017,4,18,18,661rnt,Creating the Open-Source Autonomous Vehicle,https://www.reddit.com/r/deeplearning/comments/661rnt/creating_the_opensource_autonomous_vehicle/,teamrework,1492507358,,0,1
34,2017-4-19,2017,4,19,0,663nil,Question: Autoencoder vs Pre-trained DNN,https://www.reddit.com/r/deeplearning/comments/663nil/question_autoencoder_vs_pretrained_dnn/,[deleted],1492530545,[deleted],1,0
35,2017-4-19,2017,4,19,1,66423a,[Question][Discussion] Where to go from here?,https://www.reddit.com/r/deeplearning/comments/66423a/questiondiscussion_where_to_go_from_here/,[deleted],1492534295,[deleted],0,0
36,2017-4-19,2017,4,19,3,664lfp,How do you create a self-contained deep-learning executable?,https://www.reddit.com/r/deeplearning/comments/664lfp/how_do_you_create_a_selfcontained_deeplearning/,etrnloptimist,1492539176,"I'm on Windows, and I'm looking to create a simple, portable, self-contained executable that does image classification. 

The libraries I work with (Keras, Theano, Anaconda Python, etc.) require a ton of environment stuff to run properly. Compilers, environment variables, etc. This is fine for test and development, but when it comes to production, I would like it to behave like a traditional program, with a traditional installer.

Ideally it would be run like this:

c:\\MyExecutable.exe MyModel.cnn MyTestImage.jpg

Is there a way to do this?",8,2
37,2017-4-19,2017,4,19,6,665rlj,Last Words: Computational Linguistics and Deep Learning - MITP on Nautilus,https://www.reddit.com/r/deeplearning/comments/665rlj/last_words_computational_linguistics_and_deep/,pmz,1492550162,,0,2
38,2017-4-19,2017,4,19,8,666hql,IBM Boosts Deep Learning Offerings with Anaconda Data Science Platform,https://www.reddit.com/r/deeplearning/comments/666hql/ibm_boosts_deep_learning_offerings_with_anaconda/,dataengconf,1492557629,,0,6
39,2017-4-19,2017,4,19,8,666ou0,Sentiment analysis of social media posts using deep learning,https://www.reddit.com/r/deeplearning/comments/666ou0/sentiment_analysis_of_social_media_posts_using/,wnbhckr,1492559848,"I wanted to do something interesting as my master's thesis so I chose sentiment analysis with deep learning, but now I'm a bit stuck and have motivation problems due to (in my opinion) high entry barrier of the field. My supervisor wanted me to dig in academic journals, but I have a feeling it's very hard to teach yourself from academic papers, since authors don't share (one exception I found is OpenAI) all of their work, but only some vague description, comparison tables and charts, conclusions/summary.

I think I get the gist of what sentiment analysis is, but don't exactly know what could I aim for with my research as a newbie. For now I don't even have a clue how to glue sentiment analysis with deep learning. I guess extraction of opinions about specific aspects of subjects mentioned in post would be too much.

It's worth mentioning I'm also new to deep learning, however I know the basics of neural nets and had to do with reinforcement learning a little.

Fortunately, programming skills aren't a problem.

I'm looking for advice how to get started, get hyped, so I'd want to explore and experiment more on my own. All resources which you think are valuable are welcome. Thank you for your time.",1,1
40,2017-4-19,2017,4,19,11,667k7l,"What does ""run it 5 times"" mean in ResNet paper?",https://www.reddit.com/r/deeplearning/comments/667k7l/what_does_run_it_5_times_mean_in_resnet_paper/,cuekoo,1492569798,"In the caption of Table 6 of ResNet paper (https://arxiv.org/abs/1512.03385), the authors run the model 5 times to report some results. How is it done? Is it to train the model 5 times, or to test 5 times with the same set of learned parameters?",2,1
41,2017-4-20,2017,4,20,1,66bgqs,"Harvard Professor, ""We are Building Artificial Brains and Uploading Mind in to Cloud.""",https://www.reddit.com/r/deeplearning/comments/66bgqs/harvard_professor_we_are_building_artificial/,scidem,1492620845,,0,1
42,2017-4-20,2017,4,20,7,66dixd,Caffe2: Portable High-Performance Deep Learning Framework from Facebook | Parallel Forall,https://www.reddit.com/r/deeplearning/comments/66dixd/caffe2_portable_highperformance_deep_learning/,harrism,1492639976,,0,4
43,2017-4-20,2017,4,20,7,66dsoo,[CNN] Lower batch size leads to overfitting,https://www.reddit.com/r/deeplearning/comments/66dsoo/cnn_lower_batch_size_leads_to_overfitting/,RauanArgyn,1492642710,"Hello everyone. I am trying to train a CNN to recognize facial expressions. I use FER 2013 dataset by Kaggle.


I use SGD with mini-batch. I have been playing with different values and observed that lower batch size values lead to overfitting. 

Please check these two graphs:

**1. Batch-size = 128** http://imgur.com/5iJp0zg

&gt; You can see the validation loss starts to increase after 10 epochs indicating the model starts to overfit. At the same time, the validation accuracy does not increase, so the model does output correct predictions but does so less confidently.

**2. Batch-size = 256** http://imgur.com/YGwRKHy

&gt; Exactly the same hyper-parameters, apart from the batch-size. In this case there is no overfitting, the validation loss just plateaus.

The following are my hyper-parameters:

Hyper-parameter| Value|
--------- | --------- |
Number of epochs| 30
L2 regularization term| 0.0001
Momentum| 0.9

I have tried increasing the regularization strength, it does not help. 

I should mention I use Caffe with Nvidia Digits. FC layers also contain dropout, with ratio=0.5 to prevent the network from overfitting. 

Can anyone suggest a reason why lower batch size leads to overfitting? I do realise large batch sizes allowsmore precise estimates of the gradients, but in this case I would expect the loss to oscillate around some value and not just increase monotonically. 

The following is my network arch:  
&gt;&gt;INPUT(48x48)  
CONV1(3x3, 64 filters, zero-pad=1, stride=1)  
ReLU  
CONV2(3x3, 64 filters, zero-pad=1, stride=1)  
ReLU  
POOL1(stochastic, 3x3, stride=2)  
CONV3(3x3, 128 filters, zero-pad=1, stride=1)  
ReLU  
CONV4(3x3, 128 filters, zero-pad=1, stride=1)  
ReLU  
POOL2(stochastic, 3x3, stride=2)  
CONV5(3x3, 256 filters, zero-pad=1, stride=1)  
ReLU  
CONV6(3x3, 256 filters, zero-pad=1, stride=1)  
ReLU  
POOL3(stochastic, 3x3, stride=2)  
FC1(1024 neurons)  
Dropout(ratio=0.5)  
FC2(1024 neurons)  
Dropout(ratio=0.5)  
FC7(7 neurons)  
Softmax(7 scores)  ",4,3
44,2017-4-20,2017,4,20,8,66e024,Facebook builds brain-computer interface for typing-from-thoughts and skin-hearing. Crazy!!,https://www.reddit.com/r/deeplearning/comments/66e024/facebook_builds_braincomputer_interface_for/,scidem,1492644891,,0,1
45,2017-4-20,2017,4,20,10,66ei76,Building Artificial Intelligence Together,https://www.reddit.com/r/deeplearning/comments/66ei76/building_artificial_intelligence_together/,datmo_io,1492650476,,0,1
46,2017-4-20,2017,4,20,16,66g8x0,[P]Collection of Minimal Reinforcement Learning Implementations,https://www.reddit.com/r/deeplearning/comments/66g8x0/pcollection_of_minimal_reinforcement_learning/,hr_yang,1492673783,,0,7
47,2017-4-20,2017,4,20,23,66i7hd,A guide to receptive field arithmetic for CNNs,https://www.reddit.com/r/deeplearning/comments/66i7hd/a_guide_to_receptive_field_arithmetic_for_cnns/,Nikasa1889,1492700175,,0,1
48,2017-4-21,2017,4,21,1,66iypf,What artificial intelligence can and can't do now? Does AI have moral?,https://www.reddit.com/r/deeplearning/comments/66iypf/what_artificial_intelligence_can_and_cant_do_now/,scidem,1492706986,,0,1
49,2017-4-21,2017,4,21,9,66lt4l,Photo Editing with Generative Adversarial Networks (Part 1),https://www.reddit.com/r/deeplearning/comments/66lt4l/photo_editing_with_generative_adversarial/,harrism,1492734004,,0,2
50,2017-4-21,2017,4,21,16,66nsdw,Analyzing Patents for Prior Art,https://www.reddit.com/r/deeplearning/comments/66nsdw/analyzing_patents_for_prior_art/,barnyardman,1492760437,Is there anything promising in this idea?  I don't know if this would be too complex of a concept as I haven't done much NLP.,3,0
51,2017-4-21,2017,4,21,19,66oago,How to set up Tensorflow with CUDA and cuDNN on a free Google Cloud Instance (and perform style transfer),https://www.reddit.com/r/deeplearning/comments/66oago/how_to_set_up_tensorflow_with_cuda_and_cudnn_on_a/,tftutorial,1492769472,,0,6
52,2017-4-21,2017,4,21,19,66odzb,Confusion about the transposed convolution implementation in caffe,https://www.reddit.com/r/deeplearning/comments/66odzb/confusion_about_the_transposed_convolution/,aragakiyuigaki,1492771046,"Q1: Deconv 

Hi there, I recently read the doc about the deconvolution (also be deemed as transposed convolution) implementation in the caffe framework. In the doc, it is mentioned that :


""
ConvolutionLayer computes each output value by dotting an input window with a filter; DeconvolutionLayer multiplies each input value by a filter elementwise, and sums over the resulting output windows. In other words, DeconvolutionLayer is ConvolutionLayer with the forward and backward passes reversed. DeconvolutionLayer reuses ConvolutionParameter for its parameters, but they take the opposite sense as in ConvolutionLayer (so padding is removed from the output rather than added to the input, and stride results in upsampling rather than downsampling).
""


It says that the deconvolution layer reuses convolutionParameter for its parameters. So, my question is that why not learn the parameters instead of just taking the learnt parameters of the convolution layer?

Q2: GAN

In adversarial networks, we can add a N-by-N noise to the original N-by-N image so as to fool the CNN model. The sign of the element in the N-by-N noise matrix should be the same as that in the gradient matrix. So, if we add a regularizer to constrain the gradient to satisfy that for each real image, the gradient to each pixel should be as close as possible to zero, will that help to solve this problem?",0,1
53,2017-4-22,2017,4,22,0,66psa2,Earth Day 2017: Tackling Climate Science With Deep Learning,https://www.reddit.com/r/deeplearning/comments/66psa2/earth_day_2017_tackling_climate_science_with_deep/,teamrework,1492787456,,0,1
54,2017-4-22,2017,4,22,0,66pt7x,"Facebook Open Sources Caffe2; Nvidia, Intel Rush to Optimize",https://www.reddit.com/r/deeplearning/comments/66pt7x/facebook_open_sources_caffe2_nvidia_intel_rush_to/,Kindlychung,1492787694,,1,6
55,2017-4-24,2017,4,24,18,67819k,compile pytorch with ICC (intel c++ compiler),https://www.reddit.com/r/deeplearning/comments/67819k/compile_pytorch_with_icc_intel_c_compiler/,niraj_vara,1493026518,"Hi

    I have the GPU server and I have install the nvidia drivers, cuda cudnn and intel python and other related packages in docker images.

I have installed the pytorch and running pytorch test scripts alos.  But  to measure the performance I have install intel parallel studio (ICC) so  I want to check  with ICC any performance difference or not.

Please guide how to use ICC(intel c++ compiler) with pytorch to check performance improve or not ?",0,2
56,2017-4-25,2017,4,25,2,67apg4,Open Source Deep Learning Frameworks and Visual Analytics,https://www.reddit.com/r/deeplearning/comments/67apg4/open_source_deep_learning_frameworks_and_visual/,psangrene,1493056412,,0,2
57,2017-4-25,2017,4,25,16,67f61o,question and problem about LSTM Keras implantation,https://www.reddit.com/r/deeplearning/comments/67f61o/question_and_problem_about_lstm_keras_implantation/,davido1221,1493106825,"can a lstm in keras process a sequence of tensors ? 
for example an lstm layer will have an input of (None,100,200,20)?
the problem is I have a matrix of words (a matrix that each row is a sentence ) that goes  through an embedding layers that adds a dim and the lstm expects a 3 dim input shape but gets 4 is there a way to go around it?",1,2
58,2017-4-25,2017,4,25,22,67goc9,Discovering Extrasolar Planets with Deep Learning,https://www.reddit.com/r/deeplearning/comments/67goc9/discovering_extrasolar_planets_with_deep_learning/,teamrework,1493128439,,0,1
59,2017-4-25,2017,4,25,23,67gqmc,Implementation of Wasserstein GAN in Torch,https://www.reddit.com/r/deeplearning/comments/67gqmc/implementation_of_wasserstein_gan_in_torch/,fonfonx,1493129084,,0,5
60,2017-4-26,2017,4,26,0,67h48p,Automatically Detect Objects in Satellite Imagery using Deep Learning,https://www.reddit.com/r/deeplearning/comments/67h48p/automatically_detect_objects_in_satellite_imagery/,DGKevin,1493132788,,0,1
61,2017-4-26,2017,4,26,4,67iuo1,Build with AI - Use deep learning in your applications,https://www.reddit.com/r/deeplearning/comments/67iuo1/build_with_ai_use_deep_learning_in_your/,deepaihost,1493148351,,0,0
62,2017-4-26,2017,4,26,11,67l8nk,Photo Editing with Generative Adversarial Networks (Part 2),https://www.reddit.com/r/deeplearning/comments/67l8nk/photo_editing_with_generative_adversarial/,harrism,1493172830,,0,4
63,2017-4-26,2017,4,26,21,67ntsu,Creating Synthetic Clouds in Python,https://www.reddit.com/r/deeplearning/comments/67ntsu/creating_synthetic_clouds_in_python/,geodawg,1493210135,,0,2
64,2017-4-27,2017,4,27,1,67p8pl,VAE_DCGAN implemented in pytorch,https://www.reddit.com/r/deeplearning/comments/67p8pl/vae_dcgan_implemented_in_pytorch/,seangal2,1493223979,,0,2
65,2017-4-27,2017,4,27,2,67phv8,Writing Travel Blog Posts with Deep Learning,https://www.reddit.com/r/deeplearning/comments/67phv8/writing_travel_blog_posts_with_deep_learning/,goncalogordo,1493226274,,0,1
66,2017-4-27,2017,4,27,5,67r0xw,Deep learning for time series made easy: Dafne van Kuppevelt,https://www.reddit.com/r/deeplearning/comments/67r0xw/deep_learning_for_time_series_made_easy_dafne_van/,Mussem17,1493240393,,0,3
67,2017-4-27,2017,4,27,6,67r14x,"Deep Learning at Booking.com: Emrah Tasli, Stas Girkin",https://www.reddit.com/r/deeplearning/comments/67r14x/deep_learning_at_bookingcom_emrah_tasli_stas/,Mussem17,1493240440,,0,3
68,2017-4-27,2017,4,27,20,67v3ph,Read to know why do we need the Democratization of Machine Learning?,https://www.reddit.com/r/deeplearning/comments/67v3ph/read_to_know_why_do_we_need_the_democratization/,kailashahirwar12,1493294099,,1,1
69,2017-4-27,2017,4,27,21,67vbnn,Scripts to install and setup Tensorflow and it's dependencies on Ubuntu.,https://www.reddit.com/r/deeplearning/comments/67vbnn/scripts_to_install_and_setup_tensorflow_and_its/,kailashahirwar12,1493296767,,0,1
70,2017-4-28,2017,4,28,3,67xmry,Data Science - Deep Learning in Python,https://www.reddit.com/r/deeplearning/comments/67xmry/data_science_deep_learning_in_python/,vasira,1493318450,,0,0
71,2017-4-28,2017,4,28,6,67yt4g,Is anyone making money by using deep learning in trading?,https://www.reddit.com/r/deeplearning/comments/67yt4g/is_anyone_making_money_by_using_deep_learning_in/,MaverickSoulprorer,1493329367,,1,5
72,2017-4-28,2017,4,28,13,680xwp,"Eldritch by Omni Dragon Development, Inc.",https://www.reddit.com/r/deeplearning/comments/680xwp/eldritch_by_omni_dragon_development_inc/,OmniDragonDevelopmen,1493353685,,0,1
73,2017-4-28,2017,4,28,17,681cku,Best hardware for Deep Learning with 2000$ USD as budget,https://www.reddit.com/r/deeplearning/comments/681cku/best_hardware_for_deep_learning_with_2000_usd_as/,Driiper,1493367456,"As the title says, anyone have tweaks on my current setup for Deep Learning?
There might also be some CPU intensive calculations like tree-search but GPU is main focus
#------------------------------------------------------------------------
Mainboard: ZOTAC GeForce GTX 1080 Ti AMP Extreme

Memory: Crucial Ballistix Sport DDR4 32GB RED

HDD: Samsung 960 EVO 250GB M.2 PCIe SSD

PSU: EVGA GQ 1000W Hybrid Modular 80+ PSU

CPU: Intel Core i7-7700K Kaby Lake Prosessor

MOBO: MSI X99A RAIDER, Socket-2011-3
#------------------------------------------------------------------------


This hardware is primarily for development so it is fine that its consumer hardware.
Is there any considerations which can improve this setup?",7,3
74,2017-4-28,2017,4,28,22,682rs6,Run Object Detection using Deep Learning on Raspberry Pi 3 - II,https://www.reddit.com/r/deeplearning/comments/682rs6/run_object_detection_using_deep_learning_on/,kailashahirwar12,1493387746,,2,6
75,2017-4-29,2017,4,29,2,6840wp,Deep Learning Cheat Sheet (using Python Libraries),https://www.reddit.com/r/deeplearning/comments/6840wp/deep_learning_cheat_sheet_using_python_libraries/,psangrene,1493399900,,1,5
76,2017-4-29,2017,4,29,21,6891xf,Using Deep Learning and Machine Learning in emotion detection technology,https://www.reddit.com/r/deeplearning/comments/6891xf/using_deep_learning_and_machine_learning_in/,parth10,1493468160,,0,1
77,2017-4-29,2017,4,29,22,689fqh,The Modern History of Object Recognition  Infographic,https://www.reddit.com/r/deeplearning/comments/689fqh/the_modern_history_of_object_recognition/,Nikasa1889,1493474022,,0,3
78,2017-4-30,2017,4,30,7,68c3dp,Separating Overlapping Chromosomes with Deep Learning,https://www.reddit.com/r/deeplearning/comments/68c3dp/separating_overlapping_chromosomes_with_deep/,mwakanosya,1493504583,,1,1
79,2017-4-30,2017,4,30,8,68ch80,How to use Magenta and Tensorflow to generate music in a free Google Cloud instance,https://www.reddit.com/r/deeplearning/comments/68ch80/how_to_use_magenta_and_tensorflow_to_generate/,tftutorial,1493509307,,1,2
80,2017-4-30,2017,4,30,9,68cu2s,Top 9 Deep Learning and Neural Networks Books,https://www.reddit.com/r/deeplearning/comments/68cu2s/top_9_deep_learning_and_neural_networks_books/,kjahan,1493513817,,0,1
