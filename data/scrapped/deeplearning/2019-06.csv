,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,deeplearning,t5_2t5eh,2019-6-1,2019,6,1,9,bvf530,self.deeplearning,"Hello! I am Mauricio Costa, and I am gathering some feedback on the second episode of my small show where I create software from famous series and movies!",https://www.reddit.com/r/deeplearning/comments/bvf530/hello_i_am_mauricio_costa_and_i_am_gathering_some/,mauricecost,1559349929," I have recently joined Reddit, and its been an awesome experience to get feedback and constructive criticism from a lot of people! Loved it :) (I applied a lot of the feedback I got from the first episode on this new one)

Having said that, I have just started a small show on Youtube where I recreate software and applications that are used in movies and films that contribute to the comedy of these TV shows.

I have just posted the second episode, where I recreate Dwight Schrutes doomsday device from The Office!

Would you mind giving your feedback?

You can check it out here: https://youtu.be/WxkZMDmDQcs

Ask me anything :D",1,3,False,self,,,,,
1,deeplearning,t5_2t5eh,2019-6-1,2019,6,1,11,bvfujo,self.deeplearning,How can I automate event detection in a short video?,https://www.reddit.com/r/deeplearning/comments/bvfujo/how_can_i_automate_event_detection_in_a_short/,Brokoba,1559354672,"At my workplace, we have a video system set up to capture certain remote events that occur, which we can analyze later on. The only problem is that we have to manually tag the starting and ending points of each event within the video.

For example, a video might last for 12 seconds, with the actual event occurring from seconds 4-9. In the next video, though, the event might occur from seconds 3-7, or 3.5-8.5. As it currently stands, we have to manually monitor the video and click ""start"" and ""end"" buttons to denominate the actual event marks. All events look roughly similar to the naked eye.

This feels like a great opportunity for automation (potentially with some sort of CNN?), but I'm not totally sure how, or even what sort of framework would work for this sort of problem.

Any and all help would be appreciated. Thanks!!",3,5,False,self,,,,,
2,deeplearning,t5_2t5eh,2019-6-1,2019,6,1,16,bviaoq,self.deeplearning,how i can download transcript talks at google youtube channel https://www.youtube.com/watch?v=ByvPp5xGL1I,https://www.reddit.com/r/deeplearning/comments/bviaoq/how_i_can_download_transcript_talks_at_google/,Doctor_who1,1559374041,"how i can download transcript talks at google youtube channel

&amp;#x200B;

 [https://www.youtube.com/watch?v=ByvPp5xGL1I](https://www.youtube.com/watch?v=ByvPp5xGL1I)",0,3,False,self,,,,,
3,deeplearning,t5_2t5eh,2019-6-1,2019,6,1,17,bviok7,i.redd.it,[AI application] Let your machine play Super Mario Bros!,https://www.reddit.com/r/deeplearning/comments/bviok7/ai_application_let_your_machine_play_super_mario/,1991viet,1559377775,,9,67,False,image,,,,,
4,deeplearning,t5_2t5eh,2019-6-2,2019,6,2,2,bvn5y5,self.deeplearning,Artificial Intelligence A-Z: Learn How To Build An AI,https://www.reddit.com/r/deeplearning/comments/bvn5y5/artificial_intelligence_az_learn_how_to_build_an/,HannahHumphreys,1559409523,[removed],0,1,False,self,,,,,
5,deeplearning,t5_2t5eh,2019-6-2,2019,6,2,2,bvnjs0,hubpages.com,My first ever article. Please have a look.,https://www.reddit.com/r/deeplearning/comments/bvnjs0/my_first_ever_article_please_have_a_look/,crazy_lazy_life,1559411722,,0,1,False,default,,,,,
6,deeplearning,t5_2t5eh,2019-6-2,2019,6,2,5,bvpa4l,self.deeplearning,Do you know about the startup called Babble Labs?,https://www.reddit.com/r/deeplearning/comments/bvpa4l/do_you_know_about_the_startup_called_babble_labs/,Gabyleon2019,1559421603,"&amp;#x200B;

The one that just got $14 million Series A Financing from Dell Technologies Capital and Intel Capital to Accelerate Speech Technology.

&amp;#x200B;

It is really cool what they're doing. You can check the info here:

&amp;#x200B;

[https://www.linkedin.com/feed/update/urn:li:activity:6540252895328247808](https://www.linkedin.com/feed/update/urn:li:activity:6540252895328247808)

&amp;#x200B;

\#DeepLearning #ArtificialIntelligence #MachineLearning",0,0,False,self,,,,,
7,deeplearning,t5_2t5eh,2019-6-2,2019,6,2,8,bvrbfw,mihaileric.com,Remember Recurrent Networks?,https://www.reddit.com/r/deeplearning/comments/bvrbfw/remember_recurrent_networks/,MusingEtMachina,1559433369,,2,5,False,default,,,,,
8,deeplearning,t5_2t5eh,2019-6-2,2019,6,2,12,bvt8ze,marktechpost.com,Do We Still Need Traditional Pattern Recognition and Signal Processing in the Age of Deep Learning?,https://www.reddit.com/r/deeplearning/comments/bvt8ze/do_we_still_need_traditional_pattern_recognition/,ai-lover,1559446148,,5,39,False,default,,,,,
9,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,0,bvycze,self.deeplearning,nn_builder - a new package that builds neural networks in 1 line,https://www.reddit.com/r/deeplearning/comments/bvycze/nn_builder_a_new_package_that_builds_neural/,__data_science__,1559488451,"nn\_builder is a new package that lets you build neural networks in 1 line using PyTorch or TensorFlow 2.0 that lots of you might find useful!

Let me know what you think and if you'd like to contribute[https://github.com/p-christ/nn\_builder](https://github.com/p-christ/nn_builder)

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/m7dd5z7bmy131.png",2,13,False,self,,,,,
10,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,4,bw137s,youtu.be,"Google struggles to transcribe the dialogs of Donald duck, to hilarious effect.",https://www.reddit.com/r/deeplearning/comments/bw137s/google_struggles_to_transcribe_the_dialogs_of/,Mr_IO,1559503155,,0,1,False,default,,,,,
11,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,5,bw1kyz,self.deeplearning,Google Cloud Platform is down,https://www.reddit.com/r/deeplearning/comments/bw1kyz/google_cloud_platform_is_down/,karlpoppery,1559505795,"https://status.cloud.google.com/incident/cloud-networking/19009

https://status.cloud.google.com/",2,20,False,self,,,,,
12,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,5,bw1ucs,i.redd.it,YouTube AI struggles to transcribe Donald duck https://youtu.be/U_ZHsk0-eF0,https://www.reddit.com/r/deeplearning/comments/bw1ucs/youtube_ai_struggles_to_transcribe_donald_duck/,Mr_IO,1559507184,,2,2,False,image,,,,,
13,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,10,bw4t0q,youtube.com,Donald Trump AI Tries To Imitate Humans,https://www.reddit.com/r/deeplearning/comments/bw4t0q/donald_trump_ai_tries_to_imitate_humans/,hanyuqn,1559524448,,0,3,False,image,,,,,
14,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,13,bw6sfk,self.deeplearning,Managing DL experiments,https://www.reddit.com/r/deeplearning/comments/bw6sfk/managing_dl_experiments/,guzguzit,1559537527,"Are there any recommended ways  to easily manage and track DL experiments? (Parameters tuning, different models)

Thanks",3,1,False,self,,,,,
15,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,14,bw72n5,self.deeplearning,Modeling for custom size images,https://www.reddit.com/r/deeplearning/comments/bw72n5/modeling_for_custom_size_images/,roban-12,1559539714,"I have a model which accepts 100\*100 size images and works perfectly when the test image is of the same size too. 

\[Question 1\] Why does the image not work properly when custom size images are given?

\[Question 2\] I want to train the model on custom size imagery. Any kind of suggestions and techniques would be of great help.

I need this urgently, please help!",3,1,False,self,,,,,
16,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,14,bw74nd,self.deeplearning,CS 294-112. Deep Reinforcement Learning by Sergey Levine. UC Berkeley. Fall 2018,https://www.reddit.com/r/deeplearning/comments/bw74nd/cs_294112_deep_reinforcement_learning_by_sergey/,ai-lover,1559540132,"**Video Lectures:** https://www.youtube.com/playlist?list=PLkFD6\_40KJIxJMR-j5A1mkxK26gh\_qg37

**Lecture Slides:** http://rail.eecs.berkeley.edu/deeprlcourse/ 

&amp;#x200B;

https://i.redd.it/njnwdbkxv2231.png",1,54,False,self,,,,,
17,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,15,bw7hsf,self.deeplearning,Advanced Machine Learning,https://www.reddit.com/r/deeplearning/comments/bw7hsf/advanced_machine_learning/,HannahHumphreys,1559543080,[removed],0,1,False,self,,,,,
18,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,15,bw7ntg,self.deeplearning,Deploying large DL models,https://www.reddit.com/r/deeplearning/comments/bw7ntg/deploying_large_dl_models/,guzguzit,1559544501,"Is there a way to deploy large DL models (&gt;1 GB) in a serverless fashion?

I couldent find any relevant  examples",4,0,False,self,,,,,
19,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,17,bw8f5a,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/bw8f5a/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1559551479,[removed],0,1,False,self,,,,,
20,deeplearning,t5_2t5eh,2019-6-3,2019,6,3,20,bw9pyc,self.deeplearning,HELP! Deep learning API,https://www.reddit.com/r/deeplearning/comments/bw9pyc/help_deep_learning_api/,defudger,1559562309,Hey! We are about to deploy a deep learning API and would need some help from someone with experience. Please send me a message if you have already done something similar so we can work out a deal! Thanks,2,0,False,self,,,,,
21,deeplearning,t5_2t5eh,2019-6-4,2019,6,4,1,bwceks,self.deeplearning,[Research] Improving Accuracy and Efficiency through AutoML and Model Scaling,https://www.reddit.com/r/deeplearning/comments/bwceks/research_improving_accuracy_and_efficiency/,cdossman,1559578039," [https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-google-ai-on-how-to-scale-up-cnn-to-obtain-better-accuracy-and-efficiency-2cc149cc47b1](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-google-ai-on-how-to-scale-up-cnn-to-obtain-better-accuracy-and-efficiency-2cc149cc47b1) 

 Google AI finds a principled method to scale up a CNN to obtain better accuracy and efficiency",0,1,False,self,,,,,
22,deeplearning,t5_2t5eh,2019-6-4,2019,6,4,2,bwd2r1,lavanya.ai,Searching for dark matter in CERN's Large Hadron Collider dataset,https://www.reddit.com/r/deeplearning/comments/bwd2r1/searching_for_dark_matter_in_cerns_large_hadron/,0_marauders_0,1559581421,,0,20,False,default,,,,,
23,deeplearning,t5_2t5eh,2019-6-4,2019,6,4,2,bwdkd8,medium.com,Serverless inference,https://www.reddit.com/r/deeplearning/comments/bwdkd8/serverless_inference/,gautkr91,1559583928,,0,0,False,default,,,,,
24,deeplearning,t5_2t5eh,2019-6-4,2019,6,4,3,bwdwva,i.redd.it,PyTorch for Beginners Series,https://www.reddit.com/r/deeplearning/comments/bwdwva/pytorch_for_beginners_series/,spmallick,1559585613,,1,5,False,image,,,,,
25,deeplearning,t5_2t5eh,2019-6-4,2019,6,4,8,bwhddq,youtube.com,How does YouTube recommend videos? - AI EXPLAINED!,https://www.reddit.com/r/deeplearning/comments/bwhddq/how_does_youtube_recommend_videos_ai_explained/,ajhalthor,1559603034,,0,2,False,image,,,,,
26,deeplearning,t5_2t5eh,2019-6-4,2019,6,4,15,bwlpwo,youtube.com,Deep Learning In 5 Minutes | What Is Deep Learning? | Deep Learning Explained Simply,https://www.reddit.com/r/deeplearning/comments/bwlpwo/deep_learning_in_5_minutes_what_is_deep_learning/,MainBuilder,1559631407,,0,1,False,default,,,,,
27,deeplearning,t5_2t5eh,2019-6-4,2019,6,4,17,bwmbsy,medium.com,Using reinforcement learning to trade Bitcoin for massive profit,https://www.reddit.com/r/deeplearning/comments/bwmbsy/using_reinforcement_learning_to_trade_bitcoin_for/,notadamking,1559636862,,37,4,False,default,,,,,
28,deeplearning,t5_2t5eh,2019-6-4,2019,6,4,17,bwmho0,self.deeplearning,Python or Octave?,https://www.reddit.com/r/deeplearning/comments/bwmho0/python_or_octave/,hariprasath891996,1559638452,"Hey guys, I'm a beginner with no coding experience. I took an introductory course on python from codecademy. I'm currently working on the Machine learning course by Andrew Ng, he recommends using Matlab or Octave. Should I really go for Octave or try to convert the code to python. I'll be moving on from machine learning to deep learning soon after a few hands-on projects. What do you recommend?",18,3,False,self,,,,,
29,deeplearning,t5_2t5eh,2019-6-4,2019,6,4,18,bwmq36,morioh.com,Deploying a Keras Deep Learning Model as a Web Application in Python,https://www.reddit.com/r/deeplearning/comments/bwmq36/deploying_a_keras_deep_learning_model_as_a_web/,ObsidianAge,1559640572,,0,4,False,default,,,,,
30,deeplearning,t5_2t5eh,2019-6-4,2019,6,4,18,bwms9n,self.learnmachinelearning,Fairseq on custom dataset,https://www.reddit.com/r/deeplearning/comments/bwms9n/fairseq_on_custom_dataset/,aryancodify,1559641101,,0,2,False,default,,,,,
31,deeplearning,t5_2t5eh,2019-6-4,2019,6,4,22,bwogd7,muens.co,The intuition behind Word2Vec,https://www.reddit.com/r/deeplearning/comments/bwogd7/the_intuition_behind_word2vec/,pmuens,1559653439,,0,1,False,default,,,,,
32,deeplearning,t5_2t5eh,2019-6-5,2019,6,5,1,bwqyiq,self.deeplearning,[Research]Towards robust audio spoofing detection,https://www.reddit.com/r/deeplearning/comments/bwqyiq/researchtowards_robust_audio_spoofing_detection/,cdossman,1559666922," [https://medium.com/ai%C2%B3-theory-practice-business/achieving-robust-audio-spoofing-detection-b7ebcf0979c6](https://medium.com/ai%C2%B3-theory-practice-business/achieving-robust-audio-spoofing-detection-b7ebcf0979c6) 

Abstract:  Automatic speaker verification, like every other biometric system, is vulnerable to spoofing attacks. Using only a few minutes of recorded voice of a genuine client of a speaker verification system, attackers can develop a variety of spoofing attacks that might trick such systems. Detecting these attacks using the audio cues present in the recordings is an important challenge. Most existing spoofing detection systems depend on knowing the used spoofing technique. With this research, we aim at overcoming this limitation, by examining robust audio features, both traditional and those learned through an autoencoder, that are generalizable over different types of replay spoofing.",0,1,False,self,,,,,
33,deeplearning,t5_2t5eh,2019-6-5,2019,6,5,2,bwrf5v,springboard.com,25 Websites to Find Data Science Jobs,https://www.reddit.com/r/deeplearning/comments/bwrf5v/25_websites_to_find_data_science_jobs/,ai_jobs,1559669273,,1,27,False,default,,,,,
34,deeplearning,t5_2t5eh,2019-6-5,2019,6,5,3,bws13a,self.deeplearning,CVPR 2019 Noise-Tolerant Training work `Learning to Learn from Noisy Labeled Data 'https://arxiv.org/pdf/1812.05214.pdf,https://www.reddit.com/r/deeplearning/comments/bws13a/cvpr_2019_noisetolerant_training_work_learning_to/,XinshaoWang,1559672298,"This work achieves promising results with meta-learning. Our result on Clothing 1M is comparable with theirs. [https://www.researchgate.net/publication/333418661\_Emphasis\_Regularisation\_by\_Gradient\_Rescaling\_for\_Training\_Deep\_Neural\_Networks\_with\_Noisy\_Labels/comments](https://www.researchgate.net/publication/333418661_Emphasis_Regularisation_by_Gradient_Rescaling_for_Training_Deep_Neural_Networks_with_Noisy_Labels/comments)

However, their modelling via meta-learning seems extremely complex in practice.

1. Too many hyper-parameters shown in their Algorithm 1 and implementation section 4.2:
2. The number of synthetic mini-batches (meta-training iterations) M;
3. Meta-training step size \\alpha;
4. Meta-learning rate \\eta;
5. Student learning rate \\beta;
6. Exponential moving average (EMA) decay \\gamma;
7. The threshold for data filtering \\tau;
8. The number of samples with label replacement, \\rho;
9. The strategies of iterative training together with iterative data filtering/cleaning, reusing last-round best model as mentor, etc., make it difficult to handle in practice.
10. However, the ideas are interesting and novel:
11. Oracle/Mentor (Consistency loss): To make meta-test reliable, the teacher/mentor model should be reliable and robust to real noisy examples. Therefore, they apply iterative training and iterative data cleaning to make the meta-test consistency loss reliable and an optimisation oracle against real noise.
12. Unaffected by synthetic noise: The meta-training sees synthetic noisy training examples. After training on them, the meta-testing evaluates its consistency with oracle and aims to maximise the consistency, i.e., making it unaffected after seeing synthetic noise.

Quetions arise:

Is meta-learning really a good solution in practice with such many configurations?

Or could we simplfiy its modelling to make it easier in practice?",1,1,False,self,,,,,
35,deeplearning,t5_2t5eh,2019-6-5,2019,6,5,3,bws3te,medium.com,CapsAttacks: Testing Adversarial Attacks on Capsule Networks,https://www.reddit.com/r/deeplearning/comments/bws3te/capsattacks_testing_adversarial_attacks_on/,Yuqing7,1559672684,,0,0,False,default,,,,,
36,deeplearning,t5_2t5eh,2019-6-5,2019,6,5,3,bws7r0,towardsdatascience.com,SELU - The best activation function,https://www.reddit.com/r/deeplearning/comments/bws7r0/selu_the_best_activation_function/,ToolTechSoftware,1559673213,,5,9,False,default,,,,,
37,deeplearning,t5_2t5eh,2019-6-5,2019,6,5,10,bwx1zr,youtube.com,Revolutionizing Medical Diagnosis with Deep Learning: TED Talk,https://www.reddit.com/r/deeplearning/comments/bwx1zr/revolutionizing_medical_diagnosis_with_deep/,DiscoverAI,1559699204,,1,14,False,image,,,,,
38,deeplearning,t5_2t5eh,2019-6-5,2019,6,5,15,bwzeqg,self.deeplearning,Machine Learning Yearning Draft by Andrew Ng [Download Link],https://www.reddit.com/r/deeplearning/comments/bwzeqg/machine_learning_yearning_draft_by_andrew_ng/,ai-lover,1559715825,"&amp;#x200B;

**Download Link :** https://media.licdn.com/dms/document/C511FAQEU5l\_Z5LYcqA/feedshare-document-pdf-analyzed/0?e=1559797200&amp;v=beta&amp;t=9Nz4PucJiq135Q6Vk-LzSKrgZ4isDHoxJXDHbXP80zI

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/az3jzqsbeh231.png",0,20,False,self,,,,,
39,deeplearning,t5_2t5eh,2019-6-5,2019,6,5,20,bx1hdf,self.deeplearning,"Efficient Net, GPipe or Amoeba Net implementation for Caffe?",https://www.reddit.com/r/deeplearning/comments/bx1hdf/efficient_net_gpipe_or_amoeba_net_implementation/,adriacabeza,1559734105,"Hi, I usually work with Caffe but with pretty common architectures like Resnet50, however the DL game has changed a lot, and I was wondering if there is any version of these classifications state-of-the-art architecture implemented in Caffe. 

&amp;#x200B;

I have been looking for them and I have not found anything.",0,0,False,self,,,,,
40,deeplearning,t5_2t5eh,2019-6-5,2019,6,5,21,bx1ya5,self.deeplearning,Machine Learning and Reinforcement Learning in Finance,https://www.reddit.com/r/deeplearning/comments/bx1ya5/machine_learning_and_reinforcement_learning_in/,HannahHumphreys,1559737501,[removed],0,1,False,self,,,,,
41,deeplearning,t5_2t5eh,2019-6-5,2019,6,5,22,bx2avr,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/bx2avr/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1559739741,[removed],0,1,False,self,,,,,
42,deeplearning,t5_2t5eh,2019-6-5,2019,6,5,23,bx3i12,self.deeplearning,[Research] Object Discovery with a Copy-Pasting GAN,https://www.reddit.com/r/deeplearning/comments/bx3i12/research_object_discovery_with_a_copypasting_gan/,cdossman,1559746612," [https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-gans-for-object-discovery-d707437ac6c8](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-gans-for-object-discovery-d707437ac6c8) 

**Abstract:** We tackle the problem of object discovery, where objects are segmented for a given input image, and the system is trained without using any direct supervision whatsoever. A novel copy-pasting GAN framework is proposed, where the generator learns to discover an object in one image by compositing it into another image such that the discriminator cannot tell that the resulting image is fake. After carefully addressing subtle issues, such as preventing the generator from cheating, this game results in the generator learning to select objects, as copy-pasting objects is most likely to fool the discriminator. The system is shown to work well on four very different datasets, including large object appearance variations in challenging cluttered backgrounds.",0,9,False,self,,,,,
43,deeplearning,t5_2t5eh,2019-6-6,2019,6,6,0,bx3zuv,self.deeplearning,Text generation dataset size,https://www.reddit.com/r/deeplearning/comments/bx3zuv/text_generation_dataset_size/,glowycosmos,1559749211,"Hi,

I was wondering how large the size of your training set should be in terms of MB's/GB's when the aim is to build an RNN that can generate semantically and syntactically (more or less) coherent sentences. I saw that OpenAI uses 40 GB of text. Does anyone know of a source which will give me an indiciation of much text is needed?

Much appreciated!",0,1,False,self,,,,,
44,deeplearning,t5_2t5eh,2019-6-6,2019,6,6,2,bx5c2r,i.redd.it,PyTorch for Beginners: Semantic Segmentation using torchvision,https://www.reddit.com/r/deeplearning/comments/bx5c2r/pytorch_for_beginners_semantic_segmentation_using/,spmallick,1559755959,,2,69,False,image,,,,,
45,deeplearning,t5_2t5eh,2019-6-6,2019,6,6,11,bxbdpt,self.deeplearning,AlexNet and VGG-16 on CIFAR-10,https://www.reddit.com/r/deeplearning/comments/bxbdpt/alexnet_and_vgg16_on_cifar10/,BubblyResponsibility,1559788389,"I'm in the process of building an AlexNet architecture and VGG-16 architecture on the CIFAR-10 dataset. Since the dimensions of the CIFAR-10 dataset is different from ImageNet, I keep getting the following error:

**RuntimeError: Given groups=1, weight of size \[64, 64, 3, 3\], expected input\[6, 3, 32, 32\] to have 64 channels, but got 3 channels instead**

&amp;#x200B;

Any help would be appreciated.",1,1,False,self,,,,,
46,deeplearning,t5_2t5eh,2019-6-6,2019,6,6,11,bxbfez,self.deeplearning,Best one shot object detector for small rogue like video game Image with &gt;150 classes?,https://www.reddit.com/r/deeplearning/comments/bxbfez/best_one_shot_object_detector_for_small_rogue/,podcast_frog3817,1559788681,"Im deciding between retina net and yolov3.   The target image is a rogue like overview 400pxX400px with small sprite characters moving through dungeon (150+ types) each about 32x32px. Ive read retina net has an advantage using focal loss for imbalance between background and foreground wrt objects of interest . Is this useless for this problem? Should I go with yolov3? I am prioritizing speed over accuracy (hence single shot object detection)

Thanks",0,1,False,self,,,,,
47,deeplearning,t5_2t5eh,2019-6-6,2019,6,6,12,bxbypj,stats.stackexchange.com,Why do attention models need to choose a maximum sentence length?,https://www.reddit.com/r/deeplearning/comments/bxbypj/why_do_attention_models_need_to_choose_a_maximum/,real_pinocchio,1559792136,,1,2,False,default,,,,,
48,deeplearning,t5_2t5eh,2019-6-6,2019,6,6,15,bxd7bl,self.deeplearning,Converting INT64 to Float32/16 Tensor (ONNX),https://www.reddit.com/r/deeplearning/comments/bxd7bl/converting_int64_to_float3216_tensor_onnx/,iamalex_,1559800886,"So I'm trying to load a certain ONNX model in OpenCV (other models work fine), but with this one it crashes, when using the ONNX float32 &lt;-&gt; float16 conversion it also gives me an error while the one that is able to load in OpenCV doesn't give any error.

&amp;#x200B;

It also gives this error when I try to convert that ONNX model to Tensorflow:  

    ValueError: Tensor conversion requested dtype float32 for Tensor with dtype int64: 'Tensor(""Mul_3:0"", shape=(), dtype=int64)'

I suppose this is why it isn't working in OpenCV, is there any way to cast the int64 Tensor to a float32 one? I can try to modify the float32 &lt;-&gt; float16 conversion function so that it can also convert int64 to float16, but think this could be quite complex.

&amp;#x200B;

Any tips or advice to help me get on the way of solving this problem and/or casting it from int64 to float32 would be greatly appreciated!!",0,0,False,self,,,,,
49,deeplearning,t5_2t5eh,2019-6-6,2019,6,6,15,bxdeye,self.deeplearning,localize sound source in visual scenes,https://www.reddit.com/r/deeplearning/comments/bxdeye/localize_sound_source_in_visual_scenes/,kzhang3256,1559802514,"We are looking for a pre-trained model to generate sound source heat map from a video. More specifically, input: video + audio, output: a heatmap showing which part of video generates this audio (i.e. engine of a car)

&amp;#x200B;

Anyone knows paper that has public code for this purpose?

Thanks!",0,2,False,self,,,,,
50,deeplearning,t5_2t5eh,2019-6-7,2019,6,7,0,bxhy35,self.deeplearning,Maths behind training of RNN Networks,https://www.reddit.com/r/deeplearning/comments/bxhy35/maths_behind_training_of_rnn_networks/,prakhar21,1559834468,"Checkout my latest read on [https://prakhartechviz.blogspot.com/2019/04/training-recurrent-neural-networks.html](https://prakhartechviz.blogspot.com/2019/04/training-recurrent-neural-networks.html)

Feel free to share your thoughts.",1,0,False,self,,,,,
51,deeplearning,t5_2t5eh,2019-6-7,2019,6,7,0,bxibts,opencodez.com,A Quick Easy Guide to Deep Learning with Java  Deeplearaning4j / DL4J,https://www.reddit.com/r/deeplearning/comments/bxibts/a_quick_easy_guide_to_deep_learning_with_java/,Shilpa_Opencodez,1559836451,,0,1,False,default,,,,,
52,deeplearning,t5_2t5eh,2019-6-7,2019,6,7,1,bxin2b,twitter.com,Deep Learning Prerequisites: The Numpy Stack in Python,https://www.reddit.com/r/deeplearning/comments/bxin2b/deep_learning_prerequisites_the_numpy_stack_in/,NicholasTower,1559838048,,7,18,False,default,,,,,
53,deeplearning,t5_2t5eh,2019-6-7,2019,6,7,2,bxjoqv,80000hours.org,"DeepMind's plan to make AI systems robust, why it's a core design issue, and how to succeed in ML",https://www.reddit.com/r/deeplearning/comments/bxjoqv/deepminds_plan_to_make_ai_systems_robust_why_its/,robwiblin,1559843342,,0,9,False,default,,,,,
54,deeplearning,t5_2t5eh,2019-6-7,2019,6,7,14,bxr1e0,self.deeplearning,Stanford Image-Paragraph-Captioning Dataset Confusion,https://www.reddit.com/r/deeplearning/comments/bxr1e0/stanford_imageparagraphcaptioning_dataset/,arjundupa,1559886165,"I am working with the Stanford Image-Paragraph-Captioning Dataset: [https://cs.stanford.edu/people/ranjaykrishna/im2p/index.html](https://cs.stanford.edu/people/ranjaykrishna/im2p/index.html)

I wanted to see how many image-caption pairs the data set had, so I downloaded the dataset (which downloads paragraphs\_v1.json) and wrote the following code:

    import json
    with open('Desktop/paragraphs_v1.json') as json_file:  
        data = json.load(json_file)
    print(len(data))

**19561** was the output.

Just for a sanity check, I then downloaded the training, val and test splits and tried to see if their total sum would give me the same number:

    with open('Desktop/train_split.json') as train_split:  
        train_split_data = json.load(train_split)
    with open('Desktop/val_split.json') as val_split:  
        val_split_data = json.load(val_split)
    with open('Desktop/test_split.json') as test_split:  
        test_split_data = json.load(test_split)
    print(len(train_split_data) + len(val_split_data) + len(test_split_data))

**19551** was the output.

Exactly 10 short of what I expected. I have no idea why this simple sanity check isn't working -- any ideas?",1,10,False,self,,,,,
55,deeplearning,t5_2t5eh,2019-6-7,2019,6,7,17,bxrym4,self.deeplearning,Deep Learning Training Institute In India,https://www.reddit.com/r/deeplearning/comments/bxrym4/deep_learning_training_institute_in_india/,SunilAhujaa,1559894850,Analytixlabs offers Deep learning training course with live project by industry expert. This Deep learning course offers practical and task-oriented training using TensorFlow and Keras on Python platform. For more visit here [https://www.analytixlabs.co.in/ai-deep-learning-training-with-python](https://www.analytixlabs.co.in/ai-deep-learning-training-with-python),0,0,False,self,,,,,
56,deeplearning,t5_2t5eh,2019-6-7,2019,6,7,20,bxtqfk,aiprobook.com,[Book WIP] Deep Learning for Programmers New Release 0.3.0,https://www.reddit.com/r/deeplearning/comments/bxtqfk/book_wip_deep_learning_for_programmers_new/,dragandj,1559908620,,2,1,False,default,,,,,
57,deeplearning,t5_2t5eh,2019-6-8,2019,6,8,0,bxvuqj,self.deeplearning,Project to fact check and simplify assertions. Opinions?,https://www.reddit.com/r/deeplearning/comments/bxvuqj/project_to_fact_check_and_simplify_assertions/,atticusfinch975,1559920884,"In my work I often have to research different topics and understand something. Often this is a question or a single term I need to understand. Currently, I find I waste a lot if time:

&amp;#x200B;

* Finding the information
   * Wiki
   * Forums
   * Papers
* Checking the veracity of the information
* Simplifying it down so I can understand it
* Simplify the language

&amp;#x200B;

I feel there should be something out there beyond google search and fact checkers. None seem to",0,4,False,self,,,,,
58,deeplearning,t5_2t5eh,2019-6-8,2019,6,8,1,bxwtij,self.deeplearning,"[Research] Moving Camera, Moving People: A Deep Learning Approach to Depth Prediction",https://www.reddit.com/r/deeplearning/comments/bxwtij/research_moving_camera_moving_people_a_deep/,cdossman,1559925892, [https://medium.com/ai%C2%B3-theory-practice-business/google-ai-how-to-effectively-design-and-implement-simultaneous-motions-in-camera-and-human-3901f0af957](https://medium.com/ai%C2%B3-theory-practice-business/google-ai-how-to-effectively-design-and-implement-simultaneous-motions-in-camera-and-human-3901f0af957),0,1,False,self,,,,,
59,deeplearning,t5_2t5eh,2019-6-8,2019,6,8,2,bxx1wg,youtube.com,[R] Stanford AI system can change what people said.,https://www.reddit.com/r/deeplearning/comments/bxx1wg/r_stanford_ai_system_can_change_what_people_said/,NicoleK1993,1559927077,,7,84,False,image,,,,,
60,deeplearning,t5_2t5eh,2019-6-8,2019,6,8,7,by0qg1,self.deeplearning,What kind of questions should I expect from a Deep learning internship interview,https://www.reddit.com/r/deeplearning/comments/by0qg1/what_kind_of_questions_should_i_expect_from_a/,zeroeagle1,1559946418,,0,5,False,self,,,,,
61,deeplearning,t5_2t5eh,2019-6-8,2019,6,8,22,by7v0b,self.deeplearning,Neural Nets with Haskell,https://www.reddit.com/r/deeplearning/comments/by7v0b/neural_nets_with_haskell/,cvantass,1559999705,"Has anyone here ever built a neural net in Haskell? If so, why did you choose Haskell? What were some advantages/disadvantages? 

I ask because the people I really want to work for use Haskell as their language of choice to build some pretty powerful RNNs, and right now all of my projects are in Python/Tensorflow/Keras, and if I want to get in with these guys I gotta translate them to Haskell. Any hints or tips are welcome, but im mostly just wondering why one would choose to use a functional programming language for something like that.",2,1,False,self,,,,,
62,deeplearning,t5_2t5eh,2019-6-9,2019,6,9,2,byakh5,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/byakh5/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1560016201,[removed],0,1,False,self,,,,,
63,deeplearning,t5_2t5eh,2019-6-9,2019,6,9,4,bybb2a,leonhillmann.github.io,Interesting AI research that requires little compute,https://www.reddit.com/r/deeplearning/comments/bybb2a/interesting_ai_research_that_requires_little/,LeonDeHill,1560020454,,0,16,False,default,,,,,
64,deeplearning,t5_2t5eh,2019-6-9,2019,6,9,8,bye9a8,self.deeplearning,"Finally did it! Hey everyone! My name is Maurice, new to reddit, and I currently gather feedback here on reddit about the software and applications that I create inspired in movies and TV shows :)",https://www.reddit.com/r/deeplearning/comments/bye9a8/finally_did_it_hey_everyone_my_name_is_maurice/,mauricecost,1560038371,"I started learning face recognition and the OpenCV library for Python a few weeks ago, and it has been an amazing journey! 

BTW, If you do not know me yet, my name is Maurice, and I started a small show on Youtube, where I recreate software and applications from movies and TV shows. 

I strongly believe that every victory should be celebrated, and a few days ago, I managed to wrap my head around some concepts of face recognition and computer vision, and implement it in Python. I feel really good, and I would like to share it with all of you! (Don't give up on your ideas, push through and you'll eventually make it).

It's been an awesome experience to get feedback and constructive criticism from a lot of people here on reddit. For the past a few days, I've been working on the third episode of this show, where I recreated the face recognition from CSI (Crime Scene Investigation).

PS: If you are interested in seeing what I did, it is right here: [https://youtu.be/eTvtUkce4IE](https://youtu.be/eTvtUkce4IE)

Ask me anything :D",2,3,False,self,,,,,
65,deeplearning,t5_2t5eh,2019-6-9,2019,6,9,9,byes9b,self.deeplearning,PyTorch Linear Layer 2D Input,https://www.reddit.com/r/deeplearning/comments/byes9b/pytorch_linear_layer_2d_input/,arjundupa,1560041761,"I am trying to use PyTorch's nn.Linear to convert a (batch\_size, 41, 2048) input into an output with shape (batch\_size, 2048):

    att_fc = nn.Linear((41, 2048), 2048)

But this gives me the following error:

    TypeError: 'tuple' object cannot be interpreted as an index

Does the linear layer accept only 1D inputs? How can I go about converting my input of shape (batch\_size, 41, 2048) into an output of shape (batch\_size, 2048) using a fully-connected layer?",1,1,False,self,,,,,
66,deeplearning,t5_2t5eh,2019-6-9,2019,6,9,10,byf5sp,self.deeplearning,PyTorch Model _forward() Parameters,https://www.reddit.com/r/deeplearning/comments/byf5sp/pytorch_model_forward_parameters/,arjundupa,1560044220,"The following is a collection of relevant parts of my code:

    def setup_vectorModel(opt):
        model = vectorModel(opt)
        return model
    
    class vectorModel(AttModel):
        def __init__(self, opt):
            super(vectorModel, self).__init__(opt)
            self.core = vectorCore(opt)
    
    class vectorCore(nn.Module):
        def __init__(self, opt, use_maxout=False):
            super(vectorCore, self).__init__()
            att_fc = nn.Linear(41, 1)
            output_fc = nn.Linear(2, 1)
            
        def forward(self, att_feats, fc_feats):
            att_feats_reshaped = self.att_fc(att_feats)
            concat = torch.cat((att_feats_reshaped, fc_feats), dim=0)
            output = self.output_fc(concat)
            return output
    
    vectorModel = models.setup_vectorModel(opt).cuda()
    dp_vectorModel = torch.nn.DataParallel(vectorModel)
    dp_vectorModel.train()
    
    semantic_features = dp_vectorModel(att_feats, fc_feats)

I get an error on the last line:

    File ""train.py"", line 168, in train
        semantic_features = dp_vectorModel(att_feats, fc_feats)
    File ""/home/arjun/anaconda3/envs/py27/lib/python2.7/site-packages/torch/nn/modules/module.py"", line 477, in __call__
        result = self.forward(*input, **kwargs)
    File ""/home/arjun/anaconda3/envs/py27/lib/python2.7/site-packages/torch/nn/parallel/data_parallel.py"", line 121, in forward
        return self.module(*inputs[0], **kwargs[0])
    File ""/home/arjun/anaconda3/envs/py27/lib/python2.7/site-packages/torch/nn/modules/module.py"", line 477, in __call__
        result = self.forward(*input, **kwargs)
    File ""/home/arjun/image-paragraph-captioning/models/CaptionModel.py"", line 31, in forward
        return getattr(self, '_'+mode)(*args, **kwargs)
    TypeError: _forward() takes at least 4 arguments (3 given)

Any ideas why my \_forward() function seems to require 4 arguments when it looks like it only requires 2? And why the error says 3 given when I only passed it 2 arguments (att\_feats, fc\_feats)?

Any ideas will be much appreciated, thanks!",2,0,False,self,,,,,
67,deeplearning,t5_2t5eh,2019-6-9,2019,6,9,16,byhqi7,self.deeplearning,How do I begin with hands-on coding with deep learning.?,https://www.reddit.com/r/deeplearning/comments/byhqi7/how_do_i_begin_with_handson_coding_with_deep/,thak123,1560064406,,9,9,False,self,,,,,
68,deeplearning,t5_2t5eh,2019-6-9,2019,6,9,18,byikfp,self.deeplearning,Hierarchical Softmax Project. Expert review?,https://www.reddit.com/r/deeplearning/comments/byikfp/hierarchical_softmax_project_expert_review/,ashwinkd,1560072821,"I finished my Hierarchical Softmax Project recently. You can read it here: [https://github.com/AshwinDeshpande96/Hierarchical-Softmax](https://github.com/AshwinDeshpande96/Hierarchical-Softmax)

I initially started with Next-Word Prediction Project: LSTM Sequential data prediction. This is where I noticed that the LSTM Network took a very long time to converge. I looked for solutions among which I found Hierarchical Softmax approach the most intriguing. After numerous research papers, post and videos, I was able to implement the network. And also got promising result. But I am concerned about its relevance today. Papers I found dated back to 2005 - (Morin &amp; Bengio) and 2008-(Mnih &amp; Hinton). I would like to know if this is important in today's community. If not please cite reason and possibly other important problems that need work.",0,1,False,self,,,,,
69,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,1,bylzzm,github.com,Wasserstein GAN in Swift for TensorFlow,https://www.reddit.com/r/deeplearning/comments/bylzzm/wasserstein_gan_in_swift_for_tensorflow/,rahulbhalley,1560097717,,0,14,False,default,,,,,
70,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,2,bymmhe,kaggle.com,How I made top 0.3% on Kaggle,https://www.reddit.com/r/deeplearning/comments/bymmhe/how_i_made_top_03_on_kaggle/,0_marauders_0,1560101118,,3,75,False,default,,,,,
71,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,2,bymqgj,reddit.com,Style transfer,https://www.reddit.com/r/deeplearning/comments/bymqgj/style_transfer/,FoCDoT,1560101700,,0,3,False,default,,,,,
72,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,3,byn98z,github.com,U-Net implementation in PyTorch for FLAIR abnormality segmentation in brain MRI,https://www.reddit.com/r/deeplearning/comments/byn98z/unet_implementation_in_pytorch_for_flair/,ketsok,1560104468,,0,2,False,default,,,,,
73,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,3,bynmsd,blockdelta.io,What Does the Future Hold For AI Salaries? - BlockDelta,https://www.reddit.com/r/deeplearning/comments/bynmsd/what_does_the_future_hold_for_ai_salaries/,BlockDelta,1560106469,,0,0,False,default,,,,,
74,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,5,byol4n,self.deeplearning,Train E-Net model on SUN-RGBD indoor dataset,https://www.reddit.com/r/deeplearning/comments/byol4n/train_enet_model_on_sunrgbd_indoor_dataset/,vldmr77,1560111553,"Hello,

I posted [this](https://www.reddit.com/r/computervision/comments/byocg2/train_enet_model_on_sunrgbd_indoor_dataset/) in r/computervision too, maybe I can get help here too. I'm trying to train an E-Net model on the [indoor dataset provided by SUN-RGBD](http://rgbd.cs.princeton.edu/), for my diploma project. However, having little to no experience on deep learning, I have trouble understand any tutorial provided on the web. Can anybody help me with a straight-forward one, or a pre-trained model, please?

What I found so far:

[https://github.com/TimoSaemann/ENet/tree/master/Tutorial](https://github.com/TimoSaemann/ENet/tree/master/Tutorial)

[https://github.com/e-lab/ENet-training/tree/master/train/data](https://github.com/e-lab/ENet-training/tree/master/train/data)

[https://github.com/ankurhanda/sunrgbd-meta-data](https://github.com/ankurhanda/sunrgbd-meta-data)

Also, the original article that teach how to do semantic segmentation on outdoor scenes, using a model trained with Cityscapes dataset, where I found the first tutorial:

[https://www.pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/](https://www.pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/)",0,1,False,self,,,,,
75,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,6,byp28v,self.deeplearning,Any hands on experience with the CM1K,https://www.reddit.com/r/deeplearning/comments/byp28v/any_hands_on_experience_with_the_cm1k/,Kainkelly2887,1560114055,"Does anyone have any hands on experience with the CM1K? I saw a indie gogo campaign and a blog post that didn't give me much information, looking to pair this with fpgas like in the indie gogo campaign. Just curious if anyone had more in depth or technical experience with this. Seems like a really odd piece of silicon.",0,1,False,self,,,,,
76,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,6,byp8wr,youtube.com,Backpropagation And Gradient Descent In Neural Networks - Tutorial,https://www.reddit.com/r/deeplearning/comments/byp8wr/backpropagation_and_gradient_descent_in_neural/,MainBuilder,1560115061,,0,1,False,default,,,,,
77,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,7,byq4ea,self.deeplearning,Is it worth picking up K80's @ $200,https://www.reddit.com/r/deeplearning/comments/byq4ea/is_it_worth_picking_up_k80s_200/,dsync1,1560119911,"I can get a lot of 12 Nvida K80's pulled from off-lease equipment at $200/pop. I've only ever worked with consumer-level cards, and am stepping up an application that has models built and requires classification of incoming data. I have a couple of servers I can put these in... Is it worth it? Or are these antiquated? 

The 24gb/Ram looks very enticing?",2,4,False,self,,,,,
78,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,11,bysnlm,self.deeplearning,Depthwise Conv2d filters,https://www.reddit.com/r/deeplearning/comments/bysnlm/depthwise_conv2d_filters/,piingpoong,1560135549,"Am I correct in my understanding of depthwise conv2d? if the input image is 8x8x3 and there is 1 filter, which is 3x3x1, the output would be 6x6x3? The same filter is applied to each channel of the initial channels?",1,1,False,self,,,,,
79,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,16,byuotg,self.deeplearning,Training with multi-GPUs vs single GPU. Take longer time when train with 8 GPUs.,https://www.reddit.com/r/deeplearning/comments/byuotg/training_with_multigpus_vs_single_gpu_take_longer/,TonyLee00,1560150079,"Hi all, I have a benchmark on training time between 1, 2, 4, 6, 8 GPUs. My question is why training with 8 GPUs take a longer time compared to 4 GPU?

My hardware:

CPU: Xeon Silver 4110 2.1Ghz (16Cores)

GPU: 8 x RTX 2080Ti

Memory: 128 Gb

https://i.redd.it/xytm3rt79h331.png",3,2,False,self,,,,,
80,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,16,byv1zz,self.deeplearning,Output shape meaning for a conv layer,https://www.reddit.com/r/deeplearning/comments/byv1zz/output_shape_meaning_for_a_conv_layer/,dennkiesauros,1560153021,"I am new to deep learning and I am doing a project based on transfer learning. After downloading the weights of VGG16 and adding GlobalMaxPooling2D, Dense, Dropout and a final Dense layer when I print out the summary of my model the output shape for input\_layer shows (None, None, None, 3). Is this alright? Why is it showing 'None'? I have set my img\_width, img\_height = 256, 256. I read in stackoverflow that 'None' allows dynamic image sizes. But on a different code using VGG16 the output shape was something like (None, 156, 156,3).

Sorry if this is a dumb question to ask. Thank you in advance.",3,1,False,self,,,,,
81,deeplearning,t5_2t5eh,2019-6-10,2019,6,10,21,byxjqt,self.deeplearning,Feel at CVPR as if you were at CVPR! CVPR Daily,https://www.reddit.com/r/deeplearning/comments/byxjqt/feel_at_cvpr_as_if_you_were_at_cvpr_cvpr_daily/,Gletta,1560171557,"**CVPR 2019**, the Computer Vision and Pattern Recognition conference, will take place in Long Beach, CA in less than 2 weeks.

If you are not going to CVPR, you can still receive the **CVPR Daily** every day in your mailbox. We will send you the link to the fresh magazine every morning and you will know the highlights of what is going on at the conference.

[**Register here, it's free!**](https://www.rsipvision.com/feel-at-cvpr-without-being-at-cvpr/)

You can also subscribe colleagues and friends who would like to receive great technology and community updates from CVPR 2019.

Enjoy!

&amp;#x200B;

https://i.redd.it/yjqolwqb1j331.jpg",0,7,False,self,,,,,
82,deeplearning,t5_2t5eh,2019-6-11,2019,6,11,2,bz0vsd,pytorch.org,"PyTorch Hub | Check out the models for Researchers and Developers, or learn How it Works",https://www.reddit.com/r/deeplearning/comments/bz0vsd/pytorch_hub_check_out_the_models_for_researchers/,asuagar,1560188796,,2,42,False,default,,,,,
83,deeplearning,t5_2t5eh,2019-6-11,2019,6,11,3,bz1po4,self.deeplearning,[P] PyTorch Hub: Towards Reproducible Research,https://www.reddit.com/r/deeplearning/comments/bz1po4/p_pytorch_hub_towards_reproducible_research/,rosstaylor90,1560192820,"[https://pytorch.org/blog/towards-reproducible-research-with-pytorch-hub/](https://pytorch.org/blog/towards-reproducible-research-with-pytorch-hub/)

&amp;#x200B;

""Reproducibility is an essential requirement for many fields of research including those based on machine learning techniques. However, many machine learning publications are either not reproducible or are difficult to reproduce. With the continued growth in the number of research publications, including tens of thousands of papers now hosted on arXiv and submissions to conferences at an all time high, research reproducibility is more important than ever. While many of these publications are accompanied by code as well as trained models which is helpful but still leaves a number of steps for users to figure out for themselves.

We are excited to announce the availability of PyTorch Hub, a simple API and workflow that provides the basic building blocks for improving machine learning research reproducibility. PyTorch Hub consists of a pre-trained model repository designed specifically to facilitate research reproducibility and enable new research. It also has built-in support for Colab, integration with Papers With Code and currently contains a broad set of models that include Classification and Segmentation, Generative, Transformers, and more.""",0,1,False,self,,,,,
84,deeplearning,t5_2t5eh,2019-6-11,2019,6,11,6,bz3op6,self.deeplearning,Any tutorial to learn BERT,https://www.reddit.com/r/deeplearning/comments/bz3op6/any_tutorial_to_learn_bert/,saravanakumar17,1560202617,"Hi guys, I've been trying to learn Google's BERT with pytorch for sometime I've tried huggingface GitHub repo and few other sources, but I couldn't quite figure out how to implement it in an end to end project with pytorch. If you folks knew any resources of this kind, please let me know. Thanks in advance.",7,1,False,self,,,,,
85,deeplearning,t5_2t5eh,2019-6-11,2019,6,11,7,bz4fvf,github.com,Rate prediction with TensorFlow Bidirectional RNN,https://www.reddit.com/r/deeplearning/comments/bz4fvf/rate_prediction_with_tensorflow_bidirectional_rnn/,resotto,1560206509,,0,0,False,default,,,,,
86,deeplearning,t5_2t5eh,2019-6-11,2019,6,11,12,bz7d92,self.deeplearning,"How much machine learning, we must know before start learning deep learning?",https://www.reddit.com/r/deeplearning/comments/bz7d92/how_much_machine_learning_we_must_know_before/,KishanJoshi98,1560223304,"How much in depth knowledge of machine learning is required, before starting deep learning ?",8,0,False,self,,,,,
87,deeplearning,t5_2t5eh,2019-6-11,2019,6,11,12,bz7p37,self.deeplearning,Is it normal for convolution neural networks?,https://www.reddit.com/r/deeplearning/comments/bz7p37/is_it_normal_for_convolution_neural_networks/,jahifu,1560225545,"Is it normal for cnn for taking so much time 
I have like training-8000 test -2000 samples of dogs and cats 
When I try to fit the  model it takes usually 1 hour per epoch and it's total 25 epochs 
So it's taking lot of time is it normal for the cnn??
Because the tutorial from.which I have learning it takes like 80 sec to train per epoch so I don't what's happening some tell me /:
My pc specs: 1TB Hardisk
                          4GB RAM
                           AMD 480 GPU
                           and name of pc if some details are wrong is    hpay008tx",7,0,False,self,,,,,
88,deeplearning,t5_2t5eh,2019-6-11,2019,6,11,13,bz84i6,self.deeplearning,Statistics with R,https://www.reddit.com/r/deeplearning/comments/bz84i6/statistics_with_r/,HannahHumphreys,1560228334,[removed],0,1,False,self,,,,,
89,deeplearning,t5_2t5eh,2019-6-11,2019,6,11,14,bz8i9a,self.deeplearning,GANs?,https://www.reddit.com/r/deeplearning/comments/bz8i9a/gans/,mayyyday,1560230990,"Can we use GANs to detect disguised faces of a particular personality?
Like I have several images of the person with different look(frontal face). So can we build GAN that can detect whether the person's image is real or being impersonated or disguised?",2,0,False,self,,,,,
90,deeplearning,t5_2t5eh,2019-6-11,2019,6,11,14,bz8mxe,self.deeplearning,Artificial Intelligence Projects with Python-HandsOn,https://www.reddit.com/r/deeplearning/comments/bz8mxe/artificial_intelligence_projects_with/,HannahHumphreys,1560231919,[removed],0,1,False,self,,,,,
91,deeplearning,t5_2t5eh,2019-6-11,2019,6,11,18,bzaiec,self.deeplearning,Unbounded Table Detection,https://www.reddit.com/r/deeplearning/comments/bzaiec/unbounded_table_detection/,data_autopsy,1560247049,"I'm currently working on page layout analysis. The purpose of this is to do attribute extraction. The whole pipeline consists of some python packages and deep learning models. In some particular cases, we're encountering unbounded tables. Now, neither the deep learning models nor the packages can help in that. We are trying to reconstruct the text based on the coordinates but generalising that is a big problem. We tried training on [Table Bank dataset](https://github.com/doc-analysis/TableBank) but the results were not good (we didn't do any pre-processing). I have attached an image sample. I am not sure how to approach this problem other than table detection and then passing it to OCR for text. 

PS We've tried Faster-RCNN, SSD. The training set is of 92000 images. There are mix of bounded and unbounded tables. Please let me know if pre-processing will help in this case or any other approach you guys can think of.

Thanks.

![img](nynfm58m9p331)",4,3,False,self,,,,,
92,deeplearning,t5_2t5eh,2019-6-11,2019,6,11,20,bzb3dm,self.deeplearning,Face Detection!,https://www.reddit.com/r/deeplearning/comments/bzb3dm/face_detection/,mayyyday,1560251334,"Could any one give me the list of various types of Algorithms to detect faces? And What would you suggest to use and why?

NOTE: For research purpose, currently I'm trying to use YOLOv3 to detect faces.",4,1,False,self,,,,,
93,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,1,bzeg29,self.deeplearning,Machine Learning and Reinforcement Learning in Finance,https://www.reddit.com/r/deeplearning/comments/bzeg29/machine_learning_and_reinforcement_learning_in/,HannahHumphreys,1560269610,[removed],0,1,False,self,,,,,
94,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,1,bzex6i,self.deeplearning,[Research] Voice Mimicry Attacks Assisted by Automatic Speaker Verification,https://www.reddit.com/r/deeplearning/comments/bzex6i/research_voice_mimicry_attacks_assisted_by/,cdossman,1560271861," [https://medium.com/ai%C2%B3-theory-practice-business/towards-designing-more-secure-speaker-verification-systems-7f6fbb3f5912](https://medium.com/ai%C2%B3-theory-practice-business/towards-designing-more-secure-speaker-verification-systems-7f6fbb3f5912) 

Abstract:  In this work, we simulate a scenario, where a publicly available ASV system is used to enhance mimicry attacks against another closed source ASV system. In specific, ASV technology is used to perform a similarity search between the voices of recruited attackers (6) and potential target speakers (7,365) from VoxCeleb corpora to find the closest targets for each of the attackers. In addition, we consider median, furthest, and common targets to serve as a reference point. Our goal is to gain insights how well similarity rankings transfer from the attackers ASV system to the attacked ASV system, whether the attackers are able to improve their attacks by mimicking, and how the properties of the voices of attackers change due to mimicking. We address these questions through ASV experiments, listening tests, and prosodic and formant analyses. For the ASV experiments, we use i-vector technology in the attacker side, and x-vectors in the attacked side. For the listening tests, we recruit listeners through crowdsourcing. The results of the ASV experiments indicate that the speaker similarity scores transfer well from one ASV system to another. Both the ASV experiments and the listening tests reveal that the mimicry attempts do not, in general, help in bringing attackers scores closer to the targets. A detailed analysis shows that mimicking does not improve attacks, when the natural voices of attackers and targets are similar to each other. The analysis of prosody and formants suggests that the attackers were able to considerably change their speaking rates when mimicking, but the changes in F0 and formants were modest. Overall, the results suggest that untrained impersonators do not pose a high threat towards ASV systems, but the use of ASV systems to attack other ASV systems is a potential threat.",0,13,False,self,,,,,
95,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,4,bzgrdz,i.redd.it,Can someone give an insight on how to approach this problem? I am thinking of creating an MSWord addon that can track the user's cursor movement. Any help is appreciated!,https://www.reddit.com/r/deeplearning/comments/bzgrdz/can_someone_give_an_insight_on_how_to_approach/,pm_me_your_codebase,1560280131,,1,0,False,image,,,,,
96,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,16,bzo99k,self.deeplearning,Introduction to Multilayer Neural Networks with TensorFlows Keras API,https://www.reddit.com/r/deeplearning/comments/bzo99k/introduction_to_multilayer_neural_networks_with/,CarlJohnson8x,1560325471,[removed],0,1,False,self,,,,,
97,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,17,bzonx9,self.deeplearning,How to properly setup tensorflow with anaconda for python 3.5?,https://www.reddit.com/r/deeplearning/comments/bzonx9/how_to_properly_setup_tensorflow_with_anaconda/,atmadeepArya,1560328812,Can someone tell me a good way with required version numbers ? I keep on getting various errors due to version mismatch? Should I use pip or conda for installing tensorflow? Well I want it to be inside a conda environment so can you tell me what is the difference between using two?,9,13,False,self,,,,,
98,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,18,bzp6t6,medium.com,Pythia (Facebook) Greek god doing Deep learning,https://www.reddit.com/r/deeplearning/comments/bzp6t6/pythia_facebook_greek_god_doing_deep_learning/,whitezl0,1560332878,,0,12,False,default,,,,,
99,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,19,bzpmuq,self.deeplearning,CI/CD for deploying Deep Learning models,https://www.reddit.com/r/deeplearning/comments/bzpmuq/cicd_for_deploying_deep_learning_models/,neeraj_sujan,1560336158,"Hey, 

&amp;#x200B;

What is the best approach to integrate a CI/CD pipeline in deploying my machine learning models. I want to automate this process where the model is only integrated if a specific criterion is met like for example the accuracy of the model is above a certain threshold. I want to integrate this with the gitlab CI/CD pipeline. What is the best approach to tackle this problem? Thanks",7,7,False,self,,,,,
100,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,20,bzq25t,self.deeplearning,Training and validation loss completely overlap in a time series regression,https://www.reddit.com/r/deeplearning/comments/bzq25t/training_and_validation_loss_completely_overlap/,BeingSorena,1560339065,"The dataset here is about the arrival rate in a queue. I used one-hot coding to represent the features for the user type, year and hour of arrival in integer_hour column. Before performing any coding, the first few lines of dataset looked like this: enter image description here Afterwards, here's how it looks like:

enter image description here

Here's the code:

my_df= pd.read_csv(""proj_dataset.csv"")
user_types = list(my_df['user_type'].unique())
print(f'Number of user_types: {len(user_types)}')
print(f'user_type: {user_types}')
dummies = pd.get_dummies(my_df['user_type'],prefix='user_type')
df = pd.concat([my_df,dummies],axis=1)
df.drop(['user_type', 'start_time', 'id_timeslot'], axis= 1, inplace= True)
my_list= list(df['id_date'])
for i in range(0, len(my_list)):
    my_list[i]= my_list[i][0:4]
df['id_date']= my_list
years = list(df['id_date'].unique())
print(f'Number of different years: {len(years)}')
print(f'Years: {years}')
dummies = pd.get_dummies(['2012', '2013', '2014', '2015', '2016', '2017', '2018'],prefix='Year')
dummies = pd.get_dummies(df['id_date'],prefix='Year')
df3 = pd.concat([df ,dummies],axis=1)
df3.drop('id_date', axis= 1, inplace= True)
ColumnsTitles= ['integer_hour', 'user_type_A', 'user_type_C', 'user_type_P',
'Year_2012', 'Year_2013', 'Year_2014', 'Year_2015', 'Year_2016',
'Year_2017', 'Year_2018', 'arrivals']
df4=df3.reindex(columns=ColumnsTitles)

hours = list(df['integer_hour'].unique())
dummies = pd.get_dummies(['8', '9', '10', '11', '12', '13', '14', '15', '16', '17'],prefix='hour')
dummies = pd.get_dummies(my_df['integer_hour'],prefix='hour')
my_df = pd.concat([df4,dummies],axis=1)
my_df.drop('integer_hour', axis= 1, inplace= True)
Train_Frame= my_df[:80000]
Test_Frame = my_df[80000:]
Train_Set= Train_Frame.values
Test_Set= Test_Frame.values
Test_Frame.shape;
X_Train= Train_Set[:, 0:20]
Y_Train= Train_Set[:, -1]
X_Test= Test_Set[:, 0:20]
Y_Test= Test_Set[:, -1]
X_Train.shape
model = models.Sequential() 
model.add(layers.Dense(20, input_shape=(20,), kernel_regularizer=regularizers.l1_l2(l1=0.12, l2=0.10), activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(10, input_shape=(20,), kernel_regularizer=regularizers.l1_l2(l1=0.12, l2=0.10), activation='relu'))
model.add(layers.Dropout(0.9))
model.add(layers.Dense(5, input_shape=(20,), kernel_regularizer=regularizers.l1_l2(l1=0.12, l2=0.10), activation='softplus'))

model.add(layers.Dense(1))
model.compile(optimizer='rmsprop', loss='mse', metrics= ['acc'])
history= model.fit(X_Train, Y_Train, verbose=0, epochs= 200, batch_size=1000, validation_data=(X_Test, Y_Test));
Results = model.evaluate(X_Test, Y_Test)
It seems rather odd that the training and validation loss perfectly overlap. As usual, the same is true for training and validation accuracy. Thanks for your answers.

enter image description here",0,1,False,self,,,,,
101,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,22,bzr0mm,info.cnvrg.io,Register Now | Webinar: How to use continual learning in your ML models,https://www.reddit.com/r/deeplearning/comments/bzr0mm/register_now_webinar_how_to_use_continual/,Mayalittlepony,1560344896,,0,1,False,default,,,,,
102,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,22,bzr6y2,blockdelta.io,Setting Rythym in Algorithm (Contd),https://www.reddit.com/r/deeplearning/comments/bzr6y2/setting_rythym_in_algorithm_contd/,BlockDelta,1560345873,,0,2,False,default,,,,,
103,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,22,bzre1i,self.deeplearning,Confused by the semantics,https://www.reddit.com/r/deeplearning/comments/bzre1i/confused_by_the_semantics/,StrasJam,1560346962,"I am currently working on a project where I am supposed to accurately outline the locations of rows of vegetation (ex. bushes) from satellite imagery. Typically I would have thought of this to be a classification approach (classify areas as either bush-rows or non-bush), but now that I have thought about it some more I am thinking that this might be an object detection problem (detect the linear vegetation objects in the image). It would help me to know which approach best applies to my project so that I can read the proper articles and such so if anyone could give me some insight into which approach is more appropriate for this task I would greatly appreciate it.  


Thanks!!!",6,2,False,self,,,,,
104,deeplearning,t5_2t5eh,2019-6-12,2019,6,12,22,bzrk1q,self.deeplearning,[Research] Real-Time Adversarial Attacks,https://www.reddit.com/r/deeplearning/comments/bzrk1q/research_realtime_adversarial_attacks/,cdossman,1560347894," [https://medium.com/ai%C2%B3-theory-practice-business/how-about-real-time-adversarial-attacks-6aba92d59c1e?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/how-about-real-time-adversarial-attacks-6aba92d59c1e?postPublishedType=initial) 

**Abstract:**  In recent years, many efforts have demonstrated that modern machine learning algorithms are vulnerable to adversarial attacks, where small, but carefully crafted, perturbations on the input can make them fail. While these attack methods are very effective, they only focus on scenarios where the target model takes static input, i.e., an attacker can observe the entire original sample and then add a perturbation at any point of the sample. These attack approaches are not applicable to situations where the target model takes streaming input, i.e., an attacker is only able to observe past data points and add perturbations to the remaining (unobserved) data points of the input. In this paper, we propose a real-time adversarial attack scheme for machine learning models with streaming inputs",0,1,False,self,,,,,
105,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,0,bzskdq,self.deeplearning,"Network topology, Resnet50 (for example) or something smaller",https://www.reddit.com/r/deeplearning/comments/bzskdq/network_topology_resnet50_for_example_or/,brechmos,1560353154,"I am reasonably new at NN and all.  I am starting an astrophysics project that will have a couple tasks, one is object classification based on cutouts and the other is object detection (YOLO or faster-RCNN, I think) in a larger image. The objects are not going to be galaxies or stars etc, but regions with more subtle effects in images.  

For the object classification, would it make sense to start with Resnet50 or VGG16 (from Keras) and retrain it on the labeled data, or would it make more sense to start with a less complicated network? There are going to be 3-4 classes that an image might fall into.  So I am \*thinking\* of taking Resnet50, for example, strip off the top layer and add my own that has 3-4 output nodes and then re-train based on the data I have. Part of the answer might be ""you have to try it"" but I would like to hear any intuition before I do that :).

In reading through on the ImageNet trained networks, they seem to focus more on texture in the images rather than structure.  If this is a property of the underlying trained CNN (e.g., Resnet 50) then this might be a benefit to the types of images I am going to have.

Any thoughts or guidance would be appreciated.",2,1,False,self,,,,,
106,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,1,bzt0ea,self.deeplearning,Projects in Machine Learning : Beginner To Professional,https://www.reddit.com/r/deeplearning/comments/bzt0ea/projects_in_machine_learning_beginner_to/,HannahHumphreys,1560355397,[removed],0,1,False,self,,,,,
107,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,4,bzv8lq,youtube.com,Deep Learning Tutorial for Beginner | Background &amp; History |60 mins of tutorial,https://www.reddit.com/r/deeplearning/comments/bzv8lq/deep_learning_tutorial_for_beginner_background/,KiranKiller,1560366245,,0,1,False,image,,,,,
108,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,4,bzvm0y,self.deeplearning,Failing at Image Captioning!,https://www.reddit.com/r/deeplearning/comments/bzvm0y/failing_at_image_captioning/,plmlp1,1560368039,"Hello I'm trying to learn CNNs and I've hit a deadend with an Image Captioning project I was working on for fun.

Dataset: 10k images from [Google Conceptual Captions] (https://ai.google.com/research/ConceptualCaptions/download)  
Tutorial I'm mostly following: [Automatic Image Captioning](https://github.com/hlamba28/Automatic-Image-Captioning)  


One difference between my dataset and the Flicker8k dataset in the tutorial is that my dataset only has one caption per image but latter has five captions per image.

The problem is that I am getting the same caption for nearly all images. I have tried to use:
- LSTM instead of GRU cells
- 50 and 200 Glove word embeddings. I even tried to create my own embeddings using all captions in the dataset
- beam search and greedy search to get a prediction

What do I do?",0,1,False,self,,,,,
109,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,4,bzvtgh,self.deeplearning,Text to image conversion,https://www.reddit.com/r/deeplearning/comments/bzvtgh/text_to_image_conversion/,LolSalaam,1560369042,"Hi all. I'm looking for something that will help me in text to image conversion. 

Text is a paragraph consisting of sentences where each of these sentences are basically instructions on how a room should look like and the image produced is supposed to comply with these instructions.

I'm currently looking into some stackGAN implementations. If someone has any other idea do share.
Would be glad if someone could help.
Thanks:)",1,3,False,self,,,,,
110,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,5,bzwebn,self.deeplearning,What is the hardest thing about implementing Deep Learning in your business?,https://www.reddit.com/r/deeplearning/comments/bzwebn/what_is_the_hardest_thing_about_implementing_deep/,HenryAILabs,1560371862,,12,23,False,self,,,,,
111,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,10,bzze2x,youtu.be,Enlightenment,https://www.reddit.com/r/deeplearning/comments/bzze2x/enlightenment/,markusdamon5,1560388053,,1,0,False,default,,,,,
112,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,12,c00qum,self.deeplearning,X-Ray Dataset for Research,https://www.reddit.com/r/deeplearning/comments/c00qum/xray_dataset_for_research/,Redhatchamp00,1560396312,"Hello!

Does anyone know of a dataset of X-ray images of the cervical spine region. I need it for research purposes, but I can't find it anywhere. It would be of great help if someone could share a link to any such database. 

Thanks",0,6,False,self,,,,,
113,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,13,c018gh,self.deeplearning,An AI-Powered Domain Name Generator,https://www.reddit.com/r/deeplearning/comments/c018gh/an_aipowered_domain_name_generator/,Refeb,1560399497,"Hey there, we are so happy and pleased to share our platform with you today:

&amp;#x200B;

DeepNamer is an AI-powered domain name generator and deep brainstorm platform that can help you find a catchy and creative domain name for your business for free. DeepNamer is built based on a deep sequence-to-sequence (i.e., keywords-to-domain) architecture, which utilizes the most recent natural language processing algorithms such as dynamic recurrent neural networks.

&amp;#x200B;

Note that we find our name DeepNamer via our AI algorithm and our platform inspired by the way startups names their businesses.

**We would be happy to share our platform (**[**DeepNamer.com**](https://DeepNamer.com)**) with you and any comment, feedback or suggestion would be appreciated.**",1,2,False,self,,,,,
114,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,15,c024i5,youtube.com,Deep Learning Frameworks 2019,https://www.reddit.com/r/deeplearning/comments/c024i5/deep_learning_frameworks_2019/,MainBuilder,1560405777,,1,1,False,default,,,,,
115,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,19,c03yjm,self.deeplearning,Awesome papers and engineering reviews on Computer Vision News of June (with codes!). Links for free reading!,https://www.reddit.com/r/deeplearning/comments/c03yjm/awesome_papers_and_engineering_reviews_on/,Gletta,1560420526,"RSIP Vision has just published the June issue of **Computer Vision News**. Here it is for you to read online.

42 pages with exclusive articles on **AI, computer vision and deep learning**.

Subscribe for free on page 42. Important message about **CVPR** on page 9.

[**HTML5 version (recommended)**](https://www.rsipvision.com/ComputerVisionNews-2019June/)

[**PDF version**](https://www.rsipvision.com/computer-vision-news-2019-june-pdf/)

Enjoy!

&amp;#x200B;

https://i.redd.it/4j1md77pl3431.jpg",4,17,False,self,,,,,
116,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,20,c04eas,self.deeplearning,Geometric deep learning applications?,https://www.reddit.com/r/deeplearning/comments/c04eas/geometric_deep_learning_applications/,Matimath,1560423725,"Hi all,

do you know any papers that apply spectral graph convolution to solve real life problem (or at least a problem based on real data)? I am particularly interested in those where both learning and inference happen in the same domain.",0,4,False,self,,,,,
117,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,20,c04ife,dessa.com,RealTalk: This Speech Synthesis Model Recreates A Human Voice Perfectly,https://www.reddit.com/r/deeplearning/comments/c04ife/realtalk_this_speech_synthesis_model_recreates_a/,lopespm,1560424460,,1,7,False,default,,,,,
118,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,20,c04lof,self.deeplearning,PySyft,https://www.reddit.com/r/deeplearning/comments/c04lof/pysyft/,susmit410,1560425082,PySyft and the Emergence of Private Deep Learning by Jesus Rodriguez https://link.medium.com/FXydw6q8tX,1,2,False,self,,,,,
119,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,20,c04pjl,self.deeplearning,"Telegram group about deep learning ,machine learning , Artificial Intelligence ,....",https://www.reddit.com/r/deeplearning/comments/c04pjl/telegram_group_about_deep_learning_machine/,Doctor_who1,1560425756,"The Main topics that we are going to discuss here are as below:

  Business Development and Business Model in Digital Transformation Age

  Data Science 

  Artificial Intelligence 

  Machine Learning

  Deep Learning

  Cognitive Science

  Neuroscience

&amp;#x200B;

&amp;#x200B;

Please  post in English  language.

&amp;#x200B;

Telegram  group 

join 

[https://t.me/joinchat/CuFqkRQSxRy5M\_6KxhKrCA](https://t.me/joinchat/CuFqkRQSxRy5M_6KxhKrCA)",3,1,False,self,,,,,
120,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,21,c05dnd,youtube.com,"Professor Shai Shen-Orr PhD., Associate Professor at Technion - Israel Institute of Technology, and Founder and Chief Scientist CytoReason, Discussing Artificial Intelligence Speeding Up Drug Discovery",https://www.reddit.com/r/deeplearning/comments/c05dnd/professor_shai_shenorr_phd_associate_professor_at/,bioquarkceo,1560429956,,0,5,False,image,,,,,
121,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,22,c0603g,self.deeplearning,[Research] How Much Does Audio Matter to Recognize Egocentric Object Interactions?,https://www.reddit.com/r/deeplearning/comments/c0603g/research_how_much_does_audio_matter_to_recognize/,cdossman,1560433503," [https://medium.com/ai%C2%B3-theory-practice-business/how-much-does-audio-matter-to-recognize-egocentric-object-interactions-ed01b2f7c680?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/how-much-does-audio-matter-to-recognize-egocentric-object-interactions-ed01b2f7c680?postPublishedType=initial) 

Abstract:  In this preliminary work, we propose an audio model for egocentric action recognition and explore its usefulness on the parts of the problem (noun, verb, and action classification). Our model achieves a competitive result in terms of verb classification (34.26% accuracy) on a standard benchmark with respect to vision-based state of the art systems, using a comparatively lighter architecture.",0,1,False,self,,,,,
122,deeplearning,t5_2t5eh,2019-6-13,2019,6,13,23,c067pw,youtube.com,"AI, art, and autonomy: an introduction to the Abraham project",https://www.reddit.com/r/deeplearning/comments/c067pw/ai_art_and_autonomy_an_introduction_to_the/,keghn,1560434639,,0,11,False,image,,,,,
123,deeplearning,t5_2t5eh,2019-6-14,2019,6,14,1,c07z8a,youtube.com,Applied Deep Learning Tutorial For Beginners| Theory &amp; Application| 1 Hr Tutorial,https://www.reddit.com/r/deeplearning/comments/c07z8a/applied_deep_learning_tutorial_for_beginners/,KiranKiller,1560443417,,0,0,False,image,,,,,
124,deeplearning,t5_2t5eh,2019-6-14,2019,6,14,2,c08sr7,self.deeplearning,Can GANs generate conditional y values given x values which y comes from mixture densities?,https://www.reddit.com/r/deeplearning/comments/c08sr7/can_gans_generate_conditional_y_values_given_x/,Shanghoosh,1560447344,"I have a table with two attributes (x,y). for each x there are several y values that come from different normal distributions. Now, I want to generate y values given x. I know Mixture Density Networks do this for me, but I need GANs to do it. I have implemented conditional GANs, but the results are not good, seems random. by the way, my conditional GAN works well on simple functions such as y=x\^2.

my data is like this: 

&amp;#x200B;

[for each x there are several mu and sigma of mixture normal distribution](https://i.redd.it/rgr0sop0t5431.png)

Any answers are appreciated.",0,1,False,self,,,,,
125,deeplearning,t5_2t5eh,2019-6-14,2019,6,14,5,c0b1ma,producthunt.com,DeepNamer: An AI-Powered Domain Name Generator,https://www.reddit.com/r/deeplearning/comments/c0b1ma/deepnamer_an_aipowered_domain_name_generator/,Refeb,1560458172,,3,15,False,default,,,,,
126,deeplearning,t5_2t5eh,2019-6-14,2019,6,14,16,c0h92x,self.deeplearning,Deep learning telegram group and car learning with the collaboration of Kursera website and world experts and researchers including andrew ng,https://www.reddit.com/r/deeplearning/comments/c0h92x/deep_learning_telegram_group_and_car_learning/,Doctor_who1,1560497138," 

The Main topics that we are going to discuss here are as below:

 Data Science

 Artificial Intelligence

 Machine Learning

 Deep Learning

 Cognitive Science

 Neuroscience

Please post in English language.

Telegram group

join

[https://t.me/joinchat/CuFqkRQSxRy5M\_6KxhKrCA](https://t.me/joinchat/CuFqkRQSxRy5M_6KxhKrCA)",0,0,False,self,,,,,
127,deeplearning,t5_2t5eh,2019-6-14,2019,6,14,18,c0i561,ai4beginners.com,AI for Beginners: An introduction to Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/c0i561/ai_for_beginners_an_introduction_to_artificial/,Oratorshub,1560505153,,0,3,False,default,,,,,
128,deeplearning,t5_2t5eh,2019-6-14,2019,6,14,23,c0kpl4,self.deeplearning,[Research]Investigating the Lombard Effect Influence on End-to-End Audio-Visual Speech Recognition,https://www.reddit.com/r/deeplearning/comments/c0kpl4/researchinvestigating_the_lombard_effect/,cdossman,1560522377," [https://medium.com/ai%C2%B3-theory-practice-business/the-impact-of-the-lombard-effect-in-audio-visual-speech-recognition-613904484bd4?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/the-impact-of-the-lombard-effect-in-audio-visual-speech-recognition-613904484bd4?postPublishedType=initial) 

Abstract:  Several audio-visual speech recognition models have been recently proposed which aim to improve the robustness over audio-only models in the presence of noise. However, almost all of them ignore the impact of the Lombard effect, i.e., the change in speaking style in noisy environments which aims to make speech more intelligible and affects both the acoustic characteristics of speech and the lip movements. In this paper, we investigate the impact of the Lombard effect in audio-visual speech recognition. To the best of our knowledge, this is the first work which does so using end-to-end deep architectures and presents results on unseen speakers. Our results show that properly modeling Lombard speech is always beneficial. Even if a relatively small amount of Lombard speech is added to the training set then the performance in a real scenario, where noisy Lombard speech is present, can be significantly improved. We also show that the standard approach followed in the literature, where a model is trained and tested on noisy plain speech, provides a correct estimate of the video-only performance and slightly underestimates the audio-visual performance. In case of audio-only approaches, performance is overestimated for SNRs higher than -3dB and underestimated for lower SNRs",0,8,False,self,,,,,
129,deeplearning,t5_2t5eh,2019-6-15,2019,6,15,3,c0nqel,self.deeplearning,Best course for deep learning,https://www.reddit.com/r/deeplearning/comments/c0nqel/best_course_for_deep_learning/,AhmedZubairGCU,1560538017,I am thinking about starting Andrew Ng's deep learning specialisation. I just wanted to ask if there is some better alternative or is it good enough? Also after completing this is it worth mentioning in my resume?,9,19,False,self,,,,,
130,deeplearning,t5_2t5eh,2019-6-15,2019,6,15,4,c0ob7k,self.deeplearning,CSDN account,https://www.reddit.com/r/deeplearning/comments/c0ob7k/csdn_account/,davimoises2015,1560541028,"Someone from china, please download a file for min please. It's urgent, because I'm using it for work.

link 1:  [https://download.csdn.net/download/cjxin2009/10751701](https://download.csdn.net/download/cjxin2009/10751701) 

link 2:  [https://download.csdn.net/download/qq\_30091273/10823889](https://download.csdn.net/download/qq_30091273/10823889) 

link 3:   [https://download.csdn.net/download/njfkib/10941006](https://download.csdn.net/download/njfkib/10941006)

link 4:  [https://download.csdn.net/download/mss60/10967014](https://download.csdn.net/download/mss60/10967014)   


Meu E-mail: davi.empresajw@gmail.com",0,1,False,self,,,,,
131,deeplearning,t5_2t5eh,2019-6-15,2019,6,15,14,c0u4oc,self.deeplearning,Tensorflow gpu on mac Sierra 10.12.6,https://www.reddit.com/r/deeplearning/comments/c0u4oc/tensorflow_gpu_on_mac_sierra_10126/,durgesh2018,1560578304,"I am trying to set tensorflow gpu on Sierra. What is the easiest way to achieve this.

Thank you!",11,8,False,self,,,,,
132,deeplearning,t5_2t5eh,2019-6-15,2019,6,15,22,c0x1ui,youtube.com,Understanding deep learning (part1): Deep neural networks overview,https://www.reddit.com/r/deeplearning/comments/c0x1ui/understanding_deep_learning_part1_deep_neural/,TheTesseractAcademy,1560603710,,1,24,False,image,,,,,
133,deeplearning,t5_2t5eh,2019-6-16,2019,6,16,0,c0yd1b,youtube.com,Understanding deep learning (part 2): Feedforward and recurrent neural networks,https://www.reddit.com/r/deeplearning/comments/c0yd1b/understanding_deep_learning_part_2_feedforward/,TheTesseractAcademy,1560611815,,0,1,False,image,,,,,
134,deeplearning,t5_2t5eh,2019-6-16,2019,6,16,0,c0ydp9,self.deeplearning,Advanced Data Science with IBM,https://www.reddit.com/r/deeplearning/comments/c0ydp9/advanced_data_science_with_ibm/,HannahHumphreys,1560611918,[removed],0,1,False,self,,,,,
135,deeplearning,t5_2t5eh,2019-6-16,2019,6,16,18,c189gq,self.deeplearning,Managing image datasets ?,https://www.reddit.com/r/deeplearning/comments/c189gq/managing_image_datasets/,dandashino,1560678388,"Hello,

I am trying to create the datasets management part of a deep learning project.  The use cases that we will be covering will mostly be related to images so I want to focus on that for now. 

My idea was to just make a small API that will handle file management operations on the images (create, delete, move, make directories...) which will represent the datasets. I have recently came across posts where they use hdf5 (which i thought was only a format used by keras/tensorflow cuz iz a bit noob in this)  files to store files/images and their metadata. 

Has anyone tried (or just seen) saving images as hdf5 files for cv datasets?  If so, do you recommend using that for performance gains?",4,10,False,self,,,,,
136,deeplearning,t5_2t5eh,2019-6-16,2019,6,16,20,c18vgr,self.deeplearning,Video quality for Creating realistic deepfake?,https://www.reddit.com/r/deeplearning/comments/c18vgr/video_quality_for_creating_realistic_deepfake/,Seedani,1560684035,"Just how good does the video quality have to be to create a near-perfect deepfake? 

Is it possible to create a realistic deepfake with a heavily encoded file, for example? 

Thanks!",0,0,False,self,,,,,
137,deeplearning,t5_2t5eh,2019-6-16,2019,6,16,22,c19tco,self.deeplearning,Model not learning in Keras!,https://www.reddit.com/r/deeplearning/comments/c19tco/model_not_learning_in_keras/,dennkiesauros,1560691237,"So this is my first deep learning project where I am using a pretrained model to classify images using keras. Right now I am using VGG16 to check its performance. But my model is not learning. I have divided the dataset in two ways.

In the first method, I have created 3 directories manually, Train, Test, Validation which have subdirectories of various classes. When I am training and validating my model on this dataset using  datagen.flow, my model has an accuracy over 97%. It has pretty high accuracy on the test data too.

In the second method I have converted the images into numpy arrays and then used sklearn test\_train\_split to create test, train, valid data. But when I am training the model on this set of data, my model  is not learning anything. It shows the same loss, acc, val\_loss, val\_acc over the epochs. I cannot understand why is this happening. I wanted to use this method because I wanted to evaluate the sklearn metrics like confusion matrix and classification report. Is there any way I can use the previous dataset and datagen.flow to evaluate these metrics?

I have tried every possible way to convert my images to numpy arrays. Can anyone please help me?",13,8,False,self,,,,,
138,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,0,c1b7yw,self.deeplearning,Machine Learning with TensorFlow on Google Cloud Platform,https://www.reddit.com/r/deeplearning/comments/c1b7yw/machine_learning_with_tensorflow_on_google_cloud/,HannahHumphreys,1560699496,[removed],0,1,False,self,,,,,
139,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,1,c1bqg5,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c1bqg5/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1560702267,[removed],0,1,False,self,,,,,
140,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,1,c1c0q6,techunalt.com,NVIDIA's AI that generates photorealistic images from your doodles is now in beta stage and open for all to try out,https://www.reddit.com/r/deeplearning/comments/c1c0q6/nvidias_ai_that_generates_photorealistic_images/,azmodeus99,1560703821,,4,48,False,default,,,,,
141,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,2,c1caac,vks.ai,Helper library for NLP tasks: textsearch (fast and configurable text search in Python),https://www.reddit.com/r/deeplearning/comments/c1caac/helper_library_for_nlp_tasks_textsearch_fast_and/,pvkooten,1560705244,,1,1,False,default,,,,,
142,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,3,c1d2e9,self.deeplearning,Awesome DL and ML Courses,https://www.reddit.com/r/deeplearning/comments/c1d2e9/awesome_dl_and_ml_courses/,Msadat97,1560709289,"Hey guys,

&amp;#x200B;

I've recently found this awesome collection of ml and dl courses.

&amp;#x200B;

[Deep Learning and Machine Learning Drizzle](https://github.com/kmario23/deep-learning-drizzle)

&amp;#x200B;

Hope it'll help interested people. Please add related resources in the comments. (I am personally more interested in ml and dl theory, so your comments would be appreciated).",3,2,False,self,,,,,
143,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,4,c1e1yg,github.com,pastiche: a PyTorch implementation of Neural Style Transfer,https://www.reddit.com/r/deeplearning/comments/c1e1yg/pastiche_a_pytorch_implementation_of_neural_style/,dstein64,1560714416,,0,1,False,default,,,,,
144,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,7,c1fm4h,self.deeplearning,Best GPU for Pytorch?,https://www.reddit.com/r/deeplearning/comments/c1fm4h/best_gpu_for_pytorch/,DeepLearningStudent,1560722732,"Hi all,

&amp;#x200B;

I am a fledgling deep learning student and until fairly recently, for anything but the most basic of prototypes, I have been using my organization's high performance computing cluster for deep learning tasks. However, I would like to do some home prototyping and inference with models I develop or analyze without having to wrestle with the cluster every time and risk maintenance downtime, errors, and other headaches. To that end, I have begun looking for a graphics card that would maximize my ability to prototype from one machine without a dedicated GPU machine. 

&amp;#x200B;

Any recommendations would be appreciated!",4,1,False,self,,,,,
145,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,16,c1klna,self.deeplearning,How do you tag your data?,https://www.reddit.com/r/deeplearning/comments/c1klna/how_do_you_tag_your_data/,abhiksark,1560755956,"I work as a Machine Learning Engineer, so a lot of work revolves around data. To fulfill our needs we are having a team of dedicated taggers who tag the data suiting the requirements. But it's a slow and an error Prone Process.  How do you/your company manages this task?",12,7,False,self,,,,,
146,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,16,c1kv8e,self.deeplearning,Classification of image style using deep learning with Python - Custom Web Development Blog,https://www.reddit.com/r/deeplearning/comments/c1kv8e/classification_of_image_style_using_deep_learning/,issart,1560758264,[removed],0,1,False,self,,,,,
147,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,17,c1l12f,self.deeplearning,difference between 'Image captioning' and 'Scene graph generation'..?,https://www.reddit.com/r/deeplearning/comments/c1l12f/difference_between_image_captioning_and_scene/,GW_KIM,1560759672,"I noticed that recently there some many researches about 'Scene graph generation'

But is there any difference between it and 'Image captioning'..?

Naively, i think we could build Scene graph from output of 'Image captioning'

Thx :)",4,6,False,self,,,,,
148,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,18,c1lotz,self.deeplearning,Keras - Random word embeddings performing better than pre-trained ones?,https://www.reddit.com/r/deeplearning/comments/c1lotz/keras_random_word_embeddings_performing_better/,rodrigonader,1560765372,"Im having trouble to understand the behavior of my word embedding layer when using pre-trained fixed weights vs random weights. Please see full post here and share your thoughts:

https://stackoverflow.com/q/55051269/10382479",4,7,False,self,,,,,
149,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,19,c1lqm5,self.deeplearning,A Very General Introduction to Keras,https://www.reddit.com/r/deeplearning/comments/c1lqm5/a_very_general_introduction_to_keras/,Abhi_9991,1560765753,"A quick post about creating a neural network classifier in keras.

Please read and review.

[A Very General Introduciton to Keras](https://dev.to/abhisarshukla/a-very-general-introduction-to-keras-1g33)",0,3,False,self,,,,,
150,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,19,c1lvs7,self.deeplearning,One-shot learning in DARTS paper,https://www.reddit.com/r/deeplearning/comments/c1lvs7/oneshot_learning_in_darts_paper/,0x7A,1560766891,"I recently read the  ""DARTS - Differentiable Architecture Search"" paper ([https://arxiv.org/abs/1806.09055](https://arxiv.org/abs/1806.09055)) by Liu et al. While it is not mentioned in the paper itself, several reviewers at OpenReview ([https://openreview.net/forum?id=S1eYHoC5FX](https://openreview.net/forum?id=S1eYHoC5FX)) claim that DARTS can be considered a one-shot learning approach. I only know one-shot learning from an object recognition context, so I don't quite see the connection here. Do you have any explanation why DARTS would be a one-shot algorithm?",5,6,False,self,,,,,
151,deeplearning,t5_2t5eh,2019-6-17,2019,6,17,23,c1oj4s,self.deeplearning,Free cloud GPU credits for deep learning,https://www.reddit.com/r/deeplearning/comments/c1oj4s/free_cloud_gpu_credits_for_deep_learning/,whitezl0,1560783582,"Hi, I am offering free credits for 1080Ti GPU instances for deep learning purposes  more than 12hrs for free

I am working on https://www.tensorpad.com/  developing cloud infrastructure for machine learning.

Part of our computational capacity is idle; hence, were offering credits at a free and discounted rate, so that data scientists can benefit from the resources available, and work on neural networks.

Specs:  60GB of RAM, 4 CPUs, 1080Ti GPU  JupyterLab environment with access to the terminal  Pre-installed Tensorflow, Keras, and other ML frameworks

You can access the free credits by signing up (https://dashboard.tensorpad.com/ and redeeming ""promo450"" promo code in the Billing tab (https://dashboard.tensorpad.com/billing).

For any questions, please contact us here, through support@tensorpad.com, or the Intercom on the site.",0,3,False,self,,,,,
152,deeplearning,t5_2t5eh,2019-6-18,2019,6,18,1,c1pp8a,self.deeplearning,[Research] Leveraging BERT for Extractive Text Summarization on Lectures,https://www.reddit.com/r/deeplearning/comments/c1pp8a/research_leveraging_bert_for_extractive_text/,cdossman,1560789215," [https://medium.com/ai%C2%B3-theory-practice-business/cloud-based-service-utilizes-bert-for-dynamic-extractive-lecture-summarizations-1b2796291f96?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/cloud-based-service-utilizes-bert-for-dynamic-extractive-lecture-summarizations-1b2796291f96?postPublishedType=initial) 

**Abstract:**  In the last two decades, automatic extractive text summarization on lectures has demonstrated to be a useful tool for collecting key phrases and sentences that best represent the content. However, many current approaches utilize dated approaches, producing sub-par outputs or requiring several hours of manual tuning to produce meaningful results. Recently, new machine learning architectures have provided mechanisms for extractive summarization through the clustering of output embeddings from deep learning models. This paper reports on the project called lecture summarization service, a python-based RESTful service that utilizes the BERT model for text embeddings and K-Means clustering to identify sentences closest to the centroid for summary selection. The purpose of the service was to provide students a utility that could summarize lecture content, based on their desired number of sentences. On top of summary work, the service also includes lecture and summary management, storing content on the cloud which can be used for collaboration.",0,23,False,self,,,,,
153,deeplearning,t5_2t5eh,2019-6-18,2019,6,18,3,c1r8b9,self.deeplearning,Plotting linear/affine regions of NNs in 2D.,https://www.reddit.com/r/deeplearning/comments/c1r8b9/plotting_linearaffine_regions_of_nns_in_2d/,PureTune,1560796444,"I've been checking out a couple papers on the complexity of NNs with ReLU nonlinearities, expressed through their linear/affine regions (some of these I heard about from ICML recently), e.g.

* [https://arxiv.org/abs/1901.09021](https://arxiv.org/abs/1901.09021)
* [https://arxiv.org/abs/1901.07647](https://arxiv.org/abs/1901.07647)
* [https://papers.nips.cc/paper/5422-on-the-number-of-linear-regions-of-deep-neural-networks.pdf](https://papers.nips.cc/paper/5422-on-the-number-of-linear-regions-of-deep-neural-networks.pdf)
* [https://arxiv.org/abs/1312.6098](https://arxiv.org/abs/1312.6098)

I want to understand this phenomena better, and I was thinking maybe I would do some visualization experiments involving data in 2D. Problem is, I'm not really sure how I would be able to efficiently compute the linear regions, esp. with NNs involving more than one layer. Would anyone here with more experience on this topic mind pointing me in the right direction?",2,2,False,self,,,,,
154,deeplearning,t5_2t5eh,2019-6-18,2019,6,18,3,c1ra31,medium.com,Debugging your neural net the right way!,https://www.reddit.com/r/deeplearning/comments/c1ra31/debugging_your_neural_net_the_right_way/,solitary_sandman,1560796689,,1,1,False,default,,,,,
155,deeplearning,t5_2t5eh,2019-6-18,2019,6,18,3,c1reat,medium.com,"Yoshua Bengio on the Turing Award, AI Trends, and Very Unfortunate US-China Tensions",https://www.reddit.com/r/deeplearning/comments/c1reat/yoshua_bengio_on_the_turing_award_ai_trends_and/,Yuqing7,1560797265,,0,4,False,default,,,,,
156,deeplearning,t5_2t5eh,2019-6-18,2019,6,18,6,c1t2tu,self.deeplearning,What precautions should I take while using a pre trained deep learning model?,https://www.reddit.com/r/deeplearning/comments/c1t2tu/what_precautions_should_i_take_while_using_a_pre/,bananaskywalker,1560805371,"I found a pre-trained model for a task that I am working on in my internship and its results are excellent. However, there are a few caveats:

1) It doesn't handle rotated versions of the input image very well, so I thought of fine-tuning it to fix the model.

2) However, I cannot use the model to develop the project\* as it has a non-commercial license, though it is open source. If I were to fine tune it, can I be legally allowed to call it my own or for my own use, provided I notify the original authors and I give the fine-tuned model back to them?

3) That brings me into an even murkier area, considering I am working for a company, a very small one, and I cannot really release it to be open source and I am not sure if the authors will be okay with it, if I am fine tune it and don't give back to the community.

4) Also, since it is trained on a huge dataset extensively and is currently the only solution out there that works and gives accuracy to make it viable for work.

The project is fine tune the model and develop an API for it, that is meant for commercial use.",0,1,False,self,,,,,
157,deeplearning,t5_2t5eh,2019-6-18,2019,6,18,6,c1t311,self.deeplearning,"5 minute summary of chapter 1 of ""Reinforcement Learning: An Introduction""",https://www.reddit.com/r/deeplearning/comments/c1t311/5_minute_summary_of_chapter_1_of_reinforcement/,jdyr1729,1560805398,"Hi,

I've distilled the first chapter of Sutton and Barto's book into a 5 minute summary.

I created it for myself, but thought I'd share it here for anybody who'd like a quick overview.

[https://jackdry.com/reinforcement-learning-an-introduction](https://jackdry.com/reinforcement-learning-an-introduction)

Hope you find it useful!

Jack",1,14,False,self,,,,,
158,deeplearning,t5_2t5eh,2019-6-18,2019,6,18,11,c1ws2b,i.redd.it,"Quick art by Nvidia GauGAN, this is the mountain in my dream [Site: http://52.12.58.174]",https://www.reddit.com/r/deeplearning/comments/c1ws2b/quick_art_by_nvidia_gaugan_this_is_the_mountain/,bonnieng,1560825927,,10,122,False,image,,,,,
159,deeplearning,t5_2t5eh,2019-6-18,2019,6,18,12,c1x09y,self.deeplearning,A Simple Implementation of `Neural Style in Keras` [Python],https://www.reddit.com/r/deeplearning/comments/c1x09y/a_simple_implementation_of_neural_style_in_keras/,signal_v_noise,1560827312," 

An implementation of ""A Neural Algorithm of Artistic Style"" ([http://arxiv.org/abs/1508.06576](http://arxiv.org/abs/1508.06576)) in Keras

The code present in this repository is presented in this [blog](https://medium.com/@singhal.amogh1995/utilising-cnns-to-transform-your-model-into-a-budding-artist-1330dc392e25).

The code is written in Keras 2.2.2

Link to Repo:  [https://github.com/devAmoghS/Keras-Style-Transfer](https://github.com/devAmoghS/Keras-Style-Transfer) 

[Project Preview](https://camo.githubusercontent.com/e060da134fe07f5aadf0e900a7223c407306468d/68747470733a2f2f6d656469612e67697068792e636f6d2f6d656469612f6934456c684b65704d5463495a6971636d612f67697068792e676966)",1,2,False,self,,,,,
160,deeplearning,t5_2t5eh,2019-6-18,2019,6,18,13,c1xs71,self.deeplearning,Machine Learning with AWS AI and IBM Watson,https://www.reddit.com/r/deeplearning/comments/c1xs71/machine_learning_with_aws_ai_and_ibm_watson/,HannahHumphreys,1560832370,[removed],0,1,False,self,,,,,
161,deeplearning,t5_2t5eh,2019-6-18,2019,6,18,20,c20xco,adhityamohan.in,Wrote a guide to setup fastai on your local linux machine with ease,https://www.reddit.com/r/deeplearning/comments/c20xco/wrote_a_guide_to_setup_fastai_on_your_local_linux/,Poad42,1560856149,,0,0,False,default,,,,,
162,deeplearning,t5_2t5eh,2019-6-18,2019,6,18,20,c21cq8,self.MachineLearning,[X-Post] Trying to get more views for a question I have,https://www.reddit.com/r/deeplearning/comments/c21cq8/xpost_trying_to_get_more_views_for_a_question_i/,radcapbill,1560859094,,0,1,False,default,,,,,
163,deeplearning,t5_2t5eh,2019-6-19,2019,6,19,0,c23hgy,deep-temporal-seg.informatik.uni-freiburg.de,[project] DeepTemporalSeg: Temporally Consistent Semantic Segmentation of 3D LiDAR Scans,https://www.reddit.com/r/deeplearning/comments/c23hgy/project_deeptemporalseg_temporally_consistent/,deep_descriptor,1560871034,,4,3,False,default,,,,,
164,deeplearning,t5_2t5eh,2019-6-19,2019,6,19,0,c23sbk,self.deeplearning,Help for finding research papers on RNN,https://www.reddit.com/r/deeplearning/comments/c23sbk/help_for_finding_research_papers_on_rnn/,sayan_c,1560872502,Can Someone recommend me any research papers on application of recurrent neural networks? I'd greatly appreciate any help.,2,1,False,self,,,,,
165,deeplearning,t5_2t5eh,2019-6-19,2019,6,19,1,c24oqo,self.deeplearning,Junior looking for feedback,https://www.reddit.com/r/deeplearning/comments/c24oqo/junior_looking_for_feedback/,waterchiller,1560876880,"Hi I am currently trying my hands on deep learning. And I created https://github.com/ChristianSchneeweiss/Dog-Breed-Classification/tree/master model which can predict the breed of a dog with 61% accuracy. I would love if somebody can give me feedback. 

Furthermore I do not think this accuracy is too great, as I saw a reddit post yesterday who created a model which can predict car brands and so on with a 92% accuracy.",0,0,False,self,,,,,
166,deeplearning,t5_2t5eh,2019-6-19,2019,6,19,3,c25m59,i.redd.it,Faster R-CNN Object Detection with PyTorch,https://www.reddit.com/r/deeplearning/comments/c25m59/faster_rcnn_object_detection_with_pytorch/,spmallick,1560881218,,2,30,False,image,,,,,
167,deeplearning,t5_2t5eh,2019-6-19,2019,6,19,3,c267fp,self.deeplearning,[Help] Has anyone trained Yolov3 on COCO?,https://www.reddit.com/r/deeplearning/comments/c267fp/help_has_anyone_trained_yolov3_on_coco/,pitafallafel,1560883998,"Hi, I am trying to retrain Yolov3 on COCO, using [this](https://github.com/YunYang1994/tensorflow-yolov3) repo. I twisted some stuff, changed the input pipeline but after some checks, everything seems right. Training seems to stabilize around 45%mAP@50, which is much lower than the paper (55mAP). I am wondering if maybe the hyperparameters are wrong. I used Adam(1e-4), batch size of 8. After checking several implementations (pjreddie, alexey, ultralytics), it seems they use nesterov + weight decay, with a batch size of 64, so I implemented this version too and am ready to launch it. Now I have several questions:

\- Do you think a simple change of optimizer and batch size could fix this mAP gap? 10% mAP@50 seems a lot.

\- If anyone has successfully trained it, could they share their hyperparameters (nesterov is much slower than Adam, so if a training is successful with Adam it would help a lot). There are not a lot of people on these repos that really detail their training routines, share their loss curves and show the final results.

\- Do you have some leads to debug it?

I am screwing up somewhere, and it is REALLY frustrating me. Thanks for any help",7,4,False,self,,,,,
168,deeplearning,t5_2t5eh,2019-6-19,2019,6,19,8,c298bm,self.deeplearning,"What's the ""best"" workstation for RTX 2070 &amp; an image processing project?",https://www.reddit.com/r/deeplearning/comments/c298bm/whats_the_best_workstation_for_rtx_2070_an_image/,iheartcookiecrisp,1560898905,"I'm specifically looking to get a workstation that works with NVDIA's RTX 2070 (just one) and AMD CPU (AMD Ryzen). Preferably, the workstation would have 2 GPU slots at least in case I want to add on more GPUs in the future. I know my system needs a lot of memory for the project I'm doing (involves a lot of image processing and CUDA), but other than that, I'm kind of lost as to which workstation would best suit my needs. 

&amp;#x200B;

One system that seems like it could have worked is the [TensorBook from Lambda Labs](https://lambdalabs.com/deep-learning/laptops/tensorbook/basic/customize), but it looks more like a gaming laptop than a deep learning machine.",12,7,False,self,,,,,
169,deeplearning,t5_2t5eh,2019-6-19,2019,6,19,14,c2czw2,self.deeplearning,How to do when the train image is too large to fed into the network onece time?,https://www.reddit.com/r/deeplearning/comments/c2czw2/how_to_do_when_the_train_image_is_too_large_to/,ruokuanwu,1560921853,"I'm using [voxelmorph](https://github.com/voxelmorph/voxelmorph) to do lung image registration. But my train images are too large to fed into the network, also the images have different shape, and the shape are not regular, some are 513,436...(not multiple of 2, so can not directly use U-NET or other CNN).

To address these problems, I split the train images into 128x128x128 sub-images with step=100. it looks like this: 

&amp;#x200B;

[split images](https://i.redd.it/1n8kexdiy8531.png)

In the predict phase, I also split the image into some sub-images, use the network to predict every sub-image, then I combine the results. But there is a problem that the boundaries of the sub-images look different with the internal region,like this:

&amp;#x200B;

[boundary problem](https://i.redd.it/mct36m1qy8531.png)

My naive approach is smoothig, But I found it does not work. I think this is a common problem. How to fix this? Please help.",3,0,False,self,,,,,
170,deeplearning,t5_2t5eh,2019-6-19,2019,6,19,19,c2f8df,self.deeplearning,Interviewing for Google AI Residency: My ML Journey,https://www.reddit.com/r/deeplearning/comments/c2f8df/interviewing_for_google_ai_residency_my_ml_journey/,init__27,1560939030,"Hi Everyone! 

The title really says it, I recently made it to the final rounds of the Google AI Residency interviews. This post describes my journey and experience:

&amp;#x200B;

Link to post: [https://medium.com/@init\_27/interviewing-for-google-ai-residency-a-kaggle-gold-finish-dsnet-launch-c621930b043d](https://medium.com/@init_27/interviewing-for-google-ai-residency-a-kaggle-gold-finish-dsnet-launch-c621930b043d)",4,53,False,self,,,,,
171,deeplearning,t5_2t5eh,2019-6-19,2019,6,19,20,c2fzlx,opencodez.com,A Quick Easy Guide to Deep Learning with Java  Deeplearaning4j / DL4J,https://www.reddit.com/r/deeplearning/comments/c2fzlx/a_quick_easy_guide_to_deep_learning_with_java/,Shilpa_Opencodez,1560944676,,0,2,False,default,,,,,
172,deeplearning,t5_2t5eh,2019-6-19,2019,6,19,21,c2gmi5,self.deeplearning,Short Course on DL in South Florida,https://www.reddit.com/r/deeplearning/comments/c2gmi5/short_course_on_dl_in_south_florida/,mpcrlab,1560948320," Calling all enthusiastic learners!This summer you could be part of MPCRs Deep Learning Short Course 

From August 13-16th the Machine Perception and Cognitive Robotics Laboratory will be hosting an expedited learning experience from the very basics of what deep learning is all the way to how we can apply it in our everyday endeavors! By the time you and your friends leave, youll be implementing models and heading conversations in AI. We invite you to check out this amazing opportunity at [http://mpcrlab.com/shortcourse19/](http://mpcrlab.com/shortcourse19/). Please see the details below and well look forward to seeing you soon. [Here is a link to our flyer!](https://imgur.com/a/vxC79Xh)

For any philanthropist who would like to sponsor students, please directly email: [DLshortcourse@pmcrlab.com](mailto:DLshortcourse@pmcrlab.com). People like you really do make a difference!",0,1,False,self,,,,,
173,deeplearning,t5_2t5eh,2019-6-19,2019,6,19,22,c2hf2q,self.deeplearning,[Research]Word-Level Speech Recognition With a Dynamic Lexicon,https://www.reddit.com/r/deeplearning/comments/c2hf2q/researchwordlevel_speech_recognition_with_a/,cdossman,1560952702," [https://medium.com/ai%C2%B3-theory-practice-business/achieving-efficient-direct-to-word-speech-recognition-d83eba6f57b0?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/achieving-efficient-direct-to-word-speech-recognition-d83eba6f57b0?postPublishedType=initial) 

**Abstract:**  We propose a direct-to-word sequence model with a dynamic lexicon. Our word network constructs word embeddings dynamically from the character level tokens. The word network can be integrated seamlessly with arbitrary sequence models including Connectionist Temporal Classification and encoder-decoder models with attention. Sub-word units are commonly used in speech recognition yet are generated without the use of acoustic context. We show our direct-to-word model can achieve word error rate gains over sub-word level models for speech recognition. Furthermore, we empirically validate that the word-level embeddings we learn contain significant acoustic information, making them more suitable for use in speech recognition. We also show that our direct-to-word approach retains the ability to predict words not seen at training time without any retraining.",0,2,False,self,,,,,
174,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,0,c2i96c,self.deeplearning,Machine Learning using Azure Machine Learning (AzureML),https://www.reddit.com/r/deeplearning/comments/c2i96c/machine_learning_using_azure_machine_learning/,HannahHumphreys,1560957027,[removed],0,1,False,self,,,,,
175,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,1,c2j0di,self.deeplearning,Confusion Matrix Simplified,https://www.reddit.com/r/deeplearning/comments/c2j0di/confusion_matrix_simplified/,DataScienceWithRJ,1560960815,"Confusion Matrix 
It is used to describe the performance of classifier. It can be used to derive various model evaluation metrics. 

https://youtu.be/eyLxo1ATD2Q",1,1,False,self,,,,,
176,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,2,c2jq9v,self.deeplearning,What are some beginner projects in Deep Learning.,https://www.reddit.com/r/deeplearning/comments/c2jq9v/what_are_some_beginner_projects_in_deep_learning/,reddyManudeep,1560964291,I just completed Andrew ng's specialisation.,2,1,False,self,,,,,
177,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,2,c2jqxn,freeeducationsite.com,PHP for Beginners  Become a PHP Master  CMS Project,https://www.reddit.com/r/deeplearning/comments/c2jqxn/php_for_beginners_become_a_php_master_cms_project/,Free_Education123,1560964379,,0,1,False,default,,,,,
178,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,2,c2js26,stats.stackexchange.com,Is it true that Bahdanau's attention mechanism is not Global like Luong's?,https://www.reddit.com/r/deeplearning/comments/c2js26/is_it_true_that_bahdanaus_attention_mechanism_is/,real_pinocchio,1560964530,,1,6,False,default,,,,,
179,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,3,c2knn9,self.deeplearning,Any good tutorials for using UNets for instance segmentation,https://www.reddit.com/r/deeplearning/comments/c2knn9/any_good_tutorials_for_using_unets_for_instance/,DucotrDumbutt,1560968639,"Hi guys,

I'm currently preparing for a project where I'm going to be analyzing high resolution images of some slides with organic tissue, and need to do per-pixel segmentation on each type of tissue on the slide (muscle tissue, membrane, etc.) And I'm kind of freaking out about it.

I've been looking for tutorials everywhere but they keep being coded in those infernal notebooks that I really can not use. 

I'm working on a remote gpu cluster with keras and tensorflow in python. If someone can direct me to a tutorial or a repo that does instance segmentation on images that doesn't involve stuff like ipython, jupyter, and stuff, I would REALLY appreciate that.

Thanks for the help!",6,6,False,self,,,,,
180,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,4,c2ljfl,self.deeplearning,Relational Reasoning Tasks,https://www.reddit.com/r/deeplearning/comments/c2ljfl/relational_reasoning_tasks/,lollocat3,1560972837,"I have recently read this paper on Arxiv about recurrent relational networks used to solve relational reasoning tasks: 


https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;url=https://arxiv.org/abs/1711.08028&amp;ved=2ahUKEwicnJTjmvbiAhVKY1AKHRTKBmIQFjAAegQIBxAB&amp;usg=AOvVaw2z89rvMn-uSXBe8BArUaqp&amp;cshid=1560970177794

In this paper, the author evaluates the network on the Babi and CLEVR dataset and on Sudokus with 17 givens. I was wondering if any of you knew of other relatively complex relational reasoning tasks on which I could test the architecture on.
Thanks in advance",0,5,False,self,,,,,
181,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,4,c2llnv,self.deeplearning,Best course of action for a Faster-RCNN implementation,https://www.reddit.com/r/deeplearning/comments/c2llnv/best_course_of_action_for_a_fasterrcnn/,DanMan259,1560973144,"I have a faster-rcnn caffe model that I am using, and was looking to transfer to the tensorflow object detection api. What would be the suggested method for translating the model from caffe to tensorflow.",0,4,False,self,,,,,
182,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,15,c2sgw5,arxiv.org,"SEN12MS: Largest, curated satellite imagery dataset",https://www.reddit.com/r/deeplearning/comments/c2sgw5/sen12ms_largest_curated_satellite_imagery_dataset/,burn_in_flames,1561011725,,9,17,False,default,,,,,
183,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,17,c2taom,self.deeplearning,Can anyone share simple pytorch implementation of style gan?,https://www.reddit.com/r/deeplearning/comments/c2taom/can_anyone_share_simple_pytorch_implementation_of/,sanchit2843,1561017950,,0,1,False,self,,,,,
184,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,18,c2u4q5,self.deeplearning,Deep learning models combine,https://www.reddit.com/r/deeplearning/comments/c2u4q5/deep_learning_models_combine/,nanitiru18,1561024755,How can I extend image segmentation(UNET) with a classifier for semantic segmentation to get better accuracy.,0,1,False,self,,,,,
185,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,20,c2uz37,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c2uz37/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1561030870,[removed],0,1,False,self,,,,,
186,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,22,c2vv9h,self.deeplearning,Visualizing CNN filters,https://www.reddit.com/r/deeplearning/comments/c2vv9h/visualizing_cnn_filters/,PyWarrior,1561036381,"I want to learn the entire concept of **Visualizing CNN filters**. I have googled many articles over the internet regarding this but I couldn't find any detailed article. 

I want to gain insight over the mathematical concept involved.",17,23,False,self,,,,,
187,deeplearning,t5_2t5eh,2019-6-20,2019,6,20,23,c2wmmx,self.deeplearning,Tensorflow facenet,https://www.reddit.com/r/deeplearning/comments/c2wmmx/tensorflow_facenet/,alexjolly28,1561040581,"is there anyone who worked with Tensorflow facenet... I'm stuck at validation code...
thank you",0,1,False,self,,,,,
188,deeplearning,t5_2t5eh,2019-6-21,2019,6,21,0,c2xf2o,self.deeplearning,"[Project] Tensorflow implementation of ""Zero-Shot Knowledge Distillation in Deep Networks """,https://www.reddit.com/r/deeplearning/comments/c2xf2o/project_tensorflow_implementation_of_zeroshot/,sseung0703,1561044545,[removed],0,1,False,self,,,,,
189,deeplearning,t5_2t5eh,2019-6-21,2019,6,21,3,c2zrg7,rsipvision.com,"CVPR Daily of today, Thursday 20 June - Directly from CVPR 2019 in Long Beach",https://www.reddit.com/r/deeplearning/comments/c2zrg7/cvpr_daily_of_today_thursday_20_june_directly/,Gletta,1561055918,,0,1,False,default,,,,,
190,deeplearning,t5_2t5eh,2019-6-21,2019,6,21,13,c35x26,self.deeplearning,Best GPU for machine learning / deep learning,https://www.reddit.com/r/deeplearning/comments/c35x26/best_gpu_for_machine_learning_deep_learning/,durgesh2018,1561090242,"Hello everyone!
I want to upgrade my existing GTX 950 for deep learning purpose. Please suggest me a decent GPU under 500 USD.

My build is:
Intel dh87RL mother board
Intel i5 4670 processor
Samsung 256 GB SSD
Corsair VS 550 PSU

Thank you!",15,2,False,self,,,,,
191,deeplearning,t5_2t5eh,2019-6-21,2019,6,21,13,c35y66,youtube.com,Donald Trump Reads The Navy Seal Copypasta (Deepfake),https://www.reddit.com/r/deeplearning/comments/c35y66/donald_trump_reads_the_navy_seal_copypasta/,hanyuqn,1561090440,,0,16,False,image,,,,,
192,deeplearning,t5_2t5eh,2019-6-21,2019,6,21,19,c38ugx,blog.tensorpad.com,A comprehensive intro to PyTorch,https://www.reddit.com/r/deeplearning/comments/c38ugx/a_comprehensive_intro_to_pytorch/,whitezl0,1561112180,,2,43,False,default,,,,,
193,deeplearning,t5_2t5eh,2019-6-21,2019,6,21,19,c392ah,coursera.org,Course 3 of the deeplearning.ai TensorFlow Specialization is now available: TensorFlow in Practice | Coursera,https://www.reddit.com/r/deeplearning/comments/c392ah/course_3_of_the_deeplearningai_tensorflow/,lopespm,1561113897,,2,17,False,default,,,,,
194,deeplearning,t5_2t5eh,2019-6-21,2019,6,21,21,c3a74w,blog.floydhub.com,Generative Adversarial Networks - The Story So Far,https://www.reddit.com/r/deeplearning/comments/c3a74w/generative_adversarial_networks_the_story_so_far/,pirate7777777,1561121615,,0,29,False,default,,,,,
195,deeplearning,t5_2t5eh,2019-6-21,2019,6,21,21,c3a8xq,self.deeplearning,[Research] Toward Interpretable Music Tagging with Self-Attention,https://www.reddit.com/r/deeplearning/comments/c3a8xq/research_toward_interpretable_music_tagging_with/,cdossman,1561121915," [https://medium.com/ai%C2%B3-theory-practice-business/toward-interpretable-music-tagging-with-self-attention-67a8136048d0?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/toward-interpretable-music-tagging-with-self-attention-67a8136048d0?postPublishedType=initial) 

**Abstract:**  Self-attention is an attention mechanism that learns a representation by relating different positions in the sequence. The transformer, which is a sequence model solely based on self-attention, and its variants achieved state-of-the-art results in many natural language processing tasks. Since music composes its semantics based on the relations between components in sparse positions, adopting the self-attention mechanism to solve music information retrieval (MIR) problems can be beneficial. Hence, we propose a self-attention based deep sequence model for music tagging. The proposed architecture consists of shallow convolutional layers followed by stacked Transformer encoders. Compared to conventional approaches using fully convolutional or recurrent neural networks, our model is more interpretable while reporting competitive results. We validate the performance of our model with the MagnaTagATune and the Million Song Dataset. In addition, we demonstrate the interpretability of the proposed architecture with a heat map visualization.",0,1,False,self,,,,,
196,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,0,c3bqgg,self.deeplearning,Deep Learning Machine Shutting Off When Using Both GPUs,https://www.reddit.com/r/deeplearning/comments/c3bqgg/deep_learning_machine_shutting_off_when_using/,clarke_msmd,1561129647,"I have been using my machine for a couple of months now to successfully train 3d CNNs. However, recently if I try to train a model using both GPUs, the machine (along with all of the lights on the motherboard) will turn off. The only way to turn the machine back on again is to unplug the PSU, wait \~30 sec and plug back in again. I can still use each card individually, just not at the same time. Any ideas as to what could be going on?

&amp;#x200B;

Motherboard: Asrock Taichi X399

CPU: AMD Threadripper 2950x

GPU: 2x EVGA 2080ti Black edition

PSU: EVGA Supernova 1000 PQ 80+ Platinum

RAM: 4x Corsair LPX 2666 Hz 16 GB

SSD: Samsung 970 Evo 500GB

SSD: Samsung 860 Evo 2TB",4,2,False,self,,,,,
197,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,3,c3eae8,self.deeplearning,[D] Any references for deep learning on non uniform and unstructured meshes/ grids?,https://www.reddit.com/r/deeplearning/comments/c3eae8/d_any_references_for_deep_learning_on_non_uniform/,pradeep_sinngh,1561141161,,1,5,False,self,,,,,
198,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,4,c3f2sx,self.deeplearning,"[Revision/Study Group] fast.ai Part 1 2019, Saturdays 4PM IST (Zoom calls)",https://www.reddit.com/r/deeplearning/comments/c3f2sx/revisionstudy_group_fastai_part_1_2019_saturdays/,init__27,1561144745,[removed],0,1,False,self,,,,,
199,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,5,c3fuhs,self.deeplearning,Hello guys this is one of my project based on face recognition.,https://www.reddit.com/r/deeplearning/comments/c3fuhs/hello_guys_this_is_one_of_my_project_based_on/,Ckvb,1561148337,"https://github.com/CKVB/FACE-RECOGNITION-BASED-SMART-ATTENDANCE-MANAGMENT-SYSTEM-USING-DLIB/blob/master/README.md

I would like to hear some feedback if any.",0,0,False,self,,,,,
200,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,6,c3h3z2,self.deeplearning,Giving my future reinforced neural network a little boost to learn to play a game,https://www.reddit.com/r/deeplearning/comments/c3h3z2/giving_my_future_reinforced_neural_network_a/,elmazzun,1561154352,"I'm making a neural network that can play The Binding of Isaac.  
Up now, this is what I planned to do:

1. feed YOLO or OpenCV with screenshots from running game;
2. teach the vision library to detect in-game objects: enemies, items, walls, rocks, ...
3. train a reinforced neural network to take decisions according to game events from screenshots.

In all the articles I read about reinforcement learning (offline Chrome dinosaur jumping trees, Flappy Birds, Snake, ...) the neural network is abandoned to itself, making random movements, taking damage, dying, getting a penalty and so on, generation by generation, until it learns how to stay alive.

This is the ""boost"" I wrote about in the title: *instead of making the poor Isaac randomly dying until he learns, is it possible to make him learn by some actual gameplays of mine?*

Let me explain: it would be nice seeing little Isaac making his way through all the enemies, but it would be nicer to make him do more.

* there are hidden rooms: you should blow up a wall in order to discover a hidden room, but you must use bombs which are not infinite; the net can't blow up every wall of the game, not enough bombs and there should be a pattern to discover hidden rooms;
* by learning from my gameplays, the net may learn a not perfect gameplay and I may contaminate its learning, but at least he would not take hundreds of generations to learn that getting hit is not good;
* there are items that have more sinergies with others, but there are so many items that it would faster to code these sinergies and just train the vision library to detect items;
* after defeating a boss, there are choices: go to the next level, go to the bonus room, go back to do something that was not possible to do prior defeting the boss, ...

I'd code what can be coded (like item sinergies), but all other possibilities may be learned from a gameplay, that would be worth hundreds of line codes!  


Back to my original question: I'd like to be a more present father to Isaac and give him some life tips with my gameplays instead of letting him roaming wild xD

What I miss is some theory about this reinforcement learning: **is it possible / advisable / recommended to provide a hybrid learning to this neural network**?  
Is it right to make him learn the basics of the game with my gameplays and then let him walk on his feet with what I taught him?

&amp;#x200B;

Thanks in advance for the support. If this project will sail, I'd love to share my GitHub with you.",1,2,False,self,,,,,
201,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,7,c3hpbq,blog.paperspace.com,Building a CIFAR classifier neural network with PyTorch,https://www.reddit.com/r/deeplearning/comments/c3hpbq/building_a_cifar_classifier_neural_network_with/,coffeepants87,1561157321,,0,0,False,default,,,,,
202,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,14,c3lo0m,self.deeplearning,"Not sure if this is the correct thread, GPU related.",https://www.reddit.com/r/deeplearning/comments/c3lo0m/not_sure_if_this_is_the_correct_thread_gpu_related/,Ryzen120,1561180494,"So hoping someone in this thread can help or direct me to the correct place. Anyways, can one run a Teska k80 GPU for their training models while using another AMD card to just display graphics and do other basic activities while the model is trained using tensorflow ?",3,3,False,self,,,,,
203,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,20,c3ojdp,self.deeplearning,Using deep learning for indoor autonomous navigation of a small quad-rotor. Need help with research,https://www.reddit.com/r/deeplearning/comments/c3ojdp/using_deep_learning_for_indoor_autonomous/,atmadeepArya,1561202268,"Hi, So for my masters thesis, I want to make a neural network for indoor navigation of a small quad-rotor. The data will be generated initially by a simulation, and then I want to test it in real world. I need help on the following topics:

1. Can you guys help with some research papers of your choice?
2. Which universities/ research groups are doing/interested in this kind of work?
3. What are the absolute basics which I should know before proceeding?

I only have about a year to complete this project (integrated course) so I'm looking for something not-so-difficult.",1,5,False,self,,,,,
204,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,22,c3pisk,self.deeplearning,Google Colab: FileNotFoundError,https://www.reddit.com/r/deeplearning/comments/c3pisk/google_colab_filenotfounderror/,DebayonDC,1561209019,"`# Run this cell to mount your Google Drive.`

`from google.colab import drive`

`drive.mount('/content/drive')`

&amp;#x200B;

I used the above code as given by the Google colab and drive got mounted successfully but I get a ""File Not Found Error"" when trying to import some data from Google Drive. Someone kindly help me out. The Code that I used for importing data (""images in this case"") is as follows:

&amp;#x200B;

&lt;&gt;

`training_set = train_datagen.flow_from_directory(`

`'content/drive/My Drive/Colab_Data/dataset/training_set',`

`target_size=(64, 64),`

`batch_size=32,`

`class_mode='binary')`

&lt;/&gt;

and the output of the Notebook Error is as follows:

&lt;&gt;

 \--------------------------------------------------------------------------- FileNotFoundError                         Traceback (most recent call last) [&lt;ipython-input-13-ffd4a90d6c52&gt;](https://localhost:8080/#) in &lt;module&gt;()       **3** target\_size=(64, 64),       **4** batch\_size=32, ----&gt; 5         class\_mode='binary')  1 frames[/usr/local/lib/python3.6/dist-packages/keras\_preprocessing/image/image\_data\_generator.py](https://localhost:8080/#) in flow\_from\_directory(self, directory, target\_size, color\_mode, classes, class\_mode, batch\_size, shuffle, seed, save\_to\_dir, save\_prefix, save\_format, follow\_links, subset, interpolation)     **538** follow\_links=follow\_links,     **539** subset=subset, --&gt; 540 interpolation=interpolation     **541**         )     **542**   [/usr/local/lib/python3.6/dist-packages/keras\_preprocessing/image/directory\_iterator.py](https://localhost:8080/#) in \_\_init\_\_(self, directory, image\_data\_generator, target\_size, color\_mode, classes, class\_mode, batch\_size, shuffle, seed, data\_format, save\_to\_dir, save\_prefix, save\_format, follow\_links, subset, interpolation, dtype)     **104** if not classes:     **105** classes = \[\] --&gt; 106 for subdir in sorted(os.listdir(directory)):     **107** if os.path.isdir(os.path.join(directory, subdir)):     **108** classes.append(subdir)  FileNotFoundError: \[Errno 2\] No such file or directory: 'content/drive/My Drive/Colab\_Data/dataset/training\_set' 

&lt;/&gt;",9,5,False,self,,,,,
205,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,22,c3pkp3,self.deeplearning,Deep learning - price prediction - papers/code,https://www.reddit.com/r/deeplearning/comments/c3pkp3/deep_learning_price_prediction_paperscode/,_synaps_,1561209338,"Hi,

do you know any nice state of the deep learning algorithms or research papers which are treating the topic price prediction or trading suggestion?

thnx!",2,22,False,self,,,,,
206,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,23,c3q5uc,self.deeplearning,A question about text prediction RNNs,https://www.reddit.com/r/deeplearning/comments/c3q5uc/a_question_about_text_prediction_rnns/,ivxnc,1561212819,"So I want to create a word predict RNN that I am going to feed with the books from one author(I want to capture his style). So when I started thinking about the process, I  got confused by the following: Would training a RNN with one book at a time, then saving it's weights for the next book and so on be the same as loading the same RNN with all of the books at once(if not, which do you think would be better and why). I'm learning ML/DL since January, and this question never occured me really. It's probably very intuitive, but I can't get around it. Thanks in advance",4,4,False,self,,,,,
207,deeplearning,t5_2t5eh,2019-6-22,2019,6,22,23,c3qahv,intellectyx.com,How Hadoop Helps Solve the Big Data Problem?,https://www.reddit.com/r/deeplearning/comments/c3qahv/how_hadoop_helps_solve_the_big_data_problem/,raj11113,1561213553,,0,2,False,default,,,,,
208,deeplearning,t5_2t5eh,2019-6-23,2019,6,23,0,c3qy0d,self.deeplearning,IBM Data Science Professional Certificate,https://www.reddit.com/r/deeplearning/comments/c3qy0d/ibm_data_science_professional_certificate/,HannahHumphreys,1561217051,[removed],0,1,False,self,,,,,
209,deeplearning,t5_2t5eh,2019-6-23,2019,6,23,0,c3r77w,blockdelta.io,Robotics Revolution in Healthcare Industry - Introduction,https://www.reddit.com/r/deeplearning/comments/c3r77w/robotics_revolution_in_healthcare_industry/,BlockDelta,1561218424,,0,1,False,default,,,,,
210,deeplearning,t5_2t5eh,2019-6-23,2019,6,23,1,c3rr73,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c3rr73/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1561221249,[removed],0,1,False,self,,,,,
211,deeplearning,t5_2t5eh,2019-6-23,2019,6,23,1,c3s1l4,self.deeplearning,Indoor localizations and NN/DNN papers,https://www.reddit.com/r/deeplearning/comments/c3s1l4/indoor_localizations_and_nndnn_papers/,konradbjk,1561222674,"Hello,

I am looking for papers about usage of neural or deep neural networks to predict signal errors. Preferably in area of indoor localizations.",3,1,False,self,,,,,
212,deeplearning,t5_2t5eh,2019-6-23,2019,6,23,2,c3s349,self.learnmachinelearning,Correct way for transfer learning?,https://www.reddit.com/r/deeplearning/comments/c3s349/correct_way_for_transfer_learning/,waterchiller,1561222876,,1,2,False,default,,,,,
213,deeplearning,t5_2t5eh,2019-6-23,2019,6,23,12,c3yvrb,self.deeplearning,What's the actual reason for exploding gradients?,https://www.reddit.com/r/deeplearning/comments/c3yvrb/whats_the_actual_reason_for_exploding_gradients/,revolutionizescience,1561262297,"In case of vanishing gradients,
1. We know that product of 2 numbers between (0,1) gives still smaller number. 
eg: 0.1 * 0.3 = 0.03
2. So if gradients are smaller then in  case of deep network ,this effects the earlier layers. 
eg. (0.5)^10 = exponentially small. 
3. But why does gradients are smaller in the first place, because we can see that by the graph of derivative of sigmoid or tanh . The range is (0,0.25) for sigmoid and (0,1) for tanh.

So, I want to understand that how does gradients become larger, which in turn causes exploding gradient problem. Help needed.",14,3,False,self,,,,,
214,deeplearning,t5_2t5eh,2019-6-23,2019,6,23,16,c40qff,self.deeplearning,Performance on CPU vs GPU.,https://www.reddit.com/r/deeplearning/comments/c40qff/performance_on_cpu_vs_gpu/,lxknvlk,1561275934," 

I was making load tests on a model that classifies nsfw images. I was expecting the performance on a high end GPU to be better.

&amp;#x200B;

1) aws c5.large instance (2vCPU, 4 gm mem) using caffe-cpu : processing an image takes about 700ms

2) aws p3.2xlarge specialized deep learning GPU instance with a Tesla V100 GPU, (16gb gpu mem, 8 vCPU, 61gb mem), using caffe-gpu with cuda, cudnn, and all that stuff - and it processes the image in about 950ms.

I expected the processing time to be much faster. Am I misunderstanding something?",9,13,False,self,,,,,
215,deeplearning,t5_2t5eh,2019-6-24,2019,6,24,10,c4gdgv,self.deeplearning,I wrote my first blog on RNNs!,https://www.reddit.com/r/deeplearning/comments/c4gdgv/i_wrote_my_first_blog_on_rnns/,MLnub22,1561339965,"Hi all, I just wrote my first blog on RNNs and was hoping to get some feedback. This blog post is my current understanding of RNNs, so it would be great to know if what I think I know about RNNs are wrong (especially the math / backpropagation part). 

&amp;#x200B;

Big thanks in advance. I'm open to any discussion around the topic!",3,28,False,self,,,,,
216,deeplearning,t5_2t5eh,2019-6-24,2019,6,24,11,c4gy3l,blockdelta.io,Edge Computing - Event Horizon Part I,https://www.reddit.com/r/deeplearning/comments/c4gy3l/edge_computing_event_horizon_part_i/,BlockDelta,1561342718,,0,0,False,default,,,,,
217,deeplearning,t5_2t5eh,2019-6-24,2019,6,24,12,c4hnfu,medium.com,Label Smoothing: An ingredient of higher accuracy when there is mislabeled data,https://www.reddit.com/r/deeplearning/comments/c4hnfu/label_smoothing_an_ingredient_of_higher_accuracy/,solitary_sandman,1561346977,,0,12,False,default,,,,,
218,deeplearning,t5_2t5eh,2019-6-24,2019,6,24,14,c4ipzn,youtube.com,Style Transfer Medley,https://www.reddit.com/r/deeplearning/comments/c4ipzn/style_transfer_medley/,dstein64,1561353911,,0,0,False,default,,,,,
219,deeplearning,t5_2t5eh,2019-6-24,2019,6,24,15,c4jfmp,github.com,"Tips for making a GAN's outputs more diverse? This one works fine, but seems to lack variety.",https://www.reddit.com/r/deeplearning/comments/c4jfmp/tips_for_making_a_gans_outputs_more_diverse_this/,patr1234,1561359072,,2,2,False,default,,,,,
220,deeplearning,t5_2t5eh,2019-6-24,2019,6,24,17,c4k533,self.deeplearning,Attention Mechanisms Implementation,https://www.reddit.com/r/deeplearning/comments/c4k533/attention_mechanisms_implementation/,pylocke,1561364479,"Hi everyone! Attention has been a hot topic in computer vision and natural language processing for a while. While trying to use attention mechanism in a language modeling RNN project of mine, I came up across countless different implementations online. Most of them differed from what I expected to see by reading the papers that introduced the concepts to the domain in the first place, and the challenge doubled since I was trying to use attention for a many-to-one sequence task instead of the conventional many-to-many.

Hence, I created my own implementations and I want to share them with you here in case anyone is going through the same path or just wants to learn about the different attention mechanisms: [https://github.com/ongunuzaymacar/attention-mechanisms](https://github.com/ongunuzaymacar/attention-mechanisms). It includes implementations of various papers and I am hoping to extend it as I encounter different versions. Feel free to share your opinions with me in case you spot something odd or have a suggestion!",0,5,False,self,,,,,
221,deeplearning,t5_2t5eh,2019-6-24,2019,6,24,21,c4n9en,self.deeplearning,Advice on how to pick the right architecture,https://www.reddit.com/r/deeplearning/comments/c4n9en/advice_on_how_to_pick_the_right_architecture/,zerociudo,1561380734,"Hello, I am creating a car licence plate detection and recognition model for learning purposes and I cant wrap my head around the many architecture choices I have. Basically I am think of using YOLO v2 or v3 to detect the vehicle and the licence plate, then use character segmentation and recognition to extract licence plate characters.

I have seen couple of YOLO v2 papers and I could use architecture similar to DarkNet-19 but I feel like it is quite a lot layers for this problem if I assume that I will have only 1 licence plate per image on my dataset. 

A lot of papers use customized YOLOv2 architectures that I have read and I am not sure how could I customize it for my problem exactly, I did study CNN architectures, but I do not have the intuition for picking right filters sizes or layers amount.

Are there some references on this that I could read/watch or which architecture you would advice?",6,20,False,self,,,,,
222,deeplearning,t5_2t5eh,2019-6-24,2019,6,24,23,c4p8te,self.deeplearning,[Research] Adversarial Attacks on Copyright Detection Systems,https://www.reddit.com/r/deeplearning/comments/c4p8te/research_adversarial_attacks_on_copyright/,cdossman,1561388109," [https://medium.com/ai%C2%B3-theory-practice-business/adversarial-attacks-on-copyright-detection-systems-3dacc64d9702?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/adversarial-attacks-on-copyright-detection-systems-3dacc64d9702?postPublishedType=initial) 

 It is well-known that many machine learning models are susceptible to so-called ""adversarial attacks,"" in which an attacker evades a classifier by making small perturbations to inputs. This paper discusses how industrial copyright detection tools, which serve a central role on the web, are susceptible to adversarial attacks. We discuss a range of copyright detection systems, and why they are particularly vulnerable to attacks. These vulnerabilities are especially apparent for neural network based systems. As a proof of concept, we describe a well-known music identification method, and implement this system in the form of a neural net. We then attack this system using simple gradient methods. Adversarial music created this way successfully fools industrial systems, including the AudioTag copyright detector and YouTubes Content ID system. Our goal is to raise awareness of the threats posed by adversarial examples in this space, and to highlight the importance of hardening copyright detection systems to attacks.",0,15,False,self,,,,,
223,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,0,c4pxyr,self.deeplearning,"A PyTorch implementation of ""Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks"" (KDD 2019)",https://www.reddit.com/r/deeplearning/comments/c4pxyr/a_pytorch_implementation_of_clustergcn_an/,benitorosenberg,1561390503,"&amp;#x200B;

https://i.redd.it/b4rp0143qb631.jpg

GitHub: [https://github.com/benedekrozemberczki/ClusterGCN](https://github.com/benedekrozemberczki/ClusterGCN)

Paper: [https://arxiv.org/abs/1905.07953](https://arxiv.org/abs/1905.07953)

Abstract:

Graph  convolutional network (GCN) has been successfully applied to many   graph-based applications; however, training a large-scale GCN remains   challenging. Current SGD-based algorithms suffer from either a high   computational cost that exponentially grows with number of GCN layers,   or a large space requirement for keeping the entire graph and the   embedding of each node in memory. In this paper, we propose Cluster-GCN,   a novel GCN algorithm that is suitable for SGD-based training by   exploiting the graph clustering structure. Cluster-GCN works as the   following: at each step, it samples a block of nodes that associate with   a dense subgraph identified by a graph clustering algorithm, and   restricts the neighborhood search within this subgraph. This simple but   effective strategy leads to significantly improved memory and   computational efficiency while being able to achieve comparable test   accuracy with previous algorithms. To test the scalability of our   algorithm, we create a new Amazon2M data with 2 million nodes and 61   million edges which is more than 5 times larger than the previous   largest publicly available dataset (Reddit). For training a 3-layer GCN   on this data, Cluster-GCN is faster than the previous state-of-the-art   VR-GCN (1523 seconds vs 1961 seconds) and using much less memory (2.2GB   vs 11.2GB). Furthermore, for training 4 layer GCN on this data, our   algorithm can finish in around 36 minutes while all the existing GCN   training algorithms fail to train due to the out-of-memory issue.   Furthermore, Cluster-GCN allows us to train much deeper GCN without much   time and memory overhead, which leads to improved prediction   accuracy---using a 5-layer Cluster-GCN, we achieve state-of-the-art test   F1 score 99.36 on the PPI dataset, while the previous best result was   98.71.",0,1,False,self,,,,,
224,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,0,c4pzb6,self.deeplearning,Deep Learning Project,https://www.reddit.com/r/deeplearning/comments/c4pzb6/deep_learning_project/,harsh_sagar,1561390634,"Hi Everyone!

I    am sharing the GitHub link to my project 'Image Classification on  Fashion-MNIST dataset using CNN' . I have tried to write a well  commented code, so that   anyone can learn from it. I have also added  some presentation slides for better understanding.

The project is done on Fashion-Mnist dataset  which can be downloaded from Kaggle.

[https://github.com/harshgarg27/LastAssignment\_DeepLeraning\_CNN\_Classification](https://github.com/harshgarg27/LastAssignment_DeepLeraning_CNN_Classification)

Feel free to give suggestions and reviews.

Thanks!",1,2,False,self,,,,,
225,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,1,c4r1cw,self.deeplearning,I wanted to ask about the inpainting results from all major papers (GAN based approach)?,https://www.reddit.com/r/deeplearning/comments/c4r1cw/i_wanted_to_ask_about_the_inpainting_results_from/,nile6499,1561394292,"The model trained and tested on is often CelebA (Aligned), which results in generating over fitted images. The conference really don't care about over fitting of GANs on a particular dataset? I believe training should be on different dataset than testing.

Training on CelebA, and testing on LFW makes more sense rather than generating over fitted images.",1,5,False,self,,,,,
226,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,5,c4v56s,self.deeplearning,dnn Compiler,https://www.reddit.com/r/deeplearning/comments/c4v56s/dnn_compiler/,srohit0,1561408306,"Calling all  developers and deep learning enthusiasts for [opensource](https://twitter.com/hashtag/opensource?src=hashtag_click) [\#deeplearning](https://twitter.com/hashtag/deeplearning?src=hashtag_click) [\#compiler](https://twitter.com/hashtag/compiler?src=hashtag_click) [\#development](https://twitter.com/hashtag/development?src=hashtag_click)  targets for [\#ComputerVision](https://twitter.com/hashtag/ComputerVision?src=hashtag_click) [\#embedded](https://twitter.com/hashtag/embedded?src=hashtag_click) [\#application](https://twitter.com/hashtag/application?src=hashtag_click) on [\#platforms](https://twitter.com/hashtag/platforms?src=hashtag_click) like [\#riscV](https://twitter.com/hashtag/riscV?src=hashtag_click) and  [\#RaspberryPi](https://twitter.com/hashtag/RaspberryPi?src=hashtag_click).

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/9olbapry6d631.png",1,0,False,self,,,,,
227,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,5,c4vd4b,self.deeplearning,Can't fine tune VGG16 to classify dog breeds,https://www.reddit.com/r/deeplearning/comments/c4vd4b/cant_fine_tune_vgg16_to_classify_dog_breeds/,reddyManudeep,1561409080,"I fine-tuned VGG-16 to classify dog breeds using the Stanford Dog dataset with 120 classes.

I removed the FC layers and added a Dense(4096) and Dense(120, softmax). First, for a few epochs, I froze the layers of base vgg-16 to warm up FC layers.( With small learning rate)

After that, I unfroze the last block of Conv layers and trained the model. But still I am not able to achieve a decent acc/val_acc. Is there anything that I can fix? or should I consider fine-tuning other models like resnet etc?",10,4,False,self,,,,,
228,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,10,c4ztzh,self.deeplearning,computer vision article,https://www.reddit.com/r/deeplearning/comments/c4ztzh/computer_vision_article/,iraf1,1561425583,"hi
I am working in robotics field and computer vision.
I want to write an ISI article about deeplearning and computer vision. can someone help me to pick an up to date and practical subject.
thanks",0,1,False,self,,,,,
229,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,10,c506r5,self.deeplearning,Image Sequence to Image Sequence Architecture,https://www.reddit.com/r/deeplearning/comments/c506r5/image_sequence_to_image_sequence_architecture/,pmpforever,1561426960,"I have a problem where my data set is a sequence of (satellite) images and I would like to write a model which takes a sequence of images and generates a sequence of new images. These new images are novel but similar to their predecessors. I don't have too much experience with Deep Learning, I understand CNNs and RNNs and bit about LSTMs and GRUs. What kinds of architectures should I look at for solving this type of problem?",3,2,False,self,,,,,
230,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,12,c51pgh,self.deeplearning,GTX 1080 ti or RTX 2060,https://www.reddit.com/r/deeplearning/comments/c51pgh/gtx_1080_ti_or_rtx_2060/,durgesh2018,1561433438,"Hello everyone,
I am planning to buy a GPU for tinkering with machine learning and deep learning.

Please suggest me a card in 1080ti and RTX 2060.

My budget is 500 USD in Indian market.",34,15,False,self,,,,,
231,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,12,c522wr,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c522wr/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1561435190,[removed],0,1,False,self,,,,,
232,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,13,c52g3y,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c52g3y/data_science_career_track_prep_course/,HannahHumphreys,1561436951,[removed],0,1,False,self,,,,,
233,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,15,c545jl,self.deeplearning,Pytorch 1.0 tutorials??,https://www.reddit.com/r/deeplearning/comments/c545jl/pytorch_10_tutorials/,kunalkarda,1561445691,"I want to learn pytorch but all tuts available on github and on websites are of ver 0.4 
So anyone has some link ??",2,1,False,self,,,,,
234,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,16,c548xz,self.deeplearning,Google Colab,https://www.reddit.com/r/deeplearning/comments/c548xz/google_colab/,zom8ie99,1561446189,I trained the model using Kaggle GPU. and now I want to try Google Collab's TPU for training the CNN model. So I wanted to know if there are any issues in training the dataset using google colab.,19,6,False,self,,,,,
235,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,18,c55olf,self.deeplearning,Introducing deep learning,https://www.reddit.com/r/deeplearning/comments/c55olf/introducing_deep_learning/,itspcificp,1561454403,"Dont believe in short term hype, but do believe in long-term vision by Prashant rai https://link.medium.com/pjvwEimUNX",0,1,False,self,,,,,
236,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,19,c56ddq,stackoverflow.com,How to decode an image on the GPU while training a network in Keras?,https://www.reddit.com/r/deeplearning/comments/c56ddq/how_to_decode_an_image_on_the_gpu_while_training/,ale152,1561458195,,0,1,False,default,,,,,
237,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,23,c59nk5,self.deeplearning,[Research] Google AI: Applying AutoML to Transformer Architectures,https://www.reddit.com/r/deeplearning/comments/c59nk5/research_google_ai_applying_automl_to_transformer/,cdossman,1561474136," [https://medium.com/ai%C2%B3-theory-practice-business/google-ai-applying-automl-to-transformer-architectures-fd2e8402d2f7?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/google-ai-applying-automl-to-transformer-architectures-fd2e8402d2f7?postPublishedType=initial) 

Google AI conducted a large-scale NAS on translation task and discovered the Evolved Transformer (ET). Like most sequence to sequence (seq2seq) neural network architectures, it has an encoder that encodes the input sequence into embeddings and a decoder that uses those embeddings to construct an output sequence; in the case of translation, the input sequence is the sentence to be translated and the output sequence is the translation.",3,1,False,self,,,,,
238,deeplearning,t5_2t5eh,2019-6-25,2019,6,25,23,c59nzk,labs.eleks.com,Neural Machine Translation With Attention Mechanism: Step-by-step Guide,https://www.reddit.com/r/deeplearning/comments/c59nzk/neural_machine_translation_with_attention/,Victor_Stakh,1561474189,,0,1,False,default,,,,,
239,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,0,c59zo1,medium.com,"Supervisely June Update: Keypoints, Python Scripts, and more!",https://www.reddit.com/r/deeplearning/comments/c59zo1/supervisely_june_update_keypoints_python_scripts/,tdionis,1561475564,,0,1,False,default,,,,,
240,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,0,c5aic6,intellectyx.com,How big data is transforming the real estate industry,https://www.reddit.com/r/deeplearning/comments/c5aic6/how_big_data_is_transforming_the_real_estate/,raj11113,1561477719,,0,10,False,default,,,,,
241,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,2,c5byyi,self.deeplearning,Deep Learning Research 2019,https://www.reddit.com/r/deeplearning/comments/c5byyi/deep_learning_research_2019/,selfcreation,1561483582,"Hi everyone!  
I just did a quick Web of Science analysis on deep learning research. As you can see in the screenshot below, there are about 7.000 publications for 2019. Since we're about half into the year, can you say that the publication count will double until the end of 2019? Which would mean that it would be less than 2018?

Thank you for your help!

https://i.redd.it/7c414ptiej631.png",0,1,False,self,,,,,
242,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,2,c5c6bw,i.redd.it,"#Learn how to make sure you are getting the best #predictions your model can provide. https://buff.ly/2ZFXbr4 @Experfy #MachineLearning #modeltuning #experfy #experfytraining #courses #ai For more courses, visit experfy.com/training",https://www.reddit.com/r/deeplearning/comments/c5c6bw/learn_how_to_make_sure_you_are_getting_the_best/,tstanya77,1561484397,,0,1,False,image,,,,,
243,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,3,c5cnpv,i.redd.it,Mask R-CNN Instance Segmentation with PyTorch,https://www.reddit.com/r/deeplearning/comments/c5cnpv/mask_rcnn_instance_segmentation_with_pytorch/,spmallick,1561486309,,2,58,False,image,,,,,
244,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,3,c5cuez,experfy.com,Learn the fundamentals of deep learning and neural network models.,https://www.reddit.com/r/deeplearning/comments/c5cuez/learn_the_fundamentals_of_deep_learning_and/,VeenaBhargavi,1561487064,,0,0,False,default,,,,,
245,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,11,c5jqq6,self.deeplearning,Implementation of 19 Regression algorithms in R using CPU performance data.,https://www.reddit.com/r/deeplearning/comments/c5jqq6/implementation_of_19_regression_algorithms_in_r/,HannahHumphreys,1561516249,[removed],0,1,False,self,,,,,
246,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,12,c5kj4y,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/c5kj4y/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1561520197,[removed],0,1,False,self,,,,,
247,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,13,c5kx3n,i.redd.it,How does it work?,https://www.reddit.com/r/deeplearning/comments/c5kx3n/how_does_it_work/,Sahil8141,1561522226,,5,1,False,image,,,,,
248,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,18,c5nr2e,i.redd.it,Practical deep learning for coders,https://www.reddit.com/r/deeplearning/comments/c5nr2e/practical_deep_learning_for_coders/,freevideolectures,1561541654,,1,0,False,image,,,,,
249,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,20,c5ohsn,arxiv.org,Generating Question-Answer Hierarchies,https://www.reddit.com/r/deeplearning/comments/c5ohsn/generating_questionanswer_hierarchies/,rahulbhalley,1561547238,,0,8,False,default,,,,,
250,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,22,c5pmec,self.deeplearning,how to call embed .py script to c# ?,https://www.reddit.com/r/deeplearning/comments/c5pmec/how_to_call_embed_py_script_to_c/,lacaai,1561554555,"Hey, I need help, how can I call a .py script from C#?  


I want to call a python script, which is not an .exe.  
The best would be, that I should not install python, nor the libaries, like tensorflow or keras, just add the dlls or dependencies and it would works nicely.",0,1,False,self,,,,,
251,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,23,c5qagn,self.deeplearning,Using GPT-2 to gennerate realistic text,https://www.reddit.com/r/deeplearning/comments/c5qagn/using_gpt2_to_gennerate_realistic_text/,saravanakumar17,1561558274,"(there are a few spelling mistake in the source text don't mind it) I recently used gpt-2 to generate text and got blown away by the kind of output text accuracy it can deliver. 

[Just for testing purpose only, don't take it seriously.](https://i.redd.it/d6tr4ofskp631.png)",0,2,False,self,,,,,
252,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,23,c5qm08,webinars.on24.com,July 11 Talk on Deep Learning with ACM A.M. Turing Laureate Yann LeCun,https://www.reddit.com/r/deeplearning/comments/c5qm08/july_11_talk_on_deep_learning_with_acm_am_turing/,ACMLearning,1561559959,,0,20,False,default,,,,,
253,deeplearning,t5_2t5eh,2019-6-26,2019,6,26,23,c5qrye,self.deeplearning,LSTM For Sequential Panel Data,https://www.reddit.com/r/deeplearning/comments/c5qrye/lstm_for_sequential_panel_data/,themoonman237,1561560807,"Hi, 

I'm currently in the process of planning an LSTM or some sort of RNN at least for a data set of sequences I have. 

I've fit a ANN already to test out predictive capabilities and was relatively happy but it's shortcomings are apparent in its inability to  discern temporal relationships between certain features. 

My question, or what I'm looking for is just some insight from any of you folks who might have some experience with LSTM models that aren't strictly for time series data in the usual sense. 

My sequences of data vary in size, and each row in a sequence contains only maybe 5 features that change from 1..N in a given sequence. However this change in each feature is important and predictive. 

Also each sequence stands alone, in that it refers to a single individual object . So if we have 100 sequences that equals 100 objects, unlike in a regular time series where a sequence might measure 1 object i.e bitcoin, stocks etc. 

Any insights or advice on such a problem would be really appreciated!",0,4,False,self,,,,,
254,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,0,c5r7df,self.deeplearning,GloVe and BERT on a new corpus?,https://www.reddit.com/r/deeplearning/comments/c5r7df/glove_and_bert_on_a_new_corpus/,DeepLearningStudent,1561562922,"Im trying to produce word embeddings from a textual corpus that I have reason to believe is substantially different from the corpora that GloVe and BERT have been trained on. I think I need to generate a vocabulary from the corpus but I am having trouble understanding how. Ive cleaned the corpus so it is white space-separated. However, Im having trouble understanding how to actually refrain these models to produce the desired word embeddings based off of the corpus.

Any simplified explanations, tips, advice, or guides would be greatly appreciated.",1,2,False,self,,,,,
255,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,1,c5s2q1,youtu.be,Deep Learning Applications,https://www.reddit.com/r/deeplearning/comments/c5s2q1/deep_learning_applications/,MainBuilder,1561567234,,0,1,False,image,,,,,
256,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,2,c5svei,self.deeplearning,[Research] Towards Transfer Learning for End-to-End Speech Synthesis from Deep Pre-Trained Language Models,https://www.reddit.com/r/deeplearning/comments/c5svei/research_towards_transfer_learning_for_endtoend/,cdossman,1561571008," [https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-towards-transfer-learning-for-end-to-end-speech-synthesis-from-deep-pre-trained-6395ae8108fa](https://medium.com/ai%C2%B3-theory-practice-business/ai-scholar-towards-transfer-learning-for-end-to-end-speech-synthesis-from-deep-pre-trained-6395ae8108fa) 

 Modern text-to-speech (TTS) systems are able to generate audio that sounds almost as natural as human speech. However, the bar of developing high-quality TTS systems remains high since a sizable set of studio-quality &lt;text, audio&gt; pairs is usually required. Compared to commercial data used to develop state-of-the-art systems, publicly available data are usually worse in terms of both quality and size. Audio generated by TTS systems trained on publicly available data tends to not only sound less natural, but also exhibits more background noise. In this work, we aim to lower TTS systems' reliance on high-quality data by providing them the textual knowledge extracted by deep pre-trained language models during training. In particular, we investigate the use of BERT to assist the training of Tacotron-2, a state of the art TTS consisting of an encoder and an attention-based decoder.",0,1,False,self,,,,,
257,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,7,c5wves,self.deeplearning,Can (a variant of) DNN give reasoning for their decisions?,https://www.reddit.com/r/deeplearning/comments/c5wves/can_a_variant_of_dnn_give_reasoning_for_their/,JohannesWurst,1561587158,"(I'm a CS student, but no expert on machine learning.)

When DNNs are used to judge people whether they might be criminals or whether they might be suitable for a job, it would be useful if they can give some arguments, so a user has a basis to decide to trust the decision or not. Some people say they might be racist or sexist, or simple inaccurate.

**As far as I know regular DNN don't provide reasoning, but are there any variants that do?**

In the field of image recognition, with convolutional neural networks or adversarial neural networks, I thought I heard somewhere that you can see which geometrical shapes the network detected as a sub-step in order to categorize a picture as a cat.

In this [work](https://www.youtube.com/watch?v=4VAkrUNLKSo) someone extracted the features that a neural network thought important for human faces: gender, age, size...

Could something similar be used to make e.g. recruiting systems more accountable?

There is also this ""IBM Project Debater"". Could this help in that regard?",5,1,False,self,,,,,
258,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,10,c5yxwm,youtube.com,Implementing K-Means Clustering From Scratch: Simply Explained,https://www.reddit.com/r/deeplearning/comments/c5yxwm/implementing_kmeans_clustering_from_scratch/,DiscoverAI,1561597517,,0,2,False,default,,,,,
259,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,10,c5z92s,youtube.com,How Neural Networks Work- Simply Explained,https://www.reddit.com/r/deeplearning/comments/c5z92s/how_neural_networks_work_simply_explained/,DiscoverAI,1561599369,,1,0,False,default,,,,,
260,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,10,c5zawe,youtube.com,Guide to Securing Machine Learning and Software Engineering Internships,https://www.reddit.com/r/deeplearning/comments/c5zawe/guide_to_securing_machine_learning_and_software/,DiscoverAI,1561599660,,0,26,False,image,,,,,
261,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,11,c5zy1o,self.deeplearning,Learning Python Artificial Intelligence by Example,https://www.reddit.com/r/deeplearning/comments/c5zy1o/learning_python_artificial_intelligence_by_example/,HannahHumphreys,1561603335,[removed],0,1,False,self,,,,,
262,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,14,c61czy,self.MachineLearning,Google robbed the dropout technique as his own. Ridiculous!,https://www.reddit.com/r/deeplearning/comments/c61czy/google_robbed_the_dropout_technique_as_his_own/,hungrybear2005,1561612148,,1,0,False,default,,,,,
263,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,17,c62yxm,self.learnmachinelearning,Deep Blueberry Book - five weekend curriculum for self-learners,https://www.reddit.com/r/deeplearning/comments/c62yxm/deep_blueberry_book_five_weekend_curriculum_for/,mikasarei,1561624055,,0,3,False,default,,,,,
264,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,17,c631mm,vice.com,This is super creepy and scary,https://www.reddit.com/r/deeplearning/comments/c631mm/this_is_super_creepy_and_scary/,mohit__,1561624688,,0,1,False,default,,,,,
265,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,18,c63ibi,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c63ibi/data_science_career_track_prep_course/,HannahHumphreys,1561628452,[removed],0,1,False,self,,,,,
266,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,20,c648jj,self.deeplearning,The best telegram group on Women in Machine Learning and Computer Vision,https://www.reddit.com/r/deeplearning/comments/c648jj/the_best_telegram_group_on_women_in_machine/,Doctor_who1,1561633941," 

The best telegram group on Women in Machine Learning and Computer Vision with the presence of Professor Fei-Fei Li

join to telegram group

[https://t.me/joinchat/CuFqkU0HkHTloTFnZFtFEA](https://t.me/joinchat/CuFqkU0HkHTloTFnZFtFEA)",1,0,False,self,,,,,
267,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,21,c650yh,technologyreview.com,Training a single AI model can emit as much carbon as five cars in their lifetimes,https://www.reddit.com/r/deeplearning/comments/c650yh/training_a_single_ai_model_can_emit_as_much/,mercury_new,1561639178,,4,1,False,default,,,,,
268,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,22,c65gtb,self.deeplearning,I need help for my prediction algorithm project,https://www.reddit.com/r/deeplearning/comments/c65gtb/i_need_help_for_my_prediction_algorithm_project/,TheWipyk,1561641786,"Hi guys!

I want to make a project that predicts which team is more likely to win. [Here](https://drive.google.com/open?id=1qlJU5vuXehomT2VhyngqvgwC7UOkm8RI) is part of the dataset I'm working with. 

The first column indicates the winner, +1 or -1 for team A or B. The following B, C, D columns will be ignored for now. The rest of the Columns indicate a chosen character for team A or B, 0 is not participating. 

&amp;#x200B;

I'm new to deep learning and unsure which algorithm should I use. I was thinking about some matrix manipulation or cluster analysis.

&amp;#x200B;

Thanks!",1,1,False,self,,,,,
269,deeplearning,t5_2t5eh,2019-6-27,2019,6,27,23,c662oo,github.com,Laplace - BTCUSD ticker values prediction AI,https://www.reddit.com/r/deeplearning/comments/c662oo/laplace_btcusd_ticker_values_prediction_ai/,resotto,1561645119,,0,0,False,default,,,,,
270,deeplearning,t5_2t5eh,2019-6-28,2019,6,28,0,c66mbs,self.deeplearning,[Research] Speech Recognition With No Speech Or With Noisy Speech Beyond English,https://www.reddit.com/r/deeplearning/comments/c66mbs/research_speech_recognition_with_no_speech_or/,cdossman,1561647925,"[https://medium.com/ai%C2%B3-theory-practice-business/speech-recognition-with-no-speech-or-with-noisy-speech-beyond-english-86cbce0bca5f?postPublishedType=initial](https://medium.com/ai%C2%B3-theory-practice-business/speech-recognition-with-no-speech-or-with-noisy-speech-beyond-english-86cbce0bca5f?postPublishedType=initial) 

Abstract: In this paper, researchers demonstrate continuous noisy speech recognition using connectionist temporal classification (CTC) model on limited Chinese vocabulary using electroencephalography (EEG) features with no speech signal as input and we further demonstrate single CTC model based continuous noisy speech recognition on limited joint English and Chinese vocabulary using EEG features with no speech signal as input.",0,1,False,self,,,,,
271,deeplearning,t5_2t5eh,2019-6-28,2019,6,28,0,c66uuo,medium.com,"Multi-class classification using CNN over PyTorch, and the basics of CNN.",https://www.reddit.com/r/deeplearning/comments/c66uuo/multiclass_classification_using_cnn_over_pytorch/,thevatsalsaglani,1561649099,,0,1,False,default,,,,,
272,deeplearning,t5_2t5eh,2019-6-28,2019,6,28,0,c67539,medium.com,Geoffrey Hintons Unsupervised Capsule Networks Achieve SOTA Results on SVHN - Medium,https://www.reddit.com/r/deeplearning/comments/c67539/geoffrey_hintons_unsupervised_capsule_networks/,Yuqing7,1561650534,,1,65,False,default,,,,,
273,deeplearning,t5_2t5eh,2019-6-28,2019,6,28,2,c68m3i,intellectyx.com,10 Big Data Trends to Watch in 2019,https://www.reddit.com/r/deeplearning/comments/c68m3i/10_big_data_trends_to_watch_in_2019/,rohit1221qq,1561657731,,0,1,False,default,,,,,
274,deeplearning,t5_2t5eh,2019-6-28,2019,6,28,4,c69jkm,self.deeplearning,Port of pretrained tensorflow face recognition models to pytorch,https://www.reddit.com/r/deeplearning/comments/c69jkm/port_of_pretrained_tensorflow_face_recognition/,timesler,1561662289,"[https://github.com/timesler/facenet-pytorch](https://github.com/timesler/facenet-pytorch)

&amp;#x200B;

Hi all, this project contains pytorch pretrained inception resnets ported from the davidsandberg/facenet github repo. Models are implemented and used according to the standard pytorch/torchvision methodology (inheritable model modules, torchvision style model zoo for downloaded/cached pretrained state dictionaries etc.). Currently, the project covers face detection using MTCNN and face recognition. MTCNN is implemented as a single stand-alone pytorch module that wraps the p-, r-, and o-net modules as well as the post-processing, making it easy to chain MTCNN and recognition resnets together in a face recognition pipeline.

&amp;#x200B;

The motivation for the project was the lack of a clean implementation in pytorch that provides the performance of the davidsandberg/facenet github repo. My aim was to build a project that could be easily used to add value existing pytorch projects without a great deal of effort. Performance wise, I see similar or better inference speed on my local machine when compared to the original repo, but that one data point doesn't say a hell of a lot. Any extra testing or feedback much appreciated.

&amp;#x200B;

I'd also like to hear people's opinions on the following design choice:

Currently, the repo contains the necessary pieces for building an inference pipeline (classes for face detection using MTCNN, embedding, and optionally classification), but does not contain code for retraining models (a training script, loss functions, etc). This was a design choice motivated by the desire to keep the project modular and general. Due to the wide range of applications, I thought the implementation would be more accessible and easily integrated into other projects if it were kept as is. I intend on adding some example code that sketches how to retrain using other open-source resources, but I'm not sure this should be added to the repo source.",0,4,False,self,,,,,
275,deeplearning,t5_2t5eh,2019-6-28,2019,6,28,4,c69ljx,medium.com,The Staggering Cost of Training SOTA AI Models,https://www.reddit.com/r/deeplearning/comments/c69ljx/the_staggering_cost_of_training_sota_ai_models/,Yuqing7,1561662548,,2,1,False,default,,,,,
276,deeplearning,t5_2t5eh,2019-6-28,2019,6,28,20,c6iurd,self.deeplearning,Label Noise in Rule based Labelling,https://www.reddit.com/r/deeplearning/comments/c6iurd/label_noise_in_rule_based_labelling/,lifeinsrndpt,1561719888,"I have unlabelled data. Generally for classification problems (say sentiment), in order to train a network, you need to generate labels. You look at the dataset, find a pattern that (for binary classification) gives about 70% accuracy when compared to ground truth. 

Now if you directly train a network on such a data, it will converge at the rule you used to label the data.
So instead you remove the rule(say a number/word etc.)  from the dataset, and let the network find another (maybe more complex mapping) to classify the data.

My question is, 
1) with enough data will the network learn to generalise over wrongly labelled data?

I tried with a dataset of 100 document. It works to some extent (measuring qualitatively) but there still some problem. 

2) Is there a some trick to deal with such problem?",0,1,False,self,,,,,
277,deeplearning,t5_2t5eh,2019-6-28,2019,6,28,23,c6l3sr,intellectyx.com,How big data &amp; Deep Learning is transforming the real estate industry,https://www.reddit.com/r/deeplearning/comments/c6l3sr/how_big_data_deep_learning_is_transforming_the/,rohit1221qq,1561733456,,0,13,False,default,,,,,
278,deeplearning,t5_2t5eh,2019-6-29,2019,6,29,0,c6lvbe,self.deeplearning,Diffgram: Learn to work with deep learning without code (Product Hunt),https://www.reddit.com/r/deeplearning/comments/c6lvbe/diffgram_learn_to_work_with_deep_learning_without/,diffgram-anthony,1561737319,"[https://www.producthunt.com/posts/diffgram](https://www.producthunt.com/posts/diffgram) 

&amp;#x200B;

https://i.redd.it/hqdab3m9d4731.png

https://i.redd.it/5mde8tl9d4731.png

https://i.redd.it/k6wyrsl9d4731.png

https://i.redd.it/hn6unrl9d4731.png",1,2,False,self,,,,,
279,deeplearning,t5_2t5eh,2019-6-29,2019,6,29,1,c6m6mk,self.deeplearning,"Uncertainty modelling by using Deep Learning for confident predictions, a research PhD topic.",https://www.reddit.com/r/deeplearning/comments/c6m6mk/uncertainty_modelling_by_using_deep_learning_for/,4xel,1561738839,"Hi there!

Following we present a video to introduce the research topic of my Industrial PhD that is about *Uncertainty modelling by using Deep Learning for confident predictions*:

&amp;#x200B;

(1) Twitter video: [https://twitter.com/dindustrialscat/status/1144204447947665408](https://twitter.com/dindustrialscat/status/1144204447947665408)

(2) Linkedin video: [https://www.linkedin.com/feed/update/urn:li:activity:6549976288814223360](https://www.linkedin.com/feed/update/urn:li:activity:6549976288814223360)

&amp;#x200B;

Actually, the video is a simple introduction to how to capture the different types of uncertainty through deep learning (limited to two minutes...!). However, we hope that soon the different works that I have in review come to light and we can comment on it!  


If you like the video, I would appreciate it if you retweet it (1) and share it with linkedin (2) given that it is the metric used to choose the video of the industrial doctorate winner of the contest where I am participating.  


Thank you very much and if you want to get in touch with us, do not hesitate at any time :)",0,2,False,self,,,,,
280,deeplearning,t5_2t5eh,2019-6-29,2019,6,29,1,c6mct6,self.deeplearning,"fast.ai Part 2(2019) ""Deep Learning from the Foundations"" is now available publically!",https://www.reddit.com/r/deeplearning/comments/c6mct6/fastai_part_22019_deep_learning_from_the/,init__27,1561739691,[removed],0,1,False,self,,,,,
281,deeplearning,t5_2t5eh,2019-6-29,2019,6,29,1,c6mflb,self.deeplearning,Created Neural Network from Scratch in plain python and Numpy.,https://www.reddit.com/r/deeplearning/comments/c6mflb/created_neural_network_from_scratch_in_plain/,reddyManudeep,1561740083,"Today I implemented 5- Layer neural network in python without using any deep learning frameworks. It was a tedious experience but, it is totally worth it. I (re)learned a lot of things that work under the hood of DL libraries. Can check my code [here](https://github.com/DeepManuPy/MultiLayer-Perceptrons/blob/master/NN-numpy.py).",3,2,False,self,,,,,
282,deeplearning,t5_2t5eh,2019-6-29,2019,6,29,1,c6mjwo,self.deeplearning,How to get reproducible results in deep learning ?,https://www.reddit.com/r/deeplearning/comments/c6mjwo/how_to_get_reproducible_results_in_deep_learning/,FluidReality,1561740677,"Say you want to add something to your model that you think might improve overall performance, e.g. some feature engineering or you decide to add to your training data, some new data you acquired. How do you make sure that this is actually increasing performance and that it is not just due to the randomness of the process ?

I kinda see how it goes for traditional ML with traditional IID assumption, fix a seed for anything that is random and just compare. But what about deep learning models ?

For instance, say you have your neural network tuned for some past state. Wouldn't comparing past configuration with new configuration (with the added features or training data) on the same network be biased ? Maybe the feature engineering was relevant but because the network isn't large enough, it is not able to process those additional features. Or maybe adding more data changed the loss surface and the learning rate/batch size tuned to the previous configuration is not well fitted to the new configuration ? Or maybe more data meant more updates per epoch (assuming the batch size is the same), so maybe we missed the optimal training state because we only look at the validation loss per epoch. So surely setting a seed for the randomness of the network training (weights initialization, shuffle after each epoch ... ) is not enough.

I've thought of doing some sort of autoML/gridsearch to optimize on the learning rate/batch size for several seeds on the weights initialization and do some statistical significance on the results but this would take way too much time considering how many things I need to check. I feel like a statistical study on a given network (with hyperparameters fixed) for different weights initialization might not be relevant.

I'm asking this because whenever I change something on the preprocessing side (new feature, new data, different scaling ...), or even weights initialization of the network, the ""optimal"" learning rate I find by hand tuning my network is never the same (and can differ a lot).

Any idea is welcome!",0,4,False,self,,,,,
283,deeplearning,t5_2t5eh,2019-6-29,2019,6,29,3,c6nw46,course.fast.ai,Part 2: Deep Learning from the Foundations(2019) by Fast.ai is launched!,https://www.reddit.com/r/deeplearning/comments/c6nw46/part_2_deep_learning_from_the_foundations2019_by/,harrshjain,1561747183,,8,71,False,default,,,,,
284,deeplearning,t5_2t5eh,2019-6-29,2019,6,29,4,c6og1w,fast.ai,Deep Learning from the Foundations  fast.ai,https://www.reddit.com/r/deeplearning/comments/c6og1w/deep_learning_from_the_foundations_fastai/,asuagar,1561749859,,0,1,False,default,,,,,
285,deeplearning,t5_2t5eh,2019-6-29,2019,6,29,16,c6vrp0,self.deeplearning,Introduction to machine learning for coders,https://www.reddit.com/r/deeplearning/comments/c6vrp0/introduction_to_machine_learning_for_coders/,freevideolectures,1561791601, https://freevideolectures.com/course/3742/introduction-to-machine-learning-for-coders#utm\_source=Bm,1,0,False,self,,,,,
286,deeplearning,t5_2t5eh,2019-6-29,2019,6,29,21,c6yh7w,self.deeplearning,GTX 1660 TI Installation to Desktop,https://www.reddit.com/r/deeplearning/comments/c6yh7w/gtx_1660_ti_installation_to_desktop/,rlamarr,1561811934,"Hi guys, I've been trying to install my new GTX 1660 Ti to my HP Pavilion desktop CPU. I power the graphics card from an external 500W PSU which is connected directly to the GPU and kick started using a clip. This is because the CPU uses 250W PSU. The GPU starts and the vent fan rolls, but when the GPU is installed and I turn on the Desktop CPU, The CPU basically doesn't come up at all until I remove the graphics card and turn it on.
Is this because the Desktop is old or Is the graphics card the faulty one? I really need help installing this.",9,1,False,self,,,,,
287,deeplearning,t5_2t5eh,2019-6-29,2019,6,29,22,c6yydt,self.deeplearning,Can anyone give an explanation about what are contrastive methods and generative methods in deep learning?,https://www.reddit.com/r/deeplearning/comments/c6yydt/can_anyone_give_an_explanation_about_what_are/,H_uuu,1561814924,,2,1,False,self,,,,,
288,deeplearning,t5_2t5eh,2019-6-30,2019,6,30,3,c72w3m,self.deeplearning,Any graph CNN work that changes the weight on the edges/links?,https://www.reddit.com/r/deeplearning/comments/c72w3m/any_graph_cnn_work_that_changes_the_weight_on_the/,AbduallahM,1561833432,"I been trying to locate a deep model that do a convolution on the edges and vertices of graphs, any leads?",6,6,False,self,,,,,
289,deeplearning,t5_2t5eh,2019-6-30,2019,6,30,13,c78wo4,self.deeplearning,How can I improve performance of deep learning model ?,https://www.reddit.com/r/deeplearning/comments/c78wo4/how_can_i_improve_performance_of_deep_learning/,kesha1997,1561867968,I have built a deep learnings image classification  model but the accuracy is not sufficient . Other that augmentation what are different ways to improve performance of model ?,2,1,False,self,,,,,
290,deeplearning,t5_2t5eh,2019-6-30,2019,6,30,13,c792pv,self.deeplearning,How to build recommendation system using deep learning ?,https://www.reddit.com/r/deeplearning/comments/c792pv/how_to_build_recommendation_system_using_deep/,kesha1997,1561869090,I want to build a recommendation system which will recommend books.I know the theory of recommendation system and its type.but how to implement it ?,3,12,False,self,,,,,
291,deeplearning,t5_2t5eh,2019-6-30,2019,6,30,14,c79mr9,self.deeplearning,Best practise to deploy multiple deep learning models in production.,https://www.reddit.com/r/deeplearning/comments/c79mr9/best_practise_to_deploy_multiple_deep_learning/,amit2rockon,1561873029,"Hi everyone, I have a query about the best way to deploy multiple deep learning models in production for a scale serving.",2,6,False,self,,,,,
292,deeplearning,t5_2t5eh,2019-6-30,2019,6,30,17,c7azbc,medium.com,Neuromorphic Hardware: Trying to Put Brain Into Chips,https://www.reddit.com/r/deeplearning/comments/c7azbc/neuromorphic_hardware_trying_to_put_brain_into/,prime_007,1561884249,,0,1,False,default,,,,,
293,deeplearning,t5_2t5eh,2019-6-30,2019,6,30,17,c7b0h0,self.deeplearning,Machine Learning Specialization,https://www.reddit.com/r/deeplearning/comments/c7b0h0/machine_learning_specialization/,HannahHumphreys,1561884564,[removed],0,1,False,self,,,,,
294,deeplearning,t5_2t5eh,2019-6-30,2019,6,30,18,c7bcmd,i.redd.it,Cleaning this data,https://www.reddit.com/r/deeplearning/comments/c7bcmd/cleaning_this_data/,jahifu,1561887725,,5,0,False,image,,,,,
295,deeplearning,t5_2t5eh,2019-6-30,2019,6,30,18,c7be7a,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/c7be7a/data_science_career_track_prep_course/,HannahHumphreys,1561888177,[removed],0,1,False,self,,,,,
296,deeplearning,t5_2t5eh,2019-6-30,2019,6,30,20,c7c61p,self.deeplearning,Is it possible to build a classifier in Deep Learning for 1000 (or 10000) objects of the same species with only one picture each?,https://www.reddit.com/r/deeplearning/comments/c7c61p/is_it_possible_to_build_a_classifier_in_deep/,PolyTrickPony,1561894942,\^,5,2,False,self,,,,,
297,deeplearning,t5_2t5eh,2019-6-30,2019,6,30,21,c7ckfn,self.deeplearning,Need DNA sequence data with the respective person's facial features,https://www.reddit.com/r/deeplearning/comments/c7ckfn/need_dna_sequence_data_with_the_respective/,clean_pegasus,1561896664,Is there any DNA dataset available that also includes facial features of that respective person?,2,1,False,self,,,,,
