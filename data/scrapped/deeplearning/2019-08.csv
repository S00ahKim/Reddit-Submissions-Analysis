,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,11,ckii5b,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/ckii5b/data_science_career_track_prep_course/,HannahHumphreys,1564627816,[removed],0,1,False,self,,,,,
1,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,13,ckjm3s,self.deeplearning,1D conv-net,https://www.reddit.com/r/deeplearning/comments/ckjm3s/1d_convnet/,nicetryho,1564634323,Working with a semi complex 1Dconv network that takes in raw time series data with no prior feature extraction. When training my model seems to learn very quickly only after 10 epochs..what is this a sign of ? I have adjusted the learning rate but even then by 40 its at over 90 acc.,2,1,False,self,,,,,
2,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,14,ckjy1g,medium.com,AI and deep learning to tackle traffic congestion,https://www.reddit.com/r/deeplearning/comments/ckjy1g/ai_and_deep_learning_to_tackle_traffic_congestion/,Ripple2709,1564636435,,1,4,False,default,,,,,
3,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,16,ckkw00,self.deeplearning,Classifying Dogs vs Cats problem using Deep Learning in C++!,https://www.reddit.com/r/deeplearning/comments/ckkw00/classifying_dogs_vs_cats_problem_using_deep/,Kushashwa,1564642901,"Hi Everyone!

As some would know from my [last post](https://www.reddit.com/r/deeplearning/comments/cbqovr/announcing_a_series_of_blogs_on_pytorch_c_api/), I have started a series of blogs on using PyTorch C++ API. The recent post is on classifying Dogs vs Cats using a CNN in C++. 

[Link to the blog: https:\/\/krshrimali.github.io\/Classifying-Dogs-Cats-PyTorch-CPP-Part-2\/](https://i.redd.it/mngex1xqcsd31.jpg)

I hope this helps those who are just getting started with Deep Learning and have good hands on C++. I look forward for your feedback and any suggestions, as this keeps me going. 

If anyone faces any problem, or wants to collaborate, you can message me here! 

Happy Learning, fellas!",4,14,False,self,,,,,
4,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,16,ckkx8d,self.deeplearning,Encrypt keras model (hdf5 or h5),https://www.reddit.com/r/deeplearning/comments/ckkx8d/encrypt_keras_model_hdf5_or_h5/,nanitiru18,1564643135,"How can I encrypt hdf5 or h5 model, cause  reverse engineering is possible in case of only weights are saved in h5 file",7,4,False,self,,,,,
5,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,17,cklmqu,self.deeplearning,Sharing Papers?,https://www.reddit.com/r/deeplearning/comments/cklmqu/sharing_papers/,Dragonofburdur,1564648454,"Hello, wanted to ask an easy question about papers. Am I allowed share paper links in a public repository to share with my colleagues. I asked google but couldn't really find an answer if there is a regulation about that issue. Thanks.",2,6,False,self,,,,,
6,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,21,cknr59,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cknr59/data_science_career_track_prep_course/,HannahHumphreys,1564662668,[removed],0,1,False,self,,,,,
7,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,22,ckoftq,reddit.com,Career advice by Yoshua and Rich,https://www.reddit.com/r/deeplearning/comments/ckoftq/career_advice_by_yoshua_and_rich/,Nishanth127,1564666402,,0,0,False,default,,,,,
8,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,22,ckojjj,habr.com,Contextual Emotion Detection in Textual Conversations Using Neural Networks,https://www.reddit.com/r/deeplearning/comments/ckojjj/contextual_emotion_detection_in_textual/,atomlib_com,1564666943,,0,1,False,default,,,,,
9,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,23,ckoybr,youtube.com,"For those of you that are unfamiliar with Keras, here is a great video-introduction that explains exactly what it is.",https://www.reddit.com/r/deeplearning/comments/ckoybr/for_those_of_you_that_are_unfamiliar_with_keras/,antaloaalonso,1564669026,,3,35,False,default,,,,,
10,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,23,ckpdy6,self.deeplearning,[Research],https://www.reddit.com/r/deeplearning/comments/ckpdy6/research/,cdossman,1564671132," **Abstract**Continuous affect prediction involves the discrete time-continuous regression of affect dimensions. Dimensions to be predicted often include arousal and valence. Continuous affect prediction researchers are now embracing multimodal model input. This provides motivation for researchers to investigate previously unexplored affective cues. Speech-based cues have traditionally received the most attention for affect prediction, however, non-verbal inputs have significant potential to increase the performance of affective computing systems and in addition, allow affect modelling in the absence of speech. However, nonverbal inputs that have received little attention for continuous affect prediction include eye and head-based cues. The eyes are involved in emotion displays and perception while headbased cues have been shown to contribute to emotion conveyance and perception. Additionally, these cues can be estimated noninvasively from video, using modern computer vision tools. This work exploits this gap by comprehensively investigating head and eye-based features and their combination with speech for continuous affect prediction. Hand-crafted, automatically generated and CNN-learned features from these modalities will be investigated for continuous affect prediction. The highest performing feature sets and feature set combinations will answer how effective these features are for the prediction of an individuals affective state. 

 [https://medium.com/@cdossman/hand-crafted-feature-sets-based-on-head-and-eye-based-cues-f4bee0103d3e](https://medium.com/@cdossman/hand-crafted-feature-sets-based-on-head-and-eye-based-cues-f4bee0103d3e)",0,1,False,self,,,,,
11,deeplearning,t5_2t5eh,2019-8-1,2019,8,1,23,ckpf58,self.deeplearning,"[Research] Speech, Head, and Eye-based Cues for Continuous Affect Prediction",https://www.reddit.com/r/deeplearning/comments/ckpf58/research_speech_head_and_eyebased_cues_for/,cdossman,1564671300," **Abstract**  Continuous affect prediction involves the discrete time-continuous regression of affect dimensions. Dimensions to be predicted often include arousal and valence. Continuous affect prediction researchers are now embracing multimodal model input. This provides motivation for researchers to investigate previously unexplored affective cues. Speech-based cues have traditionally received the most attention for affect prediction, however, non-verbal inputs have significant potential to increase the performance of affective computing systems and in addition, allow affect modelling in the absence of speech. However, nonverbal inputs that have received little attention for continuous affect prediction include eye and head-based cues. The eyes are involved in emotion displays and perception while headbased cues have been shown to contribute to emotion conveyance and perception. Additionally, these cues can be estimated noninvasively from video, using modern computer vision tools. This work exploits this gap by comprehensively investigating head and eye-based features and their combination with speech for continuous affect prediction. Hand-crafted, automatically generated and CNN-learned features from these modalities will be investigated for continuous affect prediction. The highest performing feature sets and feature set combinations will answer how effective these features are for the prediction of an individuals affective state. 

[https://medium.com/@cdossman/hand-crafted-feature-sets-based-on-head-and-eye-based-cues-f4bee0103d3e](https://medium.com/@cdossman/hand-crafted-feature-sets-based-on-head-and-eye-based-cues-f4bee0103d3e)",0,1,False,self,,,,,
12,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,1,ckqkje,self.deeplearning,Speaker identification through intonation,https://www.reddit.com/r/deeplearning/comments/ckqkje/speaker_identification_through_intonation/,hega72,1564676563,"Hi all
Does anybody know of an approach to identify a speaker although the voice was obfuscated ? I thought I came wrote about an approach that was able to do that but I cant find it anymore. 
Any suggestions ?",0,2,False,self,,,,,
13,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,1,ckqzru,self.deeplearning,Image augmentation: best way to augment associated xml files that contain bounding box information?,https://www.reddit.com/r/deeplearning/comments/ckqzru/image_augmentation_best_way_to_augment_associated/,ml_runway,1564678459,"Let's say I have an image `train.png` and associated xml file `train_boxes.xml` that contains information about the image, including bounding boxes and their labels (the standard kind of thing you would get with annotation software like labelimg).

Now when I want to augment `train.png` (say, with a rotation or whatever), is there a standard way people then create new xml files? My goal is to create a new image/xml file pair for each augmented image, so `train_aug_1.png` and `train_aug_1_boxes.xml` by simply changing the data in the original xml file (i.e., changing the image path and bounding boxes, but leaving the labels and everything else the same).

I imagine this is such a common workflow but I haven't found anything online about it, and am wondering if there is already a pipeline out there that I can use, or if I should just write it myself (I was planning to just use `imgaug` and `ElementTree` for all the relevant operations):    

-  https://imgaug.readthedocs.io/en/latest/    
-  https://docs.python.org/3.7/library/xml.etree.elementtree.html

I'm curious what people think or if they have any advice I have never done this before...",0,1,False,self,,,,,
14,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,3,cksn2j,self.deeplearning,Kaggle 1st Pos Solution of Data Science for Good: City of LA Kaggle Comp | Interview with Shivam Bansal,https://www.reddit.com/r/deeplearning/comments/cksn2j/kaggle_1st_pos_solution_of_data_science_for_good/,init__27,1564685840,"Interview with Shivam Bansal about his 1st position Winning solution to the Data Science for Good: City of LA Kaggle Comp

&amp;#x200B;

Podcast: [https://anchor.fm/chaitimedatascience/episodes/Data-Science-for-Good-City-of-LA-Kaggle-Winning-Solution-Interview-with-Kaggle-Kernels-Grandmaster-Shivam-Bansal-e4qc36/a-ak0h7g](https://anchor.fm/chaitimedatascience/episodes/Data-Science-for-Good-City-of-LA-Kaggle-Winning-Solution-Interview-with-Kaggle-Kernels-Grandmaster-Shivam-Bansal-e4qc36/a-ak0h7g)

&amp;#x200B;

Video: [https://www.youtube.com/watch?v=VdnUmrRuuWE&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=5](https://www.youtube.com/watch?v=VdnUmrRuuWE&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=5)",0,3,False,self,,,,,
15,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,4,ckstct,self.deeplearning,[P] Critic - Learning Music Taste With Deep Neural Nets,https://www.reddit.com/r/deeplearning/comments/ckstct/p_critic_learning_music_taste_with_deep_neural/,[deleted],1564686625,[deleted],0,1,False,default,,,,,
16,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,4,cktgol,self.deeplearning,[I built] Critic - Learning Music Taste With Deep Neural Nets,https://www.reddit.com/r/deeplearning/comments/cktgol/i_built_critic_learning_music_taste_with_deep/,_Radish_Spirit_,1564689576,"[Deployed Web App](https://michaeldarr.github.io/MuCritic_App/)

[Source Code](https://github.com/MichaelDarr/MuCritic)

[Model Explanation](https://michaeldarr.github.io/MuCritic_App/#/about)

Hi all! I graduated with a BS in computer science last spring and have spent the last few months building and deploying my first large-scale ML project. I would love to hear any feedback or criticism you have to offer. Thanks!",1,1,False,self,,,,,
17,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,4,cktgrq,self.deeplearning,Self-Supervised Learning + GANs outperforms Supervised GANs,https://www.reddit.com/r/deeplearning/comments/cktgrq/selfsupervised_learning_gans_outperforms/,HenryAILabs,1564689585,[https://youtu.be/-oJWFcexolY](https://youtu.be/-oJWFcexolY),0,6,False,self,,,,,
18,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,5,cku3hn,self.deeplearning,"Tensorflow, GAN, etc, with AMD GPU.",https://www.reddit.com/r/deeplearning/comments/cku3hn/tensorflow_gan_etc_with_amd_gpu/,jgemeigh,1564692499,"Okay, okay, I know, I messed up buying tons of AMD GPU instead of Nvidia.
That's out of the way. 
So I have 40 gpus that I mine with and make a killing on crypto, protein folding, and golem.io

But I have always aspired to put that computing towards something more, that I can do independently. 

I found some code on GitHub today that uses deeplearning to make some amazing Renaissance portraits and anime character faces from selfies and photos. It says it uses tensorflow and GANs.

I am wondering if there is a legitimate way to use AMD gpus to accomplish this stuff. Not asking for a whole explanation, I can do the research myself. But I keep hitting walls in forums that just say amd gpus can't do deeplearning. And I don't believe it. 

Does anyone know if tensorflow, GANs can be used with AMD gpus, and maybe a link to a useful guide on doing so?

Thank you all for any input.",7,4,False,self,,,,,
19,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,11,ckxyb5,self.deeplearning,Tensorflow proposal for outer product operation,https://www.reddit.com/r/deeplearning/comments/ckxyb5/tensorflow_proposal_for_outer_product_operation/,sz524,1564712141,"&amp;#x200B;

[https://github.com/tensorflow/tensorflow/issues/17564](https://github.com/tensorflow/tensorflow/issues/17564)

[https://github.com/4d55397500/proposed-outer-product-tensorflow](https://github.com/4d55397500/proposed-outer-product-tensorflow)

I have a longstanding issue open in the Tensorflow project to create an outer product operation.

Does anyone else think it ironic that the fundamental operation on tensors of outer product is not supported by Tensorflow?",6,11,False,self,,,,,
20,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,16,cl0z97,arxiv.org,Unsupervised Domain Adaptation via Disentangled Representations: Application to Cross-Modality Liver Segmentation,https://www.reddit.com/r/deeplearning/comments/cl0z97/unsupervised_domain_adaptation_via_disentangled/,junlin639,1564731406,,0,3,False,default,,,,,
21,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,20,cl2opw,medium.com,Artificial Intelligence to speed up trip planning,https://www.reddit.com/r/deeplearning/comments/cl2opw/artificial_intelligence_to_speed_up_trip_planning/,MachineLearning001,1564744173,,0,4,False,default,,,,,
22,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,21,cl3ft6,self.deeplearning,Data Science with R - Best books to become an Expert,https://www.reddit.com/r/deeplearning/comments/cl3ft6/data_science_with_r_best_books_to_become_an_expert/,HannahHumphreys,1564748820,[removed],0,1,False,self,,,,,
23,deeplearning,t5_2t5eh,2019-8-2,2019,8,2,22,cl48ke,blog.floydhub.com,N-Shot Learning: Learning More with Less Data,https://www.reddit.com/r/deeplearning/comments/cl48ke/nshot_learning_learning_more_with_less_data/,pirate7777777,1564753135,,0,36,False,default,,,,,
24,deeplearning,t5_2t5eh,2019-8-3,2019,8,3,0,cl5i7v,self.deeplearning,[R] Fooling real cars with Deep Learning (Deep Learning + Cybersecurity)),https://www.reddit.com/r/deeplearning/comments/cl5i7v/r_fooling_real_cars_with_deep_learning_deep/,oblongatas_blancas,1564759280,"Hey, posting after /r/MachineLearning

We attacked a real vehicle using Deep Learning to generate real life Adversarial traffic signs, effective on cars from different manufacturers. We used nothing more than a strong GPU and commercially available printing services.

Would love feedback and/or discussion :-)

the paper [https://arxiv.org/abs/1907.00374](https://arxiv.org/abs/1907.00374)

medium post with a Demo video [https://medium.com/@shacharm/fooling-real-cars-with-deep-learning-cace6422c396](https://medium.com/@shacharm/fooling-real-cars-with-deep-learning-cace6422c396)",0,3,False,self,,,,,
25,deeplearning,t5_2t5eh,2019-8-3,2019,8,3,8,clbtzl,self.deeplearning,Ubuntu Server OS vs Ubuntu Desktop OS help?,https://www.reddit.com/r/deeplearning/comments/clbtzl/ubuntu_server_os_vs_ubuntu_desktop_os_help/,RisingShogun,1564789766,"I'm a beginner in deep learning and was dead set on using Ubuntu for the operating system of the system I am building, however, I ran into a slight roadblock in what version of Ubuntu I should use. I am aware that the Server OS doesn't have a GUI and the Desktop OS does, but is there a benefit of using one OS versus another for deep learning?",4,2,False,self,,,,,
26,deeplearning,t5_2t5eh,2019-8-3,2019,8,3,12,cle28p,self.deeplearning,Threadripper 2920X vs i7-9800X (can't decide),https://www.reddit.com/r/deeplearning/comments/cle28p/threadripper_2920x_vs_i79800x_cant_decide/,th1nkpatriot,1564802863,"Looking to build a deep learning rig and trying to decide on the AMD Threadripper 2920X vs the Intel i7-9800X CPUs.

This will be used for a signal processing/audio fingerprinting system.

Does one have an advantage/disadvantage in this use-case? Does it matter?",30,10,False,self,,,,,
27,deeplearning,t5_2t5eh,2019-8-3,2019,8,3,13,clefzf,self.deeplearning,What services do you use for deploying Deep Learning models in production?,https://www.reddit.com/r/deeplearning/comments/clefzf/what_services_do_you_use_for_deploying_deep/,benur7,1564805228,"Hey guys, what services do you currently use for your Deep Learning models in production? I have a Tensorflow Model that I would like to deploy.",4,1,False,self,,,,,
28,deeplearning,t5_2t5eh,2019-8-3,2019,8,3,13,cles4c,self.computervision,N-Shot learning: Learn more with less data,https://www.reddit.com/r/deeplearning/comments/cles4c/nshot_learning_learn_more_with_less_data/,Hsankesara,1564807428,,0,13,False,default,,,,,
29,deeplearning,t5_2t5eh,2019-8-3,2019,8,3,14,clf7qa,self.deeplearning,Yolo architecture from scratch,https://www.reddit.com/r/deeplearning/comments/clf7qa/yolo_architecture_from_scratch/,shivam529,1564810485,"Can I make a yolo architecture from scratch improvising on lots of things like I know my objects are all of the same size, my objects being digits 1-9, like I dont think I would need anchor boxes and also the fact that I know pre hand my bounding boxes are all of the same size ?",4,2,False,self,,,,,
30,deeplearning,t5_2t5eh,2019-8-4,2019,8,4,2,cll9ro,self.deeplearning,Artificial Intelligence Projects with Python-HandsOn,https://www.reddit.com/r/deeplearning/comments/cll9ro/artificial_intelligence_projects_with/,HannahHumphreys,1564852897,[removed],0,1,False,self,,,,,
31,deeplearning,t5_2t5eh,2019-8-4,2019,8,4,5,clnkck,self.deeplearning,Projects Ideas for DGX-1,https://www.reddit.com/r/deeplearning/comments/clnkck/projects_ideas_for_dgx1/,toshn_,1564864799, I will have access to DGX-1 NVIDIA for my final year project. Can you suggest some nice projects ideas and applications where I can make full use of this beast?,14,6,False,self,,,,,
32,deeplearning,t5_2t5eh,2019-8-4,2019,8,4,12,clrv7z,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/clrv7z/data_science_career_track_prep_course/,HannahHumphreys,1564890005,[removed],0,1,False,self,,,,,
33,deeplearning,t5_2t5eh,2019-8-4,2019,8,4,16,cltqdm,self.deeplearning,Data Science Career Track Prep Course,https://www.reddit.com/r/deeplearning/comments/cltqdm/data_science_career_track_prep_course/,HannahHumphreys,1564903821,[removed],0,1,False,self,,,,,
34,deeplearning,t5_2t5eh,2019-8-4,2019,8,4,16,cltv40,self.deeplearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/deeplearning/comments/cltv40/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1564905016,[removed],0,1,False,self,,,,,
35,deeplearning,t5_2t5eh,2019-8-4,2019,8,4,21,clvpnh,self.deeplearning,I need to make my voice sound like Tom Cruise in Top Gun,https://www.reddit.com/r/deeplearning/comments/clvpnh/i_need_to_make_my_voice_sound_like_tom_cruise_in/,omasque,1564921234,"I am trying to achieve something along the lines of the ""Nic Cage in every movie"" vid that went around a while back. Not the part where his face is pasted on characters, but his voice saying the lines. I'm not sure if this was done TTS or by converting the spoken audio in the movie to a trained model(?) of his voice... ideally I would like to do either.

Without boring anyone with too much detail, I am producing some animated clips parodying Top Gun and can do a, let's say South Park-tier Tom Cruise impression. I'd like to be able to record the clips with my inflection and emphasis, then ""train"" that audio on recordings of Tom Cruise dialogue in that movie and several others from the time period, then use some sort of deep learning process to make my recorded dialogue sound more like Cruise.

Failing that, whatever process was used in the Nic Cage clip would suffice, as that is a very convincing level of recognisability in his voice. I've searched and found tutorials and articles about how the face was done, but can't seem to find a lot on the voice.",10,4,False,self,,,,,
36,deeplearning,t5_2t5eh,2019-8-4,2019,8,4,23,clwm84,self.deeplearning,Same guy Putin  rnn model using news footage by approximating heartbeat,https://www.reddit.com/r/deeplearning/comments/clwm84/same_guy_putin_rnn_model_using_news_footage_by/,godDLL,1564927274,"I'm thinking of disproving the conjecture that Putin **has doubles** on video in the news. I wonder whether a model could be made that would distinguish *Putin* / *Not-Putin* by heart beat approximated from the footage. How would I go about doing that, in 17 simple steps?..

Is that two models, one for deriving the heart-beat from video footage, one for same-guy evaluation?

Or is it more.

How do I even. Approach this, how. Full stop. I cant. How. %)",6,1,False,self,,,,,
37,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,2,clyvfc,self.deeplearning,"Deep Learning Research, Deep Learning Hardware, Sparse Networks | Interview with Tim Dettmers",https://www.reddit.com/r/deeplearning/comments/clyvfc/deep_learning_research_deep_learning_hardware/,init__27,1564939195,"Interview with Tim Dettmers, PhD Student at University of Washington. 

We talk a lot about DL Research, DL Hardware :smile: and Tim's Kaggle experience 

Audio: https://anchor.fm/chaitimedatascience/episodes/Deep-Learning-Research--Hardware--Kaggle--Interview-with-Tim-Dettmers-e4qcad/a-ak0hr6

Video: https://www.youtube.com/watch?v=4857Lph2ndk&amp;feature=youtu.be",0,8,False,self,,,,,
38,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,4,cm05yi,mlait.tech,Transfer Learning with MobileNetV2,https://www.reddit.com/r/deeplearning/comments/cm05yi/transfer_learning_with_mobilenetv2/,mlait1908,1564945502,,0,7,False,default,,,,,
39,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,4,cm08x1,self.deeplearning,Can't get GAN python program working due to lack of info about dependency version number,https://www.reddit.com/r/deeplearning/comments/cm08x1/cant_get_gan_python_program_working_due_to_lack/,sierrafourteen,1564945887,"Hi all

&amp;#x200B;

I'm trying to get hzwer's [ICCV2019-LearningToPaint](https://github.com/hzwer/ICCV2019-LearningToPaint) software running, but I keep coming up with issues that I'm assuming correspond to changes in dependencies that I'm using - I have some - the github page specifies the below data, although I don't understand how I can have torch as 0.4.1 and as 1.1.0 - but it doesn't tell me what versions other dependencies of dependencies are - meaning that I get problems such as `""AttributeError: module 'PIL' has no attribute 'Image'""`

  Can anyone help me determine what versions I should pick? Is it as simple as finding the versions that were available when the github repository was first created?

&amp;#x200B;

**Listed Dependencies:**

* [PyTorch](http://pytorch.org/) 0.4.1
* [tensorboardX](https://github.com/lanpa/tensorboard-pytorch/tree/master/tensorboardX)
* [opencv-python](https://pypi.org/project/opencv-python/) 3.4.0

&amp;#8203;

    pip3 install torch==1.1.0 pip3 install tensorboardX pip3 install opencv-python",5,1,False,self,,,,,
40,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,11,cm4y0s,self.deeplearning,Deep Learning Written Website,https://www.reddit.com/r/deeplearning/comments/cm4y0s/deep_learning_written_website/,mrblasto,1564971108,"All the fake news articles on this website are written using a tensor flow.

http://www.blastolabs.com

I just input the stories title and it creates the rest.",10,17,False,self,,,,,
41,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,11,cm55v5,self.deeplearning,"How to save a model that knows ""English"" but learns a style on a new text dataset?",https://www.reddit.com/r/deeplearning/comments/cm55v5/how_to_save_a_model_that_knows_english_but_learns/,maggles20,1564972423,"So my goal here is to make a webapp that users can write some sentences in (very small data) and train an rnn to learn their style and generate new text. Now I know thag dataset of just a few sentences is too small to train a completely new rnn, just wondering if it's possible to train an rnn on publicly available text data right now for it to learn grammar rules and whatnot now, and then teach it someone's style on just a few sentences?",2,0,False,self,,,,,
42,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,14,cm71zb,youtu.be,#Free #Machinearning course by #Google,https://www.reddit.com/r/deeplearning/comments/cm71zb/free_machinearning_course_by_google/,mlait1908,1564984156,,0,0,False,image,,,,,
43,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,15,cm7i8w,medium.com,Conversational AI: The Advanced Form of Chatbots,https://www.reddit.com/r/deeplearning/comments/cm7i8w/conversational_ai_the_advanced_form_of_chatbots/,MachineLearning001,1564987392,,0,0,False,default,,,,,
44,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,15,cm7lrv,analyticsindiamag.com,How To Go Beyond CNNs With Stand-Alone Self-Attention Models,https://www.reddit.com/r/deeplearning/comments/cm7lrv/how_to_go_beyond_cnns_with_standalone/,analyticsindiam,1564988125,,0,1,False,default,,,,,
45,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,16,cm8238,self.deeplearning,Deep Learning,https://www.reddit.com/r/deeplearning/comments/cm8238/deep_learning/,moizsawan,1564991525,Has anyone ever worked on image classification through graph neural networks?,2,0,False,self,,,,,
46,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,20,cm9j3z,self.deeplearning,AMD Radeon Pro WX 7100 8GB GFX or NVIDIA Quadro P5000 16GB for DeepLearning?,https://www.reddit.com/r/deeplearning/comments/cm9j3z/amd_radeon_pro_wx_7100_8gb_gfx_or_nvidia_quadro/,testimoni,1565002870,"I have two options available to choose for deep learning projects.

Which one would you choose?

AMD Radeon Pro WX 7100 8GB GFX or NVIDIA Quadro P5000 16GB?",5,1,False,self,,,,,
47,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,20,cm9p1f,self.deeplearning,What journal was the original GAN paper published?,https://www.reddit.com/r/deeplearning/comments/cm9p1f/what_journal_was_the_original_gan_paper_published/,clean_pegasus,1565003948,Can someone tell me in what journal the original GAN was published?,5,3,False,self,,,,,
48,deeplearning,t5_2t5eh,2019-8-5,2019,8,5,22,cmb7bf,self.deeplearning,[Research] A Robustly Optimized BERT Pretraining Approach,https://www.reddit.com/r/deeplearning/comments/cmb7bf/research_a_robustly_optimized_bert_pretraining/,cdossman,1565012953,"[https://medium.com/ai%C2%B3-theory-practice-business/researchers-propose-bert-pre-training-procedure-modifications-that-improve-end-task-performance-6fab990afd9a](https://medium.com/ai%C2%B3-theory-practice-business/researchers-propose-bert-pre-training-procedure-modifications-that-improve-end-task-performance-6fab990afd9a) 

Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have a significant impact on the final results. We present a replication study of BERT pretraining that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE, and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.",0,3,False,self,,,,,
49,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,0,cmc6hm,medium.com,"Harvard Researchers Benchmark TPU, GPU &amp; CPU for Deep Learning",https://www.reddit.com/r/deeplearning/comments/cmc6hm/harvard_researchers_benchmark_tpu_gpu_cpu_for/,Yuqing7,1565017846,,1,10,False,default,,,,,
50,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,1,cmd8u0,self.deeplearning,OmniNet: A unified architecture for multi-modal multi-task learning,https://www.reddit.com/r/deeplearning/comments/cmd8u0/omninet_a_unified_architecture_for_multimodal/,turing_1997,1565022722,"**Paper title:** OmniNet: A unified architecture for multi-modal multi-task learning

**Paper url:** [https://arxiv.org/abs/1907.07804](https://arxiv.org/abs/1907.07804)

**Code:** [https://github.com/subho406/OmniNet](https://github.com/subho406/OmniNet?fbclid=IwAR08pJ7Fnxq6n4IStevp_dsXCLhak_nW53w1crtn22yGirKBHcwQwH3szYY)

**Abstract:** Transformer is a popularly used neural network architecture, especially for language understanding. We introduce an extended and unified architecture which can be used for tasks involving a variety of modalities like image, text, videos, etc. We propose a spatio-temporal cache mechanism that enables learning spatial dimension of the input in addition to the hidden states corresponding to the temporal input sequence. The proposed architecture further enables a single model to support tasks with multiple input modalities as well as asynchronous multi-task learning, thus we refer to it as OmniNet. For example, a single instance of OmniNet can concurrently learn to perform the tasks of part-of-speech tagging, image captioning, visual question answering and video activity recognition. We demonstrate that training these four tasks together results in about three times compressed model while retaining the performance in comparison to training them individually. We also show that using this neural network pre-trained on some modalities assists in learning an unseen task. This illustrates the generalization capacity of the self-attention mechanism on the spatio-temporal cache present in OmniNet.

&amp;#x200B;

https://i.redd.it/j57h2d1aqne31.png",0,1,False,self,,,,,
51,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,2,cmdn20,self.deeplearning,Multimodal Future Prediction - CVPR 2019,https://www.reddit.com/r/deeplearning/comments/cmdn20/multimodal_future_prediction_cvpr_2019/,os1a,1565024487,"A  recent work about multimodal future prediction which is critical for AI applied to autonomous driving:

[https://arxiv.org/abs/1906.03631](https://arxiv.org/abs/1906.03631)",0,1,False,self,,,,,
52,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,2,cmefo2,self.deeplearning,Help for deep learning laptop purchase?,https://www.reddit.com/r/deeplearning/comments/cmefo2/help_for_deep_learning_laptop_purchase/,deep_curiosity,1565027981,"Hello. I'm a deep learning engineer. My company lets me renew my 2-year old laptop. Budget is \~$3,000. I googled many laptops and reviews, but none was similar to my case, so excuse me to advise to the deep learning community.

For information, my old laptop was Acer Predator 17x with NVIDIA 1080. It's super huge and big. I have been very satisfied the build quality and did great job, but its portability was too horrible. (e.g., if you put the laptop on airplane seat desks, the desk almost crashes...)

I also somewhat agree that setting up desktop or cloud and then sshing from laptop is practical, but I already have a multiple of workstations each with 4 Titan Xs. But I also like to have NVIDIA GPU in my laptop because: although I'll not run intense training, many times I need to check my Proof-of-Concept network architecture with small batch sizes and I need to develop my application using CUDA calculation and inference without the Internet.

I'll use Ubuntu Dual boot. Ubuntu with GPU is essential.

So, **my criterion**:

* Development usage, No gaming
* Linux (Ubuntu) boot
* Portability and battery life to work everywhere (Battery life on Linux seems to require optimization anyway..)
* Preferably, decent NVIDIA GPU (Not intense training but for at least forward inference and CUDA calculation)

Here's are my lists:

**Surface book2**: Good portability. NVIDIA 1060. Maybe additional benefits for reading papers. Not sure Ubuntu with GPU. (I found some git repo about optimizing Linux for surface book 2, but still, I feel like the hardware might too optimized to Windows.)

**Lenovo extreme X1**: Temping, but NVIDIA 1050, which sounds too weak even for inference and CUDA (right..?).

**Razer Blade 15 (2019) RTX 2080 Max-Q** vs. **Gigabyte new Aero 15"" OLED RTX 2070 (XA-9US5130SP)**: Highly likely choice. Which one do you recommend if you are familiar with these?

Will be there a better choice? 

Advice please, and let me know if this kind of questions is not appropriate.",6,1,False,self,,,,,
53,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,3,cmeq3s,mlfromscratch.com,"Explaining Feedforward, Backpropagation and Optimization: The Math Explained Clearly with Visualizations. I took the time to write this long article (&gt;5k words), and I hope it helps someone understand neural networks better.",https://www.reddit.com/r/deeplearning/comments/cmeq3s/explaining_feedforward_backpropagation_and/,permalip,1565029237,,0,1,False,default,,,,,
54,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,3,cmexqw,self.deeplearning,what is site to learn neural network with api's?,https://www.reddit.com/r/deeplearning/comments/cmexqw/what_is_site_to_learn_neural_network_with_apis/,manish939,1565030187,learn neural networks working and api's like tenserflow nd keras suggest me the online best courses with practise sheets nd must be free,2,0,False,self,,,,,
55,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,5,cmgjvu,self.deeplearning,Explaining How DeepMind's Population Based Training Works,https://www.reddit.com/r/deeplearning/comments/cmgjvu/explaining_how_deepminds_population_based/,HenryAILabs,1565037282,[https://www.youtube.com/watch?v=pEANQ8uau88&amp;t=33s](https://www.youtube.com/watch?v=pEANQ8uau88&amp;t=33s),8,29,False,self,,,,,
56,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,9,cmj48h,kdnuggets.com,Pytorch Cheat Sheet for Beginners and Udacity Deep Learning Nanodegree,https://www.reddit.com/r/deeplearning/comments/cmj48h/pytorch_cheat_sheet_for_beginners_and_udacity/,glassjar123,1565049658,,0,1,False,default,,,,,
57,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,10,cmke4w,self.deeplearning,Which is the better GPU for deep learning? Titan series or Tesla series?,https://www.reddit.com/r/deeplearning/comments/cmke4w/which_is_the_better_gpu_for_deep_learning_titan/,clean_pegasus,1565056626,,2,5,False,self,,,,,
58,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,16,cmnhun,self.deeplearning,Transporting neural nets?,https://www.reddit.com/r/deeplearning/comments/cmnhun/transporting_neural_nets/,swoonz101,1565076512,"I was wondering if transferring neural nets through TCP/IP was the most efficient way to go about it. I'm working on a deep learning project that has remote deployment along with inference at the edge. Model training is done in the cloud and inference is done at the edge. Given that the network connection available is a bit spotty, I was wondering if there was a faster way to transmit neural nets. Is there any research papers or projects on this subject?",6,2,False,self,,,,,
59,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,18,cmo6ty,blog.floydhub.com,When Not to Choose the Best NLP Model,https://www.reddit.com/r/deeplearning/comments/cmo6ty/when_not_to_choose_the_best_nlp_model/,pirate7777777,1565082206,,0,10,False,default,,,,,
60,deeplearning,t5_2t5eh,2019-8-6,2019,8,6,21,cmq4ko,self.deeplearning,"PyTorch Implementation of various Semantic Segmentation models (deeplabV3+, PSPNet, Unet, ...)",https://www.reddit.com/r/deeplearning/comments/cmq4ko/pytorch_implementation_of_various_semantic/,youali,1565095542,"To get a handle of semantic segmentation methods, I re-implemented some well known models with a clear structured code (following this [PyTorch template](https://github.com/victoresque/pytorch-template)), in particularly:

- The implemented models are: Deeplab V3+ - GCN - PSPnet - Unet - Segnet and FCN

- Supported datasets: Pascal Voc, Cityscapes, ADE20K, COCO stuff,

- Losses: Dice-Loss, CE Dice loss, Focal Loss and Lovasz Softmax,

with various data augmentations and learning rate schedulers (poly learning rate and one cycle).

I though I share this implementation in case anyone might be interested, and here it is :

**Github**: https://github.com/yassouali/pytorch_segmentation",8,49,False,self,,,,,
61,deeplearning,t5_2t5eh,2019-8-7,2019,8,7,0,cmrscv,self.deeplearning,Why does backpropagation have it's own name? Isn't it just a use of the chain rule?,https://www.reddit.com/r/deeplearning/comments/cmrscv/why_does_backpropagation_have_its_own_name_isnt/,PertPerri,1565104168,"I know that a lot of machine learning is just reusing and renaming things discovered a long time ago in other fields, but come on. When people talk about backpropagation as if it's some fancy algorithm, it distracts from the clever bit that all the deep learning libraries use to calculate gradients: automatic differentiation. Maybe it's just in YouTube tutorials, but everyone seems to talk about calculating gradients and none of them explain what automatic differentiation is or how it works/is implemented in popular libraries.

Perhaps I'm just odd, but I absolutely hate it when people use unnecessary, fancy-sounding words.",11,2,False,self,,,,,
62,deeplearning,t5_2t5eh,2019-8-7,2019,8,7,0,cmsbri,self.deeplearning,can I use an nvidia 1060 6 GB from a VM (win 10 host)? anything I need to know/do?,https://www.reddit.com/r/deeplearning/comments/cmsbri/can_i_use_an_nvidia_1060_6_gb_from_a_vm_win_10/,remotepie0,1565106741,"Hi,  (terminology: host means the bare metals computer that boots for example I am runnign windows 10, guest is the computer within a VM like if I run a vm and install linux within it then linux is the guest OS.)

I'm curious if I would have any detriment from running my machine learning stuff from inside a VM within my host, Windows 10.  I have a 6 GB nvidia 1060.  I can imagine the VM either can, or can't, just directly pass through the stuff that needs on the card.

What do I need to know?

1.  i.e. what VM can I use (such as Parallels Desktop 14, Oracle VM Virtualbox, VMware Fusion and Workstation?)

2.  Do I need to configure anything special to make the pass-through work properly?

3.  I use windows 10 as the host, but since I am learning about machine learning for the first time I am curious about what guest(s) would be appropriate - also windows 10, or is linux much better?  Which Linux?

I have 16 GB of RAM on the host computer and heard that deep learning doesn't take much ram, so I plan to just give 4 GB to my guest machine.

If this setup is unlikely to work well please let me know.  I suppose I can run the things I'm learning about directly on my host comptuer.  The reason I would not like to do this is to keep from adding things to my computer as I install all the tooling I would use.  For example I woudl prefer not to install python and tensorflow on my (host) computer, just within the guest.  Additionally, I kind of have the idea that later I could upload my guest to the cloud and scale out my learning algorithms without configuring anything else, almost like if I had it as a docker thing.  but this could be kind of stupid.

please let me know what I need to know.  thanks.",5,1,False,self,,,,,
63,deeplearning,t5_2t5eh,2019-8-7,2019,8,7,3,cmu7xy,towardsdatascience.com,Fake it 'till you make it: in defence of a simulated approach to build (good) Computer Vision projects,https://www.reddit.com/r/deeplearning/comments/cmu7xy/fake_it_till_you_make_it_in_defence_of_a/,pjgrizel,1565115476,,0,0,False,default,,,,,
64,deeplearning,t5_2t5eh,2019-8-7,2019,8,7,4,cmv3ix,self.MachineLearning,[P] Open source an NLP/speech library DELTA,https://www.reddit.com/r/deeplearning/comments/cmv3ix/p_open_source_an_nlpspeech_library_delta/,hankun11,1565119484,,2,1,False,default,,,,,
65,deeplearning,t5_2t5eh,2019-8-7,2019,8,7,6,cmwsij,self.deeplearning,"Robust Lane Detection and Tracking Framework for Autonomous Vehicle (Indian Roads) using DeepCNN, Ext. Hough Transform and Kalman Filter.",https://www.reddit.com/r/deeplearning/comments/cmwsij/robust_lane_detection_and_tracking_framework_for/,ayush0016,1565128613,"Being part of the perception team at an autonomous vehicle research group, I had been working on the Lane detection and tracking module for the vehicle.  What made the project challenging were many factors unique to the Indian landscape like highly weathered lanes and unusually congested traffic problems, which took the project close to long 8 months to complete.

The framework is trained and evaluated on the data collected by our experimental vehicle on Indian roads. The dataset consists of a total of 4500 frames with varying driving scenarios, including highways, urban roads, traffic, shadowed lanes, partially visible lanes and curved lanes.",0,1,False,self,,,,,
66,deeplearning,t5_2t5eh,2019-8-7,2019,8,7,8,cmxxon,self.deeplearning,derivations for recursive neural tensor networks and kernel invariants,https://www.reddit.com/r/deeplearning/comments/cmxxon/derivations_for_recursive_neural_tensor_networks/,sz524,1565134050,"Some notes of mine, one derivations from the RNTN paper, the other invariance forms for kernels (convolutional nets) derived by infinitesimal variation under the corresponding symmetry group. Apologies for the bad handwriting.

[https://github.com/4d55397500/handwritten-notes](https://github.com/4d55397500/handwritten-notes)",0,0,False,self,,,,,
67,deeplearning,t5_2t5eh,2019-8-7,2019,8,7,13,cn0y91,youtu.be,Linear Regression in Machine Learning | MLAIT,https://www.reddit.com/r/deeplearning/comments/cn0y91/linear_regression_in_machine_learning_mlait/,mlait1908,1565150853,,0,1,False,default,,,,,
68,deeplearning,t5_2t5eh,2019-8-7,2019,8,7,15,cn25z2,self.deeplearning,New to deep learning!,https://www.reddit.com/r/deeplearning/comments/cn25z2/new_to_deep_learning/,YALAMARTHI97,1565159122,"Hey ya guys.. The recent AIs playing games using deep learning has pricked my interest in deep learning and I find myself switching from python based low lvl ML implementation ( like regressions and stuff ... P.s learnt it in Univ not a pretty good implementer of em anyway )

I do have some theoretical knowledge about neural networks . I now wanna try to create an AI bot which can play a certain game by learning from the basic rules and stuff of the game using deep learning .

Am finding it hard to pin point any articles which would guide me on that particular way of creating a bit using deep learning and enabling it to play the game ..

R there any helpful weblinks r articles r psuedo codes of such sort which I can go through .. learn and then implement em ..???

Thanks in advance !

Desperate learner",4,0,False,self,,,,,
69,deeplearning,t5_2t5eh,2019-8-7,2019,8,7,16,cn2vsf,medium.com,Benefits of Using AI Chatbots in Insurance,https://www.reddit.com/r/deeplearning/comments/cn2vsf/benefits_of_using_ai_chatbots_in_insurance/,MachineLearning001,1565164476,,0,8,False,default,,,,,
70,deeplearning,t5_2t5eh,2019-8-7,2019,8,7,17,cn2zns,youtube.com,Deep insight of AI,https://www.reddit.com/r/deeplearning/comments/cn2zns/deep_insight_of_ai/,OliviaWillson,1565165366,,0,1,False,default,,,,,
71,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,0,cn7a87,towardsdatascience.com,Illustrated: 10 CNN Architectures,https://www.reddit.com/r/deeplearning/comments/cn7a87/illustrated_10_cnn_architectures/,raibosome,1565191947,,1,42,False,default,,,,,
72,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,2,cn8p9h,i.redd.it,Guys!! I m doing andrew ng s deep learning specialisation . Can anyone help me that how he got Z[1] (with derivation in detail) . It would be nice :) [i alread asked this question in forums but no reply ;( ],https://www.reddit.com/r/deeplearning/comments/cn8p9h/guys_i_m_doing_andrew_ng_s_deep_learning/,Sahil8141,1565198507,,10,1,False,image,,,,,
73,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,4,cnaqe0,self.deeplearning,"[Research] Robust Lane detection and tracking framework for Autonomous Vehicles(Indian Roads) using Deep CNN, Ext. Hough Transform and Kalman Filter.",https://www.reddit.com/r/deeplearning/comments/cnaqe0/research_robust_lane_detection_and_tracking/,ayush0016,1565207714,"Being part of the perception team at an Autonomous Vehicle research lab I had been working on the development of the lane detection and tracking module for the vehicle catering to Indian road scenario. What made the project challenging were many factors unique to the Indian landscape like highly weathered lanes and unusually congested traffic problems which took the project close to 8 months to complete.  
The framework is trained and evaluated on the data collected by our experimental vehicle on Indian roads. The dataset consists of a total of 4500 frames with varying driving scenarios, including highways, urban roads, traffic, shadowed lanes, partially visible lanes and curved lanes.

Project Page/Github link : [https://github.com/ayush1997/Robust-Lane-Detection-and-Tracking](https://github.com/ayush1997/Robust-Lane-Detection-and-Tracking)",0,1,False,self,,,,,
74,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,5,cnbh00,self.deeplearning,Trying to understand the foundation of batch normalization,https://www.reddit.com/r/deeplearning/comments/cnbh00/trying_to_understand_the_foundation_of_batch/,cooperbaerseth,1565211087,"I have a basic/fundamental question that I think I've glossed over in the past and would now like to look at more rigorously. 

&amp;#x200B;

For neural networks, why is it so important that we keep the distribution of the data constant as we proceed with training/validation/testing? This basic fact is what batch normalization seems to be based on, but I don't really understand the reason why it's so important. Intuitively or mathematically. 

&amp;#x200B;

Also, any text that explains the idea is very much appreciated. Thanks!!",4,4,False,self,,,,,
75,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,5,cnbhac,reddit.com,"convert video data (.avi, .mp4 etc.) to TensorFlow tfrecords",https://www.reddit.com/r/deeplearning/comments/cnbhac/convert_video_data_avi_mp4_etc_to_tensorflow/,whiletrue2,1565211122,,0,1,False,default,,,,,
76,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,6,cncbyg,self.deeplearning,Medical image classification,https://www.reddit.com/r/deeplearning/comments/cncbyg/medical_image_classification/,moizsawan,1565215178,"Hi all! I am currently working on a medical based image classification. But now I also have age of the patient as another feature (has a relationship with the outcome). I dont know how to incorporate age feature with the deep features. I have tried concatenation but as expected, the results are poor. I want to use deep features as a separate feature and age feature as a separate feature. Any idea how to go around with this problem (you can also refer me some research paper). In the future, I will have more features such as weight, etc. So I want to have a concrete setup for this problem.",13,9,False,self,,,,,
77,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,8,cnda6y,self.deeplearning,[Project] Temporal Attentive Alignment for Large-Scale Video Domain Adaptation (ICCV 2019 Oral),https://www.reddit.com/r/deeplearning/comments/cnda6y/project_temporal_attentive_alignment_for/,cmhung34,1565219837,"Hello,  

It's my pleasure to share our recent work on Video Domain Adaptation with you!    
We proposed large-scale cross-domain action datasets, and developed an attention-based spatio-temporal DA mechanism to achieve effective domain alignment.  

Temporal Attentive Alignment for Large-Scale Video Domain Adaptation (ICCV 2019 Oral)  
\[GitHub\] https://github.com/cmhungsteve/TA3N   
\[arXiv\] https://arxiv.org/abs/1907.12743    


Feel free to share with others :)",0,1,False,self,,,,,
78,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,12,cng98o,self.deeplearning,convNetQuake overfitting,https://www.reddit.com/r/deeplearning/comments/cng98o/convnetquake_overfitting/,arjundupa,1565236418,"I am training the convNetQuake architecture ([https://advances.sciencemag.org/content/advances/4/2/e1700578.full.pdf](https://advances.sciencemag.org/content/advances/4/2/e1700578.full.pdf)) on time-series data for binary classification. 

Here's the architecture in PyTorch:

    class ConvNetQuake(nn.Module):
        def __init__(self):
            super(ConvNetQuake, self).__init__()
            
            self.conv1 = nn.Conv1d(in_channels=2, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv2 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv3 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv4 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv5 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv6 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv7 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.conv8 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1)
            self.linear = nn.Linear(128, 1)
            self.sigmoid = nn.Sigmoid()
    
        def forward(self, x):
            x = F.relu((self.conv1(x)))
            x = F.relu((self.conv2(x)))
            x = F.relu((self.conv3(x)))
            x = F.relu((self.conv4(x)))
            x = F.relu((self.conv5(x)))
            x = F.relu((self.conv6(x)))
            x = F.relu((self.conv7(x)))
            x = F.relu((self.conv8(x)))
            # After the eighth convolution, the features are flattened into a 1D vector of 128 features.
            x = torch.reshape(x, (10, -1))
            # A fully connected layer outputs the class scores
            x = self.linear(x)
            x = self.sigmoid(x)
    
            return x

My issue is that this base model is overfitting on my binary classification task. Here are some accuracies I obtained:

base\_model: 77/78

base\_model + batchNorm(): **87/88**

base\_model + dropout(0.1): 81/82

base\_model + label\_smoothing: 82/83

base\_model + batchNorm() + dropout(0.1): 82/83

base\_model + batchNorm() + label\_smoothing: 85

smaller base\_model (6 layers): 81/82

smaller base\_model (4 layers): 72/73

&amp;#x200B;

&amp;#x200B;

|Model|Accuracy (%)|
|:-|:-|
|base\_model|77/78|
|base\_model + batchNorm()|**87/88**|
|base\_model + dropout(0.1)|81/82|
|base\_model + label\_smoothing|82/83|
|base\_model + batchNorm() + dropout(0.1)|82/83|
|base\_model + batchNorm() + label\_smoothing|85|
|smaller base\_model (6 layers)|81/82|
|smaller base\_model (4 layers)|72/73|

&amp;#x200B;

All of these models overfit, despite the effort to combat this overfitting. Any ideas about what else could be tried?",9,2,False,self,,,,,
79,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,15,cnhmjy,self.deeplearning,Slow AI response.,https://www.reddit.com/r/deeplearning/comments/cnhmjy/slow_ai_response/,Gkiid,1565244815,"Hello,   


I create a voice recognition on python, and everytime I command the ai, its responses is very slow, like taking 10 seconds to do the task. is it possible to enhance this or make it more faster responsiveness? any libraries needed for it?   


Thanks  


if specs matters, i have:

Ryzen 5 2600x  
Strix 2060   
HyperX 3200mhz RAM 16GB

mic: Plantronics Blackwire 3225 Series.",3,1,False,self,,,,,
80,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,15,cnhykc,medium.com,Benefits of Using AI Chatbots in Insurance,https://www.reddit.com/r/deeplearning/comments/cnhykc/benefits_of_using_ai_chatbots_in_insurance/,MachineLearning001,1565247027,,0,1,False,default,,,,,
81,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,17,cnixpp,youtu.be,Building a Simple #NeuralNetwork in #Tensorflow | #MLAIT #ml #ai #DeepLearning,https://www.reddit.com/r/deeplearning/comments/cnixpp/building_a_simple_neuralnetwork_in_tensorflow/,mlait1908,1565253920,,0,0,False,image,,,,,
82,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,17,cnj1vw,self.deeplearning,Real time Face-Detection on the RaspberryPi-4 achieving a frame rate of 15-17 FPS(deep learning),https://www.reddit.com/r/deeplearning/comments/cnj1vw/real_time_facedetection_on_the_raspberrypi4/,shunyaos4ai,1565254792,You can refer to the instructions here: [https://www.instructables.com/id/Real-Time-Face-Detection-on-the-RaspberryPi-4/](https://www.instructables.com/id/Real-Time-Face-Detection-on-the-RaspberryPi-4/) Also you can find the library documentation and APIguide here on github: [https://github.com/shunyaos/shunyaface](https://github.com/shunyaos/shunyaface),5,24,False,self,,,,,
83,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,19,cnk3rt,self.deeplearning,Collaboration on a research paper,https://www.reddit.com/r/deeplearning/comments/cnk3rt/collaboration_on_a_research_paper/,clean_pegasus,1565261861,I'm working on a research paper on Generative adversarial networks (GANs). Hit me up if you wanna colab.,10,4,False,self,,,,,
84,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,22,cnlwyt,self.deeplearning,Bridging Microsoft SEAL into TensorFlow,https://www.reddit.com/r/deeplearning/comments/cnlwyt/bridging_microsoft_seal_into_tensorflow/,ybsu,1565271609,Check out this blog about how we bridged Microsoft SEAL into Tensorflow! We hope that this will help bring new privacy preserving features to machine learning and more! [https://medium.com/dropoutlabs/bridging-microsoft-seal-into-tensorflow-b04cc2761ad4](https://medium.com/dropoutlabs/bridging-microsoft-seal-into-tensorflow-b04cc2761ad4),0,2,False,self,,,,,
85,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,22,cnm1gg,self.deeplearning,Medical Classification (non-image data),https://www.reddit.com/r/deeplearning/comments/cnm1gg/medical_classification_nonimage_data/,moizsawan,1565272206,Hi all! I want to know of state of the art models for predictions on medical data (non image). Thanks.,0,0,False,self,,,,,
86,deeplearning,t5_2t5eh,2019-8-8,2019,8,8,23,cnmcon,self.deeplearning,[Research] An End-to-End Empathetic Chatbot,https://www.reddit.com/r/deeplearning/comments/cnmcon/research_an_endtoend_empathetic_chatbot/,cdossman,1565273647,"**Abstract:**  In this paper, we present an end-to-end empathetic conversation agent CAiRE. Our system adapts TransferTransfo (Wolf et al., 2019) learning approach that fine-tunes a large-scale pre-trained language model with multi-task objectives: response language modeling, response prediction and dialogue emotion detection. We evaluate our model on the recently proposed empathetic-dialogues dataset (Rashkin et al., 2019), the experiment results show that CAiRE achieves state-of-the-art performance on dialogue emotion detection and empathetic response generation. 

[https://medium.com/ai%C2%B3-theory-practice-business/meet-caire-an-end-to-end-empathetic-conversation-chatbot-2e34abf84afc](https://medium.com/ai%C2%B3-theory-practice-business/meet-caire-an-end-to-end-empathetic-conversation-chatbot-2e34abf84afc)",0,3,False,self,,,,,
87,deeplearning,t5_2t5eh,2019-8-9,2019,8,9,5,cnrcym,self.deeplearning,Neural network inference pipeline for videos in Tensorflow,https://www.reddit.com/r/deeplearning/comments/cnrcym/neural_network_inference_pipeline_for_videos_in/,alseambusher,1565295526,"Just as we saw a huge influx of images in the past decade or so, we are now seeing a lot of videos being produced on social media. The need to understand and moderate videos using machine learning has never been greater.

In this post, I will show you how to build an efficient pipeline to processes videos in Tensorflow.


https://lifepluslinux.blogspot.com/2019/08/neural-network-inference-pipeline-for.html",0,23,False,self,,,,,
88,deeplearning,t5_2t5eh,2019-8-9,2019,8,9,6,cnsi1x,self.AmazonGameTech,Gamescom 2019  Game Tech Community Event,https://www.reddit.com/r/deeplearning/comments/cnsi1x/gamescom_2019_game_tech_community_event/,CGAmonster,1565300415,,0,1,False,default,,,,,
89,deeplearning,t5_2t5eh,2019-8-9,2019,8,9,7,cnt00p,self.deeplearning,Is my assigned task even possible?,https://www.reddit.com/r/deeplearning/comments/cnt00p/is_my_assigned_task_even_possible/,ArmoredBaguette,1565302635,"Hello everyone, i'm a French IT student working as an intern for a very small startup, and long story short, my goal is to build a system that reliably recognizes individual faces in real time. 

After a lot of tinkering, i'm using a custom fine-tuned VGG FACE with Keras. 

&amp;#x200B;

My question is the following: without going into details, is it possible to obtain quick reliable face recognition with this ""cocktail"" (Keras, Fine-tuning, and VGG face).

If yes, what should i look out for?

If No, are there better alternatives?",18,10,False,self,,,,,
90,deeplearning,t5_2t5eh,2019-8-9,2019,8,9,10,cnvkej,self.deeplearning,Getting Started to Achieving Kaggle Kernels GM Rank #4 in just 9 months | Interview with Shivam Bansal,https://www.reddit.com/r/deeplearning/comments/cnvkej/getting_started_to_achieving_kaggle_kernels_gm/,init__27,1565315503,"Interview with Shivam Bansal, Kernels GM Ranked 4: 

Did you know Shivam made it to the Top 4 Rankings in Kernels after just 9 months of getting started on Kaggle!

We talk about his journey into Data Science, Kaggle. Shivam also shares his pipeline and motivation behind writing kernels. 

(Audio) https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Kernels-GM-Shivam-Bansal-e4qcbe/a-ak0id3

(Video) https://www.youtube.com/watch?v=0K4C1FMVbgQ",0,3,False,self,,,,,
91,deeplearning,t5_2t5eh,2019-8-9,2019,8,9,11,cnvoey,self.deeplearning,Getting Started to Achieving Kaggle Kernels GM &amp; Rank #2 in just 9 months | Interview with Shivam Bansal,https://www.reddit.com/r/deeplearning/comments/cnvoey/getting_started_to_achieving_kaggle_kernels_gm/,init__27,1565316081,"Interview with Shivam Bansal, Kernels GM Ranked 4: 

Did you know Shivam made it to the Top 2 Rankings in Kernels after just 9 months of getting started on Kaggle!

We talk about his journey into Data Science, Kaggle. Shivam also shares his pipeline and motivation behind writing kernels. 

(Audio) https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Kernels-GM-Shivam-Bansal-e4qcbe/a-ak0id3

(Video) https://www.youtube.com/watch?v=0K4C1FMVbgQ",0,14,False,self,,,,,
92,deeplearning,t5_2t5eh,2019-8-9,2019,8,9,20,co17dr,medium.com,How AI Is Transforming The Healthcare Sector,https://www.reddit.com/r/deeplearning/comments/co17dr/how_ai_is_transforming_the_healthcare_sector/,MachineLearning001,1565350914,,0,2,False,default,,,,,
93,deeplearning,t5_2t5eh,2019-8-9,2019,8,9,21,co1w38,self.deeplearning,Explicit construction of manifolds in latent space.,https://www.reddit.com/r/deeplearning/comments/co1w38/explicit_construction_of_manifolds_in_latent_space/,nefrpitou,1565354820,"GANs and VAEs sample from a known distribution like Unit Gaussian and map dataset to it.

I however, want to explicitly map certain images/inputs to exact points in the latent space. For example, if we have a 0-mean 1-std multi-variate gaussian, I want to be able to map certain images in my dataset, explicitly to 0-mean 0.5-std of the latent space. 

Extending the idea further, I want to construct a hypersphere or hypercube in latent n-dimensional space, and want to place certain datapoints at the vertices of this manifold. The rest of the datapoints should be mapped accordingly, based on the training process and the pre-placed datapoints.

Are there any theoretical papers that you know of, that have aimed to do this?",5,12,False,self,,,,,
94,deeplearning,t5_2t5eh,2019-8-9,2019,8,9,23,co2syf,towardsdatascience.com,(Video demos) How We Construct a Virtual Beings Brain with Deep Learning,https://www.reddit.com/r/deeplearning/comments/co2syf/video_demos_how_we_construct_a_virtual_beings/,nahuak,1565359417,,0,13,False,default,,,,,
95,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,1,co4wrn,self.deeplearning,How to annotate/augment images for multi-class semantic segmentation?,https://www.reddit.com/r/deeplearning/comments/co4wrn/how_to_annotateaugment_images_for_multiclass/,74throwaway,1565368801,"I'm confused as to how to annotate images with different classes of objects in them. For example, in ""a simple example"" at: https://imgaug.readthedocs.io/en/latest/source/examples_segmentation_maps.html

The original `segmap` variable has values of 0, 1,..., 5. Yet after the augmentation, if I were to inspect the values of the pixels in column 5 of the `cells` after the augmentation (line `cells.append(segmap_aug.draw(size=image_aug.shape[:2]))`), each pixel takes on rgb values, such as (200,50,50), instead of a single number from 0-5

Aren't the augmented images supposed to have values between 0-5 instead of rgb values if I wanted to use those augmented images directly within a semantic segmentation model, such as Unet from here: https://github.com/zhixuhao/unet ?",0,5,False,self,,,,,
96,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,7,co9bec,pub.dfblue.com,"Here are the tools which have lead to the wildfire of deepfakes on the internet. I have used both and did a comparision between the two. Have you checked out the softwares yet? If yes, what did you think?",https://www.reddit.com/r/deeplearning/comments/co9bec/here_are_the_tools_which_have_lead_to_the/,deepfakeblue,1565388380,,0,2,False,default,,,,,
97,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,8,coacyt,self.deeplearning,Need help building an NLP model,https://www.reddit.com/r/deeplearning/comments/coacyt/need_help_building_an_nlp_model/,gulzainali,1565393588,"I am buidling a deep learning model which can generate relevant questions about businesses. I have a dataset of business reviews. Model should be able to build some questions like ""did you like donut"" or ""how good was the dinner "". I wanted to know if i can find any helpful tutorial/code/paper implementation on building such a model. 

I only know how to build a sequence to sequence model. It would be of great help if you can direct me to a good resource or guide me through the solution in the comments. Thanks in advance!",6,9,False,self,,,,,
98,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,13,codp6e,self.deeplearning,Any good alternative to deeplearning.net?,https://www.reddit.com/r/deeplearning/comments/codp6e/any_good_alternative_to_deeplearningnet/,pleaseThisNotBeTaken,1565412638,"I just started following [deeplearning.net](https://deeplearning.net) tutorials to start with deeplearning, however, they use Theano and from what I've learnt is that it's effectively dead (the team announced they'll stop any major development back in 2017). I believe those were excellent tutorials for getting started and I just wanted an opinion from people here on what would be a good alternative for the site that uses frameworks like PyTorch, CNTK, Tensorflow.",3,1,False,self,,,,,
99,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,16,coevrf,i.redd.it,We developed arrow color detection using transfer learning and online training. For application in self driving mini rovers. It was really fun and exciting.,https://www.reddit.com/r/deeplearning/comments/coevrf/we_developed_arrow_color_detection_using_transfer/,bathon,1565420838,,9,34,False,image,,,,,
100,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,16,cof614,self.deeplearning,UNet and Segmentation In-depth Explanation,https://www.reddit.com/r/deeplearning/comments/cof614/unet_and_segmentation_indepth_explanation/,bluesky314,1565422929,"Hey guys, I have been working in DL research for about a year and have found very less info explaining how segmentation works in neural networks, especially compared to classification. Beginners have much trouble wrapping their head around how the network is able to segment an entire image, so I made a video to explain what goes on:

[https://www.youtube.com/watch?v=NzY5IJodjek](https://www.youtube.com/watch?v=NzY5IJodjek)

&amp;#x200B;

The people I've shown it to like it and some stuff is not explained anywhere. If you're working on segmentation, it well worth the watch. Feedback and likes appreciated!",1,3,False,self,,,,,
101,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,16,cofa33,self.deeplearning,[P] Simple PyTorch implementation of Language Model,https://www.reddit.com/r/deeplearning/comments/cofa33/p_simple_pytorch_implementation_of_language_model/,lyeoni,1565423809,"A step-by-step tutorial on how to implement and adapt recurrent language model to Wikipedia text.

A pre-trained BERT, XLNET is publicly available ! But, for NLP beginners, like me, It could be hard to use/adapt after full understanding. For them, I covered whole, end-to-end implementation process for language modeling, using recurrent network, we already know. + do not use torchtext !

I hope that this repo can be a good solution for people who want to have their own language model :)

https://github.com/lyeoni/pretraining-for-language-understanding",0,1,False,self,,,,,
102,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,17,cofbs7,self.deeplearning,ManiFold Mixup,https://www.reddit.com/r/deeplearning/comments/cofbs7/manifold_mixup/,bluesky314,1565424149,"What do people think about the new regulariser Manifold Mixup explained well here: [https://www.youtube.com/watch?v=1L83tM8nwHU](https://www.youtube.com/watch?v=1L83tM8nwHU)?

&amp;#x200B;

Seems like a great idea",0,4,False,self,,,,,
103,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,21,cohmch,self.deeplearning,"Hi Everyone, I am planning to build a Deep Learning Machine with config mentioned in the image. Is this config good enough, any suggestion is welcomed. Help me out.",https://www.reddit.com/r/deeplearning/comments/cohmch/hi_everyone_i_am_planning_to_build_a_deep/,mayurat22,1565441339,"&amp;#x200B;

https://i.redd.it/lt25t2eramf31.png",4,1,False,self,,,,,
104,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,22,coi3is,learnworthy.net,"""Difference Between Artificial Intelligence, Machine Learning and Deep Learning""",https://www.reddit.com/r/deeplearning/comments/coi3is/difference_between_artificial_intelligence/,susanvilleula1,1565444052,,0,3,False,default,,,,,
105,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,23,coifgi,self.deeplearning,The Modularity of Deep Learning,https://www.reddit.com/r/deeplearning/comments/coifgi/the_modularity_of_deep_learning/,MasterSnipes,1565445830,"[https://jinayjain.code.blog/2019/08/07/the-modularity-of-deep-learning/](https://jinayjain.code.blog/2019/08/07/the-modularity-of-deep-learning/)

I decided to write a post on how extensible and modular the process of training neural networks is, all glued together with the power of backpropagation. It's quite amazing how quickly people can design and iterate on models and this facet of deep learning doesn't appear in many other fields. I thought I'd discuss that in a blogpost so here it is!

I'm new to blogging so any feedback or even a quick follow is appreciated!",0,3,False,self,,,,,
106,deeplearning,t5_2t5eh,2019-8-10,2019,8,10,23,coipcy,twitter.com,"[PSA] ""Deep Learning Cookbook"" on the Machine Learning ebook bundle ($1 - ending in 2 days)",https://www.reddit.com/r/deeplearning/comments/coipcy/psa_deep_learning_cookbook_on_the_machine/,wazuddin,1565447274,,0,1,False,default,,,,,
107,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,0,cojc1u,twitter.com,Reminder: Deep Learning Cookbook on the Machine Learning book pack. Ends in two days,https://www.reddit.com/r/deeplearning/comments/cojc1u/reminder_deep_learning_cookbook_on_the_machine/,tomsmith434,1565450480,,0,1,False,default,,,,,
108,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,0,cojmab,self.deeplearning,Reminder: Deep Learning Cookbook on the Machine Learning book pack. Ends in two days,https://www.reddit.com/r/deeplearning/comments/cojmab/reminder_deep_learning_cookbook_on_the_machine/,tomsmith434,1565451863," O'Reilly's books are valuable and so is this bundle. The relevant title is on the first tier anyway for $1 so I thought some would appreciate the reminder to quickly grab it.

&amp;#x200B;

[Here](https://twitter.com/Deeplearningthem/status/1160158936881946628)",6,35,False,self,,,,,
109,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,0,cojqh9,self.deeplearning,Working with large data,https://www.reddit.com/r/deeplearning/comments/cojqh9/working_with_large_data/,sambalshikhar,1565452448, I am working on a project for document type classification.I have approc 400k training samples.I have a 920mx 4gb gpu which is inefficient.The data size is around 100gb which is huge so no colab in action.I am using batches of 16 as that is the max my gpu can fit.What are ur suggestions?,4,3,False,self,,,,,
110,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,2,cokomo,self.deeplearning,Help with DL framework.,https://www.reddit.com/r/deeplearning/comments/cokomo/help_with_dl_framework/,ragingpot,1565456943,"I'm working on writing a DL framework. I'm looking for an implementation of a convolutional layer in numpy. Also if anyone here has an idea about implemention an autograd package from the ground up, hell would be appreciated. Not looking for any blazing fast performance, just some inside knowledge about how frameworks work.",3,0,False,self,,,,,
111,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,2,col1d8,self.deeplearning,"Can we discuss exposure bias/teacher forcing, the motivation of the ACL 2019 best paper?",https://www.reddit.com/r/deeplearning/comments/col1d8/can_we_discuss_exposure_biasteacher_forcing_the/,cloudygoose,1565458562,"The ACL 2019 best paper ([https://arxiv.org/pdf/1906.02448.pdf](https://arxiv.org/pdf/1906.02448.pdf)), brings out the exposure bias/teacher forcing again, an important topic in language modeling/language generation.

The point I want to make is, I believe a good way to do research is that you FIRST show me some problem is really serious, and THEN you propose a way to solve it. In the introduction part, they provide a reasoning about their motivations, it makes sense, but it' does not concretely show the problem is serious. As we know, most MLE-trained STOA NMT models are doing well at their job.

So, let's assume exposure bias/teacher forcing is really bad for language generation, can we use a simple way to show it?

I design the following experiment, take a MLE-trained LSTM-LM on some data-set, you feed three types of history prefix sequence to it. And let the model do sampling and complete the sentence.

(1) The ground truth data prefix.

(2) Samples from the model itself.

(3) Completely random sequence, totally rubbish.

These three type of history gives different level of training-inference discrepancy. Now, I expect the quality of the completion samples should be (1) &gt; (2) &gt;&gt; (3), do you agree?

This is the samples I get:

https://i.redd.it/rzm5nqhwpnf31.png

My observation is that, I don't see very significant sample quality difference. Even for the random input, the model quickly start to generate fairly reasonable samples.

This experiment make me seriously question ""is exposure bias really a big problem?"" 

If you also feel interested, please read our paper [https://arxiv.org/pdf/1905.10617.pdf](https://arxiv.org/pdf/1905.10617.pdf) , and comments are welcome.

I think this is also similar to the batch-norm case, you just CLAIM ""covariate shift"" is really bad, you propose batch-norm to solve it, you get good gains. That's great, but does ""covariate shift"" really exist? May not. See [https://arxiv.org/pdf/1805.11604.pdf](https://arxiv.org/pdf/1805.11604.pdf)

Final note, in section 5.7 of the ACL paper, they claimed the performance gain is from solving exposure bias, but I really don't see it. Their arguments can convince me their model is better than baseline, but I don't see how it's related to exposure bias.

And I'm not saying the ACL paper is a bad paper, it's great they get solid gains. I'm just suggesting we should be careful about validating our research motivations.",1,3,False,self,,,,,
112,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,3,colswv,self.deeplearning,RTX 2080 With Intel i7 8700k !,https://www.reddit.com/r/deeplearning/comments/colswv/rtx_2080_with_intel_i7_8700k/,mayurat22,1565462235,Will RTX 2080 work with full efficiency if tied up with i7-8700k or the performance of the graphic card will reduce because of pcie lane support Intel i7  ?,2,0,False,self,,,,,
113,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,7,coobpx,self.deeplearning,GPU Tensor Cores vs. FLOPs vs. Memory Bandwidth,https://www.reddit.com/r/deeplearning/comments/coobpx/gpu_tensor_cores_vs_flops_vs_memory_bandwidth/,jahoho,1565474529,"In this relatively popular [blog](https://timdettmers.com/2019/04/03/which-gpu-for-deep-learning/) the author Tim Dettmers explains that when choosing optimal GPU for Convolutional Neural Network architecture, priority should follow: **Tensor Cores &gt; FLOPs &gt; Memory Bandwidth &gt; 16-bit capability**

&amp;nbsp;

With that in mind, would you choose an RTX 2080 Max-Q over an RTX 2070, mainly because it has 28% more tensor cores, although it also has 14% less FLOPs and 14% less Memory Bandwidth than the 2070?

&amp;nbsp;

RTX 2080 Max Q:
- 368 Tensor Cores
- 12.89 TFLOPs (FP16)
- 384 GB/s Memory Bandwidth

&amp;nbsp;

RTX 2070:
- 288 Tensor Cores
- 14.93 TFLOPs (FP16)
- 448 GB/s Memory Bandwidth",3,2,False,self,,,,,
114,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,8,cop826,self.deeplearning,Tool for visualizing the training of neural networks in a web browser?,https://www.reddit.com/r/deeplearning/comments/cop826/tool_for_visualizing_the_training_of_neural/,notreallysocool,1565479148,"I am aware of TensorSpace.js but AFAIK, it can only visualize a pretrained model. I think it would really helpful if we could visualize the neural network while training (eg: we could see how each weights value changes over epochs and it could provide many other useful visualizations). It would be a really useful tool for debugging. Is there already any tool like this? I am not aware of any such tool.",1,1,False,self,,,,,
115,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,11,cor6s5,self.deeplearning,Simple PyTorch implementation of Language Model on Wikipedia text,https://www.reddit.com/r/deeplearning/comments/cor6s5/simple_pytorch_implementation_of_language_model/,lyeoni,1565490240," A step-by-step tutorial on how to implement and adapt recurrent language model to Wikipedia text.

A pre-trained BERT, XLNET is publicly available ! But, for NLP beginners, like me, It could be hard to use/adapt after full understanding. For them, I covered whole, end-to-end implementation process for language modeling, using recurrent network, we already know. + do not use torchtext !

I hope that this repo can be a good solution for people who want to have their own language model :)

[https://github.com/lyeoni/pretraining-for-language-understanding](https://github.com/lyeoni/pretraining-for-language-understanding)",3,20,False,self,,,,,
116,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,12,coru9l,youtube.com,What is a Neural Network - Deep learning chapter1. Using neural nets to ...,https://www.reddit.com/r/deeplearning/comments/coru9l/what_is_a_neural_network_deep_learning_chapter1/,poop2u,1565494080,,19,0,False,default,,,,,
117,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,13,cos80u,self.deeplearning,A good gpu vs a 16gb ram,https://www.reddit.com/r/deeplearning/comments/cos80u/a_good_gpu_vs_a_16gb_ram/,susmit410,1565496382,"I am a newbie to deep learning i don't know any gpu optimizations however I have 16gb ram pc which is fairly good in my opinion to run simple classification algorithms and dqn algos.
The pc has inbuilt gpu too,am not sure tho would i need a gpu ??
Pls help!",9,0,False,self,,,,,
118,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,14,cot4mx,atakans.com,Weakly Supervised Deep Detection Networks,https://www.reddit.com/r/deeplearning/comments/cot4mx/weakly_supervised_deep_detection_networks/,Alkadian,1565502365,,1,4,False,default,,,,,
119,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,20,covh7d,self.deeplearning,Image Segmentation: Why do UNET outperform sliding-window approaches?,https://www.reddit.com/r/deeplearning/comments/covh7d/image_segmentation_why_do_unet_outperform/,automatedredditor,1565521529,"I'm writing a thesis that heavily focuses on semantic segmentation of biomedical images.

I'm reviewing different segmentation approaches, identifying two main approach branches:

* A **sliding window**\-like approach: a classification network is used over different patches of original image to reconstruct a pixel-by-pixel estimates of the probability maps.
* A **full-image** approach: like the FCNN and UNET approach, rely on fully convolutional architectures and the upscaling phase is incorporated in the network itself using transposed convolutions.[https://arxiv.org/abs/1505.04597](https://arxiv.org/abs/1505.04597)

The second approach clearly outperforms the first one. I have a vague hunch on why this happens: my hypothesis is that the transposed-convolution operations, being at their core local operations, force local criteria on the segmentation of close pixels so that pixel contiguity is heavily encouraged in the fully convolutional case.

I do not find this kind of explanation satisfying because of two reasons:

1. I do not have papers or real data to support this: I cannot seem to find any paper on the theme.
2. The sliding-window approach has a built-in form of local consistency as well: if overlapping windows share most of the pixels it's reasonable to think that - given the network is not totally chaotic and shows enough linearity - the outputs would be similar.

Do anyone have a bit of insight or source on any of this? Any contribution, even brainstorming or unsupported hypothesis (like mine) is well appreciated.",8,16,False,self,,,,,
120,deeplearning,t5_2t5eh,2019-8-11,2019,8,11,22,cownr8,learnworthy.net,"Difference Between Artificial Intelligence, Machine Learning and Deep Learning",https://www.reddit.com/r/deeplearning/comments/cownr8/difference_between_artificial_intelligence/,susanvilleula1,1565529703,,2,0,False,default,,,,,
121,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,0,coy7sn,self.deeplearning,Any AIs Where You Can Give it A Bunch Of Images And Have It Generate A New Image In The Same Style?,https://www.reddit.com/r/deeplearning/comments/coy7sn/any_ais_where_you_can_give_it_a_bunch_of_images/,BloodyPommelStudio,1565538001,I'm looking for an AI downloadable or online where I can give it 1000s of pieces of art from the same artist and have it generate new and unique pictures with the same style.,5,0,False,self,,,,,
122,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,0,coyei4,kaggle.com,Training a Neural Network? Start here!,https://www.reddit.com/r/deeplearning/comments/coyei4/training_a_neural_network_start_here/,0_marauders_0,1565538905,,0,0,False,default,,,,,
123,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,1,coyy4d,self.deeplearning,Burn Wound Dataset,https://www.reddit.com/r/deeplearning/comments/coyy4d/burn_wound_dataset/,asjad18,1565541513,"Hi, I was thinking about working on burn wound classification for my final year project, but I am unable to find any datasets online. Can someone tell me where I can find the required dataset?
Thanks",0,1,False,self,,,,,
124,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,7,cp3nug,i.redd.it,"Which tool do people use to make such figures? Draw.io for the boxes maybe, but what about the input/output images?",https://www.reddit.com/r/deeplearning/comments/cp3nug/which_tool_do_people_use_to_make_such_figures/,Jesper89,1565563704,,17,45,False,image,,,,,
125,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,9,cp55jn,self.deeplearning,Can I load a Caffe2 model in PyTorch?,https://www.reddit.com/r/deeplearning/comments/cp55jn/can_i_load_a_caffe2_model_in_pytorch/,fieldcady,1565571509,"Does anybody know a way to load a model from the [Caffe2 Model Zoo](https://github.com/caffe2/models) with PyTorch?  I found a [notebook](https://github.com/onnx/tutorials/blob/master/tutorials/Caffe2OnnxExport.ipynb) that supposedly loads the models with ONNX (from which I could presumably get it into pytorch), but the code fails for me (google.protobuf.message.DecodeError: Error parsing message).  I'm still kinda a noob with deep learning, so I would really appreciate some help and/or guidance.  Thanks!!",1,1,False,self,,,,,
126,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,15,cp8ebp,self.deeplearning,"Interview with Kaggle Kernels Grandmaster Ranked #1, ""Artgor"" Andrew Lukyanenko",https://www.reddit.com/r/deeplearning/comments/cp8ebp/interview_with_kaggle_kernels_grandmaster_ranked/,init__27,1565590386,"Just Released the interview with the King of Kaggle Kernels (currently ranked #1) Grandmaster ""Artgor"": Andrew Lukyanenko

We talk about his journey into DS, his current projects at work, his pipeline, insights, and many tips for writing Kaggle Kernels

[https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Kernels-Grandmaster-1-Artgor--Andrew-Lukyanenko-e4r6du/a-ak53o7](https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Kernels-Grandmaster-1-Artgor--Andrew-Lukyanenko-e4r6du/a-ak53o7)",4,5,False,self,,,,,
127,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,16,cp8tzm,nanonets.com,How to use OCR APIs for character recognition,https://www.reddit.com/r/deeplearning/comments/cp8tzm/how_to_use_ocr_apis_for_character_recognition/,RubiksCodeNMZ,1565593338,,0,2,False,default,,,,,
128,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,16,cp90ky,rubikscode.net,Top Deep Learning Frameworks of 2019,https://www.reddit.com/r/deeplearning/comments/cp90ky/top_deep_learning_frameworks_of_2019/,RubiksCodeNMZ,1565594605,,0,0,False,default,,,,,
129,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,17,cp9pah,self.deeplearning,Machine Learning and Data Analysis ebook bundle is ending in about 9 hours,https://www.reddit.com/r/deeplearning/comments/cp9pah/machine_learning_and_data_analysis_ebook_bundle/,gdotlester,1565599765,"O'Reilly's book bundle. It is valuable imo. The deep learning title is on the first tier for $1 so I thought of sharing.

&amp;#x200B;

[Humble Bundle](https://twitter.com/Thedeeplearningmachine/status/1160158936881946628)",1,18,False,self,,,,,
130,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,20,cpb9p2,medium.com,Strengthening Cybersecurity with Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/cpb9p2/strengthening_cybersecurity_with_artificial/,MachineLearning001,1565610384,,0,0,False,default,,,,,
131,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,21,cpc1qb,mihaileric.com,Trends in Natural Language Processing,https://www.reddit.com/r/deeplearning/comments/cpc1qb/trends_in_natural_language_processing/,MusingEtMachina,1565614776,,0,4,False,default,,,,,
132,deeplearning,t5_2t5eh,2019-8-12,2019,8,12,22,cpci2f,self.deeplearning,Best of AI Articles of July,https://www.reddit.com/r/deeplearning/comments/cpci2f/best_of_ai_articles_of_july/,BastouBab,1565617103,"Hi All!  
These are my 10 favorite AI articles and news published in July. They talk about autonomous driving, artificial intelligence, another GAN application.  
What are your best news and articles of the month of July?  
[https://blog.sicara.com/07-2019-best-ai-new-articles-this-month-3e1fa3f6c321](https://blog.sicara.com/07-2019-best-ai-new-articles-this-month-3e1fa3f6c321)",0,8,False,self,,,,,
133,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,1,cpeflp,blog.paperspace.com,Building a State of the Art Bacterial Classifier with Paperspace Gradient and Fast.ai,https://www.reddit.com/r/deeplearning/comments/cpeflp/building_a_state_of_the_art_bacterial_classifier/,dkobran,1565626036,,0,24,False,default,,,,,
134,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,1,cpeswz,self.deeplearning,DenseNet (Medical Classification),https://www.reddit.com/r/deeplearning/comments/cpeswz/densenet_medical_classification/,moizsawan,1565627625,"I have a classification problem where I have an image, age and the weight as features. How can I use DenseNet in the following manner:
-&gt; For example 3 Dense Blocks
-&gt; Input to the first Dense Block = Image
-&gt; Input to the second Dense Block = Output of first Dense Block and the age
-&gt; Input to the third Dense Block = Output of the second Dense Block and the weight
Can DenseNet be used in the following manner? Basically a numeric feature input to a Dense Block.",0,1,False,self,,,,,
135,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,1,cpezmd,self.deeplearning,DenseNet (Medical classification),https://www.reddit.com/r/deeplearning/comments/cpezmd/densenet_medical_classification/,moizsawan,1565628423,"I have a classification problem where I have an image, age and the weight as features. How can I use DenseNet in the following manner:
For example 3 Dense Blocks.
Input to the first Dense Block = Image.
Input to the second Dense Block = Output of first Dense Block and the age.
Input to the third Dense Block = Output of the second Dense Block and the weight.
Can DenseNet be used in the following manner? Basically a numeric feature input to a Dense Block.",0,1,False,self,,,,,
136,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,4,cpgvq5,teddykoker.com,Histopathologic Cancer Detection with Transfer Learning using Pytorch,https://www.reddit.com/r/deeplearning/comments/cpgvq5/histopathologic_cancer_detection_with_transfer/,asuagar,1565636509,,0,3,False,default,,,,,
137,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,5,cphwqe,self.deeplearning,Plant Disease Detector with Fastai,https://www.reddit.com/r/deeplearning/comments/cphwqe/plant_disease_detector_with_fastai/,imskrai,1565640890,"I have created a Web Application for detecting plant diseases.

Using Fast.ai which sits on top of Pytorch with Resnet34 pre-trained model!

Used Plant Village Dataset, Trained it on Google Cloud Platform and deployed it on AWS Elastic Beans!

Accuracy 99.654%

Fork or Star  on GitHub: https://github.com/imskr/Plant_Disease_Detection",0,1,False,self,,,,,
138,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,9,cpl8ou,self.deeplearning,How to preprocess labeled images for multi-class semantic segmentation?,https://www.reddit.com/r/deeplearning/comments/cpl8ou/how_to_preprocess_labeled_images_for_multiclass/,74throwaway,1565656137,"Let's say I have 100 training images, each of size 512x512. I was able to one-hot encode them using `to_categorical` in Keras with

    numclasses=3 #should this be 4?
    masks_one_hot=to_categorical(maskArr,numclasses)

where `maskArr` is a 100x512x512x1, and `masks_one_hot` is 100x512x512x3. I then saved each image in `masks_one_hot` using `imwrite` into `data/input/label_oneHot` (the non-mask images are in `data/input/image`)

I then performed augmentation:

    data_gen_args = dict(rotation_range=30, width_shift_range=0.05, horizontal_flip=True, vertical_flip=True, ...)
    myGeneratorDefects = trainGeneratorOneHot(20,'data/input','image','label_oneHot',data_gen_args,save_to_dir = ""data/input/aug"",flag_multi_class = True,num_class = numclasses,target_size = (512,512))
     num_batch=3
     for i,batch in enumerate(myGeneratorDefects):
         if(i &gt;= num_batch):
             break

Was I supposed to include `class_mode=""categorical""`? When I tried to, I got some kind of error, I believe it was an `IndexError` with the Unet

Each augmented `mask` then had size of 512x512x3 and had values ranging from 0-255. I then converted it to a 512x512x1 array where each value ranged from 0-2, and then I one-hot encoded it again using `to_categorical`",0,2,False,self,,,,,
139,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,12,cpn6wp,self.deeplearning,Making a generic line detection algorithm,https://www.reddit.com/r/deeplearning/comments/cpn6wp/making_a_generic_line_detection_algorithm/,muaz65,1565665708,"I am working on soccer field cordinate translation to a (100,100) 2d plane.

The task involves translating original field coordinates of players and ball from the live soccer stream to a 2d cartesian plane. 

The solution proposed in literature is to detect field lines and find the distance of players from the lines so that we can map the distance to our 2d cordinate system. After segmenting the field and removing the noise from the frames the obvious method was either to apply Hough lines or to make contours after using some edge detectors like canny.

Most of the existing literature use the same methodology  in order to segment/detect soccer field lines. But none of them seems to work in a generic manner. 

Hough lines, a cv2 library implementation of hough transform is a parameter specific function. Which doesn't work properly on different camera angles. Contours fails due to the width of line making variations in shape of contours. I tried some deep learning classiers for line Detection but that also failed and to train my own i ll have to label the lines manually which is quite extensive task. I am looking for some generalized line Detection approach which can work for any camera view. Any opinion on the matter is appreciated.",3,1,False,self,,,,,
140,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,15,cpp9ra,medium.com,Conversational Banking: Future of Banks with Chatbots,https://www.reddit.com/r/deeplearning/comments/cpp9ra/conversational_banking_future_of_banks_with/,MachineLearning001,1565678275,,0,10,False,default,,,,,
141,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,16,cppgpy,github.com,[Tutorial] How to perform direct and reverse image search on Flickr30k image data with AquilaDB,https://www.reddit.com/r/deeplearning/comments/cppgpy/tutorial_how_to_perform_direct_and_reverse_image/,iamjbn123,1565679630,,0,1,False,default,,,,,
142,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,16,cppuml,self.deeplearning,Real-time human action understanding with video data and fully convolutional neural network (Video demo),https://www.reddit.com/r/deeplearning/comments/cppuml/realtime_human_action_understanding_with_video/,nahuak,1565682288,"Hi deep learning redditors,

I'd like to share our most recent human activity recognition video demo at [TwentyBN](https://20bn.com/) with you. The neural network is trained on TwentyBN's [video datasets](https://20bn.com/products/datasets). Check out our most recent newsletter on our efforts in [building a virtual being's brain](http://www.embodiedai.co/issues/a-trip-inside-a-virtual-being-s-brain-with-video-demos-190155).

Feel free to comment below for questions and feedback :)

![video](tw1qqbk076g31 ""TwentyBN's human behavior understanding demo (Credit: TwentyBN)"")",0,46,False,self,,,,,
143,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,17,cpqaov,self.deeplearning,Computational Neuroscience software project. Looking for talented open source programmers,https://www.reddit.com/r/deeplearning/comments/cpqaov/computational_neuroscience_software_project/,mynercloud,1565685505,"Hello, 

we have a software project for computational neuroscience software. We want to analyze all different kinds of brain and body data using machine learning algorithms. Eventually it will be a huge software library. 

If you have questions, comment under the post or if you are interested or join the discord server for the dev talk [https://discord.gg/EtPghCG](https://discord.gg/EtPghCG). The github repo can be found here [https://github.com/neurapilot/neurapilot](https://github.com/neurapilot/neurapilot)",1,2,False,self,,,,,
144,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,18,cpqx8k,self.deeplearning,Free Cloud GPU Credits For Deep Learning,https://www.reddit.com/r/deeplearning/comments/cpqx8k/free_cloud_gpu_credits_for_deep_learning/,whitezl0,1565689953,"Hi, I am offering free credits for 1080Ti GPU instances for deep learning purposes  more than 24hrs for free

I am working on https://www.tensorpad.com/  developing cloud infrastructure for machine learning.

Part of our computational capacity is idle; hence, were offering credits at a free and discounted rate, so that data scientists can benefit from the resources available, and work on neural networks.

Specs: 
 60GB of RAM, 4 CPUs, 1080Ti GPU 
 JupyterLab environment with access to the terminal 
 Pre-installed Tensorflow, Keras, and other ML frameworks

You can access the free credits by signing up (https://dashboard.tensorpad.com/ and redeeming ""reddit500"" promo code in the Billing tab (https://dashboard.tensorpad.com/billing).

For any questions, please contact us here, through support@tensorpad.com, or the Intercom on the site.",0,11,False,self,,,,,
145,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,20,cpro3w,self.deeplearning,[ OpenCV/DL Question ] Realtime scene analysis/detection glasses,https://www.reddit.com/r/deeplearning/comments/cpro3w/opencvdl_question_realtime_scene/,_whitezetsu,1565694887," So I am a final year CS student working on my FYP which is basically glasses for visually impaired people.  
The thing is that we haven't started ML yet, since it's supposed to to be saved for last semester.  
The basic proposal was to use a nVidia x2 to make a path finder for the blind and guide it using voice navigation but it was converted to An android based glasses capable of processing the image \[ using phone/realtime\] and tell the person what's happening in its surrounding.  
Since I am as noob as it gets with ML/DL or CV and so is my partner, can anybody guide  
1: What technologies do we need to learn?  
2: What approach should we use?  
3: Is it possible to do a real time image analysis on such a small device?

P.S: I am good with android programming and I've completed my advanced python course recently if it helps.",0,0,False,self,,,,,
146,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,21,cpsa4f,self.deeplearning,Awesome Artificial Intelligence Research and Projects on Computer Vision News (with codes!) August 2019,https://www.reddit.com/r/deeplearning/comments/cpsa4f/awesome_artificial_intelligence_research_and/,Gletta,1565698407,"The August issue of Computer Vision News: 38 pages about AI and Deep Learning through both research and practical applications.

Newly improved graphics for easier reading. Don't miss the review of the new Google Research paper and the interview with Julia Elliott, the leader of the competitions team at Kaggle.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019August/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-august-pdf/)

Subscribe for free on page 38.

&amp;#x200B;

https://i.redd.it/ip5r39enj7g31.jpg",0,1,False,self,,,,,
147,deeplearning,t5_2t5eh,2019-8-13,2019,8,13,21,cpsju5,youtube.com,Energy-Efficient Load Balancing in Wireless Sensor Network Matlab | Project Query,https://www.reddit.com/r/deeplearning/comments/cpsju5/energyefficient_load_balancing_in_wireless_sensor/,flyhighwithai,1565699842,,0,1,False,image,,,,,
148,deeplearning,t5_2t5eh,2019-8-14,2019,8,14,3,cpwtsb,self.deeplearning,Towards Explainable Video Analysis  Visual Attention for Action Recognition,https://www.reddit.com/r/deeplearning/comments/cpwtsb/towards_explainable_video_analysis_visual/,dtransposed,1565719239,"&amp;#x200B;

I am currently researching practical applications of action recognition models with use of attention models. I have decided to share lessons learned from implementing several ideas from research papers in this field. The network learns to classify images from HMDB-51 dataset and creates attention heatmaps which focus on different parts on the image and thus justify model's decision. Heatmaps can be very accurate, to the point that one could probably use them for tracking.

&amp;#x200B;

[Model attends to the relevant part of the video](https://i.redd.it/nj9zulzl99g31.png)

The tutorial contains brief overview of action recognition and visual attention mechanisms. Then I present the network architecture and discuss the results of my project. Additionally, I include github repo with my implementation.

[Here are the results!](https://dtransposed.github.io/blog/Action-Recognition-Attention.html)

I hope you guys find it interesting!",0,8,False,self,,,,,
149,deeplearning,t5_2t5eh,2019-8-14,2019,8,14,7,cq08p1,self.deeplearning,TensorFlow in Practice Specialization  Build high value-high demand skills which will boost your career and earning growth ,https://www.reddit.com/r/deeplearning/comments/cq08p1/tensorflow_in_practice_specialization_build_high/,internetdigitalentre,1565733933,[removed],0,1,False,self,,,,,
150,deeplearning,t5_2t5eh,2019-8-14,2019,8,14,7,cq0s64,self.AmazonGameTech,Game Tech Machine Learning Demo Night,https://www.reddit.com/r/deeplearning/comments/cq0s64/game_tech_machine_learning_demo_night/,CGAmonster,1565736413,,0,1,False,default,,,,,
151,deeplearning,t5_2t5eh,2019-8-14,2019,8,14,9,cq2a3q,self.deeplearning,How to use flow_from_directory in Keras for multi-class semantic segmentation?,https://www.reddit.com/r/deeplearning/comments/cq2a3q/how_to_use_flow_from_directory_in_keras_for/,74throwaway,1565743827,"Let's say I have 100 training grayscale images and 100 RGB training masks, each of size 512x512. I was able to one-hot encode the masks using `to_categorical` in Keras with the below

    numclasses=3
    masks_one_hot=to_categorical(maskArr,numclasses)

where `maskArr` is a 100x512x512x1, and `masks_one_hot` is 100x512x512x3. 

However, to use `ImageDataGenerator` and `flow_from_directory` using `trainGenerator` from https://github.com/zhixuhao/unet/blob/master/data.py, I tried to save the one-hot encoded training images and then read them using `trainGenerator`. However, I noticed after using `imwrite` on them and then reading them with `imread`, they changed from one-hot encoded 512x512x3 to 512x512x3 RGB images. That is, instead of each channel having a value of 0 or 1, they now range from 0-255

As a result, if I do:

    myGenerator = trainGeneratorOneHot(20,'data/membrane/train','image','label',data_gen_args,save_to_dir = ""data/membrane/train/aug"", flag_multi_class = True,
    num_class = 3, target_size=(512,512,3))

    num_batch=3
    for i,batch in enumerate(myGenerator):
        if(i &gt;= num_batch):
            break

where `trainGeneratorOneHot` is below:

    def trainGeneratorOneHot(batch_size,...class_mode=None, image_class_mode=None):

        image_datagen = ImageDataGenerator(**aug_dict)
        mask_datagen = ImageDataGenerator(**aug_dict)
        image_generator = image_datagen.flow_from_directory(train_path,classes = [image_folder], class_mode = image_class_mode, color_mode = image_color_mode,target_size = target_size, ...)
        mask_generator = mask_datagen.flow_from_directory(train_path, classes = [mask_folder], class_mode = class_mode, target_size = target_size,...)
        train_generator = zip(image_generator, mask_generator)

        for (img,mask) in train_generator:
            img,mask = adjustDataOneHot(img,mask)
            yield (img,mask)

    def adjustDataOneHot(img,mask):
        return (img,mask)


Then I get `ValueError: could not broadcast input array from shape (512,512,1) into shape (512,512,3,1)

How can I fix this?",10,0,False,self,,,,,
152,deeplearning,t5_2t5eh,2019-8-14,2019,8,14,14,cq551o,reddit.com,The Batch: a new weekly newsletter from deeplearning.ai!,https://www.reddit.com/r/deeplearning/comments/cq551o/the_batch_a_new_weekly_newsletter_from/,LegendOfHiddnTempl,1565759613,,0,26,False,default,,,,,
153,deeplearning,t5_2t5eh,2019-8-14,2019,8,14,16,cq6afk,youtube.com,Prediction Explanation of Remaining Useful Life Using LSTM,https://www.reddit.com/r/deeplearning/comments/cq6afk/prediction_explanation_of_remaining_useful_life/,flyhighwithai,1565767420,,1,1,False,default,,,,,
154,deeplearning,t5_2t5eh,2019-8-14,2019,8,14,22,cq9s0p,self.deeplearning,Performance of Distributed TensorFlow: A Multi-Node and Multi-GPU Configuration,https://www.reddit.com/r/deeplearning/comments/cq9s0p/performance_of_distributed_tensorflow_a_multinode/,ValVish,1565789827,"Hi!

I'd like to share [this technical research](https://www.altoros.com/research-papers/performance-of-distributed-tensorflow-a-multi-node-and-multi-gpu-configuration/) embodies performance evaluation of distributed training with TensorFlow under two scenarios: a multi-node and multi-GPU infrastructure configuration. The benchmark was carried out using the Inception architecture as a neural network model and the Camelyon16 data as a training set. To test training scalability of distributed TensorFlow running on an Amazon EC2 cluster, the g2.2xlarge and g2.8xlarge instance types were employed.",0,4,False,self,,,,,
155,deeplearning,t5_2t5eh,2019-8-14,2019,8,14,22,cq9svh,github.com,blackbox: A Python module for parallel optimization of expensive black-box functions,https://www.reddit.com/r/deeplearning/comments/cq9svh/blackbox_a_python_module_for_parallel/,paulknysh,1565789946,,0,5,False,default,,,,,
156,deeplearning,t5_2t5eh,2019-8-14,2019,8,14,22,cq9zk2,youtu.be,Gesture generation by Deep Learning: A demo,https://www.reddit.com/r/deeplearning/comments/cq9zk2/gesture_generation_by_deep_learning_a_demo/,Svito-zar,1565790858,,0,33,False,image,,,,,
157,deeplearning,t5_2t5eh,2019-8-15,2019,8,15,1,cqcggz,self.deeplearning,Is MSI PS63 suitable for starting with deep learning?,https://www.reddit.com/r/deeplearning/comments/cqcggz/is_msi_ps63_suitable_for_starting_with_deep/,lamnhh,1565801842,"I'm planning to get into DL. I asked my teacher for a laptop recommendation and he said to get one with at least 16GB RAM, 512SSD and at least GTX 1050. He said the machine will be used for practicing setting up environment (due to the fact that Google Colab doesn't allow change of CUDA version) and to test some basic DL algorithm locally.

I searched and found the MSI PS63, with the following specs:
- Intel Core i7-8565U (1.8 GHz - 4.6 GHz / 8MB / 4 cores, 8 threads).
- Intel UHD Graphics 620 / NVIDIA GeForce GTX 1650 Max-Q 4GB GDDR5.
- 512GB SSD M.2 NVMe.
- 16GB DDR4 2666MHz.
More detail [here](https://tiki.vn/laptop-msi-ps63-8sc006vn-core-i78565u-gtx-1650-4gb-win10-156-fhd-ips-hang-chinh-hang-p17595402.html?spid=2453613) (sorry, it's in Vietnamese).

Is this device suitable for my purpose? If not, could you recommend me some other ones? My budget is $1500 and my back can't handle anything more than 3 kilograms.

Thanks a lot.",2,1,False,self,,,,,
158,deeplearning,t5_2t5eh,2019-8-15,2019,8,15,3,cqdn02,self.deeplearning,Online gpu for deep learning project,https://www.reddit.com/r/deeplearning/comments/cqdn02/online_gpu_for_deep_learning_project/,AhmedZubairGCU,1565806949,I will be starting my final year project in my university. I will have to experiment with many cnn architectures and i will require to use gpu online. In past i have used google colab and kaggle to run my code but they were my personal projects. This is a team project and university might provide financial assistance if we specify beforehand. So is there any better option than google colab or kaggle kernel for such project which you have used and found helpful in the past. If there are charges to use them kindly specify. Thanks,4,0,False,self,,,,,
159,deeplearning,t5_2t5eh,2019-8-15,2019,8,15,4,cqeh3o,medium.com,Does Deep Learning Still Need Backpropagation?,https://www.reddit.com/r/deeplearning/comments/cqeh3o/does_deep_learning_still_need_backpropagation/,Yuqing7,1565810495,,0,1,False,default,,,,,
160,deeplearning,t5_2t5eh,2019-8-15,2019,8,15,11,cqjt9p,youtu.be,Neural Style Transfer - An Intuitive Explanation,https://www.reddit.com/r/deeplearning/comments/cqjt9p/neural_style_transfer_an_intuitive_explanation/,Automato-YT,1565835858,,2,30,False,image,,,,,
161,deeplearning,t5_2t5eh,2019-8-15,2019,8,15,12,cqkqju,self.deeplearning,Simple PyTorch implementation of Autoregressive Language Model on Wikipedia text,https://www.reddit.com/r/deeplearning/comments/cqkqju/simple_pytorch_implementation_of_autoregressive/,lyeoni,1565840907,"A step-by-step tutorial on how to implement and adapt **Autoregressive language model** to Wikipedia text.

A  pre-trained BERT, XLNET is publicly available ! But, for NLP beginners,  It could be hard to use/adapt after full understanding. For  them, I covered whole, end-to-end implementation process for language  modeling, using unidirectional/bidirectional LSTM network, we already know.

* **- do not use  torchtext library !**
* **+ include trained model file, training logs**

I hope that this repo can be a good solution for people who want to have their own language model :)

[https://github.com/lyeoni/pretraining-for-language-understanding](https://github.com/lyeoni/pretraining-for-language-understanding)",0,1,False,self,,,,,
162,deeplearning,t5_2t5eh,2019-8-15,2019,8,15,19,cqntvk,self.deeplearning,"[question] why doesn't this Ubuntu vm feel native (quad i7 @3.4 Ghz, 16 GB, Windows 10, nothing else running) in vmware?",https://www.reddit.com/r/deeplearning/comments/cqntvk/question_why_doesnt_this_ubuntu_vm_feel_native/,vmcuriouss,1565863542,"Here is the image:

* https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b

It's a a fully configured deep learning VM.  It's about 7.7GB.

I am running on:

* an i7 3770 quad core at 3.4 Ghz (not the i7 3770K which has no VT-d virtualization extensions - this one does.)

* 16 GB of DDR 3 ram that is clocked at 1600 mhz.  I benchmarked it at 19000 MB/sec in Novabench.

* The GPU in the host is 1060 GPU with 6 GB of RAM - but the image file I linked above explains ""Due to licensing and installation complications, theres no GPU acceleration / CUDA support provided. So you dont need an Nvidia GPU to try this out, but it also wont take advantage of a GPU if you have one.""

* windows 10.

* I have an SSD.  It's not the fastest but the write speed is 214 MB/seconds and the read speed is 253 MB/seconds in Novabench.

* I turned the swap off entirely on the host system and have plenty of RAM left.

Without anything else running on the host computer, which is a pretty fresh install, this VM doesn't feel native at all when entering full screen, regardless if I give it 2 GB (default), 4 GB, or even 8 GB of memory. I turned on the virtualization extensions in my bios and in the vmware settings too!   I went from giving 1 CPU to 2 CPU's to the guest.  None of this helps.

why deson't it feel ""native""?  I mean things like moving the mouse around, opening a new firefox windows, etc.  It's ""obviously"" a VM.

Is it not supposed to feel native or buttery smooth?  I'm just at a loss.  Additionally, I did an update from within it and it updated Ubuntu files at 500 KB/second!  My connection is several megabytes per second.

I feel like I must be missing something....but what??",1,0,False,self,,,,,
163,deeplearning,t5_2t5eh,2019-8-15,2019,8,15,21,cqp9oa,self.deeplearning,AOD-Net Image Dehazing &amp; Neural Style Transfer (Tensorflow Tutorial),https://www.reddit.com/r/deeplearning/comments/cqp9oa/aodnet_image_dehazing_neural_style_transfer/,tush1995,1565872765,"Hey everyone!  


I have recently started implementing deep learning papers and writing tutorials and explanations for them. Wanted to share my implementation and blog post for the following with the community.   


Open to suggestions and questions :)  


**1) Neural Style Transfer (Iterative): CNN based approach to generate artwork by combining style and content from different images.**  
Github: [https://github.com/tusharsircar95/Iterative-Neural-Style-Transfer](https://github.com/tusharsircar95/Iterative-Neural-Style-Transfer)  
Medium: [https://medium.com/@tusharsircar95/neural-style-transfer-simplified-b91b990028d](https://medium.com/@tusharsircar95/neural-style-transfer-simplified-b91b990028d)

&amp;#x200B;

[Original image of buildings](https://i.redd.it/6i1sebpnxlg31.png)

[Artwork generated by the trained network by combining the image of buildings with popular paintings](https://i.redd.it/w3mr929bxlg31.png)

&amp;#x200B;

**2) AOD-Net Dehazing: Lightweight end-to-end model to de-haze images**  
Github: [https://github.com/tusharsircar95/All-In-One-Image-Dehazing-Tensorflow](https://github.com/tusharsircar95/All-In-One-Image-Dehazing-Tensorflow)  
Medium: [https://medium.com/@tusharsircar95/all-in-one-image-dehazing-aod-paper-explanation-tensorflow-implementation-bb97f6a6f1ef](https://medium.com/@tusharsircar95/all-in-one-image-dehazing-aod-paper-explanation-tensorflow-implementation-bb97f6a6f1ef) 

[AOD-net Image De-hazing Example](https://i.redd.it/fi6ojt9zwlg31.png)

&amp;#x200B;

Cheers! :D",1,9,False,self,,,,,
164,deeplearning,t5_2t5eh,2019-8-16,2019,8,16,1,cqs66d,blog.paperspace.com,Exploring what's new in TensorFlow 2.0,https://www.reddit.com/r/deeplearning/comments/cqs66d/exploring_whats_new_in_tensorflow_20/,dkobran,1565886460,,5,10,False,default,,,,,
165,deeplearning,t5_2t5eh,2019-8-16,2019,8,16,1,cqscfb,self.deeplearning,Train/Val/Test split for small dataset,https://www.reddit.com/r/deeplearning/comments/cqscfb/trainvaltest_split_for_small_dataset/,arjundupa,1565887215,I am working with a very small dataset of just 550 records. What ratio should I use for the train/val/test split?,3,1,False,self,,,,,
166,deeplearning,t5_2t5eh,2019-8-16,2019,8,16,4,cquc0y,self.deeplearning,NeurIPS 2019 workshop submission,https://www.reddit.com/r/deeplearning/comments/cquc0y/neurips_2019_workshop_submission/,shidilrzf,1565895802,Does anyone know what should be included in an extended abstract submitted to a workshop in NeurIPS? It's only 3 pages. Should I include the results?,0,2,False,self,,,,,
167,deeplearning,t5_2t5eh,2019-8-16,2019,8,16,10,cqzo4q,self.deeplearning,"NVIDIA's DALI Library, Image Augmentations | Interview with James Dellinger",https://www.reddit.com/r/deeplearning/comments/cqzo4q/nvidias_dali_library_image_augmentations/,init__27,1565920598,"Interview about Image Augmentations, NVIDIA's DALI Library with James Dellinger. 

We talk about performance, convenience, and comparisons of the frameworks against other frameworks.

&amp;#x200B;

Audio: [https://anchor.fm/chaitimedatascience/episodes/NVIDIAs-DALI-Library--Image-Augmentations-Discussion-Interview-with-James-Dellinger-e4r6f7/a-ak5426](https://anchor.fm/chaitimedatascience/episodes/NVIDIAs-DALI-Library--Image-Augmentations-Discussion-Interview-with-James-Dellinger-e4r6f7/a-ak5426)

&amp;#x200B;

Video: [https://www.youtube.com/watch?v=IMOqrf5NPUU](https://www.youtube.com/watch?v=IMOqrf5NPUU)",0,12,False,self,,,,,
168,deeplearning,t5_2t5eh,2019-8-16,2019,8,16,14,cr1vmm,i.redd.it,Yoshua Bengio's online talk in University of Tehran.,https://www.reddit.com/r/deeplearning/comments/cr1vmm/yoshua_bengios_online_talk_in_university_of_tehran/,Doctor_who1,1565933047,,2,45,False,image,,,,,
169,deeplearning,t5_2t5eh,2019-8-16,2019,8,16,16,cr34z6,lionbridge.ai,Use Deep Learning to Clone Yourself as a Chatbot (Replika AI Review),https://www.reddit.com/r/deeplearning/comments/cr34z6/use_deep_learning_to_clone_yourself_as_a_chatbot/,LimarcAmbalina,1565941453,,3,5,False,default,,,,,
170,deeplearning,t5_2t5eh,2019-8-16,2019,8,16,17,cr3i53,medium.com,Strengthening Customer Relations with Facebook Messenger Bot,https://www.reddit.com/r/deeplearning/comments/cr3i53/strengthening_customer_relations_with_facebook/,MachineLearning001,1565944176,,0,0,False,default,,,,,
171,deeplearning,t5_2t5eh,2019-8-16,2019,8,16,19,cr4kj3,blog.google,"When students get stuck, Socratic can help",https://www.reddit.com/r/deeplearning/comments/cr4kj3/when_students_get_stuck_socratic_can_help/,cmillionaire9,1565951729,,0,7,False,default,,,,,
172,deeplearning,t5_2t5eh,2019-8-16,2019,8,16,19,cr4pyy,self.deeplearning,Scope of collaborative filtering,https://www.reddit.com/r/deeplearning/comments/cr4pyy/scope_of_collaborative_filtering/,vipul115,1565952774,"Hi there!

  


A newbie data scientist at a consulting firm. I recently got introduced to a problem my client is facing. The problem statement goes something like this: Calculate whether/how likely a physician is likely to give consent to receive advertisement emails based on the choices of other physicians who share similar patterns/tastes with him.

(I have data for physicians who do give consent btw)

Collaborative filtering came to mind instantly. I don't have working experience with them but have heard about it from colleagues and I think this might be a solution to the above said problem.

Wanted to know from this sub whether this would be a good direction to go into for this problem.",1,1,False,self,,,,,
173,deeplearning,t5_2t5eh,2019-8-16,2019,8,16,22,cr6h1x,self.deeplearning,Why does pytorch have operations like addcmul?,https://www.reddit.com/r/deeplearning/comments/cr6h1x/why_does_pytorch_have_operations_like_addcmul/,kjarvind,1565962635,Wondering why pytorch has primitive math ops such as torch.addcmul for things like tensor 1*tensor2 ?,0,1,False,self,,,,,
174,deeplearning,t5_2t5eh,2019-8-16,2019,8,16,23,cr746z,self.deeplearning,Chatbot with tensorflow,https://www.reddit.com/r/deeplearning/comments/cr746z/chatbot_with_tensorflow/,destroyer2047,1565965698," 

So i was learning from an online tutorial on how to make a chatbot using tensorflow . link - https://colab.research.google.com/github/tensorflow/examples/blob/master/community/en/transformer\_chatbot.ipynb#scrollTo=\_B147qKb\_0ks

but there is a problem while running the transformer def which i am not able to solve. Can anyone recommend me another tutorial(who's code actually works because i have encountered this problem in another tutorial) or solve the problem?",7,3,False,self,,,,,
175,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,0,cr85zh,self.deeplearning,Deep learning model optimization,https://www.reddit.com/r/deeplearning/comments/cr85zh/deep_learning_model_optimization/,aminehy,1565970263,"Have you Optimized your Deep Learning Model Before Deployment? by M. Amine Hadj-Youcef, Ph.D. https://link.medium.com/yYztTgyncZ",0,1,False,self,,,,,
176,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,1,cr8y7p,japantimes.co.jp,Japanese team developing tsunami scale damage forecaster with help of AI,https://www.reddit.com/r/deeplearning/comments/cr8y7p/japanese_team_developing_tsunami_scale_damage/,stevevaius,1565973681,,0,9,False,default,,,,,
177,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,3,crakjs,krshrimali.github.io,Transfer Learning in PyTorch C++ API on Dogs vs Cas (Blog 06 in the PyTorch C++ Series - using ResNet18),https://www.reddit.com/r/deeplearning/comments/crakjs/transfer_learning_in_pytorch_c_api_on_dogs_vs_cas/,Kushashwa,1565980778,,0,1,False,default,,,,,
178,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,3,craky5,krshrimali.github.io,New Blog Release: Transfer Learning using PyTorch C++ API on Dogs vs Cats (ResNet18 Model),https://www.reddit.com/r/deeplearning/comments/craky5/new_blog_release_transfer_learning_using_pytorch/,Kushashwa,1565980824,,0,1,False,default,,,,,
179,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,3,craq4c,medium.com, Dual pane File Manager for Training Data: old school meets AI in Supervisely,https://www.reddit.com/r/deeplearning/comments/craq4c/dual_pane_file_manager_for_training_data_old/,tdionis,1565981485,,0,0,False,default,,,,,
180,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,4,crazyw,self.deeplearning,hi i would like some help in understand a error that i m having in predicting a model,https://www.reddit.com/r/deeplearning/comments/crazyw/hi_i_would_like_some_help_in_understand_a_error/,octdubois,1565982702,"i m fairly new to deep learning...i managed to get a script to save a model and i would like to test it by passing some image into it bbut for some reason it keeps on returning errors that i dont see how to debug

https://i.redd.it/1j87uj9t0vg31.png

this is the link to the model : [https://www.kaggle.com/emmarex/plant-disease-detection-using-keras/comments](https://www.kaggle.com/emmarex/plant-disease-detection-using-keras/comments) 

&amp;#x200B;

i tried various ways to transform the image into array but same errors...any help would be greatly appreciated",2,0,False,self,,,,,
181,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,5,crbrr6,self.deeplearning,Aging Evolution for Neural Architecture Search Explained!,https://www.reddit.com/r/deeplearning/comments/crbrr6/aging_evolution_for_neural_architecture_search/,HenryAILabs,1565986222,[https://youtu.be/y0UvVB8k9rI](https://youtu.be/y0UvVB8k9rI),0,5,False,self,,,,,
182,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,7,crdcp3,self.deeplearning,Team Name for Gastroenterology DL Research Lab,https://www.reddit.com/r/deeplearning/comments/crdcp3/team_name_for_gastroenterology_dl_research_lab/,InGutWeTrust,1565993594,"We all know the most important part of DL research is coming up with cool names for our projects or teams. Well, my research group is currently struggling coming up with a team name. We are mostly doing computer vision research to aid histopathology-based diagnoses of pediatric gastrointestinal diseases. We have a few naming ideas, but would like to crowd-source it out to get some more feedback:

- Gut AI
- Gut Intelligence
- Gut AIDD (AI for Digestive Diseases)
- Giga Gut
- DeepGut

You can see a common theme in these names... We want it to sound like an academic research group and not like a startup company. I'll post each name below and please upvote, downvote, and comment as you wish. Thanks!",17,8,False,self,,,,,
183,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,8,crekq6,self.deeplearning,What made backpropagation feasible for deep learning?,https://www.reddit.com/r/deeplearning/comments/crekq6/what_made_backpropagation_feasible_for_deep/,shahriar49,1565999585,"I have read in many texts that in the early days of neural network computing, backpropagation was not successful for deep networks and also computing power was very limited to run simulations. Nowadays with all the deep networks of tens or hundred layers we still use backpropagation for training. What was the problem with backpropagation in old days and what has been changed in training to make it feasible for new deep networks? Just the computational power?",19,10,False,self,,,,,
184,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,14,crhx96,self.deeplearning,New Blog Release: Transfer Learning using PyTorch C++ API on Dogs vs Cats (ResNet18 Model),https://www.reddit.com/r/deeplearning/comments/crhx96/new_blog_release_transfer_learning_using_pytorch/,Kushashwa,1566018519,"Excited to share 6th Blog in the series of PyTorch C++ Blogs on - Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API.   

Link to the blog: [**https://lnkd.in/fsPR4T4**](https://lnkd.in/fsPR4T4)  

It takes a lot of efforts to publish a blog, making the code readable and explaining important details of it and I hope it reaches out to the maximum number of students who are keen to contribute to the framework as it is still in the baby stage. So please share with your friends and/or students. As always, I look forward to hearing from you on any constructive feedback. 

*Processing img 1f5k2f14zxg31...*",0,1,False,self,,,,,
185,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,18,crk0hk,self.deeplearning,"Machine Learning, AI and Deep Learning Services | Webtunix",https://www.reddit.com/r/deeplearning/comments/crk0hk/machine_learning_ai_and_deep_learning_services/,OliviaWillson,1566033940,"[**Deep learning** ](https://www.webtunix.com/deep-learning-services)is the branch of **machine learning**. It based on neural networks. Learning can be supervised, semi-supervised or unsupervised. In which we can overcome the challenges of feature extraction. The reason of deep learning models is capable of learning to focus on the right features by themselves. [**Webtunix** ](https://www.webtunix.com/)Provides the best solution and services in artificial intelligence.",0,1,False,self,,,,,
186,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,18,crk8xi,self.deeplearning,Deep Learning: A beginners diary,https://www.reddit.com/r/deeplearning/comments/crk8xi/deep_learning_a_beginners_diary/,asifali_p,1566035661,"To post some beginners post in this sub-reddit might not be of use. But still its a read worthy piece of information for the newbies joined in this discussion platform. 

 [https://www.infolks.info/blog/blog-post-deep-learning-a-beginners-diary/](https://www.infolks.info/blog/blog-post-deep-learning-a-beginners-diary/)",7,11,False,self,,,,,
187,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,19,crkhe4,self.deeplearning,rectified nesterov adam,https://www.reddit.com/r/deeplearning/comments/crkhe4/rectified_nesterov_adam/,aloo_matar_,1566037283,"My implementation of rectified nesterov adam optimizer in keras. rnadam combines nesterov accelerated gradient with rectified-adam. Any thoughts on it?

[github-link](https://github.com/niley1nov/keras_rnadam)",0,1,False,self,,,,,
188,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,20,crkzdv,self.deeplearning,Learn Tensorflow coming from Keras,https://www.reddit.com/r/deeplearning/comments/crkzdv/learn_tensorflow_coming_from_keras/,Atralb,1566041077,"Hi,

I've been working on DL for about a year now with Tensorflow as a backend but always with Keras on top. I've had a bit of introduction to Tensorflow itself by reading the first \~50 pages but stopped when I realized how much more complicated it was compared than Keras and that my knowledge then couldn't justify the hassle of learning it. Keras was far more than enough.   


Now I'd like to come back a bit at Tf but I would love for some resource teaching it with the assumption that you already are familiar and experienced with Keras. Unfortunately, after a lengthy research I didn't find any such article, book, or online course.  


I know I could just go look at resources teaching tensorflow from scratch, but I still wanted to make a discussion in here for those several reasons :  
\- Extensive courses for Tensorflow spend a lot of time explaining the theory and do so in tandem with uncovering tensorflow mechanics and functions. So it's not a straightforward ""skip the explanations"" if you already know theory and practical model building a lot. This creates a lot of ""overhead"" to getting the useful information.  
\- I believe (correct me if i'm wrong) it would actually be really interesting and relevant for our understanding to put corresponding keras and Tf functions at the forefront and compare them to explain how keras ones work under the hood in tensorflow and also to easily get what coding in Tf would enable that Keras can't. In summary a ""Tensorflow when knowing Keras"" course would IMHO be really useful source.  
\- I'm sure a LOT of people are in the same situation as I am, the reason being the overwhelming popularity of Keras and ease of use, while also Tf being overly used.

&amp;#x200B;

So I just wanted to know your opinion about this and also (now that you know my situation) if by chance some of you actually know of such resource or something close/similar to what I'm thinking. Thanks a lot !",2,15,False,self,,,,,
189,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,23,crmreh,self.deeplearning,"Given noisy data and labels, how to realize a network is good enough?",https://www.reddit.com/r/deeplearning/comments/crmreh/given_noisy_data_and_labels_how_to_realize_a/,shahriar49,1566051827,"I have created a dataset of sequences of Landsat observations for a big number of points that I realized have stable landcover (I did my judgement using Google Earth imagery using its historical view). The purpose is to train a network to decide on a point's landcover type based on its yearly Landsat observations, taking into account the phenological changes through the year to improve classification. I use LSTM network and I can reach classification accuracy over 90% easily.

I can still get some little improvements by enlarging the network and maybe adding some other features to the net, but how can I be confident that what I get is the best achievable? The data is noisy anyway, and more important, the labels are assigned by myself and therefore subject to my personal opinion. I mean, when I was looking in Google Earth to decide which label to assign to a training point, I was definitely using my personal judgement to distinguish a forest from a grassland from a wetland from a bare land (and there is no sharp border between some of them) . Worse than that, I have to use my personal estimate to decide on mixed pixels, for example by majority rule (again, majority is just my eye and brain decision, and may not be 100% accurate). Even my judgement is subject to change through time gradually...

So, with all of the above (which I think any landcover dataset is prone to it), I am pretty sure that no network can achieve 100% accuracy even on a training set (unless network is so big to completely memorize the training dataset). I still hope that the network can learn to classify better than what I could do (even from the biased training dataset) because it is not subject to human errors, but is it really possible? And again, referring to the question in title, how can decide to stop and say a network is really good and can not be better than that in these conditions?",0,2,False,self,,,,,
190,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,23,crmv6j,youtube.com,"Breast cancer diagnosis with neural networks, implemented with Keras and written in Python",https://www.reddit.com/r/deeplearning/comments/crmv6j/breast_cancer_diagnosis_with_neural_networks/,antaloaalonso,1566052412,,0,1,False,image,,,,,
191,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,23,crn0l7,self.deeplearning,Can these projects work as desired?,https://www.reddit.com/r/deeplearning/comments/crn0l7/can_these_projects_work_as_desired/,Mjjjokes,1566053260,"Summary: 1. predict depth from a single image with an accuracy of 100% (Andrew Ng and Saxena have done this with an accuracy of 67%), then, 2. use a training set of real 3d models to calculate voxels outside of a test 3d model (ideally one generated by the first project) (first predicting a single voxel, then adding that voxel to the set of known voxels, then using the new set of voxels to predict another voxel, and so on).

Will this generate the desired results (being able to calculate voxels outside of a given 3d model, and ultimately, allowing us to see things outside of the original camera scene of a given photo)?",2,2,False,self,,,,,
192,deeplearning,t5_2t5eh,2019-8-17,2019,8,17,23,crn1kf,self.deeplearning,What are some good resources to get started with Keras?,https://www.reddit.com/r/deeplearning/comments/crn1kf/what_are_some_good_resources_to_get_started_with/,merwanedr,1566053425,,3,2,False,self,,,,,
193,deeplearning,t5_2t5eh,2019-8-18,2019,8,18,1,cro802,self.deeplearning,CycleGAN learns identity transform,https://www.reddit.com/r/deeplearning/comments/cro802/cyclegan_learns_identity_transform/,ziapelta,1566058720,"I'm building a cycleGAN system to apply an aging filter, i.e. convert young faces to old faces. I've tried many tweaks, but each time both generators learn the identity function, i.e. the forward and reverse cycle image are equal to the original image. I've tried using both an implementation I wrote and one from another individual. Both show the same results. As such, I don't think there is a bug in the code. Can I tweak the way I'm training to prevent this from happening?",2,2,False,self,,,,,
194,deeplearning,t5_2t5eh,2019-8-18,2019,8,18,1,croi61,self.deeplearning,One-hot all-zero entries in Tensorflow,https://www.reddit.com/r/deeplearning/comments/croi61/onehot_allzero_entries_in_tensorflow/,shahriar49,1566060031,"I have a pixel classification application with training labels (per pixel) being one-hot encoded. For some reason there are pixels that doesn't have valid labels. One solution might be to use sample\_weight option to indirectly mask those pixels from affecting loss and gradient calculations. But I found that in Tensorflow implementation, I can generate one-hot labels being all-zero (which is an invalid one-hot encoding) for those pixels and I will not get any error during model build and training. Are these two methods the same? Is all-zero one-hot label disables loss and gradient calculation for that specific pixel?",5,4,False,self,,,,,
195,deeplearning,t5_2t5eh,2019-8-18,2019,8,18,2,crphfu,self.deeplearning,How do parameters and number of layers influence the speed of training?,https://www.reddit.com/r/deeplearning/comments/crphfu/how_do_parameters_and_number_of_layers_influence/,MLscivet16,1566064437,"I am choosing between various state of the art architectures for a classification task where speed of training is extremely important (accuracy is too, but let's focus on speed for now). The current model being used for this task is using an Inception v3 architecture (42 layers, 23.8 million parameters with ImageNet). For similar tasks, the state of the art papers use models similar to VGGnet with 22 layers and 144 million parameters (ImageNet). I am new to deep learning and assumed increasing number of layers would increase training time, but there are many more parameters to learn with VGGnet based on the ImageNet results. 

What is a better estimator of training time, number of layers or parameters? Thank you.",3,1,False,self,,,,,
196,deeplearning,t5_2t5eh,2019-8-18,2019,8,18,3,crq5l3,youtu.be,Sports Matches &amp; Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/crq5l3/sports_matches_artificial_intelligence/,cmillionaire9,1566067469,,5,39,False,image,,,,,
197,deeplearning,t5_2t5eh,2019-8-18,2019,8,18,4,crqfcr,self.deeplearning,Do regularization really make model simpler?,https://www.reddit.com/r/deeplearning/comments/crqfcr/do_regularization_really_make_model_simpler/,shahriar49,1566068744,"I hear a lot that L-2 regularization forces the network weights to be smaller, therefore makes the model simpler and less overfit to the data. But I don't understand clearly how smaller or larger weights can relate to model complexity.  A polynomial of degree inherently supports more complex models than a polynomial of degree 2, whatever the coefficients be.

I understand that with smaller weights the model is less prone to pick up every noise and change in data and try to model it, but this is another story than 'a simpler model' in my mind. If we really want a simpler model, why just not reverting to a polynomial of lower degree and keep the higher polynomial but regularizing its weights? Also, why we can not argue that with smaller weights the network may hurt to pick up strong patterns as well?",11,10,False,self,,,,,
198,deeplearning,t5_2t5eh,2019-8-18,2019,8,18,4,crqznn,self.deeplearning,How am I supposed to get started with training neural nets on my personal machine as a broke student? (Macbook Pro),https://www.reddit.com/r/deeplearning/comments/crqznn/how_am_i_supposed_to_get_started_with_training/,merwanedr,1566071361,,3,0,False,self,,,,,
199,deeplearning,t5_2t5eh,2019-8-18,2019,8,18,5,crr68f,self.deeplearning,This may sound silly.. but...,https://www.reddit.com/r/deeplearning/comments/crr68f/this_may_sound_silly_but/,TheoriginalMr,1566072251,"Done with my undergrad. Working as a software developer. 
Haven't worked under any profs back in Uni. Looking forward to master's admission and the admission committee asks for LORs ( Letter of Recommendations )
I don't want to get fake LORs.

So,
I wish to work with / under  you and publish a research paper. (Probably in deep learning). 
If you or some one you know have credentials, good enough to write me a decent LOR and if you believe I could contribute to your research ( I can spend 20 hrs a week ), please ping me. Thanks.",0,0,False,self,,,,,
200,deeplearning,t5_2t5eh,2019-8-18,2019,8,18,8,crto5m,youtu.be,Monte Carlo method in Reinforcement Learning | RL tutorial series,https://www.reddit.com/r/deeplearning/comments/crto5m/monte_carlo_method_in_reinforcement_learning_rl/,Riturajkaushik,1566084602,,0,23,False,image,,,,,
201,deeplearning,t5_2t5eh,2019-8-18,2019,8,18,13,crwsh0,self.deeplearning,Microsoft has Announced a massive online Global AI hackathon.,https://www.reddit.com/r/deeplearning/comments/crwsh0/microsoft_has_announced_a_massive_online_global/,BatmantoshReturns,1566102383,"https://azureai.devpost.com/

Do actually don't need that much AI knowledge to participate, since you can just use one of Azure's premade services. 

My team is working on different book recommender systems. Feel free to PM about joining us.",0,13,False,self,,,,,
202,deeplearning,t5_2t5eh,2019-8-18,2019,8,18,17,cryqnn,kaggle.com,A Very Simple Offline OCR SDK,https://www.reddit.com/r/deeplearning/comments/cryqnn/a_very_simple_offline_ocr_sdk/,multisilicon,1566117036,,2,6,False,default,,,,,
203,deeplearning,t5_2t5eh,2019-8-19,2019,8,19,2,cs4eii,self.deeplearning,CuDNN implementation of ConvLSTM2D,https://www.reddit.com/r/deeplearning/comments/cs4eii/cudnn_implementation_of_convlstm2d/,shahriar49,1566150290,"I see there is fast CuDNN layer for LSTM and GRU layers as listed in [keras.io](https://keras.io), but I can not find similar CuDDNN implementation for ConvLSTM2D.  Is anybody aware of that?",0,4,False,self,,,,,
204,deeplearning,t5_2t5eh,2019-8-19,2019,8,19,2,cs4jjm,self.deeplearning,SOTA BLACK BOX EXPLANATIONS AND INTUITIONS,https://www.reddit.com/r/deeplearning/comments/cs4jjm/sota_black_box_explanations_and_intuitions/,S_0ci0path,1566150899,"Is there a list of papers anyone can suggest that could help digest the idea of a neural network? I'd like state of the art papers so that I can see what I can do - being as stupid as I am, to help out or just to fulfill the idea that I might be thinking about this.",1,3,False,self,,,,,
205,deeplearning,t5_2t5eh,2019-8-19,2019,8,19,3,cs4md0,self.deeplearning,"Pooling VRAM on 2x Titan RTX in PyTorch, Tensorflow?",https://www.reddit.com/r/deeplearning/comments/cs4md0/pooling_vram_on_2x_titan_rtx_in_pytorch_tensorflow/,tripple13,1566151227,"Hey guys, I've cross-checked the internet (wholeheartedly) and I just cannot seem to find conclusive information.

# Does 2x Titan RTX allow to pool memory from 24GB to 48GB in total? If so, How?

From the website of Nvidia the following is shown

['... effective doubling of memory capacity to 48GB ...'](https://i.redd.it/5e01vefmx8h31.png)

Now I happen to run a box with 2x Titan RTX's, and I've installed the NVLink bridge - Does anyone have experience on how to utilize these features on popular frameworks? Ie. PyTorch, Tensorflow?

At the moment it just shows up in my system as two separate Titan RTX's, I just cannot figure out how to enable this feature.",9,12,False,self,,,,,
206,deeplearning,t5_2t5eh,2019-8-19,2019,8,19,6,cs77x8,self.deeplearning,Help! Basic transfer learning - existing classification model to detection.,https://www.reddit.com/r/deeplearning/comments/cs77x8/help_basic_transfer_learning_existing/,DarkAngelRUS,1566162948,"I am a complete newbie in Neural Networks and Python.
Unfortunately, I currently have to use CNNs to create an object detector from scratch for a particular image class.

I have somehow managed to follow sentdex tutorials and train a classifier model that can separate ""Objects"" from ""Not Objects"". It is trained on my own large dataset which is labelled but doesn't have bounding boxes (it would take me weeks to draw them)


What is the easiest way to upload this model into an object detector?
Where do I start as a layman?
I have seen mentions of MobileNetV2 and YOLO, but not really sure where to upload my model? I was struggling even launching YOLOv2 on examples.

Absolutely panicing right now, wouldn't typically resort to asking questions that I am sure have been answered somewhere. But information so far has been really overwhelming.

Any help would be appreciated!
Thank you!",1,3,False,self,,,,,
207,deeplearning,t5_2t5eh,2019-8-19,2019,8,19,6,cs7qzk,self.deeplearning,Deep Learning Research - Weekly Update Video,https://www.reddit.com/r/deeplearning/comments/cs7qzk/deep_learning_research_weekly_update_video/,HenryAILabs,1566165433,[https://youtu.be/gG0gSzdEDWM](https://youtu.be/gG0gSzdEDWM),2,21,False,self,,,,,
208,deeplearning,t5_2t5eh,2019-8-19,2019,8,19,15,csdctu,debuggercafe.com,"Introduction to Deep Learning with Keras (Part 5): Using Callbacks and ConvNets - A site aimed at building a Data Science, Artificial Intelligence and Machine Learning empire.",https://www.reddit.com/r/deeplearning/comments/csdctu/introduction_to_deep_learning_with_keras_part_5/,sovit-123,1566196989,,1,1,False,default,,,,,
209,deeplearning,t5_2t5eh,2019-8-19,2019,8,19,15,csdgty,self.deeplearning,"Interview with Kaggle GrandMaster, Dr. Vladimir Iglovikov about Albumentations: a fast image augmentations library",https://www.reddit.com/r/deeplearning/comments/csdgty/interview_with_kaggle_grandmaster_dr_vladimir/,init__27,1566197781,"Interview with Dr. Vladimir Iglovikov (Kaggle GM, Senior CV Engineer at Lyft) about Albumentations Framework: a fast image augmentations library 

&amp;#x200B;

We talk all about albumentations, image augs and open source. 

&amp;#x200B;

Audio: [https://anchor.fm/chaitimedatascience/episodes/Albumentations-Framework-a-fast-image-augmentations-library--Interview-with-Dr--Vladimir-Iglovikov-e4r6e4](https://anchor.fm/chaitimedatascience/episodes/Albumentations-Framework-a-fast-image-augmentations-library--Interview-with-Dr--Vladimir-Iglovikov-e4r6e4)

&amp;#x200B;

Video: [https://www.youtube.com/watch?v=P7vUzcySzkM&amp;feature=youtu.be](https://www.youtube.com/watch?v=P7vUzcySzkM&amp;feature=youtu.be)",0,5,False,self,,,,,
210,deeplearning,t5_2t5eh,2019-8-19,2019,8,19,16,csdnkk,self.deeplearning,Deeplearning course (coursea),https://www.reddit.com/r/deeplearning/comments/csdnkk/deeplearning_course_coursea/,SSJCalzana,1566199071,"Hi there,

Thinking about doing this deep learning course, but wanted to check if anyone else has done the same or something similar and would suggest before I subscribe to couresa. 

 [https://www.deeplearning.ai/deep-learning-specialization/](https://www.deeplearning.ai/deep-learning-specialization/)",3,1,False,self,,,,,
211,deeplearning,t5_2t5eh,2019-8-19,2019,8,19,16,csdrb8,rubikscode.net,Transformer with Python and TensorFlow 2.0  Encoder &amp; Decoder,https://www.reddit.com/r/deeplearning/comments/csdrb8/transformer_with_python_and_tensorflow_20_encoder/,RubiksCodeNMZ,1566199850,,0,4,False,default,,,,,
212,deeplearning,t5_2t5eh,2019-8-19,2019,8,19,20,csftkg,medium.com,Zooming into the world of computer vision applications,https://www.reddit.com/r/deeplearning/comments/csftkg/zooming_into_the_world_of_computer_vision/,MachineLearning001,1566214303,,0,0,False,default,,,,,
213,deeplearning,t5_2t5eh,2019-8-19,2019,8,19,23,cshuu6,self.deeplearning,"I explained Backpropagation and Optimization with Math and Visualizations in a very clear way. Now I'm looking for your suggestions, in which way I should take my Deep Learning content.",https://www.reddit.com/r/deeplearning/comments/cshuu6/i_explained_backpropagation_and_optimization_with/,permalip,1566225084,"Hey guys, I posted here about 2 weeks ago. People really seemed to like my writing and the way I explained things in my post, which you can view here:

**Link**: [https://mlfromscratch.com/neural-networks-explained/](https://mlfromscratch.com/neural-networks-explained/)

A specific suggestion/some feedback I got on my last post was:

* Make a followup with the code for deep neural networks in Keras (w/ TensorFlow) and PyTorch.
* Make a post about different activation functions (I'm halfway through making this).

The idea is that I would make posts in the same style, with the math clearly walked through and pictures/animations to help understand it. I have this idea of starting from the bottom, getting to know everything, then moving up into the more complicated architectures and newer research.

Given that you have read my last article (it's actually good, it even helped me a lot), what would you say I should make posts about?

Any advice is appreciated.",16,36,False,self,,,,,
214,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,0,csi866,self.deeplearning,[Research] Recent Advances in Deep Learning Object Detection,https://www.reddit.com/r/deeplearning/comments/csi866/research_recent_advances_in_deep_learning_object/,cdossman,1566226812,"By reviewing a large body of recent related work in literature, researchers systematically analyze the existing object detection frameworks and organize the survey into three major parts: (i) detection components, (ii) learning strategies, and (iii) applications &amp; benchmarks in this paper. They cover a variety of factors affecting the detection performance in detail, such as detector architectures, feature learning, proposal generation, sampling strategies, etc. Finally, they discuss several future directions to facilitate and spur future research for visual object detection with deep learning.

 [https://medium.com/ai%C2%B3-theory-practice-business/here-are-the-recent-advances-in-deep-learning-object-detection-d73dca640526](https://medium.com/ai%C2%B3-theory-practice-business/here-are-the-recent-advances-in-deep-learning-object-detection-d73dca640526)",0,1,False,self,,,,,
215,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,3,cslen0,medium.com,Of Mice and Machines: Can AI Read Rodents Minds?,https://www.reddit.com/r/deeplearning/comments/cslen0/of_mice_and_machines_can_ai_read_rodents_minds/,Yuqing7,1566240318,,0,4,False,default,,,,,
216,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,4,csmfra,self.deeplearning,Weight Agnostic Neural Networks - Video Explanation!,https://www.reddit.com/r/deeplearning/comments/csmfra/weight_agnostic_neural_networks_video_explanation/,HenryAILabs,1566244743,[https://youtu.be/QqoKl9N2oCw](https://youtu.be/QqoKl9N2oCw),0,1,False,self,,,,,
217,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,9,csqiey,self.deeplearning,Build for ML/Deep learning!?,https://www.reddit.com/r/deeplearning/comments/csqiey/build_for_mldeep_learning/,abshk_jr,1566262568,"Hi All,

This is my Freshman Year, and I am planning to build a desktop, the main purposes would be software development, and I will be focusing on Machine learning in the coming year.

This is the build that I have planned currently

CPU

AMD RYZEN 7 3700X

MOTHERBOARD

Asus ROG Strix B450-E Gaming (Wi-Fi)

(I chose this one, because it's a Tier II board, and VRMs are gonna suffice for Overclocking with enough airflow. source : https://docs.google.com/spreadsheets/d/1wmsTYK9Z3-jUX5LGRoFnsZYZiW1pfiDZnKCjaXyzd1o/edit#gid=2112472504 )

RAM

G.Skill Trident Z RGB 8GB DDR4 3200MHz

PSU

CORSAIR CX650

SSD

500GB SAMSUNG SSD 970 EVO PLUS NVME M.2

HDD

Seagate BarraCuda ST1000DM010 1 TB Internal Hard Drive

THERMAL COMPOUND

Noctua NT-H1 Thermal Compound

FANS

Cooler Master MasterFan MF120R ARGB (Triple Pack)

CABINET

Deepcool Matrexx 50 (Black)



GPU

I plan to buy something like an RX570 or GTX1060 for an year or two, then I will be upgrading to some higher card, when I require the computational power. Also I don't game frequently, but even if I do, it's CS:GO, which is not a much GPU taxing game.

I am from India.

Open for all suggestions.",12,1,False,self,,,,,
218,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,15,cstm7o,youtube.com,Tensor-flow implementation explanation tutorial 4,https://www.reddit.com/r/deeplearning/comments/cstm7o/tensorflow_implementation_explanation_tutorial_4/,flyhighwithai,1566281741,,0,1,False,default,,,,,
219,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,15,cstqas,youtube.com,Tensor-flow implementation explanation tutorial 4,https://www.reddit.com/r/deeplearning/comments/cstqas/tensorflow_implementation_explanation_tutorial_4/,flyhighwithai,1566282458,,0,1,False,default,,,,,
220,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,15,csttd0,youtube.com,Tensor-flow implementation explanation tutorial 4,https://www.reddit.com/r/deeplearning/comments/csttd0/tensorflow_implementation_explanation_tutorial_4/,flyhighwithai,1566283168,,0,1,False,default,,,,,
221,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,15,cstwo4,youtube.com,Tensor-Flow Implementation Explanation Tutorial 4,https://www.reddit.com/r/deeplearning/comments/cstwo4/tensorflow_implementation_explanation_tutorial_4/,flyhighwithai,1566283958,,0,1,False,default,,,,,
222,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,17,csuy8t,codeingschool.com,6 Types of Artificial Neural Networks Currently Being Used in Machine Learning,https://www.reddit.com/r/deeplearning/comments/csuy8t/6_types_of_artificial_neural_networks_currently/,subhamroy021,1566289688,,2,4,False,default,,,,,
223,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,20,csxc6i,self.deeplearning,I am building a face recognition algorithm that takes attendance for students that appear in the class. How many pictures do I need to train the algorithm for each individual student before I can successfully run it for the whole class?,https://www.reddit.com/r/deeplearning/comments/csxc6i/i_am_building_a_face_recognition_algorithm_that/,vigbig,1566301583,"I am implementing this via Python using OpenCV. 

I am learning this from scratch and from what I learnt is that I need a lot of pictures to train the algorithm to recognize one person. Now I don't know how much is required as many tutorials say more the better , and why I ask is I have to make this not for a student but for an entire class. 

So far I just learnt how to capture a face on camera using Haar Cascade Classifier, that is it.",10,15,False,self,,,,,
224,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,20,csxiis,self.deeplearning,Video Frame Interpolation via Cyclic Fine-Tuning and Asymmetric Reverse Flow,https://www.reddit.com/r/deeplearning/comments/csxiis/video_frame_interpolation_via_cyclic_finetuning/,mohanne,1566302299," Want to convert your video to slowmotion?  
[https://github.com/MortenHannemose/pytorch-vfi-cft](https://github.com/MortenHannemose/pytorch-vfi-cft)",1,2,False,self,,,,,
225,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,21,csxmgy,self.deeplearning,SDK for developing artificial intelligence application,https://www.reddit.com/r/deeplearning/comments/csxmgy/sdk_for_developing_artificial_intelligence/,aminehy,1566302771,"Pensar SDK: A Rapid Artificial Intelligence Application Development framework by M. Amine Hadj-Youcef, Ph.D. https://link.medium.com/FOKks3M2iZ",0,2,False,self,,,,,
226,deeplearning,t5_2t5eh,2019-8-20,2019,8,20,22,csyo5o,self.computervision,Semantic Segmentation Choroid Plexus,https://www.reddit.com/r/deeplearning/comments/csyo5o/semantic_segmentation_choroid_plexus/,senthilcaesar,1566307069,,0,2,False,default,,,,,
227,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,0,ct0s7j,self.deeplearning,Can you recommend any good tutorials that use OpenFace for facial recognition? preferably from scratch?,https://www.reddit.com/r/deeplearning/comments/ct0s7j/can_you_recommend_any_good_tutorials_that_use/,vigbig,1566315200,"I need to learn for a project that would where I have to develop a facial recognition student attendance based system.

OpenFace  has been suggested to me where it serves the purpose of recognising  several faces . And it is easier to use when compared to FaceNet.

I am new to learning Python , the best I have done some far is capturing faces using OpenCV using Haar Cascade Classifier.",0,2,False,self,,,,,
228,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,1,ct1da3,self.deeplearning,Is it ok for training Dice + Focal losses to be negative?,https://www.reddit.com/r/deeplearning/comments/ct1da3/is_it_ok_for_training_dice_focal_losses_to_be/,74throwaway,1566317357,"I'm running a semantic segmentation model using code from https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb

The loss used is:

    dice_loss = sm.losses.DiceLoss(class_weights=np.array([1, 2, 0.5])) 
    focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()
    total_loss = dice_loss + (1 * focal_loss)

The only differences are that I'm using my own data instead of the CamVid, and I'm trying to predict 3 different classes instead of `car` and `pedestrian` like in that notebook example

I've noticed that although the validation losses have stayed positive and are decreasing, the training losses went from positive and decreased to negative and continue to be more negative:

	Epoch 50/300
	9/9 [==============================] - 1171s 130s/step - loss: 0.0156 - iou_score: 0.6439 - f1-score: 0.6901 - val_loss: 0.1600 - val_iou_score: 0.6910 - val_f1-score: 0.7310
	Epoch 51/300
	9/9 [==============================] - 1173s 130s/step - loss: 0.0022 - iou_score: 0.6491 - f1-score: 0.6941 - val_loss: 0.1517 - val_iou_score: 0.6811 - val_f1-score: 0.7224
	Epoch 52/300
	9/9 [==============================] - 1184s 132s/step - loss: -0.0077 - iou_score: 0.6527 - f1-score: 0.6963 - val_loss: 0.1413 - val_iou_score: 0.6990 - val_f1-score: 0.7380
	Epoch 53/300
	9/9 [==============================] - 1176s 131s/step - loss: -0.0087 - iou_score: 0.6476 - f1-score: 0.6930 - val_loss: 0.1337 - val_iou_score: 0.7204 - val_f1-score: 0.7594
	Epoch 54/300
	9/9 [==============================] - 1166s 130s/step - loss: -0.0052 - iou_score: 0.6516 - f1-score: 0.6959 - val_loss: 0.1294 - val_iou_score: 0.7034 - val_f1-score: 0.7439

Despite the negative training loss, the predictions from the test set continue to improve as the epoch number increases

Is this ok? Or is this a sign that there's something wrong with the code or my setup?",0,1,False,self,,,,,
229,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,1,ct1iiz,youtu.be,Introduction to Self Driving Cars + Source Code,https://www.reddit.com/r/deeplearning/comments/ct1iiz/introduction_to_self_driving_cars_source_code/,mynercloud,1566317904,,3,49,False,default,,,,,
230,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,1,ct2366,self.deeplearning,A Neural Net compiler for low-memory/low-processing powered embedded devices,https://www.reddit.com/r/deeplearning/comments/ct2366/a_neural_net_compiler_for_lowmemorylowprocessing/,en1gmarikki,1566320019,"Hi folks, I am an undergraduate student working on a compiler that helps us run neural networks on low-memory devices like the raspberry pi , Please feel to review the project and help us improve it .

Introduction : 

The DNN Compiler is designed to **enable and perform** deep learning neural networks by focussing on features of custom ai-accelerators like FPGAs, eFPGAs and other embedded devices like risc-V, raspberry-pi and others. DNN Compiler is ahead of time compiler producing optimized executable based on [LLVM compiler tool chain](https://llvm.org/) and [openAcc](https://www.openacc.org/)specialized for deep neural networks with [ONNX](https://onnx.ai/) as front end. 

Link to the repo:

 [https://github.com/ai-techsystems/dnnCompiler](https://github.com/ai-techsystems/dnnCompiler)",1,12,False,self,,,,,
231,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,5,ct57hs,youtu.be,"On-Device, Real-Time Hand Tracking with MediaPipe. | machinelearning | deeplearning",https://www.reddit.com/r/deeplearning/comments/ct57hs/ondevice_realtime_hand_tracking_with_mediapipe/,cmillionaire9,1566331487,,0,10,False,image,,,,,
232,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,14,ctc739,self.deeplearning,Is it possible to decode a deep neural network as an analytical expression/formula ?,https://www.reddit.com/r/deeplearning/comments/ctc739/is_it_possible_to_decode_a_deep_neural_network_as/,yourboyrabbit,1566364346,I know a shallow neural network should be simple to do but what about a deep neural network ?,3,1,False,self,,,,,
233,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,14,ctc73p,medium.com,Improving Business Communications and Human Interactions with NLP,https://www.reddit.com/r/deeplearning/comments/ctc73p/improving_business_communications_and_human/,MachineLearning001,1566364349,,0,8,False,default,,,,,
234,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,14,ctcgvh,self.deeplearning,FileNotFoundError,https://www.reddit.com/r/deeplearning/comments/ctcgvh/filenotfounderror/,Uninvited_Geist,1566366091,"I'm using the following code:  
training\_set = train\_datagen.flow\_from\_directory('E:\\Project\\dataset\\training\_set',

But I'm getting this error:  
FileNotFoundError: \[Errno 2\] No such file or directory: 'content/gdrive/project/dataset/training\_set'   


I tried using Google Drive (already mounted) with the same error:  
training\_set = train\_datagen.flow\_from\_directory('content/gdrive/project/dataset/training\_set',  


What am I doing wrong?",2,0,False,self,,,,,
235,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,14,ctchh0,self.deeplearning,Hairsyle Fittng on Head,https://www.reddit.com/r/deeplearning/comments/ctchh0/hairsyle_fittng_on_head/,zom8ie99,1566366208,How does the apps like FaceIt work? I mean How do they fit the haitstyle on the head of the person ! What are the technologies used ? Is there is anything that I could refer ?,0,2,False,self,,,,,
236,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,15,ctcupq,self.deeplearning,Deep Learning model predicts incorrectly,https://www.reddit.com/r/deeplearning/comments/ctcupq/deep_learning_model_predicts_incorrectly/,zom8ie99,1566368642,"I have trained my self created dataset to 81% train-acc and 80% test acc. The overall taining looks good. But the model predicts incorrect categories. How can I adjust my model so that it can predict accurately ? What parameters should be adjusted ? 

My CNN architecture:

    classifier = Sequential()
    
    classifier.add(Convolution2D(64, (3, 3), input_shape = (32,32,3),padding = 'same',activation = 'relu'))
    classifier.add(MaxPooling2D(pool_size=(2,2), padding = 'same'))  
    
    classifier.add(Convolution2D(128, (3, 3),padding = 'same', activation = 'relu')) classifier.add(MaxPooling2D(pool_size=(2,2), padding = 'same'))  
    
    classifier.add(Convolution2D(256, (3, 3),padding = 'same', activation = 'relu')) classifier.add(MaxPooling2D(pool_size=(2,2), padding = 'same'))
    
    classifier.add(Flatten()) 
    
    classifier.add(Dropout(0.2)) 
    classifier.add(Dense(units = 1024, activation = 'relu')) 
    
    classifier.add(Dropout(0.5)) 
    classifier.add(Dense(units = 5, activation = 'softmax'))

Link to dataset:  [https://www.kaggle.com/zom8ie99/maize-seed](https://www.kaggle.com/zom8ie99/maize-seed) 

Thanks in Advance.",13,1,False,self,,,,,
237,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,15,ctd2wn,youtube.com,Robust Image Text Retrieval From Degraded Document Images,https://www.reddit.com/r/deeplearning/comments/ctd2wn/robust_image_text_retrieval_from_degraded/,flyhighwithai,1566370222,,0,1,False,image,,,,,
238,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,16,ctdizj,rubikscode.net,Using Machine Learning in Service Level Agreements,https://www.reddit.com/r/deeplearning/comments/ctdizj/using_machine_learning_in_service_level_agreements/,RubiksCodeNMZ,1566373382,,0,0,False,default,,,,,
239,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,17,ctdpwr,youtube.com,Iris Recognition MATLAB Implementation,https://www.reddit.com/r/deeplearning/comments/ctdpwr/iris_recognition_matlab_implementation/,flyhighwithai,1566374842,,0,1,False,default,,,,,
240,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,18,ctej9s,self.deeplearning,Regression Problem using large scale input,https://www.reddit.com/r/deeplearning/comments/ctej9s/regression_problem_using_large_scale_input/,drjotten,1566380647,"Hi community,

I am researching in Ultra High Field MRI and trying to homogenize MRI images under SAR constrictions. Since DL is pretty new to me I would like to ask you for help. I try to solve a regression problem using a very high number of input feature values: 

Nine 3D field maps (each about 20x20x10 voxel) and 100 other parameters to calculate two single values with a seperate optimization process i want to model with the NN (all in all: roughly 4100 parameters). 

Does anyone have experiences or a recommendation for some NN which is suitable for this kind of large scale inputs and regression output? 

And do you think this modeling is possible with just several thousands of inputs (50 different sets of field maps combined with several sets of those 100 other parameters).

&amp;#x200B;

Thank you very much in advance! :)",3,3,False,self,,,,,
241,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,21,ctg6m5,github.com,Microsoft Releases New Version of its Open-Source Distributed Deep Learning Library,https://www.reddit.com/r/deeplearning/comments/ctg6m5/microsoft_releases_new_version_of_its_opensource/,mhamilton723,1566390664,,0,15,False,default,,,,,
242,deeplearning,t5_2t5eh,2019-8-21,2019,8,21,23,cthmbh,self.deeplearning,Model overfitts for explicit batch sizes,https://www.reddit.com/r/deeplearning/comments/cthmbh/model_overfitts_for_explicit_batch_sizes/,Taxaria,1566397633," Hey :)  
I made a model for time series forecasting. The model works very well. I tried different batch sizes 32, 50, 64, 100, 128 and 256.  
I got the best result for a batch size of 50. With a batch size of 32 the model still works, but it takes too long until the error converges.  
I tried multiple experiments with a batch size of 64. With that batch size the model is not able to learn. The MAE is very high, the training error decreases, but the validation error is very high. It seems, that the model is overfitting for a batch size of 64.  
So I made further experiments with a batch size of 100, 128 and 256.  
100 works of, but not as good as 50. 128 shows the same results as 64. 256 shows good results in training and validation error, but not in the MAE.  
Do you have any ideas why 64 and 128 do not work?  
I know that models tend to overfit, when the batch size is too large, but this reason makes no sense for me in this case.  
Thanks for your help!",0,2,False,self,,,,,
243,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,1,ctjg23,self.deeplearning,Transfer learning varying results with different models,https://www.reddit.com/r/deeplearning/comments/ctjg23/transfer_learning_varying_results_with_different/,sambalshikhar,1566405977,"I am solving a classification problem on images of documents like, resume,letter,article etc.The best result i got was from vgg16 initialized with imgaenet weights with accuracy of 87% .I fine tuned the last 2 cnn layers of vgg.Doing the same for inception-net,resnet and other models gives terrible results like 20%.What are the reasons that this might happen?",5,1,False,self,,,,,
244,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,2,ctk73z,self.deeplearning,[Code review] Unofficial Keras implementation of the paper Instance Enhancement Batch Normalization,https://www.reddit.com/r/deeplearning/comments/ctk73z/code_review_unofficial_keras_implementation_of/,cyril_9227,1566409156,"Hello guys,

I don't know if it's the right place to ask this (I'm fairly new to reddit) but I recently implemented a Keras code for the paper  [https://arxiv.org/abs/1908.04008](https://arxiv.org/abs/1908.04008) and I would be super glad if someone experienced would review my code and give me feedbacks (it's my first time doing this kind of stuff)...

Here is the repo link :  [https://github.com/Cyril9227/Keras\_IEBN](https://github.com/Cyril9227/Keras_IEBN) 

The official Pytorch code is here :  [https://github.com/gbup-group/IEBN](https://github.com/gbup-group/IEBN) 

&amp;#x200B;

Thank's a lot :)",0,17,False,self,,,,,
245,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,2,ctkgmv,github.com,TensorBoard Empty Scalar Hider: Chrome Extension of hiding empty scalar/panes,https://www.reddit.com/r/deeplearning/comments/ctkgmv/tensorboard_empty_scalar_hider_chrome_extension/,Jasonnor,1566410302,,0,1,False,default,,,,,
246,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,3,ctkjdm,self.deeplearning,Overfitting in loss but getting good accuracy,https://www.reddit.com/r/deeplearning/comments/ctkjdm/overfitting_in_loss_but_getting_good_accuracy/,shahriar49,1566410629,"I have a LSTM network being trained with a huge amount of data (number of model parameters is around 15,000 and I trained it with a dataset of over 1 million sequences. The training and validation loss graph is shown below:

&amp;#x200B;

https://i.redd.it/9dc2jwppcuh31.png

Does the above graph shows some kind of overfitting?

I tested the network with another big set of test data. The trained model had a training accuracy of 0.945, and when I ran it on test data, I got an accuracy of 0.943. This is very close to training accuracy and therefore no sign of overfitting.

So I am confused!",17,14,False,self,,,,,
247,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,5,ctmwz1,open.spotify.com,"I didn't know deepmind had a podcast. It's a nice sci-pop style, helpful if you want to explain AI to people who aren't familiar with computer science",https://www.reddit.com/r/deeplearning/comments/ctmwz1/i_didnt_know_deepmind_had_a_podcast_its_a_nice/,cestnestmoi,1566420856,,0,1,False,default,,,,,
248,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,10,ctq2oy,github.com,C++ Implementation of the Side Window Filtering(CVPR 2019),https://www.reddit.com/r/deeplearning/comments/ctq2oy/c_implementation_of_the_side_window_filteringcvpr/,Ldpe2G,1566435631,,0,21,False,default,,,,,
249,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,14,ctsy3n,github.com,GitHub - MateLabs/AutoOut: Automated Outlier Detection and Treatment Tool,https://www.reddit.com/r/deeplearning/comments/ctsy3n/github_matelabsautoout_automated_outlier/,kailashahirwar12,1566451691,,0,5,False,default,,,,,
250,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,16,cttug9,technostacks.com,A Quick &amp; Easy Way Of Knowing Deep Learning In Python,https://www.reddit.com/r/deeplearning/comments/cttug9/a_quick_easy_way_of_knowing_deep_learning_in/,MichaelOconnor1,1566457880,,0,1,False,default,,,,,
251,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,16,cttwsw,medium.com,Improving Customer Experience with Computer Vision Applications,https://www.reddit.com/r/deeplearning/comments/cttwsw/improving_customer_experience_with_computer/,MachineLearning001,1566458345,,0,4,False,default,,,,,
252,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,16,ctu3nu,github.com,One Of The Most Easy-to-use Free Offline OCR For You,https://www.reddit.com/r/deeplearning/comments/ctu3nu/one_of_the_most_easytouse_free_offline_ocr_for_you/,multisilicon,1566459696,,5,3,False,default,,,,,
253,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,16,ctu4eh,youtube.com,Matlab Implementation of Disease Prediction System Using Neural Network,https://www.reddit.com/r/deeplearning/comments/ctu4eh/matlab_implementation_of_disease_prediction/,flyhighwithai,1566459857,,0,1,False,default,,,,,
254,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,16,ctu71x,self.deeplearning,Listening chatbot,https://www.reddit.com/r/deeplearning/comments/ctu71x/listening_chatbot/,hega72,1566460425,"Hi guys 
I am looking for the following but cant quite find it :
I was wondering if there was a WhatsApp chatbot that I could add to conversations and that would just listen and learn. 
Then I would like to periodically talk to that bot to see how he improves. 
Does that make sense ? Is there such a thing ?",1,3,False,self,,,,,
255,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,17,ctu8w1,youtube.com,Multi-Modal Bio Metric Fusion System Future AI,https://www.reddit.com/r/deeplearning/comments/ctu8w1/multimodal_bio_metric_fusion_system_future_ai/,flyhighwithai,1566460817,,0,1,True,nsfw,,,,,
256,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,19,ctvcer,self.deeplearning,Open AI - GPT2,https://www.reddit.com/r/deeplearning/comments/ctvcer/open_ai_gpt2/,Tamil94,1566468649,"GPT 2 was released and anyone tried .if yes ,please tell us the efficiency ..

we are trying to use that for machine translation.will it helpful for that....",0,1,False,self,,,,,
257,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,19,ctvftn,youtu.be,Policy iteration &amp; value iteration | RL Tutorial series,https://www.reddit.com/r/deeplearning/comments/ctvftn/policy_iteration_value_iteration_rl_tutorial/,Riturajkaushik,1566469277,,0,1,False,default,,,,,
258,deeplearning,t5_2t5eh,2019-8-22,2019,8,22,19,ctvm3x,youtube.com,Content Based Image Retrieval Using KNN and SVM in Matlab,https://www.reddit.com/r/deeplearning/comments/ctvm3x/content_based_image_retrieval_using_knn_and_svm/,flyhighwithai,1566470410,,0,1,False,default,,,,,
259,deeplearning,t5_2t5eh,2019-8-23,2019,8,23,0,ctyuiu,self.deeplearning,"Hi, I release Speech Source Separation with more real sounds!",https://www.reddit.com/r/deeplearning/comments/ctyuiu/hi_i_release_speech_source_separation_with_more/,choiilji,1566487051,"Recently, I made more stable Speech Source Separation model with Phase-aware Speech Enhancement with Deep Complex U-Net([https://arxiv.org/abs/1903.03107](https://arxiv.org/abs/1903.03107?fbclid=IwAR05qxXTDmJIXQh3tNVBkAhBs2fIwACSmGVk8ZTuLJwmYk_DvYglbzuPL8w)) .

It's modified several parts of original paper, mainly, two parts are different.

* Audioset ([https://research.google.com/audioset/](https://research.google.com/audioset/?fbclid=IwAR374LGHAxFXZ-E9OY5uc_GSx2kBVgSzdDkLYsMn6s-gzjA8fb2Kr52FgW8)) : background noise augmentation with balanced 18,000 sound samples
* Preemphasis reduces noises occurred intermittently 

&amp;#x200B;

And samples are...

* validation 10 random : [https://drive.google.com/open?id=1CafFnqWn\_QvVPu2feNLn6pnjRYIa\_rbP](https://drive.google.com/open?id=1CafFnqWn_QvVPu2feNLn6pnjRYIa_rbP&amp;fbclid=IwAR2QcmU_oLrJo33I3RgHsnt3VfdPMnPdpYmS4rYbCHDfZ0ziLFF4iCp7feI)
* CC license youtube test 5 sample : [https://drive.google.com/open?id=19Sn6pe5-BtWXYa6OiLbYGH7iCU-mzB8j](https://drive.google.com/open?id=19Sn6pe5-BtWXYa6OiLbYGH7iCU-mzB8j&amp;fbclid=IwAR3jBaB42I5zv9JB6B-CEeT4rXiDevPvcn54CDuNZPMKIIzqXoRbS62enF8)

If you wanna see sources, visit  [https://github.com/AppleHolic/source\_separation](https://github.com/AppleHolic/source_separation) . Welcome feedback!",3,25,False,self,,,,,
260,deeplearning,t5_2t5eh,2019-8-23,2019,8,23,2,cu0udj,self.deeplearning,Running keras LSTM models with multiple GPU (Tensorflow backend),https://www.reddit.com/r/deeplearning/comments/cu0udj/running_keras_lstm_models_with_multiple_gpu/,shahriar49,1566495733,"I have a keras LSTM model and want to run it under multiple GPUs for speed improvement. But I have some ambiguities:

1- I found that to really get the great speed on GPU I should define my network using CuDNNLSTM layer and not normal LSTM layer. To use multiple GPUs, I looked at  [https://keras.io/utils/#multi\_gpu\_model](https://keras.io/utils/#multi_gpu_model)  and wanted to use multi\_gpu\_model() function to make distributed model. However, in the sample scripts they recommend to define the model on CPU for easy weight sharing, but my CuDNNLSTM model is not deployable on CPU and LSTM model will not benefit from the enhancements provided by GPU. What is the correct approach?

2- So I tried many configurations, including:

\- Group 1(using the normal (non-fast) LSTM layers): placing model on CPU and no copying to GPU; placing model on CPU and then use multi\_gpu\_model to create GPU copies; place model on default GPU and no copying to other GPU; placing model on default GPU and then use multi\_gpu\_model to create two GPU copies.

\- Group2 (using CuDNNLSTM layer and therefore no possibility to place model on CPU): defining a single model (which Tensorflow places it on the default GPU); using multi\_gpu\_model to create two GPU copies.

In all cases, data parallelism (using multi\_gpu\_model) resulted in lower speed of execution. I didn't change anything else in my code and input data pipeline or batch sizes. What is wrong with me?

3- In general, should I only use CuDNN-type layers to get high speed computation with GPUs when I am programming at high level of keras API?",1,1,False,self,,,,,
261,deeplearning,t5_2t5eh,2019-8-23,2019,8,23,3,cu16es,blog.duomly.com,How to Start with Machine Learning,https://www.reddit.com/r/deeplearning/comments/cu16es/how_to_start_with_machine_learning/,atomlib_com,1566497177,,0,1,False,default,,,,,
262,deeplearning,t5_2t5eh,2019-8-23,2019,8,23,3,cu1jlc,aicheatsheets.com,AI Cheatsheets: Your favorite cheatsheets are now available on aicheatsheets@gmail.com,https://www.reddit.com/r/deeplearning/comments/cu1jlc/ai_cheatsheets_your_favorite_cheatsheets_are_now/,kailashahirwar12,1566498766,,2,0,False,default,,,,,
263,deeplearning,t5_2t5eh,2019-8-23,2019,8,23,17,cub5nd,imgur.com,Nvidia made an awesome new imaging tool. http://nvidia-research-mingyuliu.com/gaugan,https://www.reddit.com/r/deeplearning/comments/cub5nd/nvidia_made_an_awesome_new_imaging_tool/,susmit410,1566550201,,2,86,False,default,,,,,
264,deeplearning,t5_2t5eh,2019-8-23,2019,8,23,19,cubylt,ahmedbesbes.com,Visualizing Class Activation Maps to make ConvNets interpretable in medical imaging,https://www.reddit.com/r/deeplearning/comments/cubylt/visualizing_class_activation_maps_to_make/,ahmedbesbes,1566555792,,0,4,False,default,,,,,
265,deeplearning,t5_2t5eh,2019-8-23,2019,8,23,21,cuddtg,self.deeplearning,[D] Deep Reinforcement Learning (research) engineer as MSc?,https://www.reddit.com/r/deeplearning/comments/cuddtg/d_deep_reinforcement_learning_research_engineer/,Roboserg,1566564344,"I am from Germany and I looked for jobs both here in Germany and USA for Deep Reinforcement Learning positions. Every single position I've found required a Ph.D. I understand why, the field is new and mostly academic / research work. Still I wonder if anyone has any information about getting a job maybe not as a researcher scientist (where Ph.D. would be required) but maybe as a research engineer when having a [M.Sc](https://m.sc/) degree? As a research engineer you implement papers to solve current problems. The question is, is there any hope for the field of Deep Reinforcement Learning currently? I know for ""classic"" Deep Learning (supervised etc) such positions exist, but I am very interested in deep RL.

I am nearning the end of my [M.Sc](https://m.sc/). in robotics with the master thesis being on Deep Learning. I am teaching myself deep RL on my free time and would like to pursue a career in that field. I find RL and agents interacting with the environment fascinating.

Would like to hear your opinion.",0,1,False,self,,,,,
266,deeplearning,t5_2t5eh,2019-8-23,2019,8,23,22,cudkdc,self.deeplearning,[Project] Keras implementations of Attention-based BatchNormalization papers,https://www.reddit.com/r/deeplearning/comments/cudkdc/project_keras_implementations_of_attentionbased/,cyril_9227,1566565293,"Hello guys,

I have recently implemented two papers about attention-based BatchNormalization.

1) Attentive Normalization

Arxiv link : [https://arxiv.org/abs/1908.01259](https://arxiv.org/abs/1908.01259) 

Official Pytorch implementation : Not yet released but will be available here  [https://github.com/ivMCL/AttentiveNorm](https://github.com/ivMCL/AttentiveNorm) 

My Keras implementation :  [https://github.com/Cyril9227/Keras\_AttentiveNormalization](https://github.com/Cyril9227/Keras_AttentiveNormalization) 

&amp;#x200B;

2) Instance Enhancement Batch Normalization :

Arxiv link :  [https://arxiv.org/abs/1908.01259](https://arxiv.org/abs/1908.01259) 

Official Pytorch implementation :  [https://github.com/gbup-group/IEBN](https://github.com/gbup-group/IEBN) 

My Keras implementation :  [https://github.com/Cyril9227/Keras\_IEBN](https://github.com/Cyril9227/Keras_IEBN) 

&amp;#x200B;

Both implementations work as a simple droppin replacement of standard BatchNorm layer. Any feedbacks are welcome !

&amp;#x200B;

Thank's :)",0,2,False,self,,,,,
267,deeplearning,t5_2t5eh,2019-8-24,2019,8,24,7,cukmpu,self.deeplearning,"How to package a custom Keras algorithm as a tensorflow model on Sagemaker, so that it can ingest jpeg images from an S3 bucket",https://www.reddit.com/r/deeplearning/comments/cukmpu/how_to_package_a_custom_keras_algorithm_as_a/,ks23ever,1566597635,"I have a custom Keras cnn that I am trying to package as a tensorflow model and deploy on Sagemaker, using batch transform on jpeg images in an S3 bucket.

I followed this tutorial with my own model-- https://aws.amazon.com/blogs/machine-learning/deploy-trained-keras-or-tensorflow-models-using-amazon-sagemaker/

However I'm wondering how to use a batch transformer instead. I created a transformer object using the model that I loaded from the tutorial--

import sagemaker as sage sess = sage.Session()

transformer = sagemaker.transformer.Transformer( base_transform_job_name='Batch-Transform', model_name='sagemaker-tensorflow-2019-08-22-20-24-12-590', # insert model name here instance_count=1, instance_type='ml.p2.xlarge', output_path=batch_output, sagemaker_session=sess )

and tried all different versions of calling the .transform method, only to have it error out--

transformer.transform(data=batch_input, content_type='application/x-image') transformer.wait()",1,1,False,self,,,,,
268,deeplearning,t5_2t5eh,2019-8-24,2019,8,24,19,cus11v,self.deeplearning,Gpt-2 online version!,https://www.reddit.com/r/deeplearning/comments/cus11v/gpt2_online_version/,susmit410,1566644368,https://talktotransformer.com/,10,15,False,self,,,,,
269,deeplearning,t5_2t5eh,2019-8-24,2019,8,24,20,cusids,self.deeplearning,How to check if tensorflow is working exactly as supposed to with TensorRt engine.,https://www.reddit.com/r/deeplearning/comments/cusids/how_to_check_if_tensorflow_is_working_exactly_as/,mr_meeesix,1566647788,"My setup,

 CUDA 10.0  
 cuDnn 7.6  
 tensorflow 1.14  
 tensorrt 5.0

And I've been following the tutorial by [https://github.com/ardianumam/Tensorflow-TensorRT](https://github.com/ardianumam/Tensorflow-TensorRT)

Every time I run the create inference engine I feel nothing is optimized, I get 0 for number of engine nodes. 

    TensorRT model is successfully stored!
    numb. of all_nodes in frozen graph: 8016
    numb. of trt_engine_nodes in TensorRT graph: 0
    numb. of all_nodes in TensorRT graph: 882

Can you guys let me know what or where the issue is and I get zero errors which is bugging me out.

Thanks",0,2,False,self,,,,,
270,deeplearning,t5_2t5eh,2019-8-24,2019,8,24,23,cutqyt,self.deeplearning,Fortnite DeepLearning AI,https://www.reddit.com/r/deeplearning/comments/cutqyt/fortnite_deeplearning_ai/,Wandrew33,1566655333,Yo whats up boys I was wondering if it was possible to create a bot that can play Fortnite. If it is and youre able to do it you should definitely do it and post a video of it,0,0,False,self,,,,,
271,deeplearning,t5_2t5eh,2019-8-24,2019,8,24,23,cuu5mm,self.deeplearning,Project approach consultation - RF / DL / ?,https://www.reddit.com/r/deeplearning/comments/cuu5mm/project_approach_consultation_rf_dl/,progmayo,1566657512,"Hi :) hopefully this isn't too long. I tried accentuating things in bold.

I have a specific project in mind I wish to do using AI, but Im unsure which method to use, and where to focus my time in terms of the different courses and lessons available (ML / DL / etc.). The details are less important, but I'd be happy to explain more if needed. For now Ill just describe what Im trying to achieve in general.

**I have sampled points on a general mult-dimensional tensor, and the goal is to find a mapping function of these points that achieves good results in terms of a criteria I set it (MSE), under a certain constraint - some sort of upper bound limitation on the mapping.** The details are less important, the bottom line is that I'm trying to find a mapping for these points g()=? that minimizes MSE under a constraint. So, for X sampled points, I need to find X points that correspond with their mapping. Everything is continuous of course - the sampled points and their mapping.

**Ive already built** a program that does this using scipy.optimize.minimize, which uses **an iterative method** for constrained nonlinear optimization - uses gradient decent to find a local minimum that achieves the criteria under the constraint.

**I want to try to use and test the performance of a neural network, or random forest,** or something along those lines using AI, but I got a bit lost in the videos I started watching, and I did not find a suitable example that was close to what Im trying to achieve. In short, I'm unsure which algorithm I should be using, and if AI is suited for this task at all, or is what I've already built the ""standard"" way of approaching this task, and that's that.

**Id like to ask which approach you think would suit my problem (RF? DL? etc.), and if you believe that these approaches could possibly outperform the straight-forward approach I already implemented using the iterative method**, which suffers from the unwanted local minimum phenomenon, and is relatively slow in general (especially in high dimensions).",1,2,False,self,,,,,
272,deeplearning,t5_2t5eh,2019-8-24,2019,8,24,23,cuu6ii,youtube.com,Simple Perceptron explanation,https://www.reddit.com/r/deeplearning/comments/cuu6ii/simple_perceptron_explanation/,nottingpill,1566657640,,0,30,False,image,,,,,
273,deeplearning,t5_2t5eh,2019-8-25,2019,8,25,1,cuvalt,self.deeplearning,"Deep Learning : Colorizing Old Films, Charlie Chaplin's as example",https://www.reddit.com/r/deeplearning/comments/cuvalt/deep_learning_colorizing_old_films_charlie/,jadibelum91,1566663047,"**Deep Learning** is used to colorize old films, **Charlie Chaplin**'s as example , the result is absolutely amazing  [https://www.youtube.com/watch?v=IDrK85g0kdM](https://www.youtube.com/watch?v=IDrK85g0kdM)",0,3,False,self,,,,,
274,deeplearning,t5_2t5eh,2019-8-25,2019,8,25,1,cuvbsr,youtu.be,What is a Tensor ?,https://www.reddit.com/r/deeplearning/comments/cuvbsr/what_is_a_tensor/,nowsden,1566663196,,7,29,False,image,,,,,
275,deeplearning,t5_2t5eh,2019-8-25,2019,8,25,8,cv113f,self.deeplearning,Prevent overfitting in self recorded dataset: Should I remove background to avoid overfitting in action recognition task?,https://www.reddit.com/r/deeplearning/comments/cv113f/prevent_overfitting_in_self_recorded_dataset/,andytran11996,1566690695,"Hello,
I am working on a small project for my bachelor thesis. Its about a drink fridge with 4 cameras mounted on it ( I just make an experiment with 1  drawer). 3 cameras are mounted on 3 corners of the drawer and 1 on the outside.
It should recognize 3 actions: take, put and pretend to put.
I recorded a dataset about 3000 (x4 cameras) videos, 1000 each class. On a same day ( I tried to change objects position each time, also my shirt)
I split the dataset into 3 parts, 60% train, 20% val, 20% test.
Ive got &gt; 95% accuracy on all of 3 sets, for a second, i was thinking well, I did a very good job. But no, in a live test, it predicts badly, always the same class. At first I thought it was just overfitting, and tried to tune the parameters, adding regularization. That didnt help.
I spent another day to record another dataset, and the results were the same. The model trained on one dataset has bad performance in the other dataset.
 I think the background and the surrounding objects could be the reason (sometimes there was a chair, my colleague sitting on the left, etc). But since its a fridge in my company with my PC on the top, I cant move it elsewhere.
My questions are: 
- What should I do in this situation? Is removing the background ( so only
the arm and the object being taken are kept ) a good way to go? Would it solve the problem? If yes, which background subtractor is best?
- Did you ever have the same problem with self recorded dataset? What are common mistakes and it would be very helpful to hear your experience.

There are not too many public datasets for every task, I think that many other beginners like me could also be struggling with self recorded dataset and I hope this post will be helpful to us all.

Thank you :)",0,0,False,self,,,,,
276,deeplearning,t5_2t5eh,2019-8-25,2019,8,25,11,cv2ifz,medium.com,Can deep learning read mouse mind?,https://www.reddit.com/r/deeplearning/comments/cv2ifz/can_deep_learning_read_mouse_mind/,Yuqing7,1566698642,,0,0,False,default,,,,,
277,deeplearning,t5_2t5eh,2019-8-25,2019,8,25,14,cv4r0y,towardsdatascience.com,What is the difference between Optimization and Deep Learning and why should you care,https://www.reddit.com/r/deeplearning/comments/cv4r0y/what_is_the_difference_between_optimization_and/,sudo_su_,1566711637,,0,4,False,default,,,,,
278,deeplearning,t5_2t5eh,2019-8-25,2019,8,25,14,cv4rrj,self.deeplearning,"Interview with the leader of mlcourse.ai: Dr. Yury Kashnitsky | mlcourse.ai is an open course with the right balance of theory, practise and kaggle.",https://www.reddit.com/r/deeplearning/comments/cv4rrj/interview_with_the_leader_of_mlcourseai_dr_yury/,init__27,1566711778,"mlcourse.ai is a unique course with the right balance of theory+practise and Kaggle. The final iteration of the course starts on 2nd Sept, 2019. Be sure to sign up!

Following is a link to the interview with the leader of the course. Available both as a podcast, video.

In the interview, we talk all about the efforts and decisions behind the course structure. Yury also shares tips for both future students and alumni of the course.

Audio: https://anchor.fm/chaitimedatascience/episodes/Interview-with-the-Leader-of-mlcourse-ai--Dr--Yury-Kashnitsky--Chai-Time-Data-Science-e52r5u/a-alh171

Video: https://www.youtube.com/watch?v=ZmKGQdCyOFY&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=12",0,1,False,self,,,,,
279,deeplearning,t5_2t5eh,2019-8-25,2019,8,25,14,cv4tic,self.deeplearning,Computer Vision Final Year Project,https://www.reddit.com/r/deeplearning/comments/cv4tic/computer_vision_final_year_project/,TechRanger19,1566712135,"Hi Everyone, I am in my final Year in Computer Science undergraduate programme. I have little math background in CS background, and did an internship as ML Engineer to develop car plates Detector using YOLOv3 and Darknet. I am looking for Computer Vision project as my Final Year Project. There are few projects that I'm looking into:

1. Plant Disease Detection
2. Type of crops classification using drone image
3. Object detection (need suggestion on this)

As for now, I can do object detection, but i'm new for agriculture application of deep learning.Hope you guys can give me advise and suggestion on this.",5,12,False,self,,,,,
280,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,0,cv9vl9,self.deeplearning,How to preprocess image to match the model input size ?,https://www.reddit.com/r/deeplearning/comments/cv9vl9/how_to_preprocess_image_to_match_the_model_input/,luxowl,1566746952,"Hello dear deeplearning lovers !

I'm reading and implementing some CNN architectures, the Alexnet architecture take 227x227x3 images input.  
How can I preprocess images to match this input size, do I have to crop and scale it ? It seems a little bit ""naive"" to me, are there other better techniques ?

And also, does all models require a fixed size input ? 

English is not my native language, sorry.

Thank you !",12,8,False,self,,,,,
281,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,1,cvaovq,youtu.be,Find free parking space with Machine Learning,https://www.reddit.com/r/deeplearning/comments/cvaovq/find_free_parking_space_with_machine_learning/,cmillionaire9,1566750845,,2,23,False,image,,,,,
282,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,2,cvbatj,i.redd.it,Can any one explain me what exactly is happening . I am new to deep learning with almost no experience the training accuracy and validation accuracy are almost same and increase very very slightly with each epoch and they are starting from 0.98,https://www.reddit.com/r/deeplearning/comments/cvbatj/can_any_one_explain_me_what_exactly_is_happening/,codotron318,1566753681,,17,9,False,image,,,,,
283,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,2,cvbln7,self.deeplearning,Deep Learning Research - Weekly Update Video,https://www.reddit.com/r/deeplearning/comments/cvbln7/deep_learning_research_weekly_update_video/,HenryAILabs,1566755059,"[https://youtu.be/-be-O1mVD\_Q](https://youtu.be/-be-O1mVD_Q)

Thanks for watching! I would really appreciate feedback on this to improve it!!",0,0,False,self,,,,,
284,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,4,cvd1oa,self.deeplearning,DeepLearningBook by Ian Goodfellow: poor correspondence between local and global structure,https://www.reddit.com/r/deeplearning/comments/cvd1oa/deeplearningbook_by_ian_goodfellow_poor/,notreallysocool,1566761556,This problem is discussed in section 8.2.7 of the book. Are there any papers recently that address this problem?,4,7,False,self,,,,,
285,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,5,cvdza7,self.deeplearning,Month-to-month model training and maintenance services,https://www.reddit.com/r/deeplearning/comments/cvdza7/monthtomonth_model_training_and_maintenance/,jennysebastian,1566765973,Check us out at [Techsensus.com](https://Techsensus.com) :),0,3,False,self,,,,,
286,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,6,cveqql,self.deeplearning,Error while running a file for creating a restaurant chatbot,https://www.reddit.com/r/deeplearning/comments/cveqql/error_while_running_a_file_for_creating_a/,Vigneshwar_MS,1566769572,"**Am creating a restaurant search bot using Rasa framework. When i run the nlu\_model.py file, I have run into issues and i work using a mac. Attached an image of the code. Could you please help me to fix this error?**

Getting the below error :

Rasa NLU version: 0.12.3  
spacy==2.0.11Operating system : Macos

Content of model configuration file:  
language: ""en""  
pipeline: spacy\_sklearn

Full stacktrace below:

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/training\_data/training\_data.py:194: UserWarning: Entity 'people' has only 1 training examples! minimum is 2, training may fail.  
self.MIN\_EXAMPLES\_PER\_ENTITY))  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/training\_data/training\_data.py:194: UserWarning: Entity 'price' has only 1 training examples! minimum is 2, training may fail.  
self.MIN\_EXAMPLES\_PER\_ENTITY))  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/utils/**init**.py:236: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read [https://msg.pyyaml.org/load](https://msg.pyyaml.org/load) for full details.  
return yaml.load(read\_file(filename, ""utf-8""))  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
\_np\_qint8 = np.dtype(\[(""qint8"", np.int8, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
\_np\_quint8 = np.dtype(\[(""quint8"", np.uint8, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
\_np\_qint16 = np.dtype(\[(""qint16"", np.int16, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
\_np\_quint16 = np.dtype(\[(""quint16"", np.uint16, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
\_np\_qint32 = np.dtype(\[(""qint32"", np.int32, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
np\_resource = np.dtype(\[(""resource"", np.ubyte, 1)\])  
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/**init**.py:36: FutureWarning: Conversion of the second argument of issubdtype from float  
to np.floating  
is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type  
.  
from .\_conv import register\_converters as \_register\_converters  
Traceback (most recent call last):  
File ""nlu\_model.py"", line 21, in  
train\_nlu('./data/data.json', 'config\_spacy.json', './models/nlu')  
File ""nlu\_model.py"", line 12, in train\_nlu  
trainer = Trainer(config.load(config\_file), builder)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/model.py"", line 149, in **init**  
self.pipeline = self.\_build\_pipeline(cfg, component\_builder)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/model.py"", line 160, in \_build\_pipeline  
component\_name, cfg)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/components.py"", line 420, in create\_component  
cfg)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/registry.py"", line 140, in create\_component\_by\_name  
return component\_clz.create(config)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/rasa\_nlu/utils/spacy\_utils.py"", line 73, in create  
nlp = spacy.load(spacy\_model\_name, parser=False)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/**init**.py"", line 15, in load  
return util.load\_model(name, \*\*overrides)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 112, in load\_model  
return load\_model\_from\_link(name, \*\*overrides)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 129, in load\_model\_from\_link  
return cls.load(\*\*overrides)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/data/en/**init**.py"", line 12, in load  
return load\_model\_from\_init\_py(**file**, \*\*overrides)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 173, in load\_model\_from\_init\_py  
return load\_model\_from\_path(data\_path, meta, \*\*overrides)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 156, in load\_model\_from\_path  
return nlp.from\_disk(model\_path)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/language.py"", line 653, in from\_disk  
util.from\_disk(path, deserializers, exclude)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 511, in from\_disk  
reader(path / key)  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/language.py"", line 649, in  
deserializers\[name\] = lambda p, proc=proc: proc.from\_disk(p, vocab=False)  
File ""pipeline.pyx"", line 643, in spacy.pipeline.Tagger.from\_disk  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 511, in from\_disk  
reader(path / key)  
File ""pipeline.pyx"", line 626, in spacy.pipeline.Tagger.from\_disk.load\_model  
File ""pipeline.pyx"", line 627, in spacy.pipeline.Tagger.from\_disk.load\_model  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/thinc/neural/\_classes/model.py"", line 352, in from\_bytes  
copy\_array(dest, param\[b'value'\])  
File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/thinc/neural/util.py"", line 48, in copy\_array  
dst\[:\] = src  
ValueError: could not broadcast input array from shape (96) into shape (128)",0,1,False,self,,,,,
287,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,10,cvhb6o,self.deeplearning,Range of parameters for hyperparameter optmization in fully connected layers,https://www.reddit.com/r/deeplearning/comments/cvhb6o/range_of_parameters_for_hyperparameter/,BlackHawk1001,1566782633,"Hello everybody

I have designed a variational autoencoder with 2D convolutions in the encoder and decoder. I have trained this autoenocder on 50'000 unlabelled images (64 x 80). Now, I would like to use this variational autoencoder for classification on labelled data. To achieve that, I have stacked fully connected layers on top of the encoder, i.e. the latent representation is the input to the fully connected layers. I have made the layers of the encoder trainable, so I will retrain also the autoencoder during classification.

In total I have a 30 dimensional latent space and around 1000 data points (i.e. images) in 2 classes.

I think the two most important parameters for the fully connected layers are the amount of layers and the amount of nodes per layer. I think I should choose this using random search but I need some start values or range.

What range to search for the number of layers and number of nodes per layer makes sense? Especially regarding the number of nodes I'm unsure. When my latent space is of dimension 30, should I use &lt; 30 nodes in all layers? Should the number of nodes from layer to layer be multiplied by 2? For example, 64 nodes in first layer, 128 in second and so on.

Finally, is using Batch normalization or dropout for the fully connected layers reasonable in my situation? I have only 1000 data points and probably a very shallow networks (I think there will be no more than 4 layers).",1,11,False,self,,,,,
288,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,15,cvk8vn,self.deeplearning,"Interview with the creator of MuseNet: Christine Payne all about MuseNet, OpenAI and Deep Learning Research",https://www.reddit.com/r/deeplearning/comments/cvk8vn/interview_with_the_creator_of_musenet_christine/,init__27,1566800601,"Following are links to an Interview with Christine Mcleavy Payne all about MuseNet, Deep Learning Research, OpenAI  and MOOC(s):  

&amp;#x200B;

We also discuss her journey of starting with the courses by [Andrew Ng](https://twitter.com/AndrewYNg) and [fastdotai](https://twitter.com/fastdotai) to transitioning into Research.    


Audio: [https://anchor.fm/chaitimedatascience/episodes/MuseNet--OpenAI-and-Deep-Learning-Research-Interview-with-Christine-Payne-e4r6hb/a-ak54g2](https://anchor.fm/chaitimedatascience/episodes/MuseNet--OpenAI-and-Deep-Learning-Research-Interview-with-Christine-Payne-e4r6hb/a-ak54g2)

Video: [https://www.youtube.com/watch?v=LSEZXPvEV24&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=13](https://www.youtube.com/watch?v=LSEZXPvEV24&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=13)",0,3,False,self,,,,,
289,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,16,cvkuqg,techacker.net,OpenAI just released GPT-2 text generator and its scary,https://www.reddit.com/r/deeplearning/comments/cvkuqg/openai_just_released_gpt2_text_generator_and_its/,mnluxury11,1566805114,,0,1,False,default,,,,,
290,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,17,cvl45i,self.deeplearning,Course advice welcomed!,https://www.reddit.com/r/deeplearning/comments/cvl45i/course_advice_welcomed/,squeaki,1566807124,"Hi all.

I'm looking to upskill during a period of downtime before moving onward in my industry. I've enrolled on two courses already on Udemy: [Machine Learning A-Z: Hands-On Python &amp; R In Data Science](https://www.udemy.com/machinelearning/) &amp; [Complete Python Bootcamp: Go from zero to hero in Python 3](https://www.udemy.com/complete-python-bootcamp/)

I am wondering if there are courses I could buy now (10% the cost for a few days) that I will benefit from in the future.

I am looking into image processing and object identification.  
There are a lot of options for Neural Networking/Deep Learning, but I've not the experience with the subject  (like you guys in this sub have already), so I'm asking advice as to which might be worth doing. I'm wiling to buy two courses if need be, as they are 'the right price' at the moment... 10 isn't bad and I feel I can work with these prices.

Would be interested in what you folks think!

[https://www.udemy.com/courses/search/?q=neural%20network&amp;src=sac&amp;kw=Neru](https://www.udemy.com/courses/search/?q=neural%20network&amp;src=sac&amp;kw=Neru)",4,4,False,self,,,,,
291,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,17,cvl7kc,medium.com,Building Engaging Conversational Interfaces with DialogFlow,https://www.reddit.com/r/deeplearning/comments/cvl7kc/building_engaging_conversational_interfaces_with/,MachineLearning001,1566807878,,0,0,False,default,,,,,
292,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,18,cvlted,youtube.com,Satellite Image (SAR) Segmentation Using Neural Networky,https://www.reddit.com/r/deeplearning/comments/cvlted/satellite_image_sar_segmentation_using_neural/,flyhighwithai,1566812550,,0,1,False,default,,,,,
293,deeplearning,t5_2t5eh,2019-8-26,2019,8,26,23,cvotr2,self.deeplearning,"Memory Error When Building Large Hdf5 on Amazon AMI (p2.xlarge GPU, 61 GB Memory)",https://www.reddit.com/r/deeplearning/comments/cvotr2/memory_error_when_building_large_hdf5_on_amazon/,juanjop777,1566829769,"Whenever I try to  build an hdf5 dataset, I get an error saying that there is not enough space. I built the dataset on my local machine, and  it is approximately 36 GB.   


I am currently using the p2.xlarge instance with GPU, which comes with 61 GB of memory. 

Right as I ssh into the AMI I get the message:  
***Usage of ""\\"" : 53%***  
***Memory usage: 1%***  
When I run **df -h** I get that I have **/dev/xvda1 at 53%, but 30 GB available in udev and tmpfs.**   


I know that hdf5 files store data as binaries directly on Disk. Therefore:

 **---&gt; How can I move the hdf5 file to use Disk for storage, or udev or tmpfs?**

Thank you very much in advance,  


Juan",3,12,False,self,,,,,
294,deeplearning,t5_2t5eh,2019-8-27,2019,8,27,1,cvpzhy,self.deeplearning,Is cosine similarity differentiable?,https://www.reddit.com/r/deeplearning/comments/cvpzhy/is_cosine_similarity_differentiable/,mellow54,1566835227,"If I have a function f(X) which is a vector of length N and corresponding labels Y also with vector length N, I can compute the cosine similarity between Y and f(X).

If the function f is a neural network and my loss function is cosine\_sim(Y, f(X)) would it be differentiable? I.e. would I be able to train my neural network weights to minimise the cosine similarity loss?",6,10,False,self,,,,,
295,deeplearning,t5_2t5eh,2019-8-27,2019,8,27,5,cvtplb,self.deeplearning,Confusion in choosing fields to focus on.,https://www.reddit.com/r/deeplearning/comments/cvtplb/confusion_in_choosing_fields_to_focus_on/,Ryotsou,1566851703,"I am really interested in computer vision, but when I focus on vision, someone inside my head starts whispering 'NLP, NLP'. It's really weird and irritating. Should I give a fair amount of time to both of them? Or what do you suggest,",3,0,False,self,,,,,
296,deeplearning,t5_2t5eh,2019-8-27,2019,8,27,8,cvvvaj,self.deeplearning,GANs for vehicle trajectories,https://www.reddit.com/r/deeplearning/comments/cvvvaj/gans_for_vehicle_trajectories/,AbdulhadyFeteiha,1566861589,"I'm trying to generate a driving scene consisting of 4 vehicles in a street. I have preprocessed a data set and the result is 720 scenes each consisting of 4 vehicles navigating within the scene. Hence, the scene block dimensions are: 4 objects \* 2 coordinates (x,y)\*40samples.

I tried using usual DCGAN and WGAN algorithms treating the dataset as a collection of images with 2 channels(the x,y coordinates) but the results are disappointing as the generated vehicles are doing only one behavior: going back and forth on a diagonal. I interpreted the results as follows; the model can't capture the different navigation behaviors of the cars (moving forward, backward, on a curve, etc.)

I'm trying to migrate to different models, ones having a sequence capturing module (RNN/LSTM). What are your recommendations?

Finally, do you think that the whole project is promising, or it's a dead-ending approach?",0,5,False,self,,,,,
297,deeplearning,t5_2t5eh,2019-8-27,2019,8,27,8,cvwbpj,self.deeplearning,Speech Specific Text to speech model,https://www.reddit.com/r/deeplearning/comments/cvwbpj/speech_specific_text_to_speech_model/,muaz65,1566863799,"Does anyone here have any idea regarding a pre trained text to speech model which should be capable of generating person specific speech. Like a model should only require a single voice clip of a person and the speech generated by the model should be in the voice of the audio file provided.

I am unable to phrase my question in exact manner. My point is to find a pertained model/ api or something which can do following after training.
-Take a speech sample 
-Take a textual input 
-Generate speech of the given text in (tone/voice/accent) of the sound file given as a sample.

I have seen some models like [deepVoice](https://github.com/r9y9/deepvoice3_pytorch) but i am unable to understand the testing mechanism.",3,4,False,self,,,,,
298,deeplearning,t5_2t5eh,2019-8-27,2019,8,27,9,cvx04n,lionbridge.ai,Create Your Own Synthetic Voice With Just One Hour of Speech (Lyrebird Review),https://www.reddit.com/r/deeplearning/comments/cvx04n/create_your_own_synthetic_voice_with_just_one/,LimarcAmbalina,1566867195,,0,36,False,default,,,,,
299,deeplearning,t5_2t5eh,2019-8-27,2019,8,27,12,cvyxrk,self.deeplearning,Video scoring with deep learning,https://www.reddit.com/r/deeplearning/comments/cvyxrk/video_scoring_with_deep_learning/,arianaa30,1566877352," I am trying to rank video scenes/frames based on how appealing they are for a viewer. Basically, how ""interesting"" or ""attractive"" a scene inside a video can be for a viewer. My final goal is to generate say a 10-second short summary given a video as input, such as those seen on Youtube when you hover your mouse on a video.

I found an ""aesthetics"" model is good for ranking artistic images, but not good for frames of videos. So it was failing. I need a score based on ""engagement for general audience"". Basically, which scenes/frames of video will drive more clicks, likes, and shares when selected as a thumbnail.

Do we have an available deep-learning model or a prototype doing that? A ready-to-use prototype/model that I can test as opposed to a paper that I need to implement myself. Paper is fine as long as the code is open-source. I'm new and can't yet write a code given a paper.",0,1,False,self,,,,,
300,deeplearning,t5_2t5eh,2019-8-27,2019,8,27,16,cw11o6,self.deeplearning,When you build NER classifiers using BERT like Language models should the pretrained BERT weights also be adjusted while training the classifier?,https://www.reddit.com/r/deeplearning/comments/cw11o6/when_you_build_ner_classifiers_using_bert_like/,darkangel404,1566891082,,2,4,False,self,,,,,
301,deeplearning,t5_2t5eh,2019-8-27,2019,8,27,17,cw1doh,self.deeplearning,Who started deep neural embedding idea?,https://www.reddit.com/r/deeplearning/comments/cw1doh/who_started_deep_neural_embedding_idea/,pk12_,1566893569,"Does anyone have a definitive reference?

To my knowledge, Yoshua Bengio had a paper titled ""A Neural Probabilistic Language Model"", but this is for text modality only. 

Did someone propose neural embeddings before them on generating embeddings for various modalities through neural networks?",2,3,False,self,,,,,
302,deeplearning,t5_2t5eh,2019-8-27,2019,8,27,20,cw3byk,blog.paralleldots.com,Download and analyze textual data from the comfort of your spreadsheet with ParallelDots' SmartReader,https://www.reddit.com/r/deeplearning/comments/cw3byk/download_and_analyze_textual_data_from_the/,anantcoolblabla,1566906635,,0,1,False,default,,,,,
303,deeplearning,t5_2t5eh,2019-8-28,2019,8,28,2,cw81o1,nlp.town,Distilling BERT Models with spaCy,https://www.reddit.com/r/deeplearning/comments/cw81o1/distilling_bert_models_with_spacy/,yvespeirsman,1566928739,,0,25,False,default,,,,,
304,deeplearning,t5_2t5eh,2019-8-28,2019,8,28,3,cw8ktj,self.deeplearning,Unexpected result in using multiple GPUs in keras/tensorflow,https://www.reddit.com/r/deeplearning/comments/cw8ktj/unexpected_result_in_using_multiple_gpus_in/,shahriar49,1566931127,"I am using TF 1.14 and my computer has two GPUs, so I was interested to utilize both in parallel. I found different ways of doing that and it looks like the platform is very dynamic and I was confused on what to do. I generally found below two methods for doing data parallelization in keras/tensorflow:

&amp;#x200B;

Method 1:

    with tf.device('/cpu:0'):
        model = ...
    parallel_model = multi_gpu_model(model, gpus=2)
    parallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

Method 2:

    strategy = tf.distribute.MirroredStrategy()
    with strategy.scope():
        parallel_model = ...
        parallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

I tried both of the above methods, and also ran my simulation on a non-parallel mode of training (which uses just one GPU). However, the results were very strange and I don't understand what is the problem. For my specific network and data, in Method 1 the training took around 1100 seconds, while in Method 2 it took 270 seconds. Just using one GPU and halving the batch size (to make it fair to compare with parallel models) the training took around 500 seconds. So, the Method 2 result makes sense as the training time is about half the single GPU case, but what is wrong with the first method? Should I phase it out and just forget it?

P.S. I also see a minor change in reported model summary report that I have not seen previously on my non-multi-gpu machine, which is extra square brackets around the input layer shape \[(None, None, 8)\]:

    Layer (type)                 Output Shape              Param #   
    input_1 (InputLayer)         [(None, None, 8)]         0         
    lstm (LSTM)                  (None, None, 16)          1600      
    lstm_1 (LSTM)                (None, None, 16)          2112      
    lstm_2 (LSTM)                (None, 16)                2112      
    dense (Dense)                (None, 7)                 119       
    Total params: 5,943

What is this?",0,0,False,self,,,,,
305,deeplearning,t5_2t5eh,2019-8-28,2019,8,28,5,cw9y5b,self.deeplearning,"Should I consider learning this stuff? I'm coming straight to the source, and I promise this isn't bait.",https://www.reddit.com/r/deeplearning/comments/cw9y5b/should_i_consider_learning_this_stuff_im_coming/,HolyCrapItsZombies,1566937213,"I am fascinated with ML/DL, GANs, and the things that I'm seeing on a daily basis.  The GauGAN is an example of the stuff that seems simple but is super impressive, or thispersondoesnotexist/thisarticledoesnotexist. Deepfakes, computer generated voices/text and even AI music simultaneously freak me out, and kickstart my imagination at the same time. I sub and try my best to follow the Lex Fridman AI podcast, even when it gets too technical, so that's about the extent of what I know- I can follow most of what's being discussed, but actually \*do\* none of it.   


I feel like if I had a pocket-sized genius coder with me we could do amazing things just spitballing uses for this tech. But there's just me, with zero coding experience. I programmed a tank game on Commodore 64 when I was 9, back in 1990, and that's it. It was not a joy, and was tedious copy-paste if my childhood memory serves. So is getting fluent this field as daunting as becoming fluent in Mandarin, or high level physics or something like that? I'd be looking to earn eventually, not just fiddle around as a hobby. Somebody talk me into it or out of it please.",3,0,False,self,,,,,
306,deeplearning,t5_2t5eh,2019-8-28,2019,8,28,5,cw9yau,self.deeplearning,Foundations of Neuroevolution - The NEAT algorithm explained!,https://www.reddit.com/r/deeplearning/comments/cw9yau/foundations_of_neuroevolution_the_neat_algorithm/,HenryAILabs,1566937229,[https://youtu.be/b3D8jPmcw-g](https://youtu.be/b3D8jPmcw-g),2,7,False,self,,,,,
307,deeplearning,t5_2t5eh,2019-8-28,2019,8,28,19,cwj3qm,self.deeplearning,Deep Learning Based OCR for Text in the Wild,https://www.reddit.com/r/deeplearning/comments/cwj3qm/deep_learning_based_ocr_for_text_in_the_wild/,manneshiva,1566989378,"Learn how to do Optical Character Recognition(OCR) to extract text from passports, number plates, and handwritten texts to PDF, invoices, receipts.  [https://nanonets.com/blog/deep-learning-ocr/](https://nanonets.com/blog/deep-learning-ocr/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=ocrw&amp;utm_content=dl)

https://i.redd.it/t2ppylm866j31.gif",1,24,False,self,,,,,
308,deeplearning,t5_2t5eh,2019-8-28,2019,8,28,20,cwjf1t,medium.com,Assembling an Ideal Team to Build AI Chatbots,https://www.reddit.com/r/deeplearning/comments/cwjf1t/assembling_an_ideal_team_to_build_ai_chatbots/,MachineLearning001,1566991307,,0,0,False,default,,,,,
309,deeplearning,t5_2t5eh,2019-8-29,2019,8,29,0,cwm39d,self.deeplearning,[Research] A Realistic Face-to-Face Conversation System based on Deep Neural Networks,https://www.reddit.com/r/deeplearning/comments/cwm39d/research_a_realistic_facetoface_conversation/,cdossman,1567004928,[removed],0,1,False,self,,,,,
310,deeplearning,t5_2t5eh,2019-8-29,2019,8,29,2,cwoce5,self.deeplearning,How to use ML to make an A.I sports commentator?,https://www.reddit.com/r/deeplearning/comments/cwoce5/how_to_use_ml_to_make_an_ai_sports_commentator/,AboutVR018734,1567015083,"I know basics of programming (just starting). I want to teach for an ML program to be a commentator for  EA Sports FIFA Soccer. I am fed up with the slow progress of commentary in these games and its all scripted.

How to I get started?

&amp;#x200B;

Thanks",7,2,False,self,,,,,
311,deeplearning,t5_2t5eh,2019-8-29,2019,8,29,3,cwoiit,reddit.com,Faceswap made easy,https://www.reddit.com/r/deeplearning/comments/cwoiit/faceswap_made_easy/,susmit410,1567015825,,0,1,False,default,,,,,
312,deeplearning,t5_2t5eh,2019-8-29,2019,8,29,7,cwrtx1,self.deeplearning,How would you prefer using a Deep Learning Library? Let's build one together!,https://www.reddit.com/r/deeplearning/comments/cwrtx1/how_would_you_prefer_using_a_deep_learning/,akifnane,1567030724,"Hi, this will be my first post at Reddit.

I have been working on both Deep Learning and Numeric libraries recently. I was fascinated by matrix expressions and trying to calculate derivatives of matrix terms. I always wanted to have flexibility in deep learning. The libraries that can give you all opportunities with less complexity. I worked hard for two-three weeks to build a deep learning and a numeric library. When I needed a high optimized calculation, I coded it in numeric library and used it in deep learning library. Enough background!

Before building whole library, I'd like to get your ideas and opinions about how it is and it should be. I'm kinda scared to do things before consulting people. So, I am asking you how I should design the library. I will give you some code snippets to let you know what I built.

&amp;#x200B;

Manually assigning weights to a variable:

https://i.redd.it/9e4qjo86l9j31.png

Creating a custom Layer manually (not coded in library, it is temporary code)

https://i.redd.it/118hj0r6l9j31.png

Creating a XOR network (with 3 hidden layers)

https://i.redd.it/qyobbe87l9j31.png

For example we can use loss functions above. new Power(new Minus(model, y), 2); this code means squared error. I can make quick methods for loss functions like squared error etc. For now I don't wanna do over commit before deciding for what's best.

Hyperparameters (Global, not model dependent):

https://i.redd.it/0trsbos9l9j31.png

Training a model:

https://i.redd.it/8tvzur2al9j31.png

I think this is a retty code that no one should be scared of. Training is so easy. Dot minimize! that's all!

I can get rid of 'new' words when creating a layer or terms. (new power new minus etc).

I tested the code on MNIST data. It works. However CNN layers are not implemented. So, generalization of the model is not good as it is when used cnn ofc. But it works :)

How should I go on? Any designing ideas?

I hope I will bring dynamic dimensions for layers.

soon I will publish the library at My [Github Repo](https://github.com/faruknane)",0,1,False,self,,,,,
313,deeplearning,t5_2t5eh,2019-8-29,2019,8,29,9,cwtayb,self.deeplearning,"""Many Sets of Model Parameters Fit the Data Well""",https://www.reddit.com/r/deeplearning/comments/cwtayb/many_sets_of_model_parameters_fit_the_data_well/,arjundupa,1567038100,"I was reading through Andrew Ng's newest release of The Batch, where a sentence of his caught my attention:

&gt;If the training data set is small and many sets of model parameters fit the data well, for instance, the network may not realize this explicitly, leading to overly confident predictions.

I started wondering the following: if multiple models are trained on a relatively small dataset and all models (initialized to random weights) perform well but have widely varying weights, can the the models be combined in any way for an overall performance gain? Has this been explored?",3,9,False,self,,,,,
314,deeplearning,t5_2t5eh,2019-8-29,2019,8,29,11,cwur7o,self.deeplearning,Using PyTorch C++ and OpenCV (C++) in Jupyter Notebook using Xeus-Cling?,https://www.reddit.com/r/deeplearning/comments/cwur7o/using_pytorch_c_and_opencv_c_in_jupyter_notebook/,Kushashwa,1567045673,"Hi Everyone!

As some would know, I had started writing blogs on using PyTorch C++ API. Another blog in the series on **Setting up Jupyter Notebook (Xeus Cling) for Libtorch and OpenCV Libraries** is out. 

Link to the blog:  [https://krshrimali.github.io/Setting-Up-Xeus-Cling-Libtorch-OpenCV/](https://krshrimali.github.io/Setting-Up-Xeus-Cling-Libtorch-OpenCV/) 

Repository:  [https://github.com/krshrimali/Transfer-Learning-Dogs-Cats-Libtorch](https://github.com/krshrimali/Transfer-Learning-Dogs-Cats-Libtorch) 

[Blog 07 in the Series! Check more blogs on: https:\/\/krshrimali.github.io](https://i.redd.it/wmxoz71qtaj31.jpg)

Please share your feedback in the comments below. 

Thanks!",2,20,False,self,,,,,
315,deeplearning,t5_2t5eh,2019-8-29,2019,8,29,12,cwvb6i,self.deeplearning,Pruning,https://www.reddit.com/r/deeplearning/comments/cwvb6i/pruning/,arjundupa,1567048758,"What are some ways to know that pruning might be possible on your architecture (given your results, train/val loss curve, etc.)? Is there any literature out there that tries to answer this question?",0,1,False,self,,,,,
316,deeplearning,t5_2t5eh,2019-8-29,2019,8,29,16,cwxc83,towardsdatascience.com,"Its a No Brainer: An Introduction to Neural Networks (A gentle introduction to neural networks, now with zombies.)",https://www.reddit.com/r/deeplearning/comments/cwxc83/its_a_no_brainer_an_introduction_to_neural/,bugggster,1567062179,,0,3,False,default,,,,,
317,deeplearning,t5_2t5eh,2019-8-29,2019,8,29,16,cwxhlx,medium.com,How AI and Chatbots are Enriching Mobile Apps,https://www.reddit.com/r/deeplearning/comments/cwxhlx/how_ai_and_chatbots_are_enriching_mobile_apps/,MachineLearning001,1567063234,,2,3,False,default,,,,,
318,deeplearning,t5_2t5eh,2019-8-29,2019,8,29,17,cwy31u,self.deeplearning,Mask RCNN,https://www.reddit.com/r/deeplearning/comments/cwy31u/mask_rcnn/,wanabe_sarkaribabu,1567067801,"I'm trying to run a demo for object detection program by following a video given on YouTube . However I'm not able to run my CMD commands as they're depicted in video. Can someone suggest me some other video for same ?

Link of the video that I'm watching:

https://youtu.be/2TikTv6PWDw",1,0,False,self,,,,,
319,deeplearning,t5_2t5eh,2019-8-30,2019,8,30,0,cx2g32,1drv.ms,How would you prefer using a Deep Learning Library? Let's build one together!,https://www.reddit.com/r/deeplearning/comments/cx2g32/how_would_you_prefer_using_a_deep_learning/,akifnane,1567092544,,6,0,False,default,,,,,
320,deeplearning,t5_2t5eh,2019-8-30,2019,8,30,1,cx3hos,codeingschool.com,Best 4 Ways to Handle Missing Values in Pandas in Machine Learning,https://www.reddit.com/r/deeplearning/comments/cx3hos/best_4_ways_to_handle_missing_values_in_pandas_in/,subhamroy021,1567097331,,0,0,False,default,,,,,
321,deeplearning,t5_2t5eh,2019-8-30,2019,8,30,5,cx6hx4,self.deeplearning,Foundations of Neuroevolution - The CoDeepNEAT algorithm explained!,https://www.reddit.com/r/deeplearning/comments/cx6hx4/foundations_of_neuroevolution_the_codeepneat/,HenryAILabs,1567110906,[https://youtu.be/XvCbgwhMVu4](https://youtu.be/XvCbgwhMVu4),0,8,False,self,,,,,
322,deeplearning,t5_2t5eh,2019-8-30,2019,8,30,7,cx7rub,self.deeplearning,Building projects in order to get an internship,https://www.reddit.com/r/deeplearning/comments/cx7rub/building_projects_in_order_to_get_an_internship/,Krokodeale,1567116579,"Hi guys, 

I'll start my last year in my master's degree and I've got an internship to do for 6 months in 2020. This year is spe AI and I've already done some basic projects in DP. However, for my internship, I wanna be ambitious and try to look for some goods labs in order to get a PhD after.

But I don't know really what kind of projects that I can do to present my lvl in CS. I know it's important to have a good Github profile, but what do people expect from a student at my level ? Any idea from where to start ? I've got the feeling that doing things that have already been done isn't really worth it.

Thank you for you time",1,0,False,self,,,,,
323,deeplearning,t5_2t5eh,2019-8-30,2019,8,30,8,cx8mwp,self.deeplearning,Good book for neural network starter,https://www.reddit.com/r/deeplearning/comments/cx8mwp/good_book_for_neural_network_starter/,skyquek,1567120685,I am looking for free books that can help me understand the concept of neural network and deep learning. Best is come with some python example. I have some understanding on Machine Learning concept.,3,0,False,self,,,,,
324,deeplearning,t5_2t5eh,2019-8-30,2019,8,30,10,cxa1r3,self.deeplearning,How to combine multiple dataset that has different focuses,https://www.reddit.com/r/deeplearning/comments/cxa1r3/how_to_combine_multiple_dataset_that_has/,PotentialAnybody,1567128020,"I am currently training an object detection model for traffic obstacle detection. 

While I am thinking of combining different dataset to make the training more robust, I found that, even though some dataset has the class I am interested in, it doesn't always label the other class that I am also training for.

For example, Tsinghua cyclist dataset labels a large number of cyclists, but it doesn't label any cars or pedestrians or traffic light.  

So my question is, how can I combine different dataset (e.g. coco + bdd100k + Tsinghua cyclist), and tell the training that I am only interested in the class it labelled. In other word, how I can tell my network during training that, when you predict a car in the Tsinghua cyclist dataset, don't bother if the ground truth doesn't label a car there, so don't update your weight during the back prop. 

If anyone can share their trick combining dataset, I would really appreciate it.

Thanks in advance",14,10,False,self,,,,,
325,deeplearning,t5_2t5eh,2019-8-30,2019,8,30,11,cxaph7,self.deeplearning,GTX 1650 laptop or Google colab?,https://www.reddit.com/r/deeplearning/comments/cxaph7/gtx_1650_laptop_or_google_colab/,wade_wilson2120,1567131580,,13,11,False,self,,,,,
326,deeplearning,t5_2t5eh,2019-8-30,2019,8,30,12,cxbovi,self.deeplearning,few shot face translation GAN: Face swapping video from a single image without training for any face,https://www.reddit.com/r/deeplearning/comments/cxbovi/few_shot_face_translation_gan_face_swapping_video/,PuzzledProgrammer3,1567137222,"Generative adversarial networks integrating modules from FUNIT and SPADE for face-swapping

github link: [https://github.com/shaoanlu/fewshot-face-translation-GAN](https://github.com/shaoanlu/fewshot-face-translation-GAN)

elon musk and taylor swift demo video

![video](9hve1gfydij31)",0,30,False,self,,,,,
327,deeplearning,t5_2t5eh,2019-8-30,2019,8,30,15,cxd3rw,self.deeplearning,How to determine queries are context related,https://www.reddit.com/r/deeplearning/comments/cxd3rw/how_to_determine_queries_are_context_related/,CharlesLiuChina,1567146434,[removed],0,1,False,self,,,,,
328,deeplearning,t5_2t5eh,2019-8-30,2019,8,30,18,cxeri9,self.deeplearning,Intuition behind probability theory in image data,https://www.reddit.com/r/deeplearning/comments/cxeri9/intuition_behind_probability_theory_in_image_data/,PyWarrior,1567158950,"I am not able to relate the concepts of probability theory to image theory like 
1. What is the probability distribution of Image data
2. What is fitting a gaussian to an image data and what is it's practicality?

There are many more concepts. I think there is a huge gap between Neural Networks and Probability theory.

Can anyone refer me some good resources including videos or blogs or books which can give me detailed knowledge and complete understanding about probability theory in case of image dataset and help me bridge the gap between Neural Networks and Probability theory.

Thanks in advance",0,1,False,self,,,,,
329,deeplearning,t5_2t5eh,2019-8-30,2019,8,30,20,cxfvw6,medium.com,Strengthening Cybersecurity with Artificial Intelligence,https://www.reddit.com/r/deeplearning/comments/cxfvw6/strengthening_cybersecurity_with_artificial/,MachineLearning001,1567166169,,0,0,False,default,,,,,
330,deeplearning,t5_2t5eh,2019-8-31,2019,8,31,5,cxm54p,self.deeplearning,Is it generally better to look for more cores or more memory when considering GPU,https://www.reddit.com/r/deeplearning/comments/cxm54p/is_it_generally_better_to_look_for_more_cores_or/,dsync1,1567195504,"Basically, should I go with a 2x Titan RTX setup, or a 4x 2080 TI setup in building a rig for mostly NLP experimentation?",9,14,False,self,,,,,
331,deeplearning,t5_2t5eh,2019-8-31,2019,8,31,7,cxnwk9,expoundai.wordpress.com,Transfer Learning for Segmentation Using DeepLabv3 in PyTorch,https://www.reddit.com/r/deeplearning/comments/cxnwk9/transfer_learning_for_segmentation_using/,msminhas93,1567203996,,0,6,False,default,,,,,
332,deeplearning,t5_2t5eh,2019-8-31,2019,8,31,8,cxos4u,youtube.com,Meu Depoimento sobre...,https://www.reddit.com/r/deeplearning/comments/cxos4u/meu_depoimento_sobre/,guilherme_onassis,1567208416,,0,1,False,image,,,,,
333,deeplearning,t5_2t5eh,2019-8-31,2019,8,31,13,cxrgkk,self.deeplearning,When training Bert for multitask learning should be provide the Bert output to a LSTM layer?,https://www.reddit.com/r/deeplearning/comments/cxrgkk/when_training_bert_for_multitask_learning_should/,darkangel404,1567224198,Bert to LSTM ... Then the output of the LSTM is given to the three output layers and the second output layer is dependent on the first and third is dependant on first and second.,4,0,False,self,,,,,
334,deeplearning,t5_2t5eh,2019-8-31,2019,8,31,13,cxrm0o,self.deeplearning,"For a AI startup, whats the basic workstation should we have?",https://www.reddit.com/r/deeplearning/comments/cxrm0o/for_a_ai_startup_whats_the_basic_workstation/,stevevaius,1567225199,We decided to get in business of offering ML and DL solutions for Banking (fraud detection) and computer vision ( obj detection-recognition). But we are in short of cash (approx 3-4000 usd we have for workstation) Any offer for our business startup workstation? What should we consider before buy it? what models offer all-in solutions? price/performance focused,29,5,False,self,,,,,
