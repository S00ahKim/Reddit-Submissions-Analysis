,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,deeplearning,t5_2t5eh,2016-6-1,2016,6,1,20,4m0vkn,re-work.co,"Deep Listening: the Neural Network Learning to Hear in a Crowd - A Q&amp;A with John Hershey, Principal Scientist of Mitsubishi Electric Research Lab",https://www.reddit.com/r/deeplearning/comments/4m0vkn/deep_listening_the_neural_network_learning_to/,reworksophie,1464782231,,0,1,False,default,,,,,
1,deeplearning,t5_2t5eh,2016-6-5,2016,6,5,16,4mmgdh,self.deeplearning,CS algorithms VS DeepLearning algorithms,https://www.reddit.com/r/deeplearning/comments/4mmgdh/cs_algorithms_vs_deeplearning_algorithms/,whoisthriller,1465112779,"From my understanding, Machine Learning's algorithms such as SVM, k-means,Random forest are more mathematical and statistical algorithms, while CS's algorithms such as Binary Search Trees, Red-Black trees, Hash table are traditional CS algorithms which is a total different thing to ML's algorithms. Also, CS programming is object orientied programming using java, c++, while ML uses script languages such as R, SAS, Python. So why many people say it is better to get a CS degree rather than a math.stat degree to get into DL/ML field?",5,5,False,self,,,,,
2,deeplearning,t5_2t5eh,2016-6-7,2016,6,7,2,4mu33n,somatic.io,Ending busy days with more AI/Deep learning news options,https://www.reddit.com/r/deeplearning/comments/4mu33n/ending_busy_days_with_more_aideep_learning_news/,MachineLearner85,1465233564,,0,1,False,default,,,,,
3,deeplearning,t5_2t5eh,2016-6-7,2016,6,7,15,4mxnm6,self.deeplearning,"Wrote my first NN, some questions",https://www.reddit.com/r/deeplearning/comments/4mxnm6/wrote_my_first_nn_some_questions/,what_a_n00b,1465279869,"Hi there, please excuse me for being dumb:

I wrote my first neural network and it is doing well after 1000 iterations of say....  XOR or another logical binary function.  So after showing it XOR 1000 times (either 1 ^ 1 = 0, 1 ^ 0 = 1, 0 ^ 1 = 1 and 0 ^ 0 = 0).  It has 2 inputs, 1 hidden layer with 4 nodes, and 1 output.

I tried to teach it modulo.  Like a%b=c where a=1-&gt;100 and b=1-&gt;15.  I taught it 10000 iterations of this, random inputs, back propagating the expected result - it doesn't work at all.  I thought, OK, maybe it needs more example - tried 100000 iterations.  Still crap.

Then I thought...  Maybe I need more layers?  More nodes?  I tried 2 inputs, 3 layers of 10 hidden, and 1 output - still shit.  

So a couple questions...

1. How do I find out what NN topography will work best for a given problem?

2. How many examples do you need to give (a rule of thumb?) in relation to the input/output combination size?

3. If you teach the neural net to do modulo between 1-100, but you never teach it to do higher numbers, will it be inaccurate in that higher range?  Do you need to teach a NN the LIMITS of the problem space in order to interpolate results inside of this range?


Thanks,
and sorry for being such a n00b
-what_a_n00b",10,3,False,self,,,,,
4,deeplearning,t5_2t5eh,2016-6-7,2016,6,7,20,4myknt,re-work.co,Applying Deep Learning to Biomarker Development &amp; Drug Discovery,https://www.reddit.com/r/deeplearning/comments/4myknt/applying_deep_learning_to_biomarker_development/,reworksophie,1465298904,,0,1,False,default,,,,,
5,deeplearning,t5_2t5eh,2016-6-9,2016,6,9,9,4n87m2,self.deeplearning,GTX 1080 vs Titan X for deep learning,https://www.reddit.com/r/deeplearning/comments/4n87m2/gtx_1080_vs_titan_x_for_deep_learning/,DiegoAlonsoCortez,1465430787,"The 1080 has ~1.4x the base clock speed of the Titan (1600 vs 1000), ~1.3x the TFLOPS (9 vs 7  nevermind that writing a kernel that performs within 10% of the limit is a software-engineering feat), ~0.8x the CUDA cores (2560 vs 3072), ~1x the memory bandwith (320 vs 336), and ~0.7x the memory (8GB vs 12GB).

I wonder two things. 1) Should one consider upgrading if one already has a Titan X? 2) What if one doesn't own either, and is considering choosing one?

Side note. Currently there's some really cool [SGEMM](https://github.com/NervanaSystems/maxas) and [convolution kernels](https://github.com/eBay/maxDNN) that perform within 4% of the theoretical peak FLOPS, hand-coded for Maxwell. I also wonder how easy it'll be to adapt them for Pascal.",6,1,False,self,,,,,
6,deeplearning,t5_2t5eh,2016-6-9,2016,6,9,16,4n9tg8,self.deeplearning,Dealing with varying amounts of inputs?,https://www.reddit.com/r/deeplearning/comments/4n9tg8/dealing_with_varying_amounts_of_inputs/,[deleted],1465458676,[deleted],0,1,False,default,,,,,
7,deeplearning,t5_2t5eh,2016-6-10,2016,6,10,4,4ncdxn,mldb.ai,MLDB: the open-source Machine Learning Database with TensorFlow support,https://www.reddit.com/r/deeplearning/comments/4ncdxn/mldb_the_opensource_machine_learning_database/,ddcarnage,1465499487,,0,3,False,default,,,,,
8,deeplearning,t5_2t5eh,2016-6-11,2016,6,11,7,4niume,ebay.fr,NVIDIA Jetson TX1 for Deep learning users,https://www.reddit.com/r/deeplearning/comments/4niume/nvidia_jetson_tx1_for_deep_learning_users/,[deleted],1465598306,[deleted],0,0,False,default,,,,,
9,deeplearning,t5_2t5eh,2016-6-12,2016,6,12,22,4nqamx,self.deeplearning,Deeplearnig subreddit,https://www.reddit.com/r/deeplearning/comments/4nqamx/deeplearnig_subreddit/,[deleted],1465739285,[deleted],0,1,False,default,,,,,
10,deeplearning,t5_2t5eh,2016-6-13,2016,6,13,11,4ntnmr,self.deeplearning,Essential software/programming skills for effective Deep Learning with TensorFlow/etc?,https://www.reddit.com/r/deeplearning/comments/4ntnmr/essential_softwareprogramming_skills_for/,dclaz,1465785791,"Hi guys, I've seen lots of talks/slides/videos about all the wondrous things Deep Learning can do, and I'd like to equip myself with the skills required to build networks to perform various tasks.

I've recently graduated with a PhD in Applied Statistics and am familiar with most modern statistical and machine learning concepts, including very basic neural networks. 

Unfortunately, the only programming language I am adept in is R, and operating system, Windows. My main questions are:

* Do I go ahead and install and become familiar with Linux ASAP?
* Do I start learning Python? What other languages are essential or useful?
* Besides the maths, what other hurdles are there to being able build, train and operationalise deep learning models from scratch for someone in my position?

Many thanks.
",3,5,False,self,,,,,
11,deeplearning,t5_2t5eh,2016-6-13,2016,6,13,23,4nvxo3,jeremykarnowski.wordpress.com,INPUTTING IMAGE DATA INTO TENSORFLOW FOR UNSUPERVISED DEEP LEARNING,https://www.reddit.com/r/deeplearning/comments/4nvxo3/inputting_image_data_into_tensorflow_for/,[deleted],1465829052,[deleted],0,1,False,default,,,,,
12,deeplearning,t5_2t5eh,2016-6-14,2016,6,14,0,4nw04w,jeremykarnowski.wordpress.com,Inputting Image Data into TensorFlow for Unsupervised Deep Learning,https://www.reddit.com/r/deeplearning/comments/4nw04w/inputting_image_data_into_tensorflow_for/,mwakanosya,1465830003,,0,1,False,http://b.thumbs.redditmedia.com/v4KLB8vmufRfnGMQWDINnxcbH6uixbs95-SpZs84uWI.jpg,,,,,
13,deeplearning,t5_2t5eh,2016-6-14,2016,6,14,1,4nwdqz,self.deeplearning,Sentiment classification on node level for RNTN and SVN,https://www.reddit.com/r/deeplearning/comments/4nwdqz/sentiment_classification_on_node_level_for_rntn/,Faceman1208,1465834793,"Hi,

I have question regarding this paper (http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf). In the paper there are some results on page 7 in Table 1. There are results for **All** and **Root**. For the results **All** they use the results of all nodes of the tree. For **Root** they use the results on sentence level. I'm aware of how they calculate the results for the RNTN. But how do they calculate the All results for SVN?

Greetings and thanks in advance",0,1,False,self,,,,,
14,deeplearning,t5_2t5eh,2016-6-14,2016,6,14,1,4nwfl4,youtu.be,Build an AI Reader w/ Parsey Mcparseface,https://www.reddit.com/r/deeplearning/comments/4nwfl4/build_an_ai_reader_w_parsey_mcparseface/,llSourcell,1465835387,,0,5,False,http://b.thumbs.redditmedia.com/nS8SCflxLWGiBE6kLqi4kjVKMsY4YqE9wJpvQz16oQA.jpg,,,,,
15,deeplearning,t5_2t5eh,2016-6-14,2016,6,14,21,4o17lq,self.deeplearning,One more time please: what exactly was the breakthrough that led to sudden success with neural networks?,https://www.reddit.com/r/deeplearning/comments/4o17lq/one_more_time_please_what_exactly_was_the/,knnjns,1465908241,"The idea of neural networks has been around for decades.  What accounts for their sudden success in the last few years?

---

I've come across three general answers to this question.  The somewhat banal first one boils down to the availability of much larger collections of the kinds of data that neural networks are most effective for.

The second slightly less banal answer: we now have the processing power to train much deeper neural networks.

So the first two answers boil down to sheer scale, in one way or another.

The third, and to me most interesting, answer is not about scale; rather, it claims that the recent success is due to fundamentally better algorithms for training neural networks.  (To be more precise: here I'm referring to algorithms that, had they been known, say, 30 years ago, and applied to the datasets available then, running on the available hardware, they would have shown the same superior performance that they show today.)

Which is it?  It should be possible to the new ""fundamentally better algorithms"" on the old datasets.  Conversely, for the earlier algorithms, if their performance is up to the task, one could run them on the new large datasets.  (If their performance is such that they could not be applied to datasets of the size we have today, then this would argue in favor of ""better algorithms"".)

Has anyone tried to sort this one out?

Also, regarding the ""better algorithms"" answer: what exactly are the breakthrough algorithms?

---

I apologize for this question.  I'm sure something like it has been, and answered, before, but I have not yet found a satisfying answer.
",5,5,False,self,,,,,
16,deeplearning,t5_2t5eh,2016-6-14,2016,6,14,22,4o1fee,self.deeplearning,unsupervised clustering of points in R^13,https://www.reddit.com/r/deeplearning/comments/4o1fee/unsupervised_clustering_of_points_in_r13/,knnjns,1465911566,"I have a dataset consisting, basically, of ~10^8 points in R^13 (more precisely, each ""point"", aka ""event"", is a vector of 13 floating point numbers).  I'm looking for ways to cluster the 10^8 points in an unsupervised way.


Are deep learning methods suitable for this clustering problem?  If so, what keywords should I search for to learn more?

---

The 10^8 points are measurements performed on individual cells from tissue samples.  The 13 measurements per cell correlate positively with the presence of cell-surface markers that identify the cell as belonging to one of a handful of morphologically distinguishable ""families"" (macrophages, T-cells, B-cells, etc.).  My hope is that the ""signatures"" of the clusters we obtain (or at least most of them) will correspond to the expected signatures for the various families of cells.  (By a cluster's ""signature"" I mean, roughly, the 13-vector for a ""representative point"" of the cluster.)

---

In case it matters, the computational capacity I can count on is a ~2K-node 8-core/node (non-GPU) computer cluster.  I can apply for more computational resources through various channels, but I can't count on it.
",1,1,False,self,,,,,
17,deeplearning,t5_2t5eh,2016-6-15,2016,6,15,0,4o217c,medium.com,Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks,https://www.reddit.com/r/deeplearning/comments/4o217c/machine_learning_is_fun_part_3_deep_learning_and/,alpyhp,1465919326,,0,7,False,http://a.thumbs.redditmedia.com/5qXGr40rZ1e3vrcgL3lZn-6g7moR-2N3-xGGT4dxoz0.jpg,,,,,
18,deeplearning,t5_2t5eh,2016-6-17,2016,6,17,1,4oe37j,self.deeplearning,LSTM vs. Language Theory Automaton,https://www.reddit.com/r/deeplearning/comments/4oe37j/lstm_vs_language_theory_automaton/,mphuget,1466093183,"Hello everyone, 

Question from a noob: if I understand well, training a LSTM for text generation corresponds to digesting text so as to have a neural network that could predict what could be the next character based on the weights

Now, my immediate thinking about such text generation would be to use an automaton where each node is a letter and there are at most 26 edges corresponding to the letters

Then, I could generate text.

So my question is: why is it preferable to use LSTM?

Thanks for your opinion

mph",1,2,False,self,,,,,
19,deeplearning,t5_2t5eh,2016-6-17,2016,6,17,12,4ohbtq,github.com,"A topic wise list of Deep Learning tutorials, articles and other resources",https://www.reddit.com/r/deeplearning/comments/4ohbtq/a_topic_wise_list_of_deep_learning_tutorials/,hX3S,1466134148,,0,4,False,http://b.thumbs.redditmedia.com/Jjhj2RqyWIx-Qg4mM-lAJZ6FCYT5z1Z6UbA32vc7D4c.jpg,,,,,
20,deeplearning,t5_2t5eh,2016-6-17,2016,6,17,12,4ohdge,self.deeplearning,"Computers to execute neural nets, therefore neural nets are restricted to only solving the types of problems outlined by the curch-turing thesis. Are humans more?",https://www.reddit.com/r/deeplearning/comments/4ohdge/computers_to_execute_neural_nets_therefore_neural/,lildeam0n,1466134847,"Human brains are not Artificial Neural Nets for two reasons:
1) They are not executed on a computer (I.E, a turing machine)
2) They are not artificial

Therefore, humans may be able to solve problems outside of the scope of ""pseudocode"", as in, the set of computations outlined in the church turing thesis. 

What if ""intelligence"" and ""sentience"" are things which can't be computed by a turing machine. Maybe we need a different model of computing to make a truly intelligent artificial system.",1,0,False,self,,,,,
21,deeplearning,t5_2t5eh,2016-6-18,2016,6,18,0,4ojtd6,docs.mldb.ai,Image recognition tutorial with a deep convnet using Tensorflow on MLDB,https://www.reddit.com/r/deeplearning/comments/4ojtd6/image_recognition_tutorial_with_a_deep_convnet/,ddcarnage,1466178106,,0,0,False,default,,,,,
22,deeplearning,t5_2t5eh,2016-6-18,2016,6,18,7,4olpns,self.deeplearning,"Noob question, Q/A and Neural Net",https://www.reddit.com/r/deeplearning/comments/4olpns/noob_question_qa_and_neural_net/,afripress,1466201723,"Hey,
Is it possible to train a neural net to ask questions based on certain inputs and in context? Are the open source tools which could help do this. i.e i send the text ""What is computer science"", provides me with information on computer science but follow up with a question such as Do you know when the first computer was built? Is deep learning the approach to solve this kind of problem?",1,2,False,self,,,,,
23,deeplearning,t5_2t5eh,2016-6-20,2016,6,20,19,4oy1ef,devblogs.nvidia.com,Production Deep Learning with NVIDIA GPU Inference Engine,https://www.reddit.com/r/deeplearning/comments/4oy1ef/production_deep_learning_with_nvidia_gpu/,harrism,1466417533,,1,3,False,http://a.thumbs.redditmedia.com/rRDRAmukz8n1HrEYfF0_LZNUbUlCCSVtrPrgPkVvq08.jpg,,,,,
24,deeplearning,t5_2t5eh,2016-6-22,2016,6,22,14,4p929u,datasciencecentral.com,Video: Quadcopter Navigation in the Forest using Deep Neural Networks,https://www.reddit.com/r/deeplearning/comments/4p929u/video_quadcopter_navigation_in_the_forest_using/,abdsc,1466572851,,0,1,False,default,,,,,
25,deeplearning,t5_2t5eh,2016-6-23,2016,6,23,14,4pf4kx,self.deeplearning,Can Deep Q-Learning really scale to problems with continuous action spaces?,https://www.reddit.com/r/deeplearning/comments/4pf4kx/can_deep_qlearning_really_scale_to_problems_with/,juniorrojas,1466659325,"I'm getting familiar with various reinforcement learning algorithms and, having implemented the standard version of Q-learning in a grid world, it seems to me that even if I approximate the Q-function with a deep net, I'm still going to be very limited in that it's only going to work well for problems with simple discrete actions, like in classic Atari games.

I'm interested in problems with continuous action spaces like robotics and character animation, in which the possible actions are not just ""go up"" or ""go down"", but more like ""rotate joint A 3 degrees + rotate joint B 10 degrees + rotate joint C 5 degrees, simultaneously"". I guess there are some tricks one can use to make Deep Q-learning work better for continuous action spaces, but is it really worth taking the time to learn them considering I'm not interested at all in problems with discrete actions? Am I better off going straight into other methods like policy gradient?",2,6,False,self,,,,,
26,deeplearning,t5_2t5eh,2016-6-23,2016,6,23,19,4pfzdp,arxiv.org,Deep Image Homography Estimation,https://www.reddit.com/r/deeplearning/comments/4pfzdp/deep_image_homography_estimation/,jai-chaudhary,1466676159,,0,3,False,default,,,,,
27,deeplearning,t5_2t5eh,2016-6-24,2016,6,24,4,4pinly,pcworld.com,Nvidia's new Pascal GPU to supercharge deep learning. This is some serious processing power!,https://www.reddit.com/r/deeplearning/comments/4pinly/nvidias_new_pascal_gpu_to_supercharge_deep/,[deleted],1466711098,[deleted],0,1,False,default,,,,,
28,deeplearning,t5_2t5eh,2016-6-24,2016,6,24,7,4pjdww,somatic.io,Auto-enhanced city-scape,https://www.reddit.com/r/deeplearning/comments/4pjdww/autoenhanced_cityscape/,DemBones85,1466720076,,0,2,False,http://a.thumbs.redditmedia.com/PjPvNKFVlpLd0apbJDBAF0fT0JDyW_zSbQ5KmEQ9WZ0.jpg,,,,,
29,deeplearning,t5_2t5eh,2016-6-25,2016,6,25,2,4po1l3,somatic.io,ImageNet: The Original Machine Learning Database - somatic blog,https://www.reddit.com/r/deeplearning/comments/4po1l3/imagenet_the_original_machine_learning_database/,[deleted],1466788757,[deleted],0,2,False,default,,,,,
30,deeplearning,t5_2t5eh,2016-6-27,2016,6,27,22,4q38gv,lstm.seas.harvard.edu,Neat visualization tool for recurrent neural networks by the Harvard NLP group,https://www.reddit.com/r/deeplearning/comments/4q38gv/neat_visualization_tool_for_recurrent_neural/,[deleted],1467032941,[deleted],0,1,False,default,,,,,
31,deeplearning,t5_2t5eh,2016-6-28,2016,6,28,1,4q47g0,lstm.seas.harvard.edu,LSTMVis: A tool to visualize recurrent neural network by Harvard NLP,https://www.reddit.com/r/deeplearning/comments/4q47g0/lstmvis_a_tool_to_visualize_recurrent_neural/,Valedra,1467044753,,0,7,False,default,,,,,
32,deeplearning,t5_2t5eh,2016-6-29,2016,6,29,10,4qd06k,devblogs.nvidia.com,NVIDIA Docker: Deep Learning Framework Deployment Made Easy,https://www.reddit.com/r/deeplearning/comments/4qd06k/nvidia_docker_deep_learning_framework_deployment/,harrism,1467163768,,0,6,False,http://b.thumbs.redditmedia.com/Wo9m0nbc_Cantlsh42HaUa0WaZVTBFEgJ8G_aE-9B3A.jpg,,,,,
33,deeplearning,t5_2t5eh,2016-6-30,2016,6,30,12,4qjjhv,datasciencecentral.com,"10 Great Data Science, Machine / Deep Learning, IoT, AI, Stats, Python and R Resources",https://www.reddit.com/r/deeplearning/comments/4qjjhv/10_great_data_science_machine_deep_learning_iot/,abdsc,1467255883,,0,1,False,default,,,,,
34,deeplearning,t5_2t5eh,2016-6-30,2016,6,30,13,4qjtkk,self.deeplearning,List of pre-trained networks?,https://www.reddit.com/r/deeplearning/comments/4qjtkk/list_of_pretrained_networks/,gregw134,1467260156,"Hi,

Has anybody compiled a list of pre-trained neural networks? 

Thanks!",2,6,False,self,,,,,
35,deeplearning,t5_2t5eh,2016-6-30,2016,6,30,18,4qkt5o,self.deeplearning,Http://somatic.io/models/list,https://www.reddit.com/r/deeplearning/comments/4qkt5o/httpsomaticiomodelslist/,[deleted],1467278963,[deleted],1,1,False,default,,,,,
